<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 158]
- [cs.CL](#cs.CL) [Total: 80]
- [cs.CR](#cs.CR) [Total: 22]
- [cs.AI](#cs.AI) [Total: 78]
- [cs.SE](#cs.SE) [Total: 30]
- [cs.MA](#cs.MA) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Scalable spatial point process models for forensic footwear analysis](https://arxiv.org/abs/2602.07006)
*Alokesh Manna,Neil Spencer,Dipak K. Dey*

Main category: cs.CV

TL;DR: 开发了一个分层贝叶斯模型来量化鞋印中"偶然特征"的稀有性，通过潜在高斯模型和空间变化系数提高了法医鞋印分析的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 犯罪现场的鞋印证据在法医调查中至关重要，但仅匹配鞋子的品牌和型号通常不够，因为同款鞋子可能生产数千双。需要量化鞋底磨损形成的"偶然特征"（如划痕、切口）的稀有性，以准确评估证据强度。

Method: 开发了一个分层贝叶斯模型，采用潜在高斯模型框架，通过集成嵌套拉普拉斯近似实现高效推理，能够扩展到大型注释鞋印数据集。同时引入了空间变化系数来建模鞋底花纹图案与偶然特征位置之间的关系。

Result: 在保留数据上表现出优越性能，提高了鞋印分析的准确性和可靠性，相比现有方法有显著改进。

Conclusion: 提出的分层贝叶斯模型能够有效量化鞋印中偶然特征的稀有性，为法医鞋印分析提供了更准确和可靠的量化工具，有助于增强法医证据的强度评估。

Abstract: Shoe print evidence recovered from crime scenes plays a key role in forensic investigations. By examining shoe prints, investigators can determine details of the footwear worn by suspects. However, establishing that a suspect's shoes match the make and model of a crime scene print may not be sufficient. Typically, thousands of shoes of the same size, make, and model are manufactured, any of which could be responsible for the print. Accordingly, a popular approach used by investigators is to examine the print for signs of ``accidentals,'' i.e., cuts, scrapes, and other features that accumulate on shoe soles after purchase due to wear. While some patterns of accidentals are common on certain types of shoes, others are highly distinctive, potentially distinguishing the suspect's shoe from all others. Quantifying the rarity of a pattern is thus essential to accurately measuring the strength of forensic evidence. In this study, we address this task by developing a hierarchical Bayesian model. Our improvement over existing methods primarily stems from two advancements. First, we frame our approach in terms of a latent Gaussian model, thus enabling inference to be efficiently scaled to large collections of annotated shoe prints via integrated nested Laplace approximations. Second, we incorporate spatially varying coefficients to model the relationship between shoes' tread patterns and accidental locations. We demonstrate these improvements through superior performance on held-out data, which enhances accuracy and reliability in forensic shoe print analysis.

</details>


### [2] [Where Not to Learn: Prior-Aligned Training with Subset-based Attribution Constraints for Reliable Decision-Making](https://arxiv.org/abs/2602.07008)
*Ruoyu Chen,Shangquan Sun,Xiaoqing Guo,Sanyi Zhang,Kangwei Liu,Shiming Liu,Zhangcheng Wang,Qunli Zhang,Hua Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出基于归因的人类先验对齐方法，通过约束模型决策证据与人类先验区域的一致性，提高模型可靠性和决策合理性


<details>
  <summary>Details</summary>
Motivation: 传统监督学习仅提供类别标签，模型可能通过捷径相关性而非预期证据实现高准确率，需要将模型决策与人类先验证据对齐以提高可靠性

Method: 将人类先验编码为模型应依赖的输入区域（如边界框），使用高保真子集选择归因方法暴露训练中模型的决策证据，当归因区域偏离先验区域时惩罚对非先验证据的依赖

Result: 在图像分类和点击决策任务中，人类先验对齐方法在传统分类和自回归生成设置下均提高了任务准确率，同时增强了模型决策的合理性

Conclusion: 基于归因的人类先验对齐方法能有效约束模型依赖预期证据，提高模型可靠性和决策合理性，在多种任务设置中均有良好表现

Abstract: Reliable models should not only predict correctly, but also justify decisions with acceptable evidence. Yet conventional supervised learning typically provides only class-level labels, allowing models to achieve high accuracy through shortcut correlations rather than the intended evidence. Human priors can help constrain such behavior, but aligning models to these priors remains challenging because learned representations often diverge from human perception. To address this challenge, we propose an attribution-based human prior alignment method. We encode human priors as input regions that the model is expected to rely on (e.g., bounding boxes), and leverage a highly faithful subset-selection-based attribution approach to expose the model's decision evidence during training. When the attribution region deviates substantially from the prior regions, we penalize reliance on off-prior evidence, encouraging the model to shift its attribution toward the intended regions. This is achieved through a training objective that imposes attribution constraints induced by the human prior. We validate our method on both image classification and click decision tasks in MLLM-based GUI agent models. Across conventional classification and autoregressive generation settings, human prior alignment consistently improves task accuracy while also enhancing the model's decision reasonability.

</details>


### [3] [MAU-GPT: Enhancing Multi-type Industrial Anomaly Understanding via Anomaly-aware and Generalist Experts Adaptation](https://arxiv.org/abs/2602.07011)
*Zhuonan Wang,Zhenxuan Fan,Siwen Tan,Yu Zhong,Yuqian Yuan,Haoyuan Li,Hao Jiang,Wenqiao Zhang,Feifei Shao,Hongwei Wang,Jun Xiao*

Main category: cs.CV

TL;DR: 提出了MAU-Set工业异常理解数据集和MAU-GPT多模态大模型，通过AMoE-LoRA机制统一异常感知和通用专家适配，在工业异常检测任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业制造规模化发展需要自动化细粒度产品图像分析，但现有方法受限于数据集覆盖不足和模型泛化能力差，无法应对多样复杂的异常模式。

Method: 1) 构建MAU-Set多类型工业异常理解数据集，涵盖多个工业领域和分层任务结构；2) 提出MAU-GPT领域适配多模态大模型，采用新颖的AMoE-LoRA机制统一异常感知和通用专家适配。

Result: MAU-GPT在所有领域都持续优于先前最先进方法，展示了可扩展自动化工业检测的强大潜力。

Conclusion: MAU-Set数据集和MAU-GPT模型为解决工业异常理解中的数据集覆盖和模型泛化挑战提供了有效方案，推动了自动化工业检测的发展。

Abstract: As industrial manufacturing scales, automating fine-grained product image analysis has become critical for quality control. However, existing approaches are hindered by limited dataset coverage and poor model generalization across diverse and complex anomaly patterns. To address these challenges, we introduce MAU-Set, a comprehensive dataset for Multi-type industrial Anomaly Understanding. It spans multiple industrial domains and features a hierarchical task structure, ranging from binary classification to complex reasoning. Alongside this dataset, we establish a rigorous evaluation protocol to facilitate fair and comprehensive model assessment. Building upon this foundation, we further present MAU-GPT, a domain-adapted multimodal large model specifically designed for industrial anomaly understanding. It incorporates a novel AMoE-LoRA mechanism that unifies anomaly-aware and generalist experts adaptation, enhancing both understanding and reasoning across diverse defect classes. Extensive experiments show that MAU-GPT consistently outperforms prior state-of-the-art methods across all domains, demonstrating strong potential for scalable and automated industrial inspection.

</details>


### [4] [A General Model for Retinal Segmentation and Quantification](https://arxiv.org/abs/2602.07012)
*Zhonghua Wang,Lie Ju,Sijia Li,Wei Feng,Sijin Zhou,Ming Hu,Jianhao Xiong,Xiaoying Tang,Yifan Peng,Mingquan Lin,Yaodong Ding,Yong Zeng,Wenbin Wei,Li Dong,Zongyuan Ge*

Main category: cs.CV

TL;DR: RetSAM是一个通用的视网膜分割和量化框架，能够从眼底图像中分割多种解剖结构、表型模式和病变类型，并提取30多种标准化生物标志物，支持大规模眼科研究和系统性疾病关联分析。


<details>
  <summary>Details</summary>
Motivation: 视网膜成像快速、无创且广泛应用，为眼科和全身健康评估提供了可量化的结构和血管信号。然而，由于缺乏公共多标签数据集和统一的分割到量化流程，大规模分析仍然困难。

Method: RetSAM是一个通用的视网膜分割和量化框架，采用多阶段训练策略，使用私有和公共眼底数据，训练超过20万张眼底图像。支持三类任务：分割五种解剖结构、四种视网膜表型模式和20多种不同病变类型，并将分割结果转化为30多种标准化生物标志物。

Result: 在17个公共数据集上实现了优越的分割性能，平均DSC比先前最佳方法提高3.9个百分点，在具有挑战性的多任务基准上提升高达15个百分点。在不同人群、成像设备和临床环境中表现出良好的泛化能力。

Conclusion: RetSAM将眼底图像转化为标准化、可解释的定量表型，支持跨主要眼科疾病（包括糖尿病视网膜病变、年龄相关性黄斑变性、青光眼和病理性近视）的系统性关联分析，实现了大规模眼科研究和转化应用。

Abstract: Retinal imaging is fast, non-invasive, and widely available, offering quantifiable structural and vascular signals for ophthalmic and systemic health assessment. This accessibility creates an opportunity to study how quantitative retinal phenotypes relate to ocular and systemic diseases. However, such analyses remain difficult at scale due to the limited availability of public multi-label datasets and the lack of a unified segmentation-to-quantification pipeline. We present RetSAM, a general retinal segmentation and quantification framework for fundus imaging. It delivers robust multi-target segmentation and standardized biomarker extraction, supporting downstream ophthalmologic studies and oculomics correlation analyses. Trained on over 200,000 fundus images, RetSAM supports three task categories and segments five anatomical structures, four retinal phenotypic patterns, and more than 20 distinct lesion types. It converts these segmentation results into over 30 standardized biomarkers that capture structural morphology, vascular geometry, and degenerative changes. Trained with a multi-stage strategy using both private and public fundus data, RetSAM achieves superior segmentation performance on 17 public datasets. It improves on prior best methods by 3.9 percentage points in DSC on average, with up to 15 percentage points on challenging multi-task benchmarks, and generalizes well across diverse populations, imaging devices, and clinical settings. The resulting biomarkers enable systematic correlation analyses across major ophthalmic diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma, and pathologic myopia. Together, RetSAM transforms fundus images into standardized, interpretable quantitative phenotypes, enabling large-scale ophthalmic research and translation.

</details>


### [5] [Steering to Say No: Configurable Refusal via Activation Steering in Vision Language Models](https://arxiv.org/abs/2602.07013)
*Jiaxi Yang,Shicheng Liu,Yuchen Yang,Dongwon Lee*

Main category: cs.CV

TL;DR: CR-VLM提出了一种可配置的视觉语言模型拒绝机制，通过激活引导实现用户自适应的安全对齐，解决了现有拒绝策略"一刀切"的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的拒绝机制大多是"一刀切"的，无法适应不同用户需求和上下文约束，导致要么拒绝不足要么过度拒绝，需要更灵活可配置的拒绝策略。

Method: CR-VLM包含三个核心组件：1)通过教师强制机制提取可配置拒绝向量以增强拒绝信号；2)引入门控机制保护范围内查询的接受性，缓解过度拒绝；3)设计反事实视觉增强模块，使视觉表示与拒绝要求对齐。

Result: 在多个数据集和各种视觉语言模型上的综合实验表明，CR-VLM实现了有效、高效且鲁棒的可配置拒绝，为VLMs的用户自适应安全对齐提供了可扩展路径。

Conclusion: CR-VLM通过激活引导的可配置拒绝机制，解决了现有拒绝策略的局限性，为视觉语言模型提供了更灵活、用户自适应的安全对齐方法。

Abstract: With the rapid advancement of Vision Language Models (VLMs), refusal mechanisms have become a critical component for ensuring responsible and safe model behavior. However, existing refusal strategies are largely \textit{one-size-fits-all} and fail to adapt to diverse user needs and contextual constraints, leading to either under-refusal or over-refusal. In this work, we firstly explore the challenges mentioned above and develop \textbf{C}onfigurable \textbf{R}efusal in \textbf{VLM}s (\textbf{CR-VLM}), a robust and efficient approach for {\em configurable} refusal based on activation steering. CR-VLM consists of three integrated components: (1) extracting a configurable refusal vector via a teacher-forced mechanism to amplify the refusal signal; (2) introducing a gating mechanism that mitigates over-refusal by preserving acceptance for in-scope queries; and (3) designing a counterfactual vision enhancement module that aligns visual representations with refusal requirements. Comprehensive experiments across multiple datasets and various VLMs demonstrate that CR-VLM achieves effective, efficient, and robust configurable refusals, offering a scalable path toward user-adaptive safety alignment in VLMs.

</details>


### [6] [Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation](https://arxiv.org/abs/2602.07014)
*Qingyu Wu,Yuxuan Han,Haijun Li,Zhao Xu,Jianshan Zhao,Xu Jin,Longyue Wang,Weihua Luo*

Main category: cs.CV

TL;DR: Vectra是首个面向电商图像内机器翻译的无参考视觉质量评估框架，通过多维度质量指标、大规模数据集和4B参数MLLM模型，解决了现有方法在解释性和细粒度奖励信号方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图像内机器翻译研究主要关注机器翻译评估，而视觉渲染质量对用户参与度至关重要。当前基于参考的方法缺乏可解释性，模型即评判方法缺乏领域基础、细粒度的奖励信号，特别是在面对上下文密集的产品图像和多模态缺陷时。

Method: Vectra框架包含三个核心组件：1) Vectra Score - 将视觉质量分解为14个可解释维度的多维质量指标系统，采用空间感知的缺陷面积比量化减少标注歧义；2) Vectra Dataset - 通过多样性感知采样从110万真实产品图像构建的数据集，包括2K基准测试集、30K推理标注和3.5K专家标注偏好；3) Vectra Model - 4B参数的多模态大语言模型，能生成定量分数和诊断推理。

Result: 实验表明Vectra在人类排名相关性方面达到最先进水平，其模型在评分性能上超越了包括GPT-5和Gemini-3在内的领先MLLMs。

Conclusion: Vectra填补了电商图像内机器翻译视觉质量评估的空白，提供了首个无参考、MLLM驱动的评估框架，通过可解释的多维度指标、大规模数据集和高效模型，显著提升了视觉质量评估的准确性和实用性。

Abstract: In-Image Machine Translation (IIMT) powers cross-border e-commerce product listings; existing research focuses on machine translation evaluation, while visual rendering quality is critical for user engagement. When facing context-dense product imagery and multimodal defects, current reference-based methods (e.g., SSIM, FID) lack explainability, while model-as-judge approaches lack domain-grounded, fine-grained reward signals. To bridge this gap, we introduce Vectra, to the best of our knowledge, the first reference-free, MLLM-driven visual quality assessment framework for e-commerce IIMT. Vectra comprises three components: (1) Vectra Score, a multidimensional quality metric system that decomposes visual quality into 14 interpretable dimensions, with spatially-aware Defect Area Ratio (DAR) quantification to reduce annotation ambiguity; (2) Vectra Dataset, constructed from 1.1M real-world product images via diversity-aware sampling, comprising a 2K benchmark for system evaluation, 30K reasoning-based annotations for instruction tuning, and 3.5K expert-labeled preferences for alignment and evaluation; and (3) Vectra Model, a 4B-parameter MLLM that generates both quantitative scores and diagnostic reasoning. Experiments demonstrate that Vectra achieves state-of-the-art correlation with human rankings, and our model outperforms leading MLLMs, including GPT-5 and Gemini-3, in scoring performance. The dataset and model will be released upon acceptance.

</details>


### [7] [Robust and Real-Time Bangladeshi Currency Recognition: A Dual-Stream MobileNet and EfficientNet Approach](https://arxiv.org/abs/2602.07015)
*Subreena,Mohammad Amzad Hossain,Mirza Raquib,Saydul Akbar Murad,Farida Siddiqi Prity,Muhammad Hanif,Nick Rahimi*

Main category: cs.CV

TL;DR: 提出一种用于孟加拉国纸币识别的混合CNN架构，结合MobileNetV3-Large和EfficientNetB0进行特征提取，配合MLP分类器，在资源受限设备上实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 准确的货币识别对视障人士至关重要，他们依赖他人识别纸币，这使他们面临欺诈和剥削的风险。现有识别模型存在局限性，需要更鲁棒和高效的解决方案。

Method: 1) 构建新的孟加拉国纸币数据集，包含受控和真实场景；2) 整合四个额外数据集增强鲁棒性；3) 提出混合CNN架构，结合MobileNetV3-Large和EfficientNetB0进行特征提取；4) 使用多层感知机(MLP)分类器提高性能；5) 采用五折交叉验证和七种评估指标；6) 集成LIME和SHAP等可解释AI方法。

Result: 模型在受控数据集上达到97.95%准确率，复杂背景上达到92.84%准确率，所有数据集组合上达到94.98%准确率。通过七种评估指标和可解释性分析验证了模型性能。

Conclusion: 提出的混合CNN架构在孟加拉国纸币识别任务中表现出色，既保持了高精度又适合资源受限设备，同时通过可解释AI方法增强了透明度，为视障人士提供了可靠的辅助技术解决方案。

Abstract: Accurate currency recognition is essential for assistive technologies, particularly for visually impaired individuals who rely on others to identify banknotes. This dependency puts them at risk of fraud and exploitation. To address these challenges, we first build a new Bangladeshi banknote dataset that includes both controlled and real-world scenarios, ensuring a more comprehensive and diverse representation. Next, to enhance the dataset's robustness, we incorporate four additional datasets, including public benchmarks, to cover various complexities and improve the model's generalization. To overcome the limitations of current recognition models, we propose a novel hybrid CNN architecture that combines MobileNetV3-Large and EfficientNetB0 for efficient feature extraction. This is followed by an effective multilayer perceptron (MLP) classifier to improve performance while keeping computational costs low, making the system suitable for resource-constrained devices. The experimental results show that the proposed model achieves 97.95% accuracy on controlled datasets, 92.84% on complex backgrounds, and 94.98% accuracy when combining all datasets. The model's performance is thoroughly evaluated using five-fold cross-validation and seven metrics: accuracy, precision, recall, F1-score, Cohen's Kappa, MCC, and AUC. Additionally, explainable AI methods like LIME and SHAP are incorporated to enhance transparency and interpretability.

</details>


### [8] [Gaussian-Constrained LeJEPA Representations for Unsupervised Scene Discovery and Pose Consistency](https://arxiv.org/abs/2602.07016)
*Mohsen Mostafa*

Main category: cs.CV

TL;DR: 该论文研究了在IMC2025挑战中，使用受LeJEPA启发的各向同性高斯约束表示来改进无监督3D场景重建，特别是在多场景、视觉模糊条件下的场景发现和相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 从非结构化图像集合中进行无监督3D场景重建面临重大挑战，特别是当图像来自多个不相关场景且存在显著视觉模糊时。IMC2025挑战要求在实际条件下（包含异常值和混合内容）同时进行场景发现和相机姿态估计，这凸显了这些困难。

Method: 提出了三种逐步改进的管道，最终采用受LeJEPA启发的各向同性高斯约束方法，对学习到的图像嵌入施加高斯约束。该方法不是引入新的理论保证，而是经验性地评估这些约束如何影响实际中的聚类一致性和姿态估计鲁棒性。

Result: 在IMC2025上的实验结果表明，与启发式基线方法相比，高斯约束嵌入可以改善场景分离和姿态合理性，特别是在视觉模糊设置中。

Conclusion: 这些发现表明，理论驱动的表示约束为桥接自监督学习原理和实际运动结构管道提供了一个有前景的方向。

Abstract: Unsupervised 3D scene reconstruction from unstructured image collections remains a fundamental challenge in computer vision, particularly when images originate from multiple unrelated scenes and contain significant visual ambiguity. The Image Matching Challenge 2025 (IMC2025) highlights these difficulties by requiring both scene discovery and camera pose estimation under real-world conditions, including outliers and mixed content. This paper investigates the application of Gaussian-constrained representations inspired by LeJEPA (Joint Embedding Predictive Architecture) to address these challenges. We present three progressively refined pipelines, culminating in a LeJEPA-inspired approach that enforces isotropic Gaussian constraints on learned image embeddings. Rather than introducing new theoretical guarantees, our work empirically evaluates how these constraints influence clustering consistency and pose estimation robustness in practice. Experimental results on IMC2025 demonstrate that Gaussian-constrained embeddings can improve scene separation and pose plausibility compared to heuristic-driven baselines, particularly in visually ambiguous settings. These findings suggest that theoretically motivated representation constraints offer a promising direction for bridging self-supervised learning principles and practical structure-from-motion pipelines.

</details>


### [9] [XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models](https://arxiv.org/abs/2602.07017)
*Thuraya Alzubaidi,Sana Ammar,Maryam Alsharqi,Islem Rekik,Muzammil Behzad*

Main category: cs.CV

TL;DR: XAI-CLIP：一种基于多模态视觉语言模型的ROI引导扰动框架，用于生成更清晰、边界感知的显著性图，显著提升医学图像分割的可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 尽管基于transformer的医学图像分割模型性能优越，但其有限的可解释性阻碍了临床信任和部署。现有的可解释人工智能技术计算成本高、需要多次前向传播，且常产生噪声大或解剖学无关的解释。

Method: 提出XAI-CLIP框架，利用多模态视觉语言模型嵌入定位临床相关的解剖区域，通过语言引导的区域定位与医学图像分割结合，应用有针对性的区域感知扰动，生成边界感知的显著性图。

Result: 在FLARE22和CHAOS数据集上的实验显示：运行时减少60%，Dice分数提升44.6%，基于遮挡的解释的IoU提高96.7%，生成更干净、解剖学一致的归因图，减少伪影。

Conclusion: 将多模态视觉语言表示整合到基于扰动的XAI框架中，显著提升了可解释性和效率，为实现透明且可临床部署的医学图像分割系统提供了有效途径。

Abstract: Medical image segmentation is a critical component of clinical workflows, enabling accurate diagnosis, treatment planning, and disease monitoring. However, despite the superior performance of transformer-based models over convolutional architectures, their limited interpretability remains a major obstacle to clinical trust and deployment. Existing explainable artificial intelligence (XAI) techniques, including gradient-based saliency methods and perturbation-based approaches, are often computationally expensive, require numerous forward passes, and frequently produce noisy or anatomically irrelevant explanations. To address these limitations, we propose XAI-CLIP, an ROI-guided perturbation framework that leverages multimodal vision-language model embeddings to localize clinically meaningful anatomical regions and guide the explanation process. By integrating language-informed region localization with medical image segmentation and applying targeted, region-aware perturbations, the proposed method generates clearer, boundary-aware saliency maps while substantially reducing computational overhead. Experiments conducted on the FLARE22 and CHAOS datasets demonstrate that XAI-CLIP achieves up to a 60\% reduction in runtime, a 44.6\% improvement in dice score, and a 96.7\% increase in Intersection-over-Union for occlusion-based explanations compared to conventional perturbation methods. Qualitative results further confirm cleaner and more anatomically consistent attribution maps with fewer artifacts, highlighting that the incorporation of multimodal vision-language representations into perturbation-based XAI frameworks significantly enhances both interpretability and efficiency, thereby enabling transparent and clinically deployable medical image segmentation systems.

</details>


### [10] [The Geometry of Representational Failures in Vision Language Models](https://arxiv.org/abs/2602.07025)
*Daniele Savietto,Declan Campbell,André Panisson,Marco Nurisso,Giovanni Petri,Jonathan D. Cohen,Alan Perotti*

Main category: cs.CV

TL;DR: 该研究分析了视觉语言模型在多物体视觉任务中的失败机制，通过概念向量几何重叠解释模型错误模式


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多物体视觉任务中表现出令人困惑的失败，如幻觉不存在的元素或无法在干扰物中识别最相似的对象。这些错误反映了人类认知限制（如"绑定问题"），但人工系统中的内部机制仍不清楚。

Method: 通过分析开放权重VLMs（Qwen、InternVL、Gemma）的表征几何，比较提取"概念向量"的方法——编码视觉概念的潜在方向。通过转向干预验证概念向量，在简化和自然主义视觉任务中可靠地操纵模型行为。

Result: 观察到这些向量之间的几何重叠与特定错误模式强相关，为理解内部表征如何塑造模型行为和驱动视觉失败提供了基于量化的框架。

Conclusion: 概念向量的几何重叠为理解视觉语言模型在多物体任务中的失败机制提供了机制性洞察，建立了内部表征与行为错误之间的定量联系框架。

Abstract: Vision-Language Models (VLMs) exhibit puzzling failures in multi-object visual tasks, such as hallucinating non-existent elements or failing to identify the most similar objects among distractions. While these errors mirror human cognitive constraints, such as the "Binding Problem", the internal mechanisms driving them in artificial systems remain poorly understood. Here, we propose a mechanistic insight by analyzing the representational geometry of open-weight VLMs (Qwen, InternVL, Gemma), comparing methodologies to distill "concept vectors" - latent directions encoding visual concepts. We validate our concept vectors via steering interventions that reliably manipulate model behavior in both simplified and naturalistic vision tasks (e.g., forcing the model to perceive a red flower as blue). We observe that the geometric overlap between these vectors strongly correlates with specific error patterns, offering a grounded quantitative framework to understand how internal representations shape model behavior and drive visual failures.

</details>


### [11] [Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models](https://arxiv.org/abs/2602.07026)
*Xiaomin Yu,Yi Xin,Wenjie Zhang,Chonghan Liu,Hanzhen Zhao,Xiaoxing Hu,Xinlei Yu,Ziyue Qiao,Hao Tang,Xue Yang,Xiaobin Hu,Chengwei Qin,Hui Xiong,Yu Qiao,Shuicheng Yan*

Main category: cs.CV

TL;DR: 该论文提出ReVision框架，通过ReAlign训练免费模态对齐策略，利用未配对数据解决多模态对比学习中的模态间隙问题，为多模态大语言模型提供高效扩展路径。


<details>
  <summary>Details</summary>
Motivation: 多模态对比学习在视觉和语言表示对齐方面取得成功，但存在模态间隙问题：表达相同语义的不同模态嵌入占据系统偏移区域。先前方法受限于过度简化的各向同性假设，难以应用于大规模场景。

Method: 1. 提出固定框架模态间隙理论，将模态间隙分解为稳定偏差和各向异性残差；2. 提出ReAlign训练免费模态对齐策略，利用大规模未配对数据统计信息，通过锚点、追踪和质心对齐三步将文本表示对齐到图像表示分布；3. 提出ReVision可扩展训练范式，将ReAlign集成到预训练阶段，让模型在视觉指令调优前从未配对文本中学习视觉表示分布。

Result: 该框架证明统计对齐的未配对数据可以有效替代昂贵的图像-文本对，为多模态大语言模型的高效扩展提供了稳健路径。

Conclusion: 通过精确建模模态间隙几何形状并利用未配对数据统计信息，ReVision框架解决了多模态表示对齐中的几何失准问题，为大规模多模态模型训练提供了高效、可扩展的解决方案。

Abstract: Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly, the Modality Gap, remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions, hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory, which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign, a training-free modality alignment strategy. Utilizing statistics from massive unpaired data, ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment, thereby explicitly rectifying geometric misalignment. Building on ReAlign, we propose ReVision, a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage, enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning, without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.

</details>


### [12] [Fair Context Learning for Evidence-Balanced Test-Time Adaptation in Vision-Language Models](https://arxiv.org/abs/2602.07027)
*Sanggeon Yun,Ryozo Masukawa,SungHeon Jeong,Wenjun Huang,Hanning Chen,Mohsen Imani*

Main category: cs.CV

TL;DR: FCL是一种无需熵最小化的测试时适应框架，通过公平性约束解决共享证据偏差问题，提升CLIP等视觉语言模型在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的测试时适应方法依赖熵最小化，但在类别共享视觉特征时会放大虚假相关性并导致过度自信的错误，需要避免熵最小化来解决共享证据偏差问题。

Method: 提出公平上下文学习(FCL)框架，基于加性证据分解假设，将适应过程解耦为：(1)基于增强的探索识别可信类别候选；(2)公平驱动的校准，通过调整文本上下文使模型对常见视觉证据的敏感性均等化。

Result: FCL在多种领域偏移和细粒度基准测试中取得了与最先进测试时适应方法相竞争的性能，并通过实验验证了理论动机。

Conclusion: 通过避免熵最小化并引入公平性约束，FCL能够有效缓解部分特征依赖问题，在不依赖熵减少的情况下实现对文本嵌入的有效校准，提升模型在分布偏移下的鲁棒性。

Abstract: Vision-Language Models (VLMs) such as CLIP enable strong zero-shot recognition but suffer substantial degradation under distribution shifts. Test-Time Adaptation (TTA) aims to improve robustness using only unlabeled test samples, yet most prompt-based TTA methods rely on entropy minimization -- an approach that can amplify spurious correlations and induce overconfident errors when classes share visual features. We propose Fair Context Learning (FCL), an episodic TTA framework that avoids entropy minimization by explicitly addressing shared-evidence bias. Motivated by our additive evidence decomposition assumption, FCL decouples adaptation into (i) augmentation-based exploration to identify plausible class candidates, and (ii) fairness-driven calibration that adapts text contexts to equalize sensitivity to common visual evidence. This fairness constraint mitigates partial feature obsession and enables effective calibration of text embeddings without relying on entropy reduction. Through extensive evaluation, we empirically validate our theoretical motivation and show that FCL achieves competitive adaptation performance relative to state-of-the-art TTA methods across diverse domain-shift and fine-grained benchmarks.

</details>


### [13] [UNIKIE-BENCH: Benchmarking Large Multimodal Models for Key Information Extraction in Visual Documents](https://arxiv.org/abs/2602.07038)
*Yifan Ji,Zhipeng Xu,Zhenghao Liu,Zulong Chen,Qian Zhang,Zhibo Yang,Junyang Lin,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CV

TL;DR: UNIKIE-BENCH是一个用于评估大型多模态模型在文档关键信息提取任务中性能的统一基准，包含约束类别和开放类别两个互补的评测轨道。


<details>
  <summary>Details</summary>
Motivation: 现实世界文档的关键信息提取面临布局结构多样、视觉质量差异和任务特定需求等挑战，需要系统评估大型多模态模型在此任务上的能力。

Method: 构建UNIKIE-BENCH基准，包含两个互补轨道：约束类别KIE轨道（基于场景预定义模式）和开放类别KIE轨道（提取文档中任何显式存在的关键信息）。对15个最先进的大型多模态模型进行实验评估。

Result: 实验显示模型在不同模式定义、长尾关键字段和复杂布局下性能显著下降，不同文档类型和场景间存在明显性能差异，突显了基于LMM的KIE在基础准确性和布局感知推理方面的持续挑战。

Conclusion: UNIKIE-BENCH为系统评估大型多模态模型的关键信息提取能力提供了统一基准，揭示了当前模型在实际应用场景中的局限性，特别是在模式适应性、长尾字段处理和复杂布局理解方面仍需改进。

Abstract: Key Information Extraction (KIE) from real-world documents remains challenging due to substantial variations in layout structures, visual quality, and task-specific information requirements. Recent Large Multimodal Models (LMMs) have shown promising potential for performing end-to-end KIE directly from document images. To enable a comprehensive and systematic evaluation across realistic and diverse application scenarios, we introduce UNIKIE-BENCH, a unified benchmark designed to rigorously evaluate the KIE capabilities of LMMs. UNIKIE-BENCH consists of two complementary tracks: a constrained-category KIE track with scenario-predefined schemas that reflect practical application needs, and an open-category KIE track that extracts any key information that is explicitly present in the document. Experiments on 15 state-of-the-art LMMs reveal substantial performance degradation under diverse schema definitions, long-tail key fields, and complex layouts, along with pronounced performance disparities across different document types and scenarios. These findings underscore persistent challenges in grounding accuracy and layout-aware reasoning for LMM-based KIE. All codes and datasets are available at https://github.com/NEUIR/UNIKIE-BENCH.

</details>


### [14] [OMNI-Dent: Towards an Accessible and Explainable AI Framework for Automated Dental Diagnosis](https://arxiv.org/abs/2602.07041)
*Leeje Jang,Yao-Yi Chiang,Angela M. Hastings,Patimaporn Pungchanchaikul,Martha B. Lucas,Emily C. Schultz,Jeffrey P. Louie,Mohamed Estai,Wen-Chen Wang,Ryan H. L. Ip,Boyen Huang*

Main category: cs.CV

TL;DR: OMNI-Dent是一个数据高效且可解释的牙科诊断框架，通过将临床推理原则融入视觉语言模型，利用多视角智能手机照片进行牙齿级评估，无需牙科特定微调。


<details>
  <summary>Details</summary>
Motivation: 当前AI牙科诊断方法主要将诊断视为视觉模式识别任务，未能反映牙科专业人士的结构化临床推理。这些方法需要大量专家标注数据，且难以在不同真实世界成像条件下泛化。许多人缺乏及时的专业评估机会。

Method: 提出OMNI-Dent框架，将临床推理原则融入视觉语言模型（VLM）流程。框架基于多视角智能手机照片，嵌入牙科专家的诊断启发式方法，引导通用VLM进行牙齿级评估，无需对VLM进行牙科特定微调。

Result: 该框架旨在支持在缺乏临床影像数据的场景下进行诊断评估。作为早期辅助工具，帮助用户识别潜在异常并确定何时需要专业评估，为缺乏现场护理机会的个人提供实用选择。

Conclusion: OMNI-Dent通过结合临床推理原则和通用VLM能力，提供了一种数据高效、可解释的牙科诊断方法，特别适用于资源有限的环境，能够帮助改善口腔健康服务的可及性。

Abstract: Accurate dental diagnosis is essential for oral healthcare, yet many individuals lack access to timely professional evaluation. Existing AI-based methods primarily treat diagnosis as a visual pattern recognition task and do not reflect the structured clinical reasoning used by dental professionals. These approaches also require large amounts of expert-annotated data and often struggle to generalize across diverse real-world imaging conditions. To address these limitations, we present OMNI-Dent, a data-efficient and explainable diagnostic framework that incorporates clinical reasoning principles into a Vision-Language Model (VLM)-based pipeline. The framework operates on multi-view smartphone photographs,embeds diagnostic heuristics from dental experts, and guides a general-purpose VLM to perform tooth-level evaluation without dental-specific fine-tuning of the VLM. By utilizing the VLM's existing visual-linguistic capabilities, OMNI-Dent aims to support diagnostic assessment in settings where curated clinical imaging is unavailable. Designed as an early-stage assistive tool, OMNI-Dent helps users identify potential abnormalities and determine when professional evaluation may be needed, offering a practical option for individuals with limited access to in-person care.

</details>


### [15] [COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification](https://arxiv.org/abs/2602.07042)
*Magesh Rajasekaran,Md Saiful Islam Sajol,Frej Berglind,Supratik Mukhopadhyay,Kamalika Das*

Main category: cs.CV

TL;DR: COMBOOD是一个新颖的无监督半参数框架，用于图像识别的OOD检测，通过结合最近邻和马氏距离两种度量信号，在近OOD和远OOD场景下都能提供准确的置信度评分。


<details>
  <summary>Details</summary>
Motivation: 在机器学习应用中，推理时识别分布外数据对自动化应用至关重要。现有方法在近OOD场景（实际应用中常见）中表现不佳，需要一种既能处理远OOD又能处理近OOD的统一框架。

Method: COMBOOD框架结合了两种距离度量信号：最近邻（非参数方法）和马氏距离（参数方法）。最近邻方法提供非参数的OOD检测，马氏距离方法在远OOD场景中特别有效。该框架在半参数设置下将两种信号结合，为推理点生成置信度评分。

Result: COMBOOD在OpenOOD基准数据集（版本1和1.5）和文档数据集上均优于最先进的OOD检测方法，在远OOD和近OOD场景下都表现出色。在大多数基准数据集上，COMBOOD带来的准确率提升具有统计显著性。框架的复杂度与嵌入空间大小呈线性关系，适合实际应用。

Conclusion: COMBOOD框架通过结合最近邻和马氏距离两种距离度量，提供了一种有效的半参数OOD检测方法，在近OOD和远OOD场景下都能取得优异性能，且具有线性可扩展性，适合实际应用部署。

Abstract: Identifying out-of-distribution (OOD) data at inference time is crucial for many machine learning applications, especially for automation. We present a novel unsupervised semi-parametric framework COMBOOD for OOD detection with respect to image recognition. Our framework combines signals from two distance metrics, nearest-neighbor and Mahalanobis, to derive a confidence score for an inference point to be out-of-distribution. The former provides a non-parametric approach to OOD detection. The latter provides a parametric, simple, yet effective method for detecting OOD data points, especially, in the far OOD scenario, where the inference point is far apart from the training data set in the embedding space. However, its performance is not satisfactory in the near OOD scenarios that arise in practical situations. Our COMBOOD framework combines the two signals in a semi-parametric setting to provide a confidence score that is accurate both for the near-OOD and far-OOD scenarios. We show experimental results with the COMBOOD framework for different types of feature extraction strategies. We demonstrate experimentally that COMBOOD outperforms state-of-the-art OOD detection methods on the OpenOOD (both version 1 and most recent version 1.5) benchmark datasets (for both far-OOD and near-OOD) as well as on the documents dataset in terms of accuracy. On a majority of the benchmark datasets, the improvements in accuracy resulting from the COMBOOD framework are statistically significant. COMBOOD scales linearly with the size of the embedding space, making it ideal for many real-life applications.

</details>


### [16] [PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging](https://arxiv.org/abs/2602.07044)
*Tianyi Qu,Songxiao Yang,Haolin Wang,Huadong Song,Xiaoting Guo,Wenguang Hu,Guanlin Liu,Honghe Chen,Yafei Ou*

Main category: cs.CV

TL;DR: PipeMFL-240K：首个大规模公开的管道漏磁检测数据集与基准，包含24万张图像和19万标注，针对12类缺陷的长尾分布、微小目标检测等挑战，为自动化管道完整性评估提供标准化测试平台。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在管道漏磁检测自动化应用中面临缺乏大规模公开数据集和基准的问题，导致模型难以公平比较和可重复评估，阻碍了该领域的研究进展。

Method: 构建了PipeMFL-240K数据集，包含240,320张图像和191,530个高质量边界框标注，数据来自11条总长约1,480公里的管道，涵盖12个缺陷类别，具有长尾分布、微小目标和高类内变异等挑战特性。

Result: 使用最先进的目标检测器进行基准测试，结果显示现有模型仍难以有效处理漏磁数据的固有特性，表明该领域仍有很大改进空间，而PipeMFL-240K为未来研究提供了可靠且具有挑战性的测试平台。

Conclusion: PipeMFL-240K作为首个大规模公开的管道漏磁检测数据集和基准，为高效管道诊断、维护规划提供了关键基础，有望加速漏磁检测领域的算法创新和可重复研究。

Abstract: Pipeline integrity is critical to industrial safety and environmental protection, with Magnetic Flux Leakage (MFL) detection being a primary non-destructive testing technology. Despite the promise of deep learning for automating MFL interpretation, progress toward reliable models has been constrained by the absence of a large-scale public dataset and benchmark, making fair comparison and reproducible evaluation difficult. We introduce \textbf{PipeMFL-240K}, a large-scale, meticulously annotated dataset and benchmark for complex object detection in pipeline MFL pseudo-color images. PipeMFL-240K reflects real-world inspection complexity and poses several unique challenges: (i) an extremely long-tailed distribution over \textbf{12} categories, (ii) a high prevalence of tiny objects that often comprise only a handful of pixels, and (iii) substantial intra-class variability. The dataset contains \textbf{240,320} images and \textbf{191,530} high-quality bounding-box annotations, collected from 11 pipelines spanning approximately \textbf{1,480} km. Extensive experiments are conducted with state-of-the-art object detectors to establish baselines. Results show that modern detectors still struggle with the intrinsic properties of MFL data, highlighting considerable headroom for improvement, while PipeMFL-240K provides a reliable and challenging testbed to drive future research. As the first public dataset and the first benchmark of this scale and scope for pipeline MFL inspection, it provides a critical foundation for efficient pipeline diagnostics as well as maintenance planning and is expected to accelerate algorithmic innovation and reproducible research in MFL-based pipeline integrity assessment.

</details>


### [17] [VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing](https://arxiv.org/abs/2602.07045)
*Zhiming Luo,Di Wang,Haonan Guo,Jing Zhang,Bo Du*

Main category: cs.CV

TL;DR: VLRS-Bench是首个专门针对遥感复杂推理任务的基准测试，包含2000个问答对，涵盖认知、决策和预测三个维度，旨在推动多模态大语言模型在遥感领域的认知能力发展。


<details>
  <summary>Details</summary>
Motivation: 现有遥感基准测试主要偏向感知任务（如目标识别和场景分类），这限制了多模态大语言模型在认知需求高的遥感应用中的发展，需要专门的复杂推理基准来推动该领域进步。

Method: 提出了VLRS-Bench基准测试，包含2000个问答对，平均长度71词，涵盖14个任务和最多8个时间阶段。采用专门构建流程，整合遥感特定先验知识和专家知识，确保地理空间真实性和推理复杂性。

Result: 实验结果显示现有最先进的多模态大语言模型在遥感复杂推理任务上存在显著瓶颈，为遥感社区推进多模态推理提供了关键见解。

Conclusion: VLRS-Bench填补了遥感领域复杂推理基准测试的空白，揭示了当前模型的局限性，为未来多模态大语言模型在遥感认知应用中的发展提供了重要参考框架。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled complex reasoning. However, existing remote sensing (RS) benchmarks remain heavily biased toward perception tasks, such as object recognition and scene classification. This limitation hinders the development of MLLMs for cognitively demanding RS applications. To address this, , we propose a Vision Language ReaSoning Benchmark (VLRS-Bench), which is the first benchmark exclusively dedicated to complex RS reasoning. Structured across the three core dimensions of Cognition, Decision, and Prediction, VLRS-Bench comprises 2,000 question-answer pairs with an average length of 71 words, spanning 14 tasks and up to eight temporal phases. VLRS-Bench is constructed via a specialized pipeline that integrates RS-specific priors and expert knowledge to ensure geospatial realism and reasoning complexity. Experimental results reveal significant bottlenecks in existing state-of-the-art MLLMs, providing critical insights for advancing multimodal reasoning within the remote sensing community.

</details>


### [18] [ShapBPT: Image Feature Attributions Using Data-Aware Binary Partition Trees](https://arxiv.org/abs/2602.07047)
*Muhammad Rashid,Elvio G. Amparore,Enrico Ferrari,Damiano Verda*

Main category: cs.CV

TL;DR: ShapBPT是一种新的可解释AI方法，通过将分层Shapley值与图像的多尺度结构（BPT）结合，提供更高效、语义更清晰的像素级特征归因解释。


<details>
  <summary>Details</summary>
Motivation: 现有分层Shapley方法未能利用图像数据的多尺度结构，导致收敛慢、与真实形态特征对齐差，且缺乏针对计算机视觉任务的数据感知层次结构，限制了结构化视觉数据的模型可解释性。

Method: 提出ShapBPT方法，基于分层Shapley公式，将Shapley系数分配给专门为图像设计的二进制分割树（BPT）多尺度层次结构，通过数据感知的层次分割确保特征归因与内在图像形态对齐。

Result: 实验证实ShapBPT的有效性，展示出与图像结构的优越对齐性，相比现有XCV方法效率更高，20人用户研究确认人类更偏好ShapBPT的解释。

Conclusion: ShapBPT将分层Shapley方法与图像数据连接起来，为视觉可解释性提供了更高效、语义更有意义的方法，填补了结构化视觉数据模型解释的空白。

Abstract: Pixel-level feature attributions are an important tool in eXplainable AI for Computer Vision (XCV), providing visual insights into how image features influence model predictions. The Owen formula for hierarchical Shapley values has been widely used to interpret machine learning (ML) models and their learned representations. However, existing hierarchical Shapley approaches do not exploit the multiscale structure of image data, leading to slow convergence and weak alignment with the actual morphological features. Moreover, no prior Shapley method has leveraged data-aware hierarchies for Computer Vision tasks, leaving a gap in model interpretability of structured visual data. To address this, this paper introduces ShapBPT, a novel data-aware XCV method based on the hierarchical Shapley formula. ShapBPT assigns Shapley coefficients to a multiscale hierarchical structure tailored for images, the Binary Partition Tree (BPT). By using this data-aware hierarchical partitioning, ShapBPT ensures that feature attributions align with intrinsic image morphology, effectively prioritizing relevant regions while reducing computational overhead. This advancement connects hierarchical Shapley methods with image data, providing a more efficient and semantically meaningful approach to visual interpretability. Experimental results confirm ShapBPT's effectiveness, demonstrating superior alignment with image structures and improved efficiency over existing XCV methods, and a 20-subject user study confirming that ShapBPT explanations are preferred by humans.

</details>


### [19] [Enhancing IMU-Based Online Handwriting Recognition via Contrastive Learning with Zero Inference Overhead](https://arxiv.org/abs/2602.07049)
*Jindong Li,Dario Zanca,Vincent Christlein,Tim Hamann,Jens Barth,Peter Kämpf,Björn Eskofier*

Main category: cs.CV

TL;DR: 提出ECHWR训练框架，通过临时辅助分支和双重对比损失提升基于惯性测量单元的手写识别性能，不增加推理成本


<details>
  <summary>Details</summary>
Motivation: 在线手写识别使用惯性测量单元可实现纸上手写作为数字设备输入，但在边缘硬件上运行面临内存限制，需要在保持推理效率的同时提升识别精度

Method: 提出ECHWR训练框架，包含临时辅助分支将传感器信号与语义文本嵌入对齐，采用双重对比目标：批量内对比损失用于模态对齐，新颖的基于错误的对比损失区分正确信号和合成硬负样本，训练后丢弃辅助分支

Result: 在OnHW-Words500数据集上显著优于最先进基线，在独立于作者的划分上字符错误率降低7.4%，在依赖于作者的划分上降低10.4%，基于错误的对比损失对处理未见过的书写风格有效

Conclusion: ECHWR框架能在不增加推理成本的情况下提升手写识别性能，基于错误的对比损失特别适用于处理未见过的书写风格，但解决特定挑战需要特定的架构和目标配置

Abstract: Online handwriting recognition using inertial measurement units opens up handwriting on paper as input for digital devices. Doing it on edge hardware improves privacy and lowers latency, but entails memory constraints. To address this, we propose Error-enhanced Contrastive Handwriting Recognition (ECHWR), a training framework designed to improve feature representation and recognition accuracy without increasing inference costs. ECHWR utilizes a temporary auxiliary branch that aligns sensor signals with semantic text embeddings during the training phase. This alignment is maintained through a dual contrastive objective: an in-batch contrastive loss for general modality alignment and a novel error-based contrastive loss that distinguishes between correct signals and synthetic hard negatives. The auxiliary branch is discarded after training, which allows the deployed model to keep its original, efficient architecture. Evaluations on the OnHW-Words500 dataset show that ECHWR significantly outperforms state-of-the-art baselines, reducing character error rates by up to 7.4% on the writer-independent split and 10.4% on the writer-dependent split. Finally, although our ablation studies indicate that solving specific challenges require specific architectural and objective configurations, error-based contrastive loss shows its effectiveness for handling unseen writing styles.

</details>


### [20] [Interpreting Physics in Video World Models](https://arxiv.org/abs/2602.07050)
*Sonia Joseph,Quentin Garrido,Randall Balestriero,Matthew Kowal,Thomas Fel,Shahab Bakhtiari,Blake Richards,Mike Rabbat*

Main category: cs.CV

TL;DR: 研究发现现代视频模型不使用经典物理引擎那样的因子化物理变量表示，而是采用分布式表示，但仍能做出准确的物理预测


<details>
  <summary>Details</summary>
Motivation: 探索视频模型是否依赖因子化的物理变量表示来做出准确物理预测，还是采用任务特定的分布式表示，以及物理信息在视频编码器中的组织方式

Method: 使用分层探测、子空间几何、补丁级解码和针对性注意力消融等方法，分析大规模视频编码器内部的物理表示

Result: 发现物理信息在中间深度出现急剧转变（物理涌现区），标量物理量从早期层即可获得，而运动方向仅在物理涌现区才变得可访问，方向通过具有圆形几何结构的高维群体结构编码

Conclusion: 现代视频模型不使用经典物理引擎的因子化物理变量表示，而是采用分布式表示，这种表示方式足以做出物理预测

Abstract: A long-standing question in physical reasoning is whether video-based models need to rely on factorized representations of physical variables in order to make physically accurate predictions, or whether they can implicitly represent such variables in a task-specific, distributed manner. While modern video world models achieve strong performance on intuitive physics benchmarks, it remains unclear which of these representational regimes they implement internally. Here, we present the first interpretability study to directly examine physical representations inside large-scale video encoders. Using layerwise probing, subspace geometry, patch-level decoding, and targeted attention ablations, we characterize where physical information becomes accessible and how it is organized within encoder-based video transformers.
  Across architectures, we identify a sharp intermediate-depth transition -- which we call the Physics Emergence Zone -- at which physical variables become accessible. Physics-related representations peak shortly after this transition and degrade toward the output layers. Decomposing motion into explicit variables, we find that scalar quantities such as speed and acceleration are available from early layers onwards, whereas motion direction becomes accessible only at the Physics Emergence Zone. Notably, we find that direction is encoded through a high-dimensional population structure with circular geometry, requiring coordinated multi-feature intervention to control. These findings suggest that modern video models do not use factorized representations of physical variables like a classical physics engine. Instead, they use a distributed representation that is nonetheless sufficient for making physical predictions.

</details>


### [21] [Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning](https://arxiv.org/abs/2602.07051)
*Karthik Sivakoti*

Main category: cs.CV

TL;DR: 本文提出Neural Sentinel，一种基于视觉语言模型的统一车牌识别系统，通过单次前向传播同时完成车牌识别、状态分类和车辆属性提取，相比传统多阶段流水线方法在准确性和架构复杂度上有显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统ALPR系统采用多阶段流水线（目标检测+OCR模块），存在误差累积、延迟高、架构复杂的问题。需要一种更高效、准确且能处理多任务的统一解决方案。

Method: 使用PaliGemma 3B视觉语言模型，通过LoRA微调，实现单次前向传播同时回答多个关于车辆图像的视觉问题。引入人机协同持续学习框架，通过经验回放防止灾难性遗忘，保持70:30的原始训练数据与修正样本比例。

Result: 车牌识别准确率达到92.3%，比EasyOCR提升14.1%，比PaddleOCR提升9.9%。平均推理延迟152ms，预期校准误差0.048。零样本泛化能力：车辆颜色检测89%、安全带检测82%、乘员计数78%。

Conclusion: 统一的视觉语言方法代表了ALPR系统的范式转变，提供了优于传统流水线方法的准确性、降低的架构复杂度以及新兴的多任务能力，具有实际应用价值。

Abstract: Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.

</details>


### [22] [Toward Accurate and Accessible Markerless Neuronavigation](https://arxiv.org/abs/2602.07052)
*Ziye Xie,Oded Schlesinger,Raj Kundu,Jessica Y. Choi,Pablo Iturralde,Dennis A. Turner,Stefan M. Goetz,Guillermo Sapiro,Angel V. Peterchev,J. Matias Di Martino*

Main category: cs.CV

TL;DR: 该论文提出了一种无标记神经导航系统，使用低成本可见光和红外光相机结合立体和深度感知，替代传统需要物理标记的系统，实现了高精度的头部跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统神经导航系统依赖需要手动注册的物理标记，这些标记可能在手术过程中移位，造成患者不适，且成本高昂。需要开发更舒适、低成本的无标记替代方案。

Method: 使用低成本可见光和红外光相机，结合立体视觉和深度感知技术，通过算法建模面部几何特征，实现无标记的头部跟踪和导航。

Result: 在50名人类受试者上的验证显示，最佳无标记算法的中位跟踪误差仅为2.32毫米和2.01度，相比传统标记系统具有足够精度用于经颅磁刺激，且显著优于先前无标记方法。

Conclusion: 提出的无标记神经导航方法能降低设置成本和复杂性，提高患者舒适度，并扩大神经导航在临床和研究环境中的可及性。多传感器数据融合可进一步提高整体精度。

Abstract: Neuronavigation is widely used in biomedical research and interventions to guide the precise placement of instruments around the head to support procedures such as transcranial magnetic stimulation. Traditional systems, however, rely on subject-mounted markers that require manual registration, may shift during procedures, and can cause discomfort. We introduce and evaluate markerless approaches that replace expensive hardware and physical markers with low-cost visible and infrared light cameras incorporating stereo and depth sensing combined with algorithmic modeling of the facial geometry. Validation with $50$ human subjects yielded a median tracking discrepancy of only $2.32$ mm and $2.01°$ for the best markerless algorithms compared to a conventional marker-based system, which indicates sufficient accuracy for transcranial magnetic stimulation and a substantial improvement over prior markerless results. The results suggest that integration of the data from the various camera sensors can improve the overall accuracy further. The proposed markerless neuronavigation methods can reduce setup cost and complexity, improve patient comfort, and expand access to neuronavigation in clinical and research settings.

</details>


### [23] [RECITYGEN -- Interactive and Generative Participatory Urban Design Tool with Latent Diffusion and Segment Anything](https://arxiv.org/abs/2602.07057)
*Di Mo,Mingyang Sun,Chengxiu Yin,Runjia Tian,Yanhong Wu,Liyan Xu*

Main category: cs.CV

TL;DR: RECITYGEN是一个结合潜在扩散模型和交互式语义分割的工具，允许用户通过文本提示交互式生成城市街景的变体图像，用于参与式城市设计。


<details>
  <summary>Details</summary>
Motivation: 传统自上而下的城市设计方法往往忽视公众意见，导致设计愿景与现实需求之间存在差距。数字工具的发展为更广泛的利益相关者参与城市设计提供了机会。

Method: 结合最先进的潜在扩散模型和交互式语义分割技术，开发了RECITYGEN工具，用户可以通过文本提示交互式生成城市街景的变体图像。

Result: 在北京的试点项目中，用户使用RECITYGEN为正在进行的城市更新项目提出改进建议。尽管存在一些局限性，但该工具显示出与公众偏好高度契合的潜力。

Conclusion: RECITYGEN展示了向更动态、包容的城市规划方法转变的潜力，为参与式城市设计提供了新的技术途径。

Abstract: Urban design profoundly impacts public spaces and community engagement. Traditional top-down methods often overlook public input, creating a gap in design aspirations and reality. Recent advancements in digital tools, like City Information Modelling and augmented reality, have enabled a more participatory process involving more stakeholders in urban design. Further, deep learning and latent diffusion models have lowered barriers for design generation, providing even more opportunities for participatory urban design. Combining state-of-the-art latent diffusion models with interactive semantic segmentation, we propose RECITYGEN, a novel tool that allows users to interactively create variational street view images of urban environments using text prompts. In a pilot project in Beijing, users employed RECITYGEN to suggest improvements for an ongoing Urban Regeneration project. Despite some limitations, RECITYGEN has shown significant potential in aligning with public preferences, indicating a shift towards more dynamic and inclusive urban planning methods. The source code for the project can be found at RECITYGEN GitHub.

</details>


### [24] [FADE: Selective Forgetting via Sparse LoRA and Self-Distillation](https://arxiv.org/abs/2602.07058)
*Carolina R. Kelsch,Leonardo S. B. Pereira,Natnael Mola,Luis H. Arribas,Juan C. S. M. Avedillo*

Main category: cs.CV

TL;DR: FADE是一种用于文本到图像扩散模型的两阶段遗忘学习方法，通过参数定位和自蒸馏实现高效、可逆的概念擦除，在保持整体性能的同时移除特定数据的影响。


<details>
  <summary>Details</summary>
Motivation: 随着数据保护法规和负责任AI实践的要求增加，需要从训练模型中移除特定数据或概念影响的能力。当前文本到图像扩散模型的遗忘学习面临高计算成本和平衡有效遗忘与保留无关概念的挑战。

Method: FADE采用两阶段方法：1) 使用基于梯度的显著性识别对遗忘集最负责的参数，通过稀疏LoRA适配器约束更新；2) 应用自蒸馏目标，用用户定义的替代概念覆盖遗忘概念，同时保留在保留数据上的行为。

Result: 在UnlearnCanvas基准测试和多个数据集（Imagenette、LFW、ATDB、SUN Attributes）上的评估显示，FADE实现了最先进的遗忘性能，在遗忘-保留权衡方面具有细粒度控制，表现出强大的概念擦除能力和高保留性。

Conclusion: FADE提供了一种内存高效、可逆的解决方案，适配器可在运行时合并或移除，适合在基于扩散的图像生成模型中进行选择性遗忘学习，满足生产系统的灵活部署需求。

Abstract: Machine Unlearning aims to remove the influence of specific data or concepts from trained models while preserving overall performance, a capability increasingly required by data protection regulations and responsible AI practices. Despite recent progress, unlearning in text-to-image diffusion models remains challenging due to high computational costs and the difficulty of balancing effective forgetting with retention of unrelated concepts. We introduce FADE (Fast Adapter for Data Erasure), a two-stage unlearning method for image generation that combines parameter localization with self-distillation. FADE first identifies parameters most responsible for the forget set using gradient-based saliency and constrains updates through sparse LoRA adapters, ensuring lightweight, localized modifications. In a second stage, FADE applies a self-distillation objective that overwrites the forgotten concept with a user-defined surrogate while preserving behavior on retained data. The resulting adapters are memory-efficient, reversible, and can be merged or removed at runtime, enabling flexible deployment in production systems. We evaluated FADE on the UnlearnCanvas benchmark and conducted ablation studies on Imagenette, Labeled Faces in the Wild, AtharvaTaras Dog Breeds Dataset, and SUN Attributes datasets, demonstrating State-of-the-Art unlearning performance with fine-grained control over the forgetting-retention trade-off. Our results demonstrate that FADE achieves strong concept erasure and high retainability across various domains, making it a suitable solution for selective unlearning in diffusion-based image generation models.

</details>


### [25] [From Images to Decisions: Assistive Computer Vision for Non-Metallic Content Estimation in Scrap Metal](https://arxiv.org/abs/2602.07062)
*Daniil Storonkin,Ilia Dziub,Maksim Golyadkin,Ilya Makarov*

Main category: cs.CV

TL;DR: 开发了一个计算机视觉系统，通过图像分析评估废钢中的非金属夹杂物污染程度，并分类废钢类型，用于钢铁生产中的质量控制


<details>
  <summary>Details</summary>
Motivation: 当前废钢质量主要通过人工目视检查非金属夹杂物污染程度，这种方法主观性强且存在安全隐患（粉尘和移动机械）。需要客观、安全的自动化评估方法

Method: 将污染评估建模为车厢级别的回归任务，采用多实例学习（MIL）处理序列数据，结合多任务学习（MTL）同时进行污染评估和废钢分类。系统包括磁铁/车厢检测、版本化推理服务、置信度评分和主动学习循环

Result: 最佳结果：MIL方法达到MAE 0.27和R² 0.83；MTL设置达到MAE 0.36，废钢分类F1分数0.79。系统已集成到验收工作流中，实现近实时处理

Conclusion: 该计算机视觉管道减少了主观变异性，提高了人员安全性，并能集成到验收和熔炼计划工作流中，通过主动学习实现持续改进

Abstract: Scrap quality directly affects energy use, emissions, and safety in steelmaking. Today, the share of non-metallic inclusions (contamination) is judged visually by inspectors - an approach that is subjective and hazardous due to dust and moving machinery. We present an assistive computer vision pipeline that estimates contamination (per percent) from images captured during railcar unloading and also classifies scrap type. The method formulates contamination assessment as a regression task at the railcar level and leverages sequential data through multi-instance learning (MIL) and multi-task learning (MTL). Best results include MAE 0.27 and R2 0.83 by MIL; and an MTL setup reaches MAE 0.36 with F1 0.79 for scrap class. Also we present the system in near real time within the acceptance workflow: magnet/railcar detection segments temporal layers, a versioned inference service produces railcar-level estimates with confidence scores, and results are reviewed by operators with structured overrides; corrections and uncertain cases feed an active-learning loop for continual improvement. The pipeline reduces subjective variability, improves human safety, and enables integration into acceptance and melt-planning workflows.

</details>


### [26] [Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.07069)
*Zihao Fan,Xin Lu,Yidi Liu,Jie Huang,Dong Li,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: Bird-SR是一个双向奖励引导的扩散框架，通过奖励反馈学习将超分辨率建模为轨迹级偏好优化，联合利用合成LR-HR对和真实世界LR图像，在保持结构一致性的同时提升感知质量。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的超分辨率方法虽然能合成丰富细节，但在合成数据上训练的模型往往因分布偏移而在真实世界LR图像上表现不佳。需要一种能同时利用合成数据和真实世界图像，在保持结构保真度的同时提升感知质量的方法。

Method: 提出Bird-SR框架：1) 在早期扩散步骤直接在合成对上优化以保证结构保真度；2) 在后期采样步骤对合成和真实LR图像应用质量引导奖励；3) 通过相对优势空间和语义对齐约束缓解奖励攻击；4) 采用动态保真度-感知权重策略平衡结构保持和感知优化。

Result: 在真实世界超分辨率基准测试中，Bird-SR在感知质量方面持续优于最先进方法，同时保持了结构一致性，验证了其在真实世界超分辨率任务中的有效性。

Conclusion: Bird-SR通过双向奖励引导的扩散框架成功解决了真实世界超分辨率中的分布偏移问题，在结构保真度和感知质量之间取得了良好平衡，为真实世界图像增强提供了有效解决方案。

Abstract: Diffusion-based super-resolution can synthesize rich details, but models trained on synthetic paired data often fail on real-world LR images due to distribution shifts. We propose Bird-SR, a bidirectional reward-guided diffusion framework that formulates super-resolution as trajectory-level preference optimization via reward feedback learning (ReFL), jointly leveraging synthetic LR-HR pairs and real-world LR images. For structural fidelity easily affected in ReFL, the model is directly optimized on synthetic pairs at early diffusion steps, which also facilitates structure preservation for real-world inputs under smaller distribution gap in structure levels. For perceptual enhancement, quality-guided rewards are applied at later sampling steps to both synthetic and real LR images. To mitigate reward hacking, the rewards for synthetic results are formulated in a relative advantage space bounded by their clean counterparts, while real-world optimization is regularized via a semantic alignment constraint. Furthermore, to balance structural and perceptual learning, we adopt a dynamic fidelity-perception weighting strategy that emphasizes structure preservation at early stages and progressively shifts focus toward perceptual optimization at later diffusion steps. Extensive experiments on real-world SR benchmarks demonstrate that Bird-SR consistently outperforms state-of-the-art methods in perceptual quality while preserving structural consistency, validating its effectiveness for real-world super-resolution.

</details>


### [27] [MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation](https://arxiv.org/abs/2602.07082)
*Haoming Wang,Qiyao Xue,Weichen Liu,Wei Gao*

Main category: cs.CV

TL;DR: MosaicThinker是一种推理时计算技术，通过将多帧视频的空间信息整合到统一的语义地图中，增强小型视觉语言模型在跨帧空间推理任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间推理方面能力较弱，特别是涉及多帧复杂空间关系时，这限制了具身AI在机器人操作和动作规划等高级任务中的应用。

Method: 提出MosaicThinker技术，将多帧视频中的碎片化空间信息整合到统一的全局语义地图表示中，并通过视觉提示引导视觉语言模型在语义地图上进行空间推理。

Result: 实验结果表明，该技术能显著提高资源受限具身AI设备在跨帧空间推理任务上的准确性，适用于多种类型和复杂度的推理任务。

Conclusion: MosaicThinker通过构建全局语义地图和视觉提示，有效增强了小型视觉语言模型的空间推理能力，为资源受限设备上的具身AI应用提供了可行的解决方案。

Abstract: When embodied AI is expanding from traditional object detection and recognition to more advanced tasks of robot manipulation and actuation planning, visual spatial reasoning from the video inputs is necessary to perceive the spatial relationships of objects and guide device actions. However, existing visual language models (VLMs) have very weak capabilities in spatial reasoning due to the lack of knowledge about 3D spatial information, especially when the reasoning task involve complex spatial relations across multiple video frames. In this paper, we present a new inference-time computing technique for on-device embodied AI, namely \emph{MosaicThinker}, which enhances the on-device small VLM's spatial reasoning capabilities on difficult cross-frame reasoning tasks. Our basic idea is to integrate fragmented spatial information from multiple frames into a unified space representation of global semantic map, and further guide the VLM's spatial reasoning over the semantic map via a visual prompt. Experiment results show that our technique can greatly enhance the accuracy of cross-frame spatial reasoning on resource-constrained embodied AI devices, over reasoning tasks with diverse types and complexities.

</details>


### [28] [WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark](https://arxiv.org/abs/2602.07095)
*Wang Lin,Feng Wang,Majun Zhang,Wentao Hu,Tao Jin,Zhou Zhao,Fei Wu,Jingyuan Chen,Alan Yuille,Sucheng Ren*

Main category: cs.CV

TL;DR: WorldEdit是一个专门设计用于世界驱动图像编辑的数据集，旨在解决现有模型在处理隐式编辑指令时的局限性，通过两阶段训练框架提升模型在因果编辑场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型在处理显式指令（如属性操作、风格转换、姿态合成）方面表现出色，但在处理隐式编辑指令时面临挑战。隐式指令描述视觉变化的原因而不详细说明结果，需要复杂的世界知识和推理能力，而现有模型缺乏这种能力。

Method: 1. 引入WorldEdit数据集，包含高质量编辑样本，指导通过符合现实世界因果逻辑的转述指令；2. 提供WorldEdit-Test用于评估现有模型在因果编辑场景中的性能；3. 使用两阶段训练框架微调Bagel等模型，整合因果验证奖励。

Result: 提出的数据集和方法显著缩小了与GPT-4o和Nano-Banana的差距，在指令遵循和知识合理性方面表现出竞争力，而许多开源系统通常在这些方面表现不佳。

Conclusion: WorldEdit数据集和两阶段训练框架有效解决了图像编辑模型处理隐式指令的局限性，通过整合因果逻辑和世界知识，提升了模型在复杂编辑场景中的性能。

Abstract: Recent advances in image editing models have demonstrated remarkable capabilities in executing explicit instructions, such as attribute manipulation, style transfer, and pose synthesis. However, these models often face challenges when dealing with implicit editing instructions, which describe the cause of a visual change without explicitly detailing the resulting outcome. These limitations arise because existing models rely on uniform editing strategies that are not equipped to handle the complex world knowledge and reasoning required for implicit instructions. To address this gap, we introduce \textbf{WorldEdit}, a dataset specifically designed to enable world-driven image editing. WorldEdit consists of high-quality editing samples, guided by paraphrased instructions that align with real-world causal logic. Furthermore, we provide \textbf{WorldEdit-Test} for evaluating the existing model's performance on causal editing scenarios. With WorldEdit, we use a two-stage training framework for fine-tuning models like Bagel, integrating with a causal verification reward. Our results show that the proposed dataset and methods significantly narrow the gap with GPT-4o and Nano-Banana, demonstrating competitive performance not only in instruction following but also in knowledge plausibility, where many open-source systems typically struggle.

</details>


### [29] [TLC-Plan: A Two-Level Codebook Based Network for End-to-End Vector Floorplan Generation](https://arxiv.org/abs/2602.07100)
*Biao Xiong,Zhen Peng,Ping Wang,Qiegen Liu,Xian Zhong*

Main category: cs.CV

TL;DR: TLC-Plan是一个直接从输入边界合成矢量平面图的层次化生成模型，通过两层VQ-VAE编码全局布局和局部几何，使用CodeTree统一表示，并通过自回归变换器生成多样且拓扑有效的设计，在RPLAN数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在栅格空间中操作并依赖后处理矢量化，会导致结构不一致并阻碍端到端学习。受组合空间推理启发，需要开发与人类建筑工作流程（基于模块化和可重用模式）一致的矢量平面图生成方法。

Method: 提出TLC-Plan层次生成模型：1) 使用两层VQ-VAE编码全局布局（语义标记的房间边界框）和局部几何（多边形级编码）；2) 通过CodeTree统一表示层次结构；3) 使用自回归变换器在边界条件下采样编码，生成多样且拓扑有效的设计，无需显式房间拓扑或维度先验。

Result: 在RPLAN数据集上达到最先进性能（FID = 1.84，MSE = 2.06），在LIFULL数据集上也取得领先结果。框架支持约束感知和可扩展的矢量平面图生成，适用于实际建筑应用。

Conclusion: TLC-Plan通过直接合成矢量平面图，避免了栅格空间方法的局限性，实现了与人类建筑工作流程一致的高质量、多样化和拓扑有效的平面图生成，为实际建筑应用提供了先进的约束感知和可扩展解决方案。

Abstract: Automated floorplan generation aims to improve design quality, architectural efficiency, and sustainability by jointly modeling global spatial organization and precise geometric detail. However, existing approaches operate in raster space and rely on post hoc vectorization, which introduces structural inconsistencies and hinders end-to-end learning. Motivated by compositional spatial reasoning, we propose TLC-Plan, a hierarchical generative model that directly synthesizes vector floorplans from input boundaries, aligning with human architectural workflows based on modular and reusable patterns. TLC-Plan employs a two-level VQ-VAE to encode global layouts as semantically labeled room bounding boxes and to refine local geometries using polygon-level codes. This hierarchy is unified in a CodeTree representation, while an autoregressive transformer samples codes conditioned on the boundary to generate diverse and topologically valid designs, without requiring explicit room topology or dimensional priors. Extensive experiments show state-of-the-art performance on RPLAN dataset (FID = 1.84, MSE = 2.06) and leading results on LIFULL dataset. The proposed framework advances constraint-aware and scalable vector floorplan generation for real-world architectural applications. Source code and trained models are released at https://github.com/rosolose/TLC-PLAN.

</details>


### [30] [Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting](https://arxiv.org/abs/2602.07101)
*Zinan Lv,Yeqian Qian,Chen Sang,Hao Liu,Danping Zou,Ming Yang*

Main category: cs.CV

TL;DR: 提出基于可重光照3D高斯溅射的端到端强化学习框架，实现无人机在非结构化室外环境的零样本导航，克服仿真与现实间的视觉域差距和光照变化问题。


<details>
  <summary>Details</summary>
Motivation: 无人机在非结构化室外环境使用单目视觉导航面临仿真与现实间的视觉域差距问题，现有3D高斯溅射方法将静态光照与几何耦合，限制了策略在动态真实光照下的泛化能力。

Method: 提出可重光照3D高斯溅射技术，分解场景组件实现物理基础的光照编辑；在基于真实数据的高保真仿真中训练端到端强化学习策略，通过多样合成光照条件增强训练，使策略学习光照不变的视觉特征。

Result: 轻量级四旋翼在复杂森林环境中实现高达10 m/s的鲁棒无碰撞导航，对剧烈光照变化表现出显著韧性，无需微调即可零样本迁移到真实世界。

Conclusion: 通过可重光照神经表示和光照增强训练，实现了无人机在非结构化室外环境的鲁棒视觉导航，有效解决了仿真到现实的视觉域差距和光照变化挑战。

Abstract: UAV navigation in unstructured outdoor environments using passive monocular vision is hindered by the substantial visual domain gap between simulation and reality. While 3D Gaussian Splatting enables photorealistic scene reconstruction from real-world data, existing methods inherently couple static lighting with geometry, severely limiting policy generalization to dynamic real-world illumination. In this paper, we propose a novel end-to-end reinforcement learning framework designed for effective zero-shot transfer to unstructured outdoors. Within a high-fidelity simulation grounded in real-world data, our policy is trained to map raw monocular RGB observations directly to continuous control commands. To overcome photometric limitations, we introduce Relightable 3D Gaussian Splatting, which decomposes scene components to enable explicit, physically grounded editing of environmental lighting within the neural representation. By augmenting training with diverse synthesized lighting conditions ranging from strong directional sunlight to diffuse overcast skies, we compel the policy to learn robust, illumination-invariant visual features. Extensive real-world experiments demonstrate that a lightweight quadrotor achieves robust, collision-free navigation in complex forest environments at speeds up to 10 m/s, exhibiting significant resilience to drastic lighting variations without fine-tuning.

</details>


### [31] [Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models](https://arxiv.org/abs/2602.07106)
*Haoyu Zhang,Zhipeng Li,Yiwen Guo,Tianshu Yu*

Main category: cs.CV

TL;DR: Ex-Omni是一个开源的全模态框架，通过解耦语义推理与时间生成，利用语音单元作为时间支架，实现语音伴随的3D面部动画生成。


<details>
  <summary>Details</summary>
Motivation: 当前全模态大语言模型（OLLMs）在多模态理解和生成方面取得了进展，但结合语音与3D面部动画的研究仍然不足，这对于自然交互至关重要。主要挑战在于LLMs的离散、token级语义推理与3D面部运动所需的密集、细粒度时间动态之间存在表示不匹配。

Method: 提出Ex-Omni框架，通过解耦语义推理与时间生成来降低学习难度：1）利用语音单元作为时间支架；2）采用统一的token-as-query gated fusion（TQGF）机制进行受控语义注入；3）引入InstructEx数据集来支持训练。

Result: 大量实验表明，Ex-Omni在性能上与现有开源OLLMs竞争，同时能够稳定生成对齐的语音和面部动画。

Conclusion: Ex-Omni成功解决了语音与3D面部动画结合的技术挑战，通过解耦策略和TQGF机制实现了稳定的多模态生成，为全模态交互系统提供了有效解决方案。

Abstract: Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.

</details>


### [32] [Privacy in Image Datasets: A Case Study on Pregnancy Ultrasounds](https://arxiv.org/abs/2602.07149)
*Rawisara Lohanimit,Yankun Wu,Amelia Katirai,Yuta Nakashima,Noa Garcia*

Main category: cs.CV

TL;DR: 通过CLIP嵌入相似性在LAION-400M数据集中系统检索怀孕超声图像，发现数千条包含姓名、位置等敏感个人信息的高风险图像，提出了数据集管理、隐私保护和伦理使用的建议


<details>
  <summary>Details</summary>
Motivation: 生成模型的兴起导致大量从互联网收集的数据集被使用，这些数据集通常缺乏数据筛选，引发了对敏感或隐私信息包含的担忧。本研究特别关注怀孕超声图像这类包含敏感个人信息且常被在线分享的内容

Method: 使用CLIP嵌入相似性对LAION-400M数据集进行系统检查，检索包含怀孕超声的图像，并检测其中的隐私信息实体（如姓名和位置）

Result: 发现了数千个包含姓名、位置等隐私信息的实体，多个图像包含高风险信息，可能导致重新识别或身份冒充

Conclusion: 提出了数据集管理、数据隐私和公共图像数据集伦理使用的推荐实践，强调需要更好的数据筛选和隐私保护措施

Abstract: The rise of generative models has led to increased use of large-scale datasets collected from the internet, often with minimal or no data curation. This raises concerns about the inclusion of sensitive or private information. In this work, we explore the presence of pregnancy ultrasound images, which contain sensitive personal information and are often shared online. Through a systematic examination of LAION-400M dataset using CLIP embedding similarity, we retrieve images containing pregnancy ultrasound and detect thousands of entities of private information such as names and locations. Our findings reveal that multiple images have high-risk information that could enable re-identification or impersonation. We conclude with recommended practices for dataset curation, data privacy, and ethical use of public image datasets.

</details>


### [33] [DuMeta++: Spatiotemporal Dual Meta-Learning for Generalizable Few-Shot Brain Tissue Segmentation Across Diverse Ages](https://arxiv.org/abs/2602.07174)
*Yongheng Sun,Jun Shu,Jianhua Ma,Fan Wang*

Main category: cs.CV

TL;DR: DuMeta++：一种无需配对纵向数据的双元学习框架，用于跨年龄脑组织分割，通过元特征学习和元初始化学习实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑MRI组织分割在神经科学和临床应用中至关重要，但由于大脑外观和形态随年龄变化的动态性，实现跨人类生命周期的稳定性能具有挑战性。现有方法通常依赖配对纵向数据进行自监督正则化，但这类数据在实践中往往难以获得。

Method: 提出DuMeta++双元学习框架：1）元特征学习提取年龄无关的时空演化脑结构语义表示；2）元初始化学习实现数据高效的分割模型适应；3）基于记忆库的类感知正则化策略，无需显式纵向监督即可强制纵向一致性。理论证明了算法的收敛性。

Result: 在iSeg-2019、IBIS、OASIS、ADNI等多个数据集上的少样本设置实验中，DuMeta++在跨年龄泛化方面优于现有方法。

Conclusion: DuMeta++无需配对纵向数据即可实现跨年龄脑组织分割的稳定性能，通过双元学习框架和类感知正则化策略有效解决了年龄相关变化带来的挑战，在多个数据集上表现出优越的泛化能力。

Abstract: Accurate segmentation of brain tissues from MRI scans is critical for neuroscience and clinical applications, but achieving consistent performance across the human lifespan remains challenging due to dynamic, age-related changes in brain appearance and morphology. While prior work has sought to mitigate these shifts by using self-supervised regularization with paired longitudinal data, such data are often unavailable in practice. To address this, we propose \emph{DuMeta++}, a dual meta-learning framework that operates without paired longitudinal data. Our approach integrates: (1) meta-feature learning to extract age-agnostic semantic representations of spatiotemporally evolving brain structures, and (2) meta-initialization learning to enable data-efficient adaptation of the segmentation model. Furthermore, we propose a memory-bank-based class-aware regularization strategy to enforce longitudinal consistency without explicit longitudinal supervision. We theoretically prove the convergence of our DuMeta++, ensuring stability. Experiments on diverse datasets (iSeg-2019, IBIS, OASIS, ADNI) under few-shot settings demonstrate that DuMeta++ outperforms existing methods in cross-age generalization. Code will be available at https://github.com/ladderlab-xjtu/DuMeta++.

</details>


### [34] [Condition Matters in Full-head 3D GANs](https://arxiv.org/abs/2602.07198)
*Heyuan Li,Huimin Zhang,Yuda Qiu,Zhengwentai Sun,Keru Zheng,Lingteng Qiu,Peihao Li,Qi Zuo,Ce Chen,Yujian Zheng,Yuming Gu,Zilong Dong,Xiaoguang Han*

Main category: cs.CV

TL;DR: 提出使用视角不变语义特征作为条件输入，解决传统3D头部GAN中因使用视角角度作为条件导致的生成偏差问题，提升3D头部生成的全局一致性和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统全头部3D GAN使用视角角度作为条件输入，导致学习的3D头部空间存在视角方向偏差，生成质量在不同视角间差异显著，全局一致性差。需要消除这种视角依赖的偏差。

Method: 1) 使用视角不变语义特征作为条件输入，而非视角角度；2) 创建合成头部图像数据集，利用FLUX.1 Kontext扩展现有高质量正面人脸数据集到多视角；3) 使用正面视图提取的图像clip特征作为所有视角的共享语义条件。

Result: 方法在3D头部合成和单视图GAN反演任务中表现出显著更高的保真度、多样性和泛化能力，解决了视角偏差问题，提升了全局一致性。

Conclusion: 视角不变语义条件输入能有效解耦3D头部生成能力与视角方向的依赖，消除传统方法中的视角偏差，提升生成质量和多样性，同时加速训练过程。

Abstract: Conditioning is crucial for stable training of full-head 3D GANs. Without any conditioning signal, the model suffers from severe mode collapse, making it impractical to training. However, a series of previous full-head 3D GANs conventionally choose the view angle as the conditioning input, which leads to a bias in the learned 3D full-head space along the conditional view direction. This is evident in the significant differences in generation quality and diversity between the conditional view and non-conditional views of the generated 3D heads, resulting in global incoherence across different head regions. In this work, we propose to use view-invariant semantic feature as the conditioning input, thereby decoupling the generative capability of 3D heads from the viewing direction. To construct a view-invariant semantic condition for each training image, we create a novel synthesized head image dataset. We leverage FLUX.1 Kontext to extend existing high-quality frontal face datasets to a wide range of view angles. The image clip feature extracted from the frontal view is then used as a shared semantic condition across all views in the extended images, ensuring semantic alignment while eliminating directional bias. This also allows supervision from different views of the same subject to be consolidated under a shared semantic condition, which accelerates training and enhances the global coherence of the generated 3D heads. Moreover, as GANs often experience slower improvements in diversity once the generator learns a few modes that successfully fool the discriminator, our semantic conditioning encourages the generator to follow the true semantic distribution, thereby promoting continuous learning and diverse generation. Extensive experiments on full-head synthesis and single-view GAN inversion demonstrate that our method achieves significantly higher fidelity, diversity, and generalizability.

</details>


### [35] [Understanding Real-World Traffic Safety through RoadSafe365 Benchmark](https://arxiv.org/abs/2602.07212)
*Xinyu Liu,Darryl C. Jacob,Yuxin Liu,Xinsong Du,Muchao Ye,Bolei Zhou,Pan He*

Main category: cs.CV

TL;DR: RoadSafe365是一个大规模视觉语言基准，用于细粒度交通安全性分析，包含36,196个标注视频片段和864K候选选项，填补了现有基准缺乏官方安全标准系统评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有交通基准虽然推进了多模态数据分析，但缺乏与官方安全标准对齐的系统性评估。需要填补这一空白，建立能够连接官方交通安全标准与数据驱动交通理解系统的基准。

Method: 构建RoadSafe365基准，采用分层分类法系统组织，细化和扩展了碰撞、事故和违规的基础定义。从行车记录仪和监控摄像头收集真实世界视频数据，提供丰富的属性标注，包括交通事件类型、环境背景和交互场景。每个片段都配有多选题-答案集和详细场景描述。

Result: 建立了包含36,196个标注片段的大规模基准，包含864K候选选项、8.4K独特答案和36K详细场景描述。在RoadSafe365上微调显示了一致的性能提升，跨领域实验（包括真实和合成数据集）进一步验证了其有效性。

Conclusion: RoadSafe365为大规模训练和标准化评估设计，提供了一个全面的基准，能够推进真实世界交通安全性分析的可重复研究，弥合了官方安全标准与数据驱动系统之间的差距。

Abstract: Although recent traffic benchmarks have advanced multimodal data analysis, they generally lack systematic evaluation aligned with official safety standards. To fill this gap, we introduce RoadSafe365, a large-scale vision-language benchmark that supports fine-grained analysis of traffic safety from extensive and diverse real-world video data collections. Unlike prior works that focus primarily on coarse accident identification, RoadSafe365 is independently curated and systematically organized using a hierarchical taxonomy that refines and extends foundational definitions of crash, incident, and violation to bridge official traffic safety standards with data-driven traffic understanding systems. RoadSafe365 provides rich attribute annotations across diverse traffic event types, environmental contexts, and interaction scenarios, yielding 36,196 annotated clips from both dashcam and surveillance cameras. Each clip is paired with multiple-choice question-answer sets, comprising 864K candidate options, 8.4K unique answers, and 36K detailed scene descriptions collectively designed for vision-language understanding and reasoning. We establish strong baselines and observe consistent gains when fine-tuning on RoadSafe365. Cross-domain experiments on both real and synthetic datasets further validate its effectiveness. Designed for large-scale training and standardized evaluation, RoadSafe365 provides a comprehensive benchmark to advance reproducible research in real-world traffic safety analysis.

</details>


### [36] [The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models](https://arxiv.org/abs/2602.07251)
*Haley Duba-Sullivan,Steven R. Young,Emma J. Reid*

Main category: cs.CV

TL;DR: AdvSR是一种将对抗性行为嵌入超分辨率模型权重的框架，无需推理时访问输入，可在保持图像质量的同时诱导下游分类错误


<details>
  <summary>Details</summary>
Motivation: 数据驱动的超分辨率方法常作为成像管道预处理步骤，但这些SR模型引入了新的攻击面。现有攻击通常扰动输入或依赖后门触发器，而AdvSR探索在模型层面嵌入对抗行为的新威胁

Method: AdvSR在训练期间直接优化SR模型权重，联合优化重建质量和目标对抗结果。通过同时最小化重建损失和最大化下游分类错误，产生在标准图像质量指标下看似良性但能诱导误分类的模型

Result: 在三种SR架构（SRCNN、EDSR、SwinIR）与YOLOv11分类器配对评估中，AdvSR模型能以最小质量退化实现高攻击成功率，展示了模型层面的新威胁

Conclusion: AdvSR揭示了成像管道中新的模型级安全威胁，对安全关键应用中模型来源和验证方式有重要影响，需要更严格的模型验证机制

Abstract: Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inputs at inference time. Unlike prior attacks that perturb inputs or rely on backdoor triggers, AdvSR operates entirely at the model level. By jointly optimizing for reconstruction quality and targeted adversarial outcomes, AdvSR produces models that appear benign under standard image quality metrics while inducing downstream misclassification. We evaluate AdvSR on three SR architectures (SRCNN, EDSR, SwinIR) paired with a YOLOv11 classifier and demonstrate that AdvSR models can achieve high attack success rates with minimal quality degradation. These findings highlight a new model-level threat for imaging pipelines, with implications for how practitioners source and validate models in safety-critical applications.

</details>


### [37] [3D Transport-based Morphometry (3D-TBM) for medical image analysis](https://arxiv.org/abs/2602.07260)
*Hongyu Kan,Kristofor Pas,Ivan Medri,Naqib Sad Pathan,Natasha Ironside,Shinjini Kundu,Jingjia He,Gustavo Kunde Rohde*

Main category: cs.CV

TL;DR: 3D-TBM：基于最优传输的3D医学图像形态分析工具，通过可逆变换将图像嵌入传输域进行分析，并将结果投影回原始图像空间进行空间解释


<details>
  <summary>Details</summary>
Motivation: 促进基于传输的形态测量学（TBM）在临床影像研究中的更广泛应用，为3D医学图像分析提供可解释的形态学分析框架

Method: 开发3D-TBM工具，包括数据预处理、最优传输嵌入计算、主要传输方向可视化、判别方向识别等分析方法，提供完整文档和教程

Result: 开发了公开可用的3D-TBM工具，源代码通过PyTransKit提供，支持研究人员在自己的医学影像研究中应用该框架

Conclusion: 3D-TBM为3D医学图像的形态分析提供了有效的基于传输的框架，通过可逆映射实现分析结果的空间可解释性，有助于临床特征识别和研究

Abstract: Transport-Based Morphometry (TBM) has emerged as a new framework for 3D medical image analysis. By embedding images into a transport domain via invertible transformations, TBM facilitates effective classification, regression, and other tasks using transport-domain features. Crucially, the inverse mapping enables the projection of analytic results back into the original image space, allowing researchers to directly interpret clinical features associated with model outputs in a spatially meaningful way. To facilitate broader adoption of TBM in clinical imaging research, we present 3D-TBM, a tool designed for morphological analysis of 3D medical images. The framework includes data preprocessing, computation of optimal transport embeddings, and analytical methods such as visualization of main transport directions, together with techniques for discerning discriminating directions and related analysis methods. We also provide comprehensive documentation and practical tutorials to support researchers interested in applying 3D-TBM in their own medical imaging studies. The source code is publicly available through PyTransKit.

</details>


### [38] [TwistNet-2D: Learning Second-Order Channel Interactions via Spiral Twisting for Texture Recognition](https://arxiv.org/abs/2602.07262)
*Junbo Jacob Lian,Feng Xiong,Yujun Sun,Kaichen Ouyang,Mingyang Yu,Shengwei Fu,Zhong Rui,Zhang Yujun,Huiling Chen*

Main category: cs.CV

TL;DR: TwistNet-2D是一个轻量级模块，通过局部成对通道乘积和方向性空间位移来捕捉纹理特征，在保持低计算成本的同时显著提升纹理识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有纹理识别方法存在根本矛盾：双线性池化和Gram矩阵能捕捉全局通道相关性但会破坏空间结构，而自注意力通过加权聚合建模空间上下文而非显式的成对特征交互。需要一种能同时编码特征共现位置和交互方式的方法。

Method: 提出TwistNet-2D模块，核心是螺旋扭曲通道交互(STCI)：将特征图沿预定方向位移后进行逐通道元素乘法，捕捉结构化纹理的跨位置共现模式。通过四个方向头聚合，结合学习到的通道重加权，并通过sigmoid门控残差路径注入。

Result: TwistNet-2D仅增加ResNet-18的3.5%参数和2%FLOPs，但在四个纹理和细粒度识别基准上持续超越参数匹配和更大的基线模型，包括ConvNeXt、Swin Transformer和混合CNN-Transformer架构。

Conclusion: TwistNet-2D通过局部成对通道交互和方向性空间位移，有效解决了纹理识别中全局相关性与空间结构保持的矛盾，以极低的计算成本实现了显著的性能提升。

Abstract: Second-order feature statistics are central to texture recognition, yet current methods face a fundamental tension: bilinear pooling and Gram matrices capture global channel correlations but collapse spatial structure, while self-attention models spatial context through weighted aggregation rather than explicit pairwise feature interactions. We introduce TwistNet-2D, a lightweight module that computes \emph{local} pairwise channel products under directional spatial displacement, jointly encoding where features co-occur and how they interact. The core component, Spiral-Twisted Channel Interaction (STCI), shifts one feature map along a prescribed direction before element-wise channel multiplication, thereby capturing the cross-position co-occurrence patterns characteristic of structured and periodic textures. Aggregating four directional heads with learned channel reweighting and injecting the result through a sigmoid-gated residual path, \TwistNet incurs only 3.5% additional parameters and 2% additional FLOPs over ResNet-18, yet consistently surpasses both parameter-matched and substantially larger baselines -- including ConvNeXt, Swin Transformer, and hybrid CNN--Transformer architectures -- across four texture and fine-grained recognition benchmarks.

</details>


### [39] [VideoNeuMat: Neural Material Extraction from Generative Video Models](https://arxiv.org/abs/2602.07272)
*Bowen Xue,Saeed Hadadan,Zheng Zeng,Fabrice Rousselle,Zahra Montazeri,Milos Hasan*

Main category: cs.CV

TL;DR: VideoNeuMat：从视频扩散模型中提取可重用神经材质资产的两阶段流程，将视频模型的材质知识转化为独立可用的3D神经材质


<details>
  <summary>Details</summary>
Motivation: 创建逼真的3D渲染材质需要极高的艺术技巧，而生成模型因缺乏高质量训练数据而受限。视频生成模型能产生逼真的材质外观，但这些知识与几何和光照纠缠在一起，无法直接重用。

Method: 两阶段流程：1）微调大型视频模型（Wan 2.1 14B）在受控相机和光照轨迹下生成材质样本视频，创建"虚拟测角反射计"；2）通过从较小Wan 1.3B视频骨干微调的大型重建模型（LRM），从17个生成视频帧中重建紧凑的神经材质参数。

Result: 从17个生成帧中单次推理预测神经材质参数，能够泛化到新的视角和光照条件。生成的材质在真实感和多样性上远超有限的合成训练数据。

Conclusion: 成功将互联网规模视频模型中的材质知识转移到独立可重用的神经3D资产中，证明了从视频扩散模型提取可重用神经材质资产的可行性。

Abstract: Creating photorealistic materials for 3D rendering requires exceptional artistic skill. Generative models for materials could help, but are currently limited by the lack of high-quality training data. While recent video generative models effortlessly produce realistic material appearances, this knowledge remains entangled with geometry and lighting. We present VideoNeuMat, a two-stage pipeline that extracts reusable neural material assets from video diffusion models. First, we finetune a large video model (Wan 2.1 14B) to generate material sample videos under controlled camera and lighting trajectories, effectively creating a "virtual gonioreflectometer" that preserves the model's material realism while learning a structured measurement pattern. Second, we reconstruct compact neural materials from these videos through a Large Reconstruction Model (LRM) finetuned from a smaller Wan 1.3B video backbone. From 17 generated video frames, our LRM performs single-pass inference to predict neural material parameters that generalize to novel viewing and lighting conditions. The resulting materials exhibit realism and diversity far exceeding the limited synthetic training data, demonstrating that material knowledge can be successfully transferred from internet-scale video models into standalone, reusable neural 3D assets.

</details>


### [40] [Cross-View World Models](https://arxiv.org/abs/2602.07277)
*Rishabh Sharma,Gijs Hogervorst,Wayne E. Mackey,David J. Heeger,Stefano Martiniani*

Main category: cs.CV

TL;DR: XVWM通过跨视角预测目标训练世界模型，使智能体能够从不同视角（如鸟瞰图）进行规划，同时保持自我中心视角执行，利用多视角一致性作为几何正则化学习环境3D结构


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常只从单一自我中心视角操作，即使其他视角（如鸟瞰图）在某些任务（如导航）中能显著简化规划过程。需要开发能够跨不同视角进行预测和规划的世界模型

Method: 提出跨视角世界模型（XVWM），使用跨视角预测目标进行训练：给定一个视角的帧序列，预测执行动作后相同或不同视角的未来状态。在Aimlabs平台的多视角游戏数据上训练，该平台提供精确对齐的多摄像头记录和高频动作标签

Result: 模型为智能体提供跨视角的并行想象流，使智能体能够在最适合任务的参考系中进行规划，同时从自我中心视角执行。多视角一致性为空间基础表示提供了强大的学习信号

Conclusion: 跨视角世界模型通过几何正则化学习环境3D结构，使智能体能够从不同视角进行规划。从他人视角预测自身行动后果可能为多智能体环境中的视角采择奠定基础

Abstract: World models enable agents to plan by imagining future states, but existing approaches operate from a single viewpoint, typically egocentric, even when other perspectives would make planning easier; navigation, for instance, benefits from a bird's-eye view. We introduce Cross-View World Models (XVWM), trained with a cross-view prediction objective: given a sequence of frames from one viewpoint, predict the future state from the same or a different viewpoint after an action is taken. Enforcing cross-view consistency acts as geometric regularization: because the input and output views may share little or no visual overlap, to predict across viewpoints, the model must learn view-invariant representations of the environment's 3D structure. We train on synchronized multi-view gameplay data from Aimlabs, an aim-training platform providing precisely aligned multi-camera recordings with high-frequency action labels. The resulting model gives agents parallel imagination streams across viewpoints, enabling planning in whichever frame of reference best suits the task while executing from the egocentric view. Our results show that multi-view consistency provides a strong learning signal for spatially grounded representations. Finally, predicting the consequences of one's actions from another viewpoint may offer a foundation for perspective-taking in multi-agent settings.

</details>


### [41] [Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms](https://arxiv.org/abs/2602.07301)
*Aruna Jithesh,Chinmayi Karumuri,Venkata Kiran Reddy Kotha,Meghana Doddapuneni,Taehee Jeong*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的DeepLab-V3+模型，用于糖尿病视网膜病变（DR）相关病变的像素级分割，在DDR数据集上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是导致视力丧失和失明的严重眼病，早期筛查至关重要。虽然已有许多基于深度学习的自动筛查算法，但在病变分割方面的临床应用仍有限制。本文旨在提供像素级病变标注，以实际支持眼科医生从眼底图像中筛查DR。

Method: 在757张DDR数据集图像上分割四种DR相关病变：微动脉瘤、软性渗出物、硬性渗出物和出血。采用注意力机制与DeepLab-V3+结合的方法，构建Attention-DeepLab模型来增强病变分割能力。

Result: 与基线模型相比，Attention-DeepLab模型将平均精度（mAP）从0.3010提升至0.3326，平均交并比（IoU）从0.1791提升至0.1928。微动脉瘤检测从0.0205显著提升至0.0763，这在临床上具有重要意义，因为微动脉瘤是DR最早可见的症状。

Conclusion: 集成注意力机制的DeepLab-V3+模型在DR病变分割方面表现出性能提升，特别是在微动脉瘤检测方面取得了临床显著改进，有助于早期DR筛查和预防不可逆的视力丧失。

Abstract: Diabetic Retinopathy (DR) is an eye disease which arises due to diabetes mellitus. It might cause vision loss and blindness. To prevent irreversible vision loss, early detection through systematic screening is crucial. Although researchers have developed numerous automated deep learning-based algorithms for DR screening, their clinical applicability remains limited, particularly in lesion segmentation. Our method provides pixel-level annotations for lesions, which practically supports Ophthalmologist to screen DR from fundus images. In this work, we segmented four types of DR-related lesions: microaneurysms, soft exudates, hard exudates, and hemorrhages on 757 images from DDR dataset. To enhance lesion segmentation, an attention mechanism was integrated with DeepLab-V3+. Compared to the baseline model, the Attention-DeepLab model increases mean average precision (mAP) from 0.3010 to 0.3326 and the mean Intersection over Union (IoU) from 0.1791 to 0.1928. The model also increased microaneurysm detection from 0.0205 to 0.0763, a clinically significant improvement. The detection of microaneurysms is the earliest visible symptom of DR.

</details>


### [42] [Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing](https://arxiv.org/abs/2602.07310)
*Kyle Williams,Andrew Seltzman*

Main category: cs.CV

TL;DR: 该研究开发了一种基于线性遗传编程的图像过滤和分割算法，用于自动检测增材制造铌基铜合金中的析出物，替代了传统的手动标注方法，显著提高了合金开发迭代速度。


<details>
  <summary>Details</summary>
Motivation: 当前增材制造铌基铜合金的分析依赖手动标注，由于显微图像中存在对比度变化、噪声和图像伪影等问题，这严重拖慢了合金开发的迭代速度。需要自动化解决方案来加速材料成分和工艺空间的探索。

Method: 采用线性遗传编程优化图像过滤和分割算法，使用特定领域语言构建图像处理流程。该语言中的程序是一系列可调参数的图像过滤块，通过遗传算法进行可靠生成和变异，最终生成可解释的MATLAB代码表示的图像处理管道。

Result: 在理想条件下（种群大小60，最大程序长度5个块），系统找到了接近人类准确度的解决方案，平均评估误差为1.8%（通过像素级XOR误差评估与人工基准比较）。优化后的管道算法平均处理360万像素图像仅需约2秒。

Conclusion: 该自动化工作实现了更快的迭代周期，促进了材料成分和工艺空间的探索，最终有助于开发用于增材制造聚变反应堆部件的强韧、低活化、沉淀硬化铜合金。

Abstract: Current analysis of additive manufactured niobium-based copper alloys relies on hand annotation due to varying contrast, noise, and image artifacts present in micrographs, slowing iteration speed in alloy development. We present a filtering and segmentation algorithm for detecting precipitates in FIB cross-section micrographs, optimized using linear genetic programming (LGP), which accounts for the various artifacts. To this end, the optimization environment uses a domain-specific language for image processing to iterate on solutions. Programs in this language are a list of image-filtering blocks with tunable parameters that sequentially process an input image, allowing for reliable generation and mutation by a genetic algorithm. Our environment produces optimized human-interpretable MATLAB code representing an image filtering pipeline. Under ideal conditions--a population size of 60 and a maximum program length of 5 blocks--our system was able to find a near-human accuracy solution with an average evaluation error of 1.8% when comparing segmentations pixel-by-pixel to a human baseline using an XOR error evaluation. Our automation work enabled faster iteration cycles and furthered exploration of the material composition and processing space: our optimized pipeline algorithm processes a 3.6 megapixel image in about 2 seconds on average. This ultimately enables convergence on strong, low-activation, precipitation hardened copper alloys for additive manufactured fusion reactor parts.

</details>


### [43] [LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery](https://arxiv.org/abs/2602.07311)
*Difei Gu,Yunhe Gao,Gerasimos Chatzoudis,Zihan Dong,Guoning Zhang,Bangwei Guo,Yang Zhou,Mu Zhou,Dimitris Metaxas*

Main category: cs.CV

TL;DR: LUCID提出了一种统一的视觉-语言稀疏自编码器，通过共享潜在字典学习跨模态对齐的特征表示，实现可解释的概念发现。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器按模态单独训练，产生的特征字典缺乏直接可解释性，且解释无法跨域迁移。需要一种统一的方法来学习跨模态对齐的可解释特征表示。

Method: 提出LUCID框架：1) 学习图像块和文本标记的共享潜在字典，同时保留模态特定细节的私有容量；2) 通过最优传输匹配目标实现特征对齐，无需标注；3) 开发基于术语聚类的自动字典解释流程。

Result: LUCID产生可解释的共享特征，支持块级定位，建立跨模态神经元对应关系，增强对相似性评估中概念聚类问题的鲁棒性。共享特征捕获了超越对象的多样化语义类别，包括动作、属性和抽象概念。

Conclusion: LUCID为可解释的多模态表示提供了一种全面方法，通过统一的视觉-语言稀疏编码实现跨模态概念发现和解释，为理解多模态模型内部表示提供了新途径。

Abstract: Sparse autoencoders (SAEs) offer a natural path toward comparable explanations across different representation spaces. However, current SAEs are trained per modality, producing dictionaries whose features are not directly understandable and whose explanations do not transfer across domains. In this study, we introduce LUCID (Learning Unified vision-language sparse Codes for Interpretable concept Discovery), a unified vision-language sparse autoencoder that learns a shared latent dictionary for image patch and text token representations, while reserving private capacity for modality-specific details. We achieve feature alignment by coupling the shared codes with a learned optimal transport matching objective without the need of labeling. LUCID yields interpretable shared features that support patch-level grounding, establish cross-modal neuron correspondence, and enhance robustness against the concept clustering problem in similarity-based evaluation. Leveraging the alignment properties, we develop an automated dictionary interpretation pipeline based on term clustering without manual observations. Our analysis reveals that LUCID's shared features capture diverse semantic categories beyond objects, including actions, attributes, and abstract concepts, demonstrating a comprehensive approach to interpretable multimodal representations.

</details>


### [44] [Row-Column Separated Attention Based Low-Light Image/Video Enhancement](https://arxiv.org/abs/2602.07428)
*Chengqi Dong,Zhiyuan Cao,Tuoshi Qi,Kexin Wu,Yixing Gao,Fan Tang*

Main category: cs.CV

TL;DR: 提出了一种基于改进U-Net和行列分离注意力模块的低光图像/视频增强方法，通过全局信息指导局部信息，减少参数和计算量，并引入时间损失函数保持视频时序一致性。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net结构在低光图像增强中缺乏全局信息指导，导致局部噪声大和细节丢失；注意力机制能更好利用全局信息但参数和计算量大。

Method: 1. 改进U-Net结构；2. 提出行列分离注意力模块(RCSA)，输入特征图行列的均值和最大值，以较少参数利用全局信息指导局部信息；3. 提出两种时间损失函数用于低光视频增强，保持时序一致性。

Result: 在LOL、MIT Adobe FiveK图像数据集和SDSD视频数据集上的大量实验证明了该方法的有效性。

Conclusion: 提出的URCSA方法通过行列分离注意力模块有效利用全局信息指导局部增强，在减少参数的同时提升了低光图像/视频增强质量，并保持了视频时序一致性。

Abstract: U-Net structure is widely used for low-light image/video enhancement. The enhanced images result in areas with large local noise and loss of more details without proper guidance for global information. Attention mechanisms can better focus on and use global information. However, attention to images could significantly increase the number of parameters and computations. We propose a Row-Column Separated Attention module (RCSA) inserted after an improved U-Net. The RCSA module's input is the mean and maximum of the row and column of the feature map, which utilizes global information to guide local information with fewer parameters. We propose two temporal loss functions to apply the method to low-light video enhancement and maintain temporal consistency. Extensive experiments on the LOL, MIT Adobe FiveK image, and SDSD video datasets demonstrate the effectiveness of our approach. The code is publicly available at https://github.com/cq-dong/URCSA.

</details>


### [45] [Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction](https://arxiv.org/abs/2602.07444)
*Ondrej Hlinka,Georg Kaniak,Christian Kapeller*

Main category: cs.CV

TL;DR: 提出一种透视感知的对数深度融合方法，从单视角相机获取的深度和法线图重建3D表面，处理缺失深度测量并实现度量精确的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的深度-法线融合方法主要针对正交投影，而实际传感器系统通常使用透视投影，这导致重建结果在度量上不准确。需要一种能够显式处理透视投影的融合方法。

Method: 提出透视感知的对数深度融合方法，将现有的正交梯度基深度-法线融合方法扩展到透视投影场景。该方法利用对数深度表示，显式考虑透视投影效应，并利用可用的表面法线信息来填补深度测量中的缺失区域。

Result: 在DiLiGenT-MV数据集上的实验证明了该方法的有效性，并突出了透视感知深度-法线融合的重要性。该方法能够实现度量精确的3D重建，并有效处理深度测量中的缺失区域。

Conclusion: 提出的透视感知对数深度融合方法能够从单视角相机获取的深度和法线图实现度量精确的3D表面重建，显式处理透视投影效应并填补深度测量缺失，在真实数据集上验证了其有效性。

Abstract: We address the problem of reconstructing 3D surfaces from depth and surface normal maps acquired by a sensor system based on a single perspective camera. Depth and normal maps can be obtained through techniques such as structured-light scanning and photometric stereo, respectively. We propose a perspective-aware log-depth fusion approach that extends existing orthographic gradient-based depth-normals fusion methods by explicitly accounting for perspective projection, leading to metrically accurate 3D reconstructions. Additionally, the method handles missing depth measurements by leveraging available surface normal information to inpaint gaps. Experiments on the DiLiGenT-MV data set demonstrate the effectiveness of our approach and highlight the importance of perspective-aware depth-normals fusion.

</details>


### [46] [PTB-XL-Image-17K: A Large-Scale Synthetic ECG Image Dataset with Comprehensive Ground Truth for Deep Learning-Based Digitization](https://arxiv.org/abs/2602.07446)
*Naqcho Ali Mehdi*

Main category: cs.CV

TL;DR: PTB-XL-Image-17K是一个包含17,271个高质量12导联心电图图像的合成数据集，为心电图数字化研究提供首个大规模资源，支持完整的检测、分割和信号提取流程。


<details>
  <summary>Details</summary>
Motivation: 心电图数字化对于利用数十年遗留临床数据在现代深度学习应用中至关重要，但缺乏大规模同时包含心电图图像和对应真实信号标注的数据集阻碍了研究进展。

Method: 基于PTB-XL信号数据库，开发开源Python框架生成合成心电图图像，提供五种互补数据类型：真实心电图图像、像素级分割掩码、时间序列信号、YOLO格式边界框标注以及包含视觉参数和患者信息的元数据。

Result: 数据集包含17,271个样本，生成成功率100%，平均处理时间每样本1.35秒，提供可自定义参数包括走纸速度、电压标度、采样率、网格外观和波形特征。

Conclusion: PTB-XL-Image-17K填补了心电图数字化研究的关键空白，为首个支持完整流程的大规模资源，包括导联检测、波形分割和信号提取，为严格评估提供完整真实数据。

Abstract: Electrocardiogram (ECG) digitization-converting paper-based or scanned ECG images back into time-series signals-is critical for leveraging decades of legacy clinical data in modern deep learning applications. However, progress has been hindered by the lack of large-scale datasets providing both ECG images and their corresponding ground truth signals with comprehensive annotations. We introduce PTB-XL-Image-17K, a complete synthetic ECG image dataset comprising 17,271 high-quality 12-lead ECG images generated from the PTB-XL signal database. Our dataset uniquely provides five complementary data types per sample: (1) realistic ECG images with authentic grid patterns and annotations (50% with visible grid, 50% without), (2) pixel-level segmentation masks, (3) ground truth time-series signals, (4) bounding box annotations in YOLO format for both lead regions and lead name labels, and (5) comprehensive metadata including visual parameters and patient information. We present an open-source Python framework enabling customizable dataset generation with controllable parameters including paper speed (25/50 mm/s), voltage scale (5/10 mm/mV), sampling rate (500 Hz), grid appearance (4 colors), and waveform characteristics. The dataset achieves 100% generation success rate with an average processing time of 1.35 seconds per sample. PTB-XL-Image-17K addresses critical gaps in ECG digitization research by providing the first large-scale resource supporting the complete pipeline: lead detection, waveform segmentation, and signal extraction with full ground truth for rigorous evaluation. The dataset, generation framework, and documentation are publicly available at https://github.com/naqchoalimehdi/PTB-XL-Image-17K and https://doi.org/10.5281/zenodo.18197519.

</details>


### [47] [SoulX-FlashHead: Oracle-guided Generation of Infinite Real-time Streaming Talking Heads](https://arxiv.org/abs/2602.07449)
*Tan Yu,Qian Qiao,Le Shen,Ke Zhou,Jincheng Hu,Dian Sheng,Bo Hu,Haoming Qin,Jun Gao,Changhai Zhou,Shunshun Yin,Siyuan Liu*

Main category: cs.CV

TL;DR: SoulX-FlashHead：一个1.3B参数的实时高保真音频驱动肖像视频生成框架，支持无限长度流式生成，在HDTF和VFHQ基准上达到SOTA性能，Lite变体在RTX 4090上实现96 FPS推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动肖像生成方法面临高保真视觉质量与低延迟流式处理之间的平衡难题。大型模型计算成本过高，轻量级方案则牺牲了整体面部表征和时间稳定性。

Method: 提出1.3B参数统一框架SoulX-FlashHead，包含：1）流式感知时空预训练与时序音频上下文缓存机制，从短音频片段提取稳健特征；2）先知引导双向蒸馏，利用真实运动先验提供精确物理指导，缓解长序列自回归生成的误差累积和身份漂移；3）构建VividHead数据集（782小时严格对齐素材）支持训练。

Result: 在HDTF和VFHQ基准上实现最先进性能。Lite变体在单张NVIDIA RTX 4090上达到96 FPS推理速度，实现超快交互而不牺牲视觉连贯性。

Conclusion: SoulX-FlashHead成功解决了音频驱动肖像生成中高保真质量与实时流式处理之间的平衡问题，通过创新的流式感知训练机制和先知引导蒸馏方法，实现了无限长度、高质量的视频生成。

Abstract: Achieving a balance between high-fidelity visual quality and low-latency streaming remains a formidable challenge in audio-driven portrait generation. Existing large-scale models often suffer from prohibitive computational costs, while lightweight alternatives typically compromise on holistic facial representations and temporal stability. In this paper, we propose SoulX-FlashHead, a unified 1.3B-parameter framework designed for real-time, infinite-length, and high-fidelity streaming video generation. To address the instability of audio features in streaming scenarios, we introduce Streaming-Aware Spatiotemporal Pre-training equipped with a Temporal Audio Context Cache mechanism, which ensures robust feature extraction from short audio fragments. Furthermore, to mitigate the error accumulation and identity drift inherent in long-sequence autoregressive generation, we propose Oracle-Guided Bidirectional Distillation, leveraging ground-truth motion priors to provide precise physical guidance. We also present VividHead, a large-scale, high-quality dataset containing 782 hours of strictly aligned footage to support robust training. Extensive experiments demonstrate that SoulX-FlashHead achieves state-of-the-art performance on HDTF and VFHQ benchmarks. Notably, our Lite variant achieves an inference speed of 96 FPS on a single NVIDIA RTX 4090, facilitating ultra-fast interaction without sacrificing visual coherence.

</details>


### [48] [SpatialReward: Bridging the Perception Gap in Online RL for Image Editing via Explicit Spatial Reasoning](https://arxiv.org/abs/2602.07458)
*Yancheng Long,Yankai Yang,Hongyang Wei,Wei Chen,Tianke Zhang,Haonan fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Shuo Yang*

Main category: cs.CV

TL;DR: SpatialReward通过空间推理解决在线强化学习图像编辑中的奖励信号问题，显著提升评估准确性和编辑效果


<details>
  <summary>Details</summary>
Motivation: 当前在线强化学习图像编辑面临可靠细粒度奖励信号稀缺的问题，现有评估器存在"注意力崩溃"现象，忽视跨图像比较和细粒度细节，导致感知不准确和分数校准错误

Method: 提出SpatialReward奖励模型，通过显式空间推理实现精确验证，将推理锚定到预测的编辑区域，使语义判断基于像素级证据

Result: 在260k空间感知数据集上训练，在MMRB2和EditReward-Bench上达到最先进性能，在MultiEditReward-Bench上超越专有评估器；作为在线RL信号使OmniGen2在GEdit-Bench上提升+0.90，超越领先判别模型并两倍于GPT-4.1的提升

Conclusion: 空间推理对于实现图像编辑中的有效对齐至关重要，SpatialReward为解决在线强化学习图像编辑的奖励信号问题提供了有效方案

Abstract: Online Reinforcement Learning (RL) offers a promising avenue for complex image editing but is currently constrained by the scarcity of reliable and fine-grained reward signals. Existing evaluators frequently struggle with a critical perception gap we term "Attention Collapse," where models neglect cross-image comparisons and fail to capture fine-grained details, resulting in inaccurate perception and miscalibrated scores. To address these limitations, we propose SpatialReward, a reward model that enforces precise verification via explicit spatial reasoning. By anchoring reasoning to predicted edit regions, SpatialReward grounds semantic judgments in pixel-level evidence, significantly enhancing evaluative accuracy. Trained on a curated 260k spatial-aware dataset, our model achieves state-of-the-art performance on MMRB2 and EditReward-Bench, and outperforms proprietary evaluators on our proposed MultiEditReward-Bench. Furthermore, SpatialReward serves as a robust signal in online RL, boosting OmniGen2 by +0.90 on GEdit-Bench--surpassing the leading discriminative model and doubling the gain of GPT-4.1 (+0.45). These results demonstrate that spatial reasoning is essential for unlocking effective alignment in image editing.

</details>


### [49] [GlobalWasteData: A Large-Scale, Integrated Dataset for Robust Waste Classification and Environmental Monitoring](https://arxiv.org/abs/2602.07463)
*Misbah Ijaz,Saif Ur Rehman Khan,Abd Ur Rehman,Tayyaba Asif,Sebastian Vollmer,Andreas Dengel,Muhammad Nabeel Asim*

Main category: cs.CV

TL;DR: 研究人员创建了GlobalWasteData(GWD)数据集，整合了多个公开的垃圾分类数据集，包含89,807张图像、14个主类别和68个子类，旨在解决现有数据集碎片化、不一致和偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有垃圾分类数据集存在碎片化、不一致和特定环境偏差问题，类别名称、标注格式、图像条件和类别分布差异使得难以组合数据集或训练能泛化到真实场景的模型。

Method: 通过合并多个公开可用的数据集创建统一的GWD数据集，采用质量过滤、重复去除和元数据生成等预处理步骤提高数据集可靠性，确保一致的标注、改进的领域多样性和更平衡的类别表示。

Result: 创建了包含89,807张图像、14个主类别和68个子类的GWD数据集，提供了统一的资源，支持开发稳健且可泛化的垃圾识别模型。

Conclusion: GWD数据集为环境监测、回收自动化和垃圾识别的机器学习应用提供了坚实基础，公开可用以促进未来研究和可重复性。

Abstract: The growing amount of waste is a problem for the environment that requires efficient sorting techniques for various kinds of waste. An automated waste classification system is used for this purpose. The effectiveness of these Artificial Intelligence (AI) models depends on the quality and accessibility of publicly available datasets, which provide the basis for training and analyzing classification algorithms. Although several public waste classification datasets exist, they remain fragmented, inconsistent, and biased toward specific environments. Differences in class names, annotation formats, image conditions, and class distributions make it difficult to combine these datasets or train models that generalize well to real world scenarios. To address these issues, we introduce the GlobalWasteData (GWD) archive, a large scale dataset of 89,807 images across 14 main categories, annotated with 68 distinct subclasses. We compile this novel integrated GWD archive by merging multiple publicly available datasets into a single, unified resource. This GWD archive offers consistent labeling, improved domain diversity, and more balanced class representation, enabling the development of robust and generalizable waste recognition models. Additional preprocessing steps such as quality filtering, duplicate removal, and metadata generation further improve dataset reliability. Overall, this dataset offers a strong foundation for Machine Learning (ML) applications in environmental monitoring, recycling automation, and waste identification, and is publicly available to promote future research and reproducibility.

</details>


### [50] [Thermal odometry and dense mapping using learned ddometry and Gaussian splatting](https://arxiv.org/abs/2602.07493)
*Tianhao Zhou,Yujia Chen,Zhihao Zhan,Yuhang Ming,Jianzhu Huai*

Main category: cs.CV

TL;DR: TOM-GS：首个基于高斯溅射的热成像SLAM系统，结合学习里程计与密集建图，在恶劣条件下实现鲁棒运动估计和高质量重建


<details>
  <summary>Details</summary>
Motivation: 热红外传感器在黑暗、灰尘和烟雾中具有鲁棒性，但现有热成像里程计和建图方法主要是几何方法，在不同数据集上表现不佳且无法生成密集地图。受高斯溅射技术高效高质量重建能力的启发，需要开发专门针对热成像相机的SLAM系统。

Method: 提出TOM-GS方法，整合学习型里程计与基于高斯溅射的密集建图，包含专门的热图像增强和单目深度集成模块，是针对热成像相机的首个高斯溅射SLAM系统。

Result: 在运动估计和新视角渲染方面的广泛实验表明，TOM-GS优于现有的学习方法，证实了学习型流程在鲁棒热成像里程计和密集重建方面的优势。

Conclusion: TOM-GS展示了学习型里程计与高斯溅射建图结合的有效性，为热成像SLAM提供了鲁棒的解决方案，在恶劣环境下具有实际应用价值。

Abstract: Thermal infrared sensors, with wavelengths longer than smoke particles, can capture imagery independent of darkness, dust, and smoke. This robustness has made them increasingly valuable for motion estimation and environmental perception in robotics, particularly in adverse conditions. Existing thermal odometry and mapping approaches, however, are predominantly geometric and often fail across diverse datasets while lacking the ability to produce dense maps. Motivated by the efficiency and high-quality reconstruction ability of recent Gaussian Splatting (GS) techniques, we propose TOM-GS, a thermal odometry and mapping method that integrates learning-based odometry with GS-based dense mapping. TOM-GS is among the first GS-based SLAM systems tailored for thermal cameras, featuring dedicated thermal image enhancement and monocular depth integration. Extensive experiments on motion estimation and novel-view rendering demonstrate that TOM-GS outperforms existing learning-based methods, confirming the benefits of learning-based pipelines for robust thermal odometry and dense reconstruction.

</details>


### [51] [Learning Brain Representation with Hierarchical Visual Embeddings](https://arxiv.org/abs/2602.07495)
*Jiawen Zheng,Haonan Jia,Ming Li,Yuhui Zheng,Yufeng Zeng,Yang Gao,Chen Liang*

Main category: cs.CV

TL;DR: 该论文提出了一种利用多预训练视觉编码器和对比学习的大脑-图像对齐策略，通过融合先验增强跨模态一致性，在视觉解码中实现了检索准确性和重建保真度的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 当前视觉解码方法大多关注高层语义特征而忽略像素级细节，限制了我们对人类视觉系统的理解。大脑信号是否真正编码视觉信息以及编码程度仍不清楚。

Method: 1. 使用多个具有不同归纳偏置的预训练视觉编码器捕获分层多尺度视觉表示；2. 采用对比学习目标实现大脑信号与视觉嵌入的有效对齐；3. 引入融合先验，在大规模视觉数据上学习稳定映射，然后将大脑特征匹配到这个预训练先验，增强跨模态分布一致性。

Result: 大量定量和定性实验表明，该方法在检索准确性和重建保真度之间取得了良好的平衡。

Conclusion: 提出的多编码器大脑-图像对齐策略和融合先验方法能够有效解码大脑中的视觉信息，为理解人类视觉系统提供了新的视角。

Abstract: Decoding visual representations from brain signals has attracted significant attention in both neuroscience and artificial intelligence. However, the degree to which brain signals truly encode visual information remains unclear. Current visual decoding approaches explore various brain-image alignment strategies, yet most emphasize high-level semantic features while neglecting pixel-level details, thereby limiting our understanding of the human visual system. In this paper, we propose a brain-image alignment strategy that leverages multiple pre-trained visual encoders with distinct inductive biases to capture hierarchical and multi-scale visual representations, while employing a contrastive learning objective to achieve effective alignment between brain signals and visual embeddings. Furthermore, we introduce a Fusion Prior, which learns a stable mapping on large-scale visual data and subsequently matches brain features to this pre-trained prior, thereby enhancing distributional consistency across modalities. Extensive quantitative and qualitative experiments demonstrate that our method achieves a favorable balance between retrieval accuracy and reconstruction fidelity.

</details>


### [52] [IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation](https://arxiv.org/abs/2602.07498)
*Zhufeng Xu,Xuan Gao,Feng-Lin Liu,Haoxian Zhang,Zhixue Fang,Yu-Kun Lai,Xiaoqiang Liu,Pengfei Wan,Lin Gao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的隐式运动表示方法，将每帧运动压缩为紧凑的1D运动标记，解决了现有显式方法的空间不匹配问题和隐式方法的身份泄漏问题，通过三阶段训练策略实现了高效高质量的字符动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在字符动画方面存在两大挑战：显式方法（如骨架、DWPose）难以处理空间不匹配和身体比例变化；隐式方法虽然能捕捉高层运动语义，但存在身份信息泄漏和运动与外观纠缠的问题。

Method: 提出隐式运动表示，将每帧运动压缩为1D运动标记，放松了2D表示的严格空间约束；设计基于时间一致掩码标记的重定向模块，通过时间训练瓶颈减少源图像运动的干扰；采用三阶段训练策略提高训练效率和保真度。

Result: 大量实验表明，提出的隐式运动表示和IM-Animation生成能力在性能上达到或超越了现有最先进方法，有效解决了身份泄漏问题并提高了重定向一致性。

Conclusion: 本文提出的隐式运动表示方法通过1D运动标记压缩和时间一致重定向模块，成功解决了字符动画中的空间约束和身份泄漏问题，为高质量视频生成提供了有效解决方案。

Abstract: Recent progress in video diffusion models has markedly advanced character animation, which synthesizes motioned videos by animating a static identity image according to a driving video. Explicit methods represent motion using skeleton, DWPose or other explicit structured signals, but struggle to handle spatial mismatches and varying body scales. %proportions. Implicit methods, on the other hand, capture high-level implicit motion semantics directly from the driving video, but suffer from identity leakage and entanglement between motion and appearance. To address the above challenges, we propose a novel implicit motion representation that compresses per-frame motion into compact 1D motion tokens. This design relaxes strict spatial constraints inherent in 2D representations and effectively prevents identity information leakage from the motion video. Furthermore, we design a temporally consistent mask token-based retargeting module that enforces a temporal training bottleneck, mitigating interference from the source images' motion and improving retargeting consistency. Our methodology employs a three-stage training strategy to enhance the training efficiency and ensure high fidelity. Extensive experiments demonstrate that our implicit motion representation and the propose IM-Animation's generative capabilities are achieve superior or competitive performance compared with state-of-the-art methods.

</details>


### [53] [Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection](https://arxiv.org/abs/2602.07512)
*Tao Wang,Chenyu Lin,Chenwei Tang,Jizhe Zhou,Deng Xiong,Jianan Li,Jian Zhao,Jiancheng Lv*

Main category: cs.CV

TL;DR: ZoomDet：针对无人机图像小目标检测的自适应放大框架，通过非均匀放大和边界框变换提升检测性能


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的前景物体通常比普通场景图像中的物体更小、更稀疏，这阻碍了有效物体检测器的优化。因此需要自适应放大物体以更好地捕捉物体特征用于检测任务。

Method: 提出轻量级偏移预测方案结合新颖的基于边界框的放大目标，学习输入图像的非均匀放大。基于学习的放大变换，提出角对齐的边界框变换方法，将真实边界框变换到放大空间进行训练，推理时将预测边界框变换回原始空间。

Result: 在三个代表性无人机物体检测数据集（VisDrone、UAVDT、SeaDronesSee）上进行了广泛实验。在SeaDronesSee数据集上，ZoomDet使用Faster R-CNN模型获得了超过8.4个绝对mAP增益，仅增加约3ms延迟。

Conclusion: ZoomDet是架构无关的，可应用于任意物体检测架构，能有效提升无人机图像中小目标的检测性能，计算开销小。

Abstract: Detecting objects from UAV-captured images is challenging due to the small object size. In this work, a simple and efficient adaptive zoom-in framework is explored for object detection on UAV images. The main motivation is that the foreground objects are generally smaller and sparser than those in common scene images, which hinders the optimization of effective object detectors. We thus aim to zoom in adaptively on the objects to better capture object features for the detection task. To achieve the goal, two core designs are required: \textcolor{black}{i) How to conduct non-uniform zooming on each image efficiently? ii) How to enable object detection training and inference with the zoomed image space?} Correspondingly, a lightweight offset prediction scheme coupled with a novel box-based zooming objective is introduced to learn non-uniform zooming on the input image. Based on the learned zooming transformation, a corner-aligned bounding box transformation method is proposed. The method warps the ground-truth bounding boxes to the zoomed space to learn object detection, and warps the predicted bounding boxes back to the original space during inference. We conduct extensive experiments on three representative UAV object detection datasets, including VisDrone, UAVDT, and SeaDronesSee. The proposed ZoomDet is architecture-independent and can be applied to an arbitrary object detection architecture. Remarkably, on the SeaDronesSee dataset, ZoomDet offers more than 8.4 absolute gain of mAP with a Faster R-CNN model, with only about 3 ms additional latency. The code is available at https://github.com/twangnh/zoomdet_code.

</details>


### [54] [Evaluating Object-Centric Models beyond Object Discovery](https://arxiv.org/abs/2602.07532)
*Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: 论文提出了一个评估对象中心学习模型的新框架，使用指令调优的视觉语言模型作为评估器，并引入统一的评估任务和指标来联合评估定位能力和表示有用性。


<details>
  <summary>Details</summary>
Motivation: 现有对象中心学习模型的评估存在两个主要问题：1) 现有基准测试对模型表示有用性提供有限洞察；2) 定位能力和表示有用性使用分离的指标评估，导致不一致性。

Method: 使用指令调优的视觉语言模型作为评估器，在多样化的视觉问答数据集上进行可扩展的基准测试；引入统一的评估任务和指标，联合评估定位能力和表示有用性；包含一个简单的多特征重建基线作为参考点。

Result: 该方法能够更全面地评估对象中心学习模型的表示有用性，通过统一的评估框架消除分离评估带来的不一致性，为模型性能提供更准确的衡量。

Conclusion: 提出的评估框架解决了现有对象中心学习模型评估的局限性，通过使用视觉语言模型作为评估器和统一的评估指标，能够更好地衡量模型在复杂推理任务中的表示有用性和定位能力。

Abstract: Object-centric learning (OCL) aims to learn structured scene representations that support compositional generalization and robustness to out-of-distribution (OOD) data. However, OCL models are often not evaluated regarding these goals. Instead, most prior work focuses on evaluating OCL models solely through object discovery and simple reasoning tasks, such as probing the representation via image classification. We identify two limitations in existing benchmarks: (1) They provide limited insights on the representation usefulness of OCL models, and (2) localization and representation usefulness are assessed using disjoint metrics. To address (1), we use instruction-tuned VLMs as evaluators, enabling scalable benchmarking across diverse VQA datasets to measure how well VLMs leverage OCL representations for complex reasoning tasks. To address (2), we introduce a unified evaluation task and metric that jointly assess localization (where) and representation usefulness (what), thereby eliminating inconsistencies introduced by disjoint evaluation. Finally, we include a simple multi-feature reconstruction baseline as a reference point.

</details>


### [55] [Fine-Grained Cat Breed Recognition with Global Context Vision Transformer](https://arxiv.org/abs/2602.07534)
*Mowmita Parvin Hera,Md. Shahriar Mahmud Kallol,Shohanur Rahman Nirob,Md. Badsha Bulbul,Jubayer Ahmed,M. Zhourul Islam,Hazrat Ali,Mohammmad Farhad Bulbul*

Main category: cs.CV

TL;DR: 使用GCViT-Tiny架构在牛津-IIIT宠物数据集子集上实现猫品种分类，通过数据增强达到92%测试准确率


<details>
  <summary>Details</summary>
Motivation: 猫品种识别具有挑战性，因为不同品种在毛皮图案、面部结构和颜色上差异细微。需要准确的方法来支持兽医诊断、动物收容所管理和移动端识别系统等应用。

Method: 采用全局上下文视觉变换器(GCViT)架构的Tiny版本进行猫品种识别，使用牛津-IIIT宠物数据集的子集，通过旋转、水平翻转和亮度调整等数据增强技术提高模型泛化能力。

Result: GCViT-Tiny模型在测试集上达到92.00%的准确率，验证集上达到94.54%的准确率，证明了基于变换器的架构在细粒度图像分类任务中的有效性。

Conclusion: 研究表明变换器架构在猫品种分类等细粒度识别任务中表现优异，具有实际应用价值，并提供了Hugging Face演示平台供实际使用。

Abstract: Accurate identification of cat breeds from images is a challenging task due to subtle differences in fur patterns, facial structure, and color. In this paper, we present a deep learning-based approach for classifying cat breeds using a subset of the Oxford-IIIT Pet Dataset, which contains high-resolution images of various domestic breeds. We employed the Global Context Vision Transformer (GCViT) architecture-tiny for cat breed recognition. To improve model generalization, we used extensive data augmentation, including rotation, horizontal flipping, and brightness adjustment. Experimental results show that the GCViT-Tiny model achieved a test accuracy of 92.00% and validation accuracy of 94.54%. These findings highlight the effectiveness of transformer-based architectures for fine-grained image classification tasks. Potential applications include veterinary diagnostics, animal shelter management, and mobile-based breed recognition systems. We also provide a hugging face demo at https://huggingface.co/spaces/bfarhad/cat-breed-classifier.

</details>


### [56] [Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis](https://arxiv.org/abs/2602.07535)
*Md Sazidur Rahman,Kjersti Engan,Kathinka Dæhli Kurz,Mahdieh Khanmohammadi*

Main category: cs.CV

TL;DR: 提出双时相分析框架，使用统计描述符、影像组学纹理特征和深度特征嵌入来表征缺血组织，通过特征空间分析揭示卒中演变的组织表型


<details>
  <summary>Details</summary>
Motivation: 传统单时间点分割无法捕捉卒中的生物学异质性和时间演变，需要更精细的方法来表征缺血组织的状态变化和最终结局

Method: 使用双时相分析框架（入院T1和随访T2），从CTP提取统计描述符、纹理特征和深度特征嵌入（mJ-Net和nnU-Net），构建六个ROI区域，在特征空间中进行聚类分析

Result: 在18名成功再灌注患者中，区域级表征显示出有意义的聚类：可挽救组织与不可挽救组织在特征空间中明显分离，特别是mJ-Net深度特征空间显示出显著的组织分离

Conclusion: 编码器衍生的特征流形反映了基础组织表型和状态转变，为基于影像的卒中演变量化提供了新的见解，深度特征空间能有效区分可挽救与不可挽救组织

Abstract: Computed tomography perfusion (CTP) at admission is routinely used to estimate the ischemic core and penumbra, while follow-up diffusion-weighted MRI (DWI) provides the definitive infarct outcome. However, single time-point segmentations fail to capture the biological heterogeneity and temporal evolution of stroke. We propose a bi-temporal analysis framework that characterizes ischemic tissue using statistical descriptors, radiomic texture features, and deep feature embeddings from two architectures (mJ-Net and nnU-Net). Bi-temporal refers to admission (T1) and post-treatment follow-up (T2). All features are extracted at T1 from CTP, with follow-up DWI aligned to ensure spatial correspondence. Manually delineated masks at T1 and T2 are intersected to construct six regions of interest (ROIs) encoding both initial tissue state and final outcome. Features were aggregated per region and analyzed in feature space. Evaluation on 18 patients with successful reperfusion demonstrated meaningful clustering of region-level representations. Regions classified as penumbra or healthy at T1 that ultimately recovered exhibited feature similarity to preserved brain tissue, whereas infarct-bound regions formed distinct groupings. Both baseline GLCM and deep embeddings showed a similar trend: penumbra regions exhibit features that are significantly different depending on final state, whereas this difference is not significant for core regions. Deep feature spaces, particularly mJ-Net, showed strong separation between salvageable and non-salvageable tissue, with a penumbra separation index that differed significantly from zero (Wilcoxon signed-rank test). These findings suggest that encoder-derived feature manifolds reflect underlying tissue phenotypes and state transitions, providing insight into imaging-based quantification of stroke evolution.

</details>


### [57] [LLM-Guided Diagnostic Evidence Alignment for Medical Vision-Language Pretraining under Limited Pairing](https://arxiv.org/abs/2602.07540)
*Huimin Yan,Liang Bai,Xian Yang,Long Chen*

Main category: cs.CV

TL;DR: LGDEA提出了一种基于LLM引导的诊断证据对齐方法，通过证据级对齐而非全局或局部对齐，减少对配对数据的依赖，在医学视觉-语言预训练中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言预训练方法存在局限性：全局对齐容易被非诊断信息主导，局部对齐难以整合关键诊断证据，导致学习可靠诊断表示困难，限制了在配对数据有限场景下的应用。

Method: 提出LLM引导的诊断证据对齐方法(LGDEA)，利用大语言模型从放射学报告中提取关键诊断证据，构建共享诊断证据空间，实现证据感知的跨模态对齐，有效利用大量未配对的医学图像和报告。

Result: 在短语定位、图像-文本检索和零样本分类任务上取得一致且显著的改进，性能甚至可与依赖大量配对数据的预训练方法相媲美。

Conclusion: LGDEA通过证据级对齐方法，更符合医学诊断过程，显著减轻了对配对数据的依赖，为医学视觉-语言预训练提供了更有效的解决方案。

Abstract: Most existing CLIP-style medical vision--language pretraining methods rely on global or local alignment with substantial paired data. However, global alignment is easily dominated by non-diagnostic information, while local alignment fails to integrate key diagnostic evidence. As a result, learning reliable diagnostic representations becomes difficult, which limits their applicability in medical scenarios with limited paired data. To address this issue, we propose an LLM-Guided Diagnostic Evidence Alignment method (LGDEA), which shifts the pretraining objective toward evidence-level alignment that is more consistent with the medical diagnostic process. Specifically, we leverage LLMs to extract key diagnostic evidence from radiology reports and construct a shared diagnostic evidence space, enabling evidence-aware cross-modal alignment and allowing LGDEA to effectively exploit abundant unpaired medical images and reports, thereby substantially alleviating the reliance on paired data. Extensive experimental results demonstrate that our method achieves consistent and significant improvements on phrase grounding, image--text retrieval, and zero-shot classification, and even rivals pretraining methods that rely on substantial paired data.

</details>


### [58] [MUFASA: A Multi-Layer Framework for Slot Attention](https://arxiv.org/abs/2602.07544)
*Sebastian Bock,Leonie Schüßler,Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: MUFASA是一个轻量级即插即用框架，通过在多层ViT特征上进行槽注意力计算，提升无监督物体中心学习的分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于槽注意力的无监督物体中心学习方法仅使用预训练ViT的最后一层特征，忽略了其他层包含的丰富语义信息，导致信息利用不足。

Method: 提出MUFASA框架：1）在ViT编码器的多个特征层上计算槽注意力；2）提出融合策略将多层获得的槽聚合成统一的物体中心表示；3）作为轻量级插件集成到现有OCL方法中。

Result: 将MUFASA集成到现有OCL方法中，在多个数据集上提升了分割结果，达到了新的SOTA，同时改善了训练收敛性，仅带来轻微推理开销。

Conclusion: 通过充分利用ViT多层特征的语义丰富性，MUFASA框架有效提升了无监督物体中心学习的性能，证明了多层特征融合的重要性。

Abstract: Unsupervised object-centric learning (OCL) decomposes visual scenes into distinct entities. Slot attention is a popular approach that represents individual objects as latent vectors, called slots. Current methods obtain these slot representations solely from the last layer of a pre-trained vision transformer (ViT), ignoring valuable, semantically rich information encoded across the other layers. To better utilize this latent semantic information, we introduce MUFASA, a lightweight plug-and-play framework for slot attention-based approaches to unsupervised object segmentation. Our model computes slot attention across multiple feature layers of the ViT encoder, fully leveraging their semantic richness. We propose a fusion strategy to aggregate slots obtained on multiple layers into a unified object-centric representation. Integrating MUFASA into existing OCL methods improves their segmentation results across multiple datasets, setting a new state of the art while simultaneously improving training convergence with only minor inference overhead.

</details>


### [59] [Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation](https://arxiv.org/abs/2602.07550)
*Hussni Mohd Zakir,Eric Tatt Wei Ho*

Main category: cs.CV

TL;DR: DINOv3特征在少样本语义分割中表现出色，仅使用类原型和Gram矩阵优化的训练免费方法FSSDINO就能与复杂方法竞争，但研究发现存在"语义选择鸿沟"：传统启发式方法无法可靠识别最优中间层特征。


<details>
  <summary>Details</summary>
Motivation: 研究自监督视觉Transformer（如DINOv3）在少样本语义分割任务中的内在能力，探索无需训练的方法能否达到与复杂方法相当的性能，并分析特征选择中存在的问题。

Method: 提出FSSDINO方法：使用冻结的DINOv3特征，通过类特定原型和Gram矩阵优化进行训练免费的少样本语义分割。进行Oracle引导的层分析，比较不同层特征的表现。

Result: FSSDINO在二元、多类和跨域基准测试中表现出色，与需要复杂解码器或测试时适应的方法竞争。发现"最后层"是一个强大的基线，但Oracle分析显示中间层存在更高性能潜力，传统选择指标无法可靠识别这些特征。

Conclusion: 研究确立了"最后层"作为少样本语义分割的强大基线，揭示了DINOv3中潜在的语义能力，并诊断出"语义选择鸿沟"问题：传统启发式方法无法可靠识别最优特征层，为未来研究提供了重要方向。

Abstract: Recent self-supervised Vision Transformers (ViTs), such as DINOv3, provide rich feature representations for dense vision tasks. This study investigates the intrinsic few-shot semantic segmentation (FSS) capabilities of frozen DINOv3 features through a training-free baseline, FSSDINO, utilizing class-specific prototypes and Gram-matrix refinement. Our results across binary, multi-class, and cross-domain (CDFSS) benchmarks demonstrate that this minimal approach, applied to the final backbone layer, is highly competitive with specialized methods involving complex decoders or test-time adaptation. Crucially, we conduct an Oracle-guided layer analysis, identifying a significant performance gap between the standard last-layer features and globally optimal intermediate representations. We reveal a "Safest vs. Optimal" dilemma: while the Oracle proves higher performance is attainable, matching the results of compute-intensive adaptation methods, current unsupervised and support-guided selection metrics consistently yield lower performance than the last-layer baseline. This characterizes a "Semantic Selection Gap" in Foundation Models, a disconnect where traditional heuristics fail to reliably identify high-fidelity features. Our work establishes the "Last-Layer" as a deceptively strong baseline and provides a rigorous diagnostic of the latent semantic potentials in DINOv3.The code is publicly available at https://github.com/hussni0997/fssdino.

</details>


### [60] [FlexID: Training-Free Flexible Identity Injection via Intent-Aware Modulation for Text-to-Image Generation](https://arxiv.org/abs/2602.07554)
*Guandong Li,Yijun Ding*

Main category: cs.CV

TL;DR: FlexID是一个无需训练的个人化文本到图像生成框架，通过意图感知调制解决身份保真度与文本适应性之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的方法通常依赖刚性的视觉特征注入，导致身份保真度与文本适应性之间存在冲突，难以在保持身份一致性的同时实现语义变化。

Method: FlexID采用正交解耦方法，将身份分为两个维度：语义身份投影器（SIP）在语言空间注入高级先验，视觉特征锚点（VFA）在潜在空间确保结构保真度。关键创新是上下文感知自适应门控（CAG）机制，根据编辑意图和扩散时间步动态调制这两个流的权重。

Result: 在IBench上的大量实验表明，FlexID在身份一致性和文本遵循性之间实现了最先进的平衡，为复杂叙事生成提供了高效解决方案。

Conclusion: FlexID通过意图感知调制框架，成功解决了个人化文本到图像生成中的身份保真度与文本适应性冲突问题，实现了身份保存与语义变化的协同。

Abstract: Personalized text-to-image generation aims to seamlessly integrate specific identities into textual descriptions. However, existing training-free methods often rely on rigid visual feature injection, creating a conflict between identity fidelity and textual adaptability. To address this, we propose FlexID, a novel training-free framework utilizing intent-aware modulation. FlexID orthogonally decouples identity into two dimensions: a Semantic Identity Projector (SIP) that injects high-level priors into the language space, and a Visual Feature Anchor (VFA) that ensures structural fidelity within the latent space. Crucially, we introduce a Context-Aware Adaptive Gating (CAG) mechanism that dynamically modulates the weights of these streams based on editing intent and diffusion timesteps. By automatically relaxing rigid visual constraints when strong editing intent is detected, CAG achieves synergy between identity preservation and semantic variation. Extensive experiments on IBench demonstrate that FlexID achieves a state-of-the-art balance between identity consistency and text adherence, offering an efficient solution for complex narrative generation.

</details>


### [61] [Human Identification at a Distance: Challenges, Methods and Results on the Competition HID 2025](https://arxiv.org/abs/2602.07565)
*Jingzhe Ma,Meng Zhang,Jianlong Yu,Kun Liu,Zunxiao Xu,Xue Cheng,Junjie Zhou,Yanfei Wang,Jiahang Li,Zepeng Wang,Kazuki Osamura,Rujie Liu,Narishige Abe,Jingjie Wang,Shunli Zhang,Haojun Xie,Jiajun Wu,Weiming Wu,Wenxiong Kang,Qingshuo Gao,Jiaming Xiong,Xianye Ben,Lei Chen,Lichen Song,Junjian Cui,Haijun Xiong,Junhao Lu,Bin Feng,Mengyuan Liu,Ji Zhou,Baoquan Zhao,Ke Xu,Yongzhen Huang,Liang Wang,Manuel J Marin-Jimenez,Md Atiqur Rahman Ahad,Shiqi Yu*

Main category: cs.CV

TL;DR: 该论文介绍了HID 2025竞赛，该竞赛使用SUSTech-Competition数据集评估步态识别算法，参赛者在没有专用训练数据的情况下取得了94.2%的准确率，创造了该数据集的新基准。


<details>
  <summary>Details</summary>
Motivation: 远距离人体识别(HID)具有挑战性，因为传统生物特征模态如人脸和指纹在现实场景中难以获取。步态识别提供了实用的替代方案，可以在远距离可靠地捕捉。HID竞赛旨在促进步态识别进展并提供公平评估平台。

Method: 竞赛采用SUSTech-Competition数据集，该数据集包含服装、携带物品和视角的显著变化。不提供专用训练数据，参赛者需使用外部数据集训练模型。每年使用不同随机种子生成不同的评估划分，减少过拟合风险并支持跨域泛化的公平评估。

Result: HID 2025竞赛中，尽管难度增加，参赛者取得了进一步改进，最佳方法达到了94.2%的准确率，为该数据集设立了新的基准。

Conclusion: HID竞赛通过SUSTech-Competition数据集推动了步态识别技术的发展，参赛者的持续改进表明算法进步能够超越先前观察到的准确率极限。论文还分析了关键技术趋势并概述了步态识别未来研究的潜在方向。

Abstract: Human identification at a distance (HID) is challenging because traditional biometric modalities such as face and fingerprints are often difficult to acquire in real-world scenarios. Gait recognition provides a practical alternative, as it can be captured reliably at a distance. To promote progress in gait recognition and provide a fair evaluation platform, the International Competition on Human Identification at a Distance (HID) has been organized annually since 2020. Since 2023, the competition has adopted the challenging SUSTech-Competition dataset, which features substantial variations in clothing, carried objects, and view angles. No dedicated training data are provided, requiring participants to train their models using external datasets. Each year, the competition applies a different random seed to generate distinct evaluation splits, which reduces the risk of overfitting and supports a fair assessment of cross-domain generalization. While HID 2023 and HID 2024 already used this dataset, HID 2025 explicitly examined whether algorithmic advances could surpass the accuracy limits observed previously. Despite the heightened difficulty, participants achieved further improvements, and the best-performing method reached 94.2% accuracy, setting a new benchmark on this dataset. We also analyze key technical trends and outline potential directions for future research in gait recognition.

</details>


### [62] [Cross-Camera Cow Identification via Disentangled Representation Learning](https://arxiv.org/abs/2602.07566)
*Runcheng Wang,Yaru Chen,Guiguo Zhang,Honghua Jiang,Yongliang Qiao*

Main category: cs.CV

TL;DR: 提出基于解耦表征学习的跨摄像头奶牛识别框架，通过子空间可识别性保证理论分解图像特征，显著提升对未见摄像头的泛化能力，在7个跨摄像头任务上平均准确率达86.0%


<details>
  <summary>Details</summary>
Motivation: 现有动物识别方法在受控单摄像头环境下表现良好，但在跨摄像头场景中面临严重泛化挑战。当模型从源摄像头部署到具有不同光照、背景、视角和成像特性的新监控节点时，识别性能急剧下降，限制了非接触技术在动态真实农场环境中的大规模应用。

Method: 提出基于解耦表征学习的跨摄像头奶牛识别框架，利用子空间可识别性保证理论，通过建模底层物理数据生成过程，设计原则驱动的特征解耦模块，将观测图像分解为多个正交潜在子空间，有效分离跨摄像头不变的稳定身份相关生物特征。

Result: 构建了覆盖5个不同摄像头节点的高质量数据集，包含异构采集设备和复杂的光照角度变化。在7个跨摄像头任务上的广泛实验表明，所提方法平均准确率达到86.0%，显著优于仅源摄像头基线（51.9%）和最强的跨摄像头基线方法（79.8%）。

Conclusion: 本研究建立了基于子空间理论的特征解耦框架，用于协作式跨摄像头奶牛识别，为不受控智能农场环境中的精确动物监测提供了新范式，解决了跨摄像头泛化难题。

Abstract: Precise identification of individual cows is a fundamental prerequisite for comprehensive digital management in smart livestock farming. While existing animal identification methods excel in controlled, single-camera settings, they face severe challenges regarding cross-camera generalization. When models trained on source cameras are deployed to new monitoring nodes characterized by divergent illumination, backgrounds, viewpoints, and heterogeneous imaging properties, recognition performance often degrades dramatically. This limits the large-scale application of non-contact technologies in dynamic, real-world farming environments. To address this challenge, this study proposes a cross-camera cow identification framework based on disentangled representation learning. This framework leverages the Subspace Identifiability Guarantee (SIG) theory in the context of bovine visual recognition. By modeling the underlying physical data generation process, we designed a principle-driven feature disentanglement module that decomposes observed images into multiple orthogonal latent subspaces. This mechanism effectively isolates stable, identity-related biometric features that remain invariant across cameras, thereby substantially improving generalization to unseen cameras. We constructed a high-quality dataset spanning five distinct camera nodes, covering heterogeneous acquisition devices and complex variations in lighting and angles. Extensive experiments across seven cross-camera tasks demonstrate that the proposed method achieves an average accuracy of 86.0%, significantly outperforming the Source-only Baseline (51.9%) and the strongest cross-camera baseline method (79.8%). This work establishes a subspace-theoretic feature disentanglement framework for collaborative cross-camera cow identification, offering a new paradigm for precise animal monitoring in uncontrolled smart farming environments.

</details>


### [63] [TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation](https://arxiv.org/abs/2602.07595)
*Yuanzhi Liang,Xuan'er Wu,Yirui Liu,Yijie Fang,Yizhen Fan,Ke Hao,Rui Li,Ruiying Liu,Ziqi Ni,Peng Yu,Yanbo Wang,Haibin Huang,Qizhen Weng,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 该论文提出了一个系统化的视频生成模型后训练框架，将监督策略塑造、奖励驱动的强化学习和基于偏好的精炼整合到一个稳定性约束的优化堆栈中，旨在解决实际视频生成中的高成本、时间累积失败模式和异构反馈等挑战。


<details>
  <summary>Details</summary>
Motivation: 后训练是将预训练视频生成器转化为生产级模型的关键步骤，需要使模型能够遵循指令、可控且具有长时间稳定性。然而，实际视频生成面临高计算成本、时间累积的失败模式以及异构、不确定且判别性弱的反馈等挑战。

Method: 提出一个系统化的后训练框架，将监督策略塑造、奖励驱动的强化学习和基于偏好的精炼整合到单一稳定性约束优化堆栈中。采用分阶段、诊断驱动的方法而非孤立技巧的集合，围绕实际视频生成约束进行设计。

Result: 该框架提供了清晰的蓝图，能够提升感知保真度、时间一致性和提示遵循能力，同时保持初始化时建立的可控性。构建了可扩展的后训练管道，在实际部署中保持稳定、可扩展和有效。

Conclusion: 通过将多种优化技术整合到统一的稳定性约束框架中，该研究为构建生产级视频生成模型提供了系统化的后训练方法，解决了实际部署中的关键挑战，实现了感知质量、时间连贯性和指令遵循能力的协同提升。

Abstract: Post-training is the decisive step for converting a pretrained video generator into a production-oriented model that is instruction-following, controllable, and robust over long temporal horizons. This report presents a systematical post-training framework that organizes supervised policy shaping, reward-driven reinforcement learning, and preference-based refinement into a single stability-constrained optimization stack. The framework is designed around practical video-generation constraints, including high rollout cost, temporally compounding failure modes, and feedback that is heterogeneous, uncertain, and often weakly discriminative. By treating optimization as a staged, diagnostic-driven process rather than a collection of isolated tricks, the report summarizes a cohesive recipe for improving perceptual fidelity, temporal coherence, and prompt adherence while preserving the controllability established at initialization. The resulting framework provides a clear blueprint for building scalable post-training pipelines that remain stable, extensible, and effective in real-world deployment settings.

</details>


### [64] [Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.07605)
*Hulingxiao He,Zijun Geng,Yuxin Peng*

Main category: cs.CV

TL;DR: Fine-R1是一个专门用于细粒度视觉识别的多模态大语言模型，通过R1风格训练框架，仅需4-shot训练就能超越现有通用MLLM和对比CLIP模型，在识别已见和未见子类别上都表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在粗粒度视觉任务上表现良好，但在细粒度视觉识别方面存在困难。适应FGVR通常需要大量标注数据，成本高昂，且性能仍不如专门用于判别任务的对比CLIP模型。此外，MLLM容易对已见子类别过拟合，对未见子类别泛化能力差。

Method: 提出Fine-R1模型，采用R1风格训练框架：1) 思维链监督微调：构建高质量FGVR CoT数据集，包含"视觉分析、候选子类别、比较和预测"的推理过程，将模型转变为强大的开放世界分类器；2) 三元组增强策略优化：通过类内增强混合同一类别内锚点和正样本图像的轨迹来提高对类内变化的鲁棒性，通过类间增强最大化跨子类别图像条件下的响应差异来增强判别能力。

Result: 仅需4-shot训练，Fine-R1在识别已见和未见子类别上都超越了现有的通用MLLM、推理MLLM甚至对比CLIP模型，在知识密集型领域展现出潜力。

Conclusion: Fine-R1通过创新的训练框架解决了MLLM在细粒度视觉识别中的关键挑战，在少量样本下实现了优异的性能，为难以获取专家标注的知识密集型领域提供了有前景的解决方案。

Abstract: Any entity in the visual world can be hierarchically grouped based on shared characteristics and mapped to fine-grained sub-categories. While Multi-modal Large Language Models (MLLMs) achieve strong performance on coarse-grained visual tasks, they often struggle with Fine-Grained Visual Recognition (FGVR). Adapting general-purpose MLLMs to FGVR typically requires large amounts of annotated data, which is costly to obtain, leaving a substantial performance gap compared to contrastive CLIP models dedicated for discriminative tasks. Moreover, MLLMs tend to overfit to seen sub-categories and generalize poorly to unseen ones. To address these challenges, we propose Fine-R1, an MLLM tailored for FGVR through an R1-style training framework: (1) Chain-of-Thought Supervised Fine-tuning, where we construct a high-quality FGVR CoT dataset with rationales of "visual analysis, candidate sub-categories, comparison, and prediction", transition the model into a strong open-world classifier; and (2) Triplet Augmented Policy Optimization, where Intra-class Augmentation mixes trajectories from anchor and positive images within the same category to improve robustness to intra-class variance, while Inter-class Augmentation maximizes the response distinction conditioned on images across sub-categories to enhance discriminative ability. With only 4-shot training, Fine-R1 outperforms existing general MLLMs, reasoning MLLMs, and even contrastive CLIP models in identifying both seen and unseen sub-categories, showing promise in working in knowledge-intensive domains where gathering expert annotations for all sub-categories is arduous. Code is available at https://github.com/PKU-ICST-MIPL/FineR1_ICLR2026.

</details>


### [65] [HistoMet: A Pan-Cancer Deep Learning Framework for Prognostic Prediction of Metastatic Progression and Site Tropism from Primary Tumor Histopathology](https://arxiv.org/abs/2602.07608)
*Yixin Chen,Ziyu Su,Lingbin Meng,Elshad Hasanov,Wei Chen,Anil Parwani,M. Khalid Khan Niazi*

Main category: cs.CV

TL;DR: HistoMet是一个决策感知、概念对齐的多实例学习框架，用于从原发肿瘤全切片图像预测转移预后结果，采用两阶段预测流程并整合语言定义和数据自适应转移概念。


<details>
  <summary>Details</summary>
Motivation: 转移进展是癌症相关死亡的主要原因，但从组织病理学直接预测原发肿瘤是否会转移以及转移部位仍然是一个基本挑战。现有计算方法通常将转移状态或部位预测作为孤立任务处理，没有明确模拟临床顺序决策过程。

Method: 提出HistoMet框架，采用两模块预测流程：首先估计原发肿瘤转移进展的可能性，然后对高风险病例进行条件性转移部位预测。通过预训练病理视觉语言模型整合语言定义和数据自适应的转移概念，指导表示学习并提高临床可解释性。

Result: 在6504名具有转移随访和部位注释的多机构泛癌队列中评估。在临床相关高灵敏度筛查设置下（95%灵敏度），HistoMet显著减少下游工作量同时保持高转移风险召回率。对于转移病例，获得宏观F1分数74.6（标准差1.3）和宏观一对多AUC 92.1。

Conclusion: 明确模拟临床决策结构能够直接从原发肿瘤组织病理学实现稳健且可部署的转移进展和部位趋向性预后预测。

Abstract: Metastatic Progression remains the leading cause of cancer-related mortality, yet predicting whether a primary tumor will metastasize and where it will disseminate directly from histopathology remains a fundamental challenge. Although whole-slide images (WSIs) provide rich morphological information, prior computational pathology approaches typically address metastatic status or site prediction as isolated tasks, and do not explicitly model the clinically sequential decision process of metastatic risk assessment followed by downstream site-specific evaluation. To address this research gap, we present a decision-aware, concept-aligned MIL framework, HistoMet, for prognostic metastatic outcome prediction from primary tumor WSIs. Our proposed framework adopts a two-module prediction pipeline in which the likelihood of metastatic progression from the primary tumor is first estimated, followed by conditional prediction of metastatic site for high-risk cases. To guide representation learning and improve clinical interpretability, our framework integrates linguistically defined and data-adaptive metastatic concepts through a pretrained pathology vision-language model. We evaluate HistoMet on a multi-institutional pan-cancer cohort of 6504 patients with metastasis follow-up and site annotations. Under clinically relevant high-sensitivity screening settings (95 percent sensitivity), HistoMet significantly reduces downstream workload while maintaining high metastatic risk recall. Conditional on metastatic cases, HistoMet achieves a macro F1 of 74.6 with a standard deviation of 1.3 and a macro one-vs-rest AUC of 92.1. These results demonstrate that explicitly modeling clinical decision structure enables robust and deployable prognostic prediction of metastatic progression and site tropism directly from primary tumor histopathology.

</details>


### [66] [Uncovering Modality Discrepancy and Generalization Illusion for General-Purpose 3D Medical Segmentation](https://arxiv.org/abs/2602.07643)
*Yichi Zhang,Feiyang Xiao,Le Xue,Wenbo Zhang,Gang Feng,Chenguang Zheng,Yuan Qi,Yuan Cheng,Zixin Hu*

Main category: cs.CV

TL;DR: 该研究通过创建UMD数据集（包含PET/CT和PET/MRI扫描）评估3D医学基础模型，发现从结构成像转向功能成像时存在显著性能差距，表明当前模型远未达到真正通用目的状态。


<details>
  <summary>Details</summary>
Motivation: 当前3D医学基础模型的验证主要局限于区域和结构成像，存在显著的模态差异未被探索。需要提供严格客观的评估来检验这些模型在真实世界应用中的鲁棒性。

Method: 创建UMD数据集（490个全身PET/CT和464个全身PET/MRI扫描，包含约675k 2D图像和12k 3D器官标注），通过受试者内配对扫描的对照比较，将成像模态作为主要自变量，对代表性3D分割基础模型进行全面评估。

Result: 评估揭示了文献报道的基准与真实世界效能之间的显著差异，特别是在从结构域转向功能域时。这种系统性失败表明当前3D基础模型远未达到真正通用目的状态。

Conclusion: 需要向多模态训练和评估的范式转变，以弥合理想化基准测试与全面临床效用之间的差距。该数据集和分析为未来开发真正模态无关的医学基础模型奠定了基石。

Abstract: While emerging 3D medical foundation models are envisioned as versatile tools with offer general-purpose capabilities, their validation remains largely confined to regional and structural imaging, leaving a significant modality discrepancy unexplored. To provide a rigorous and objective assessment, we curate the UMD dataset comprising 490 whole-body PET/CT and 464 whole-body PET/MRI scans ($\sim$675k 2D images, $\sim$12k 3D organ annotations) and conduct a thorough and comprehensive evaluation of representative 3D segmentation foundation models. Through intra-subject controlled comparisons of paired scans, we isolate imaging modality as the primary independent variable to evaluate model robustness in real-world applications. Our evaluation reveals a stark discrepancy between literature-reported benchmarks and real-world efficacy, particularly when transitioning from structural to functional domains. Such systemic failures underscore that current 3D foundation models are far from achieving truly general-purpose status, necessitating a paradigm shift toward multi-modal training and evaluation to bridge the gap between idealized benchmarking and comprehensive clinical utility. This dataset and analysis establish a foundational cornerstone for future research to develop truly modality-agnostic medical foundation models.

</details>


### [67] [Influence of Geometry, Class Imbalance and Alignment on Reconstruction Accuracy -- A Micro-CT Phantom-Based Evaluation](https://arxiv.org/abs/2602.07658)
*Avinash Kumar K M,Samarth S. Raut*

Main category: cs.CV

TL;DR: 该研究评估了医学扫描3D重建流程中的误差，比较了不同分割算法和几何形状的体素与表面精度指标，发现Otsu方法最通用，薄壁结构需要更严格的Jaccard指数评估。


<details>
  <summary>Details</summary>
Motivation: 医学扫描创建3D模型的精度受多种因素影响，但几何类型、类别不平衡、体素和点云对齐对精度的影响尚未充分探索。本研究旨在评估重建流程中的误差，并探索不同分割算法和几何形状的体素与表面精度指标。

Method: 使用SLA技术打印球体、面罩和AAA（腹主动脉瘤）模型，通过微CT扫描。采用GMM、Otsu和RG三种分割方法。使用KU算法对齐分割模型与参考模型，评估Dice、Jaccard分数和精度等体素指标。使用ICP对齐过程配准表面网格，评估倒角距离和平均Hausdorff距离等表面指标。

Result: Otsu方法对所有几何形状最适用。AAA由于壁薄和对齐问题导致重叠分数低。类别不平衡对AAA的特异性影响最大。表面精度指标与体素指标趋势不同：RG方法对球体表现最好，GMM和Otsu对AAA表现更好。面罩表面误差最大，可能是ICP对齐过程中的问题。

Conclusion: 分割精度是重建过程各阶段误差的累积总和。在类别不平衡和对齐敏感的情况下，高体素精度指标可能具有误导性。Jaccard指数比Dice更严格，更适合评估薄壁结构的精度。必须确保体素和点云对齐才能对重建流程进行可靠评估。

Abstract: The accuracy of the 3D models created from medical scans depends on imaging hardware, segmentation methods and mesh processing techniques etc. The effects of geometry type, class imbalance, voxel and point cloud alignment on accuracy remain to be thoroughly explored. This work evaluates the errors across the reconstruction pipeline and explores the use of voxel and surface-based accuracy metrics for different segmentation algorithms and geometry types. A sphere, a facemask, and an AAA were printed using the SLA technique and scanned using a micro-CT machine. Segmentation was performed using GMM, Otsu and RG based methods. Segmented and reference models aligned using the KU algorithm, were quantitatively compared to evaluate metrics like Dice and Jaccard scores, precision. Surface meshes were registered with reference meshes using an ICP-based alignment process. Metrics like chamfer distance, and average Hausdorff distance were evaluated. The Otsu method was found to be the most suitable method for all the geometries. AAA yielded low overlap scores due to its small wall thickness and misalignment. The effect of class imbalance on specificity was observed the most for AAA. Surface-based accuracy metrics differed from the voxel-based trends. The RG method performed best for sphere, while GMM and Otsu perform better for AAA. The facemask surface was most error-prone, possibly due to misalignment during the ICP process. Segmentation accuracy is a cumulative sum of errors across different stages of the reconstruction process. High voxel-based accuracy metrics may be misleading in cases of high class imbalance and sensitivity to alignment. The Jaccard index is found to be more stringent than the Dice and more suitable for accuracy assessment for thin-walled structures. Voxel and point cloud alignment should be ensured to make any reliable assessment of the reconstruction pipeline.

</details>


### [68] [Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning](https://arxiv.org/abs/2602.07680)
*Ross Greer,Maitrayee Keskar,Angel Martinez-Sanchez,Parthib Roy,Shashank Shriram,Mohan Trivedi*

Main category: cs.CV

TL;DR: 本文研究了视觉语言模型在自动驾驶安全评估和决策中的应用，探索了三种系统级用例：基于CLIP的轻量级危险筛查、场景级嵌入在轨迹规划中的集成，以及自然语言作为运动规划的行为约束。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型能够将视觉观察与自然语言概念对齐，为安全关键自动驾驶中的语义推理提供了新机会。本文旨在探索如何将视觉语言表示集成到感知、预测和规划流程中，以支持驾驶场景安全评估和决策。

Method: 研究了三种互补的系统级用例：1）基于CLIP图像-文本相似性的轻量级、类别无关的危险筛查方法；2）将场景级视觉语言嵌入集成到基于Transformer的轨迹规划框架中（使用Waymo Open Dataset）；3）使用自然语言作为运动规划的显式行为约束（使用doScenes数据集）。

Result: 1）危险筛查方法能够低延迟检测多样化和分布外的道路危险；2）简单地将全局嵌入条件化到规划器中不会提高轨迹精度，表明表示-任务对齐的重要性；3）基于视觉场景元素的乘客式指令能够抑制罕见但严重的规划失败，在模糊场景中改善安全对齐行为。

Conclusion: 视觉语言表示在表达语义风险、意图和行为约束方面对自动驾驶安全具有重要潜力。实现这一潜力本质上是一个工程问题，需要精心设计系统和结构化基础，而不是直接特征注入。

Abstract: Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study three complementary system-level use cases. First, we introduce a lightweight, category-agnostic hazard screening approach leveraging CLIP-based image-text similarity to produce a low-latency semantic hazard signal. This enables robust detection of diverse and out-of-distribution road hazards without explicit object detection or visual question answering. Second, we examine the integration of scene-level vision-language embeddings into a transformer-based trajectory planning framework using the Waymo Open Dataset. Our results show that naively conditioning planners on global embeddings does not improve trajectory accuracy, highlighting the importance of representation-task alignment and motivating the development of task-informed extraction methods for safety-critical planning. Third, we investigate natural language as an explicit behavioral constraint on motion planning using the doScenes dataset. In this setting, passenger-style instructions grounded in visual scene elements suppress rare but severe planning failures and improve safety-aligned behavior in ambiguous scenarios. Taken together, these findings demonstrate that vision-language representations hold significant promise for autonomous driving safety when used to express semantic risk, intent, and behavioral constraints. Realizing this potential is fundamentally an engineering problem requiring careful system design and structured grounding rather than direct feature injection.

</details>


### [69] [Process-of-Thought Reasoning for Videos](https://arxiv.org/abs/2602.07689)
*Jusheng Zhang,Kaitong Cai,Jian Wang,Yongsen Zheng,Kwok-Yan Lam,Keze Wang*

Main category: cs.CV

TL;DR: 提出视频推理的思维过程框架，通过将推理分解为可验证的步骤来提升视频理解能力


<details>
  <summary>Details</summary>
Motivation: 视频理解需要处理长而嘈杂的观察，进行时间锚定的多步推理，现有方法在推理过程的可解释性和证据追溯性方面存在不足

Method: 提出思维过程推理框架，包含三个交错步骤：时间证据选择、逐步状态更新和约束答案合成，采用模型无关设计，可与现有视觉语言主干结合

Result: 在标准视频推理任务上，PoT框架显著提高了事实正确性和时间定位准确性，同时提供可解释的推理轨迹

Conclusion: PoT框架通过结构化、可验证的推理步骤，有效提升了视频推理的鲁棒性和可解释性，为复杂视频理解任务提供了新方法

Abstract: Video understanding requires not only recognizing visual content but also performing temporally grounded, multi-step reasoning over long and noisy observations. We propose Process-of-Thought (PoT) Reasoning for Videos, a framework that makes the reasoning process explicit by structuring video inference into a sequence of lightweight, verifiable steps. PoT interleaves (i) temporal evidence selection, (ii) step-wise state updates, and (iii) constrained answer synthesis, enabling the model to progressively refine hypotheses while maintaining traceability to video evidence. The framework is designed to be model-agnostic and can be plugged into existing vision-language backbones, supporting both closed-book reasoning and evidence-augmented reasoning with external tools. We further introduce a unified representation for PoT traces that aligns intermediate decisions with temporal segments, which improves robustness to distractors and reduces hallucinated explanations. Extensive experiments on standard video reasoning tasks demonstrate that PoT consistently improves factual correctness and temporal grounding, while providing interpretable reasoning traces for diagnosis and downstream use.

</details>


### [70] [Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion](https://arxiv.org/abs/2602.07775)
*Haodong Li,Shaoteng Liu,Zhe Lin,Manmohan Chandraker*

Main category: cs.CV

TL;DR: 提出Rolling Sink方法，无需额外训练即可解决自回归视频扩散模型在超长时域测试中的视觉退化问题，将视频合成扩展到5-30分钟


<details>
  <summary>Details</summary>
Motivation: 自回归视频扩散模型在有限训练时长下存在训练-测试差距，当测试时长超过训练时长时会出现视觉退化。由于开放测试可能超过任何有限训练窗口，且长视频训练计算成本高，需要寻找无需训练的解决方案

Method: 通过系统分析自回归缓存维护机制，提出Rolling Sink方法。该方法基于Self Forcing（仅用5秒片段训练），在测试时通过有效的缓存管理将视频合成扩展到超长时域

Result: Rolling Sink能够将视频合成扩展到5-30分钟（16 FPS），保持一致的物体、稳定的颜色、连贯的结构和平滑的运动。相比现有最佳基线方法，在长时域视觉保真度和时间一致性方面表现更优

Conclusion: Rolling Sink提供了一种无需训练的有效解决方案，成功解决了自回归视频扩散模型在超长时域测试中的训练-测试差距问题，实现了高质量的超长视频合成

Abstract: Recently, autoregressive (AR) video diffusion models has achieved remarkable performance. However, due to their limited training durations, a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations. Following Self Forcing, which studies the train-test gap within the training duration, this work studies the train-test gap beyond the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing. Since open-ended testing can extend beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap. To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance. These insights lead to Rolling Sink. Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions. As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines. Project page: https://rolling-sink.github.io/

</details>


### [71] [How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study](https://arxiv.org/abs/2602.07814)
*Simiao Ren,Yuchen Zhou,Xingyu Shen,Kidus Zewde,Tommy Duong,George Huang,Hatsanai,Tiangratanakul,Tsang,Ng,En Wei,Jiayu Xue*

Main category: cs.CV

TL;DR: 该研究首次对16种最先进的AI生成图像检测方法进行了全面的零样本评估，覆盖23个预训练检测器变体和12个数据集，揭示了现有检测器在真实部署场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像在数字平台上的激增，可靠的检测方法对于打击虚假信息和维护内容真实性变得至关重要。现有基准主要评估微调模型，忽略了零样本性能这一最常见的实际部署场景，存在重要研究空白。

Method: 对16种最先进的检测方法（包含23个预训练检测器变体）在12个多样化数据集上进行零样本评估，涵盖260万张图像样本和291个不同的生成器，包括现代扩散模型。

Result: 研究发现：(1)不存在通用最佳检测器，检测器排名在不同数据集间极不稳定；(2)最佳检测器（平均准确率75.0%）与最差检测器（37.5%）存在37个百分点的性能差距；(3)训练数据对齐对泛化能力影响显著，导致相同架构检测器家族内20-60%的性能差异；(4)现代商业生成器（Flux Dev、Firefly v4、Midjourney v7）能击败大多数检测器，平均准确率仅18-30%；(5)识别出三种影响跨数据集泛化的系统性失败模式。

Conclusion: 研究结果挑战了"一刀切"的检测器范式，表明从业者必须根据具体威胁环境仔细选择检测器，而不能依赖已发布的基准性能。提供了实用的部署指南。

Abstract: As AI-generated images proliferate across digital platforms, reliable detection methods have become critical for combating misinformation and maintaining content authenticity. While numerous deepfake detection methods have been proposed, existing benchmarks predominantly evaluate fine-tuned models, leaving a critical gap in understanding out-of-the-box performance -- the most common deployment scenario for practitioners. We present the first comprehensive zero-shot evaluation of 16 state-of-the-art detection methods, comprising 23 pretrained detector variants (due to multiple released versions of certain detectors), across 12 diverse datasets, comprising 2.6~million image samples spanning 291 unique generators including modern diffusion models. Our systematic analysis reveals striking findings: (1)~no universal winner exists, with detector rankings exhibiting substantial instability (Spearman~$ρ$: 0.01 -- 0.87 across dataset pairs); (2)~a 37~percentage-point performance gap separates the best detector (75.0\% mean accuracy) from the worst (37.5\%); (3)~training data alignment critically impacts generalization, causing up to 20--60\% performance variance within architecturally identical detector families; (4)~modern commercial generators (Flux~Dev, Firefly~v4, Midjourney~v7) defeat most detectors, achieving only 18--30\% average accuracy; and (5)~we identify three systematic failure patterns affecting cross-dataset generalization. Statistical analysis confirms significant performance differences between detectors (Friedman test: $χ^2$=121.01, $p<10^{-16}$, Kendall~$W$=0.524). Our findings challenge the ``one-size-fits-all'' detector paradigm and provide actionable deployment guidelines, demonstrating that practitioners must carefully select detectors based on their specific threat landscape rather than relying on published benchmark performance.

</details>


### [72] [Out of the box age estimation through facial imagery: A Comprehensive Benchmark of Vision-Language Models vs. out-of-the-box Traditional Architectures](https://arxiv.org/abs/2602.07815)
*Simiao Ren*

Main category: cs.CV

TL;DR: VLMs在面部年龄估计任务中显著优于专用模型，平均MAE为5.65年vs 9.88年，最佳VLM比最佳专用模型性能提升15%，挑战了任务专用架构的必要性假设。


<details>
  <summary>Details</summary>
Motivation: 面部年龄估计在内容审核、年龄验证和深度伪造检测中至关重要，但此前缺乏对现代视觉语言模型与专用年龄估计架构的系统性比较。

Method: 创建首个大规模跨范式基准测试，评估34个模型（22个专用架构和12个通用VLMs），在8个标准数据集上使用总计1,100张测试图像，进行MAE、年龄验证准确率等多维度分析。

Result: 零样本VLMs显著优于大多数专用模型（平均MAE 5.65年 vs 9.88年），最佳VLM（Gemini 3 Flash Preview，MAE 4.32）比最佳非LLM模型（MiVOLO，MAE 5.10）提升15%。VLMs在18岁阈值年龄验证中错误率更低（13-25% vs 60-100%）。

Conclusion: 研究挑战了任务专用架构对年龄估计必要的假设，建议领域应转向将VLM能力蒸馏到高效专用模型中，而非继续开发传统专用架构。

Abstract: Facial age estimation is critical for content moderation, age verification, and deepfake detection, yet no prior benchmark has systematically compared modern vision-language models (VLMs) against specialized age estimation architectures. We present the first large-scale cross-paradigm benchmark, evaluating \textbf{34 models} -- 22 specialized architectures with publicly available pretrained weights and 12 general-purpose VLMs -- across \textbf{8 standard datasets} (UTKFace, IMDB-WIKI, MORPH, AFAD, CACD, FG-NET, APPA-REAL, AgeDB) totaling 1{,}100 test images per model. Our key finding is striking: \emph{zero-shot VLMs significantly outperform most specialized models}, achieving an average MAE of 5.65 years compared to 9.88 for non-LLM models. The best VLM (Gemini~3 Flash Preview, MAE~4.32) outperforms the best non-LLM model (MiVOLO, MAE~5.10) by 15\%. Only MiVOLO, which uniquely combines face and body features via Vision Transformers, competes with VLMs. We further analyze age verification at the 18-year threshold, revealing that non-LLM models exhibit 60--100\% false adult rates on minors while VLMs achieve 13--25\%, and demonstrate that coarse age binning (8--9 classes) consistently degrades MAE beyond 13 years. Our stratified analysis across 14 age groups reveals that all models struggle most at extreme ages ($<$5 and 65+). These findings challenge the assumption that task-specific architectures are necessary for age estimation and suggest that the field should redirect toward distilling VLM capabilities into efficient specialized models.

</details>


### [73] [Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection](https://arxiv.org/abs/2602.07827)
*Guoting Wei,Xia Yuan,Yang Zhou,Haizhao Jing,Yu Liu,Xianbiao Qi,Chunxia Zhao,Haokui Zhang,Rong Xiao*

Main category: cs.CV

TL;DR: OTA-Det是首个统一开放词汇航空检测和遥感视觉定位的框架，通过任务重构和密集语义对齐策略，实现细粒度语义理解和多目标检测，在保持实时推理的同时在六个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇航空检测(OVAD)只能提供粗粒度类别语义，而遥感视觉定位(RSVG)仅限于单目标定位，两者都无法同时支持丰富的语义理解和多目标检测，需要统一的解决方案。

Method: 1) 任务重构策略统一任务目标和监督机制，实现跨范式数据集的联合训练；2) 密集语义对齐策略建立从整体表达到个体属性的多粒度对应关系；3) 基于RT-DETR架构扩展，引入高效模块实现开放文本检测。

Result: 在六个涵盖OVAD和RSVG任务的基准测试中达到最先进性能，同时保持34 FPS的实时推理速度。

Conclusion: OTA-Det成功统一了两个关键航空场景理解范式，实现了细粒度语义理解和多目标检测的协同，为航空场景理解提供了高效统一的解决方案。

Abstract: Open-Vocabulary Aerial Detection (OVAD) and Remote Sensing Visual Grounding (RSVG) have emerged as two key paradigms for aerial scene understanding. However, each paradigm suffers from inherent limitations when operating in isolation: OVAD is restricted to coarse category-level semantics, while RSVG is structurally limited to single-target localization. These limitations prevent existing methods from simultaneously supporting rich semantic understanding and multi-target detection. To address this, we propose OTA-Det, the first unified framework that bridges both paradigms into a cohesive architecture. Specifically, we introduce a task reformulation strategy that unifies task objectives and supervision mechanisms, enabling joint training across datasets from both paradigms with dense supervision signals. Furthermore, we propose a dense semantic alignment strategy that establishes explicit correspondence at multiple granularities, from holistic expressions to individual attributes, enabling fine-grained semantic understanding. To ensure real-time efficiency, OTA-Det builds upon the RT-DETR architecture, extending it from closed-set detection to open-text detection by introducing several high efficient modules, achieving state-of-the-art performance on six benchmarks spanning both OVAD and RSVG tasks while maintaining real-time inference at 34 FPS.

</details>


### [74] [SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models](https://arxiv.org/abs/2602.07833)
*Weijiang Lv,Yaoxuan Feng,Xiaobo Xia,Jiayu Wang,Yan Jing,Wenchao Chen,Bo Chen*

Main category: cs.CV

TL;DR: 该论文提出了SPD-Faith Bench基准，用于评估多模态大语言模型推理过程的忠实性，发现了两种系统性失败模式，并提出了无需训练的SAGE框架来改进视觉证据校准。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型广泛使用思维链推理来提高可解释性，但生成的推理轨迹的忠实性仍不清楚。先前工作主要关注感知幻觉，而推理层面的不忠实性尚未得到充分探索。

Method: 引入SPD-Faith Bench诊断基准，基于细粒度图像差异推理强制进行显式视觉比较。通过分析发现两种系统性失败模式，并提出SAGE框架，这是一个无需训练的视觉证据校准框架，通过改进视觉路由和对齐推理与感知来提升忠实性。

Result: 在先进的多模态大语言模型评估中发现了两种系统性失败模式：感知盲区和感知-推理分离。这些失败源于残差流中的视觉注意力衰减和表示偏移。SAGE框架能够有效改进视觉路由并提升推理忠实性。

Conclusion: 研究强调了在响应正确性之外显式评估忠实性的重要性。提出的基准和SAGE框架为理解和改进多模态大语言模型的推理忠实性提供了有效工具。

Abstract: Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reasoning that enforces explicit visual comparison. Evaluations on state-of-the-art MLLMs reveal two systematic failure modes, perceptual blindness and perception-reasoning dissociation. We trace these failures to decaying visual attention and representation shifts in the residual stream. Guided by this analysis, we propose SAGE, a train-free visual evidence-calibrated framework that improves visual routing and aligns reasoning with perception. Our results highlight the importance of explicitly evaluating faithfulness beyond response correctness. Our benchmark and codes are available at https://github.com/Johanson-colab/SPD-Faith-Bench.

</details>


### [75] [VFace: A Training-Free Approach for Diffusion-Based Video Face Swapping](https://arxiv.org/abs/2602.07835)
*Sanoojan Baliah,Yohan Abeysinghe,Rusiru Thushara,Khan Muhammad,Abhinav Dhall,Karthik Nandakumar,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: VFace是一个无需训练、即插即用的视频人脸交换方法，可与基于扩散模型的图像人脸交换方法无缝集成，通过频率谱注意力插值、目标结构引导和流引导注意力时序平滑三个技术提升视频人脸交换的时序一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像人脸交换方法在应用到视频时存在时序不一致问题，帧间生成结果缺乏连贯性，需要一种无需额外训练或视频特定微调的方法来提升视频人脸交换的时序一致性和视觉质量。

Method: 1. 频率谱注意力插值技术：促进生成并保留关键身份特征
2. 目标结构引导：通过即插即用的注意力注入，将目标帧的结构特征更好地对齐到生成过程
3. 流引导注意力时序平滑机制：在不修改底层扩散模型的情况下强制时空一致性，减少帧间生成的时间不一致性

Result: 大量实验表明，该方法显著提升了时序一致性和视觉保真度，为视频人脸交换提供了一个实用且模块化的解决方案。

Conclusion: VFace是一个无需训练、即插即用的视频人脸交换方法，可与现有图像人脸交换方法无缝集成，通过三个关键技术有效解决了视频人脸交换中的时序一致性问题，提供了高质量的实用解决方案。

Abstract: We present a training-free, plug-and-play method, namely VFace, for high-quality face swapping in videos. It can be seamlessly integrated with image-based face swapping approaches built on diffusion models. First, we introduce a Frequency Spectrum Attention Interpolation technique to facilitate generation and intact key identity characteristics. Second, we achieve Target Structure Guidance via plug-and-play attention injection to better align the structural features from the target frame to the generation. Third, we present a Flow-Guided Attention Temporal Smoothening mechanism that enforces spatiotemporal coherence without modifying the underlying diffusion model to reduce temporal inconsistencies typically encountered in frame-wise generation. Our method requires no additional training or video-specific fine-tuning. Extensive experiments show that our method significantly enhances temporal consistency and visual fidelity, offering a practical and modular solution for video-based face swapping. Our code is available at https://github.com/Sanoojan/VFace.

</details>


### [76] [Geometry-Aware Rotary Position Embedding for Consistent Video World Model](https://arxiv.org/abs/2602.07854)
*Chendong Xiang,Jiajun Liu,Jintao Zhang,Xiao Yang,Zhengwei Fang,Shizun Wang,Zijun Wang,Yingtian Zou,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: ViewRope是一种几何感知编码方法，通过将相机射线方向直接注入视频Transformer自注意力层，解决了预测世界模型中空间持久性不足的问题，显著改善了长期一致性并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前预测世界模型缺乏空间持久性，在长轨迹中无法保持稳定的场景结构，当相机重新访问先前观察位置时经常出现幻觉细节。这种几何漂移源于对屏幕空间位置嵌入的依赖，这与3D一致性所需的投影几何相冲突。

Method: 提出ViewRope几何感知编码，将相机射线方向直接注入视频Transformer自注意力层；提出几何感知帧稀疏注意力，利用几何线索选择性关注相关历史帧；创建ViewBench诊断套件测量闭环保真度和几何漂移。

Result: ViewRope显著改善了长期一致性，同时减少了计算成本。几何感知帧稀疏注意力提高了效率而不牺牲内存一致性。

Conclusion: 通过几何感知编码和注意力机制，可以有效解决预测世界模型中的空间持久性问题，实现更稳定的3D一致性场景建模。

Abstract: Predictive world models that simulate future observations under explicit camera control are fundamental to interactive AI. Despite rapid advances, current systems lack spatial persistence: they fail to maintain stable scene structures over long trajectories, frequently hallucinating details when cameras revisit previously observed locations. We identify that this geometric drift stems from reliance on screen-space positional embeddings, which conflict with the projective geometry required for 3D consistency. We introduce \textbf{ViewRope}, a geometry-aware encoding that injects camera-ray directions directly into video transformer self-attention layers. By parameterizing attention with relative ray geometry rather than pixel locality, ViewRope provides a model-native inductive bias for retrieving 3D-consistent content across temporal gaps. We further propose \textbf{Geometry-Aware Frame-Sparse Attention}, which exploits these geometric cues to selectively attend to relevant historical frames, improving efficiency without sacrificing memory consistency. We also present \textbf{ViewBench}, a diagnostic suite measuring loop-closure fidelity and geometric drift. Our results demonstrate that ViewRope substantially improves long-term consistency while reducing computational costs.

</details>


### [77] [Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images](https://arxiv.org/abs/2602.07860)
*Fei Yu,Shudan Guo,Shiqing Xin,Beibei Wang,Haisen Zhao,Wenzheng Chen*

Main category: cs.CV

TL;DR: 提出了一种从超高速运动模糊图像中恢复3D形状的新方法，通过快速重心坐标求解器实现高效可微的逆渲染，在平移和旋转运动场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在体育（如球类）或旋转机械等自然和工业场景中，物体高速运动会产生严重运动模糊，传统多视图立体等3D重建技术失效，需要解决从极端运动模糊图像恢复几何形状的挑战。

Method: 提出了一种新颖的逆渲染方法，核心是快速重心坐标求解器，解决了传统渲染中多次计算重心权重的计算瓶颈，实现了高达4.57倍的加速，同时保持完全可微性，支持从渲染图像到3D形状的梯度传播。

Result: 在快速平移和旋转两种代表性运动类型上验证了方法，实验结果表明：1）前向模拟中能高效逼真地建模超高速运动物体；2）成功从经历极端平移和旋转运动的物体2D图像中恢复3D形状。

Conclusion: 该方法突破了基于视觉的3D重建边界，为从超高速运动模糊图像中恢复3D形状提供了有效解决方案，在计算效率和形状恢复精度方面均有显著提升。

Abstract: We consider the problem of 3D shape recovery from ultra-fast motion-blurred images. While 3D reconstruction from static images has been extensively studied, recovering geometry from extreme motion-blurred images remains challenging. Such scenarios frequently occur in both natural and industrial settings, such as fast-moving objects in sports (e.g., balls) or rotating machinery, where rapid motion distorts object appearance and makes traditional 3D reconstruction techniques like Multi-View Stereo (MVS) ineffective.
  In this paper, we propose a novel inverse rendering approach for shape recovery from ultra-fast motion-blurred images. While conventional rendering techniques typically synthesize blur by averaging across multiple frames, we identify a major computational bottleneck in the repeated computation of barycentric weights. To address this, we propose a fast barycentric coordinate solver, which significantly reduces computational overhead and achieves a speedup of up to 4.57x, enabling efficient and photorealistic simulation of high-speed motion. Crucially, our method is fully differentiable, allowing gradients to propagate from rendered images to the underlying 3D shape, thereby facilitating shape recovery through inverse rendering.
  We validate our approach on two representative motion types: rapid translation and rotation. Experimental results demonstrate that our method enables efficient and realistic modeling of ultra-fast moving objects in the forward simulation. Moreover, it successfully recovers 3D shapes from 2D imagery of objects undergoing extreme translational and rotational motion, advancing the boundaries of vision-based 3D reconstruction. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/

</details>


### [78] [Thinking in Structures: Evaluating Spatial Intelligence through Reasoning on Constrained Manifolds](https://arxiv.org/abs/2602.07864)
*Chen Yang,Guanxin Lin,Youquan He,Peiyao Chen,Guanghe Liu,Yufan Mo,Zhouyuan Xu,Linhao Wang,Guohui Zhang,Zihang Zhang,Shenxiang Zeng,Chen Wang,Jiansheng Fan*

Main category: cs.CV

TL;DR: SSI-Bench是一个用于评估视觉-语言模型空间推理能力的VQA基准测试，专注于受约束流形上的空间推理，包含1000个排序问题，测试几何和拓扑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试大多评估无约束场景，模型可以利用2D捷径，缺乏对真实物理世界中受几何、拓扑和物理约束的空间推理能力的评估。

Method: 通过完全人工中心的流程创建：10名研究人员花费400多小时策划图像、标注结构组件、设计问题以最小化像素级线索。包含几何和拓扑推理问题，需要心理旋转、横截面推理、遮挡推理和力路径推理等复合空间操作。

Result: 评估31个广泛使用的VLM显示与人类存在巨大差距：最佳开源模型准确率22.2%，最强闭源模型33.6%，而人类得分91.6%。鼓励模型思考仅带来边际收益，错误分析显示模型在结构基础和约束一致的3D推理方面存在失败。

Conclusion: SSI-Bench揭示了当前VLM在空间推理方面的严重不足，特别是在受约束的3D结构推理上，为未来模型改进提供了重要的评估基准。

Abstract: Spatial intelligence is crucial for vision--language models (VLMs) in the physical world, yet many benchmarks evaluate largely unconstrained scenes where models can exploit 2D shortcuts. We introduce SSI-Bench, a VQA benchmark for spatial reasoning on constrained manifolds, built from complex real-world 3D structures whose feasible configurations are tightly governed by geometric, topological, and physical constraints. SSI-Bench contains 1,000 ranking questions spanning geometric and topological reasoning and requiring a diverse repertoire of compositional spatial operations, such as mental rotation, cross-sectional inference, occlusion reasoning, and force-path reasoning. It is created via a fully human-centered pipeline: ten researchers spent over 400 hours curating images, annotating structural components, and designing questions to minimize pixel-level cues. Evaluating 31 widely used VLMs reveals a large gap to humans: the best open-source model achieves 22.2% accuracy and the strongest closed-source model reaches 33.6%, while humans score 91.6%. Encouraging models to think yields only marginal gains, and error analysis points to failures in structural grounding and constraint-consistent 3D reasoning. Project page: https://ssi-bench.github.io.

</details>


### [79] [WristMIR: Coarse-to-Fine Region-Aware Retrieval of Pediatric Wrist Radiographs with Radiology Report-Driven Learning](https://arxiv.org/abs/2602.07872)
*Mert Sonmezer,Serge Vasylechko,Duygu Atasoy,Seyda Ertekin,Sila Kurugol*

Main category: cs.CV

TL;DR: WristMIR：一种基于区域感知的儿科腕部X光片检索框架，通过全局和局部对比学习提升骨折模式检索性能


<details>
  <summary>Details</summary>
Motivation: 腕部X光片中骨折模式的检索具有挑战性，因为临床重要线索细微、高度局部化，常被重叠解剖结构或不同成像视角所掩盖。现有方法受限于缺乏大规模、高质量标注的医学图像检索数据集。

Method: 提出WristMIR框架：1）使用MedGemma结构化报告挖掘生成全局和区域级描述；2）预处理腕部图像和特定骨骼区域（远端桡骨、远端尺骨、尺骨茎突）裁剪；3）联合训练全局和局部对比编码器；4）采用两阶段检索：粗粒度全局匹配筛选候选图像，然后基于解剖区域的区域条件重排序。

Result: 显著提升检索性能：图像到文本Recall@5从0.82%提升至9.35%；骨折分类性能增强（AUROC 0.949，AUPRC 0.953）；区域感知评估中，两阶段设计将骨折诊断的平均F1分数从0.568提升至0.753；放射科医生评价其检索病例临床相关性更高（平均评分从3.36升至4.35）。

Conclusion: 解剖引导的检索方法在儿科肌肉骨骼成像中具有增强诊断推理和支持临床决策的潜力，WristMIR框架通过区域感知方法显著提升了腕部骨折模式的检索性能。

Abstract: Retrieving wrist radiographs with analogous fracture patterns is challenging because clinically important cues are subtle, highly localized and often obscured by overlapping anatomy or variable imaging views. Progress is further limited by the scarcity of large, well-annotated datasets for case-based medical image retrieval. We introduce WristMIR, a region-aware pediatric wrist radiograph retrieval framework that leverages dense radiology reports and bone-specific localization to learn fine-grained, clinically meaningful image representations without any manual image-level annotations. Using MedGemma-based structured report mining to generate both global and region-level captions, together with pre-processed wrist images and bone-specific crops of the distal radius, distal ulna, and ulnar styloid, WristMIR jointly trains global and local contrastive encoders and performs a two-stage retrieval process: (1) coarse global matching to identify candidate exams, followed by (2) region-conditioned reranking aligned to a predefined anatomical bone region. WristMIR improves retrieval performance over strong vision-language baselines, raising image-to-text Recall@5 from 0.82% to 9.35%. Its embeddings also yield stronger fracture classification (AUROC 0.949, AUPRC 0.953). In region-aware evaluation, the two-stage design markedly improves retrieval-based fracture diagnosis, increasing mean $F_1$ from 0.568 to 0.753, and radiologists rate its retrieved cases as more clinically relevant, with mean scores rising from 3.36 to 4.35. These findings highlight the potential of anatomically guided retrieval to enhance diagnostic reasoning and support clinical decision-making in pediatric musculoskeletal imaging. The source code is publicly available at https://github.com/quin-med-harvard-edu/WristMIR.

</details>


### [80] [Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video](https://arxiv.org/abs/2602.07891)
*Zihui Gao,Ke Liu,Donny Y. Chen,Duochao Shi,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: SAGE框架通过互联网视频流自适应几何基础模型，解决3D标注数据稀缺问题，显著提升零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 几何基础模型在3D重建方面有潜力，但受到多样化大规模3D标注数据稀缺的限制。互联网视频提供几乎无限的原始数据，但由于缺乏真实几何信息和存在观测噪声，将其作为几何学习的扩展源具有挑战性。

Method: 提出SAGE框架，采用分层挖掘管道将视频转换为训练轨迹和混合监督：(1)信息丰富的训练轨迹选择；(2)通过SfM点云进行稀疏几何锚定提供全局结构指导；(3)通过3D高斯渲染进行密集可微一致性提供多视图约束。为防止灾难性遗忘，引入基于锚定数据的正则化策略。

Result: 在未见过的基准测试（7Scenes、TUM-RGBD、Matterport3D）上，SAGE显著增强了零样本泛化能力，与最先进的基线相比，将Chamfer距离减少了20-42%。

Conclusion: SAGE开创了通过互联网视频自适应几何基础模型的先河，为通用3D学习建立了可扩展的范式。

Abstract: Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation of GEometric foundation models from raw video streams. SAGE leverages a hierarchical mining pipeline to transform videos into training trajectories and hybrid supervision: (1) Informative training trajectory selection; (2) Sparse Geometric Anchoring via SfM point clouds for global structural guidance; and (3) Dense Differentiable Consistency via 3D Gaussian rendering for multi-view constraints. To prevent catastrophic forgetting, we introduce a regularization strategy using anchor data. Extensive experiments show that SAGE significantly enhances zero-shot generalization, reducing Chamfer Distance by 20-42% on unseen benchmarks (7Scenes, TUM-RGBD, Matterport3D) compared to state-of-the-art baselines. To our knowledge, SAGE pioneers the adaptation of geometric foundation models via Internet video, establishing a scalable paradigm for general-purpose 3D learning.

</details>


### [81] [Rethinking Practical and Efficient Quantization Calibration for Vision-Language Models](https://arxiv.org/abs/2602.07899)
*Zhenhao Shang,Haizhao Jing,Guoting Wei,Haokui Zhang,Rong Xiao,Jianqing Gao,Peng Wang*

Main category: cs.CV

TL;DR: TLQ是一个针对视觉语言模型的token级重要性感知层量化框架，通过梯度引导的token重要性集成机制和多GPU层校准方案，显著提升量化性能


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型中视觉token和文本token在激活分布和量化误差敏感性方面存在显著差异，给PTQ校准带来重大挑战，需要重新思考VLM中的校准策略

Method: 提出TLQ框架：1) 基于梯度信息的token级重要性集成机制，构建token级校准集；2) 多GPU、量化暴露的层校准方案，保持校准与真实量化推理路径一致，并分布式处理校准工作负载

Result: 在两个模型、三个模型规模和两种量化设置下进行评估，在所有设置中均实现性能提升，显示出强大的量化稳定性

Conclusion: TLQ通过细粒度的token级校准策略和高效的多GPU层校准方案，有效解决了VLM量化中的校准挑战，为视觉语言模型的部署提供了有效的后训练量化解决方案

Abstract: Post-training quantization (PTQ) is a primary approach for deploying large language models without fine-tuning, and the quantized performance is often strongly affected by the calibration in PTQ. By contrast, in vision-language models (VLMs), substantial differences between visual and text tokens in their activation distributions and sensitivities to quantization error pose significant challenges for effective calibration during PTQ. In this work, we rethink what PTQ calibration should align with in VLMs and propose the Token-level Importance-aware Layer-wise Quantization framework (TLQ). Guided by gradient information, we design a token-level importance integration mechanism for quantization error, and use it to construct a token-level calibration set, enabling a more fine-grained calibration strategy. Furthermore, TLQ introduces a multi-GPU, quantization-exposed layer-wise calibration scheme. This scheme keeps the layer-wise calibration procedure consistent with the true quantized inference path and distributes the complex layer-wise calibration workload across multiple RTX3090 GPUs, thereby reducing reliance on the large memory of A100 GPUs. TLQ is evaluated across two models, three model scales, and two quantization settings, consistently achieving performance improvements across all settings, indicating its strong quantization stability. The code will be released publicly.

</details>


### [82] [Which private attributes do VLMs agree on and predict well?](https://arxiv.org/abs/2602.07931)
*Olena Hrynenko,Darya Baranouskaya,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 该研究评估了开源视觉语言模型在隐私相关属性识别中的零样本表现，发现VLM倾向于比人类标注者更频繁地预测隐私属性存在，但在高一致性情况下可以补充人类标注的不足。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型常用于图像视觉属性的零样本检测，但对其在隐私相关属性识别方面的表现缺乏系统评估。本研究旨在评估开源VLM在隐私属性识别中的零样本能力，探索VLM与人类标注的一致性差异。

Method: 采用零样本评估方法，使用开源视觉语言模型进行隐私相关属性识别。通过分析VLM与人类标注者之间的标注一致性，识别VLM表现出高内部一致性的属性，并讨论VLM与人类标注之间的分歧情况。

Result: 研究发现：1) 与人类标注相比，VLM倾向于更频繁地预测隐私属性的存在；2) 在VLM内部一致性高的情况下，VLM能够识别人类标注者忽略的属性；3) VLM与人类标注存在系统性的分歧模式。

Conclusion: 视觉语言模型在隐私属性识别方面具有潜力，特别是在大规模图像数据集的隐私标注支持方面。VLM可以补充人类标注的不足，但需要注意其与人类标注的系统性差异。

Abstract: Visual Language Models (VLMs) are often used for zero-shot detection of visual attributes in the image. We present a zero-shot evaluation of open-source VLMs for privacy-related attribute recognition. We identify the attributes for which VLMs exhibit strong inter-annotator agreement, and discuss the disagreement cases of human and VLM annotations. Our results show that when evaluated against human annotations, VLMs tend to predict the presence of privacy attributes more often than human annotators. In addition to this, we find that in cases of high inter-annotator agreement between VLMs, they can complement human annotation by identifying attributes overlooked by human annotators. This highlights the potential of VLMs to support privacy annotations in large-scale image datasets.

</details>


### [83] [One-Shot Crowd Counting With Density Guidance For Scene Adaptaion](https://arxiv.org/abs/2602.07955)
*Jiwei Chen,Qi Wang,Junyu Gao,Jing Zhang,Dingyi Li,Jing-Jia Luo*

Main category: cs.CV

TL;DR: 本文提出一种基于少样本学习的跨场景人群计数方法，通过局部和全局密度特征引导模型适应未见过的监控场景


<details>
  <summary>Details</summary>
Motivation: 现有的人群计数模型在不同监控场景间的泛化能力有限，因为不同摄像头捕获的人群场景差异很大。为了提高模型对未见过的监控场景的适应性，需要让模型能够基于少量样本快速适应新场景。

Method: 1) 提出多局部密度学习器，学习支持场景中不同密度分布的原型，生成局部密度相似度矩阵进行局部指导；2) 从支持图像中提取全局密度特征，进行全局指导；3) 将局部和全局密度特征结合，引导模型适应目标场景。

Result: 在三个监控数据集上的实验表明，该方法能够有效适应未见过的监控场景，在少样本人群计数任务中优于当前最先进的方法。

Conclusion: 通过结合局部和全局密度特征的少样本学习方法，能够显著提升人群计数模型对未见监控场景的泛化能力，为解决跨场景人群计数问题提供了有效方案。

Abstract: Crowd scenes captured by cameras at different locations vary greatly, and existing crowd models have limited generalization for unseen surveillance scenes. To improve the generalization of the model, we regard different surveillance scenes as different category scenes, and introduce few-shot learning to make the model adapt to the unseen surveillance scene that belongs to the given exemplar category scene. To this end, we propose to leverage local and global density characteristics to guide the model of crowd counting for unseen surveillance scenes. Specifically, to enable the model to adapt to the varying density variations in the target scene, we propose the multiple local density learner to learn multi prototypes which represent different density distributions in the support scene. Subsequently, these multiple local density similarity matrixes are encoded. And they are utilized to guide the model in a local way. To further adapt to the global density in the target scene, the global density features are extracted from the support image, then it is used to guide the model in a global way. Experiments on three surveillance datasets shows that proposed method can adapt to the unseen surveillance scene and outperform recent state-of-the-art methods in the few-shot crowd counting.

</details>


### [84] [D-ORCA: Dialogue-Centric Optimization for Robust Audio-Visual Captioning](https://arxiv.org/abs/2602.07960)
*Changli Tang,Tianyi Wang,Fengyun Rao,Jing Lyu,Chao Zhang*

Main category: cs.CV

TL;DR: D-ORCA是一个面向对话的跨模态大语言模型，专注于视频中的说话人识别、语音识别和时间定位任务，在双语数据集上训练并通过强化学习优化，性能优于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 视频中的对话是重要的信息来源，准确识别谁在何时说了什么对于深度视频理解至关重要。目前开源生态中缺乏大规模高质量的多方对话视频数据集和专门针对对话理解的跨模态模型。

Method: 1. 构建DVD双语数据集（近4万训练视频+2000评估视频）；2. 开发D-ORCA对话中心跨模态大语言模型；3. 采用群体相对策略优化，引入三个新颖的奖励函数：说话人归属准确性、全局语音内容准确性、句子级时间边界对齐。

Result: D-ORCA在说话人识别、语音识别和时间定位方面显著优于现有开源模型。尽管只有80亿参数，但在多个通用音频-视觉理解基准测试中与Qwen3-Omni表现相当。

Conclusion: D-ORCA通过专门的数据集和强化学习优化策略，为视频对话理解提供了有效的解决方案，填补了开源生态中的关键空白，并在多个任务上展现了优越性能。

Abstract: Spoken dialogue is a primary source of information in videos; therefore, accurately identifying who spoke what and when is essential for deep video understanding. We introduce D-ORCA, a \textbf{d}ialogue-centric \textbf{o}mni-modal large language model optimized for \textbf{r}obust audio-visual \textbf{ca}ptioning. We further curate DVD, a large-scale, high-quality bilingual dataset comprising nearly 40,000 multi-party dialogue videos for training and 2000 videos for evaluation in English and Mandarin, addressing a critical gap in the open-source ecosystem. To ensure fine-grained captioning accuracy, we adopt group relative policy optimization with three novel reward functions that assess speaker attribution accuracy, global speech content accuracy, and sentence-level temporal boundary alignment. These rewards are derived from evaluation metrics widely used in speech processing and, to our knowledge, are applied for the first time as reinforcement learning objectives for audio-visual captioning. Extensive experiments demonstrate that D-ORCA substantially outperforms existing open-source models in speaker identification, speech recognition, and temporal grounding. Notably, despite having only 8 billion parameters, D-ORCA achieves performance competitive with Qwen3-Omni across several general-purpose audio-visual understanding benchmarks. Demos are available at \href{https://d-orca-llm.github.io/}{https://d-orca-llm.github.io/}. Our code, data, and checkpoints will be available at \href{https://github.com/WeChatCV/D-ORCA/}{https://github.com/WeChatCV/D-ORCA/}.

</details>


### [85] [EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation](https://arxiv.org/abs/2602.07967)
*Xiaofeng Tan,Wanjiang Weng,Haodong Lei,Hongsong Wang*

Main category: cs.CV

TL;DR: EasyTune提出了一种针对扩散模型的高效偏好对齐方法，通过分步微调解决传统方法中的递归依赖问题，显著降低了内存消耗并提升了训练速度。


<details>
  <summary>Details</summary>
Motivation: 当前基于可微分奖励的扩散模型偏好对齐方法存在两个主要问题：1）优化效率低且粒度粗糙；2）内存消耗高。研究发现这些限制源于去噪轨迹中不同步骤之间的递归依赖关系。

Method: 提出EasyTune方法，在去噪过程的每个步骤分别微调扩散模型，而不是在整个轨迹上进行优化，从而解耦递归依赖。此外，针对偏好运动对稀缺的问题，引入自精化偏好学习机制，动态识别偏好对并进行偏好学习。

Result: 实验表明，EasyTune在MM-Dist对齐指标上比DRaFT-50提升了8.2%，同时仅需其31.16%的额外内存开销，并实现了7.3倍的训练加速。

Conclusion: 通过分步微调策略解耦递归依赖，EasyTune实现了高效、内存友好的扩散模型偏好对齐，为解决运动生成模型与下游目标对齐问题提供了有效方案。

Abstract: In recent years, motion generative models have undergone significant advancement, yet pose challenges in aligning with downstream objectives. Recent studies have shown that using differentiable rewards to directly align the preference of diffusion models yields promising results. However, these methods suffer from (1) inefficient and coarse-grained optimization with (2) high memory consumption. In this work, we first theoretically and empirically identify the key reason of these limitations: the recursive dependence between different steps in the denoising trajectory. Inspired by this insight, we propose EasyTune, which fine-tunes diffusion at each denoising step rather than over the entire trajectory. This decouples the recursive dependence, allowing us to perform (1) a dense and fine-grained, and (2) memory-efficient optimization. Furthermore, the scarcity of preference motion pairs restricts the availability of motion reward model training. To this end, we further introduce a Self-refinement Preference Learning (SPL) mechanism that dynamically identifies preference pairs and conducts preference learning. Extensive experiments demonstrate that EasyTune outperforms DRaFT-50 by 8.2% in alignment (MM-Dist) improvement while requiring only 31.16% of its additional memory overhead and achieving a 7.3x training speedup. The project page is available at this link {https://xiaofeng-tan.github.io/projects/EasyTune/index.html}.

</details>


### [86] [FSP-Diff: Full-Spectrum Prior-Enhanced DualDomain Latent Diffusion for Ultra-Low-Dose Spectral CT Reconstruction](https://arxiv.org/abs/2602.07979)
*Peng Peng,Xinrui Zhang,Junlin Wang,Lei Li,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: FSP-Diff：一种用于超低剂量能谱CT重建的全能谱先验增强双域潜在扩散框架，通过互补特征构建、全能谱先验集成和高效潜在扩散合成，显著提升图像质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 超低剂量条件下，能谱CT中能量特异性投影的信噪比急剧下降，导致重建图像出现严重伪影和结构细节丢失，需要开发有效的重建方法来应对这一挑战。

Method: 提出FSP-Diff框架，包含三个核心策略：1）互补特征构建：整合直接图像重建和投影域去噪结果；2）全能谱先验集成：融合多能量投影为高信噪比全能谱图像作为结构参考；3）高效潜在扩散合成：将多路径特征嵌入紧凑潜在空间，在低维流形中进行交互特征融合。

Result: 在模拟和真实数据集上的大量实验表明，FSP-Diff在图像质量和计算效率方面均显著优于现有最先进方法。

Conclusion: FSP-Diff框架为临床可行的超低剂量能谱CT成像提供了有前景的解决方案，通过双域特征整合和潜在扩散机制实现了细节保真与噪声抑制的良好平衡。

Abstract: Spectral computed tomography (CT) with photon-counting detectors holds immense potential for material discrimination and tissue characterization. However, under ultra-low-dose conditions, the sharply degraded signal-to-noise ratio (SNR) in energy-specific projections poses a significant challenge, leading to severe artifacts and loss of structural details in reconstructed images. To address this, we propose FSP-Diff, a full-spectrum prior-enhanced dual-domain latent diffusion framework for ultra-low-dose spectral CT reconstruction. Our framework integrates three core strategies: 1) Complementary Feature Construction: We integrate direct image reconstructions with projection-domain denoised results. While the former preserves latent textural nuances amidst heavy noise, the latter provides a stable structural scaffold to balance detail fidelity and noise suppression. 2) Full-Spectrum Prior Integration: By fusing multi-energy projections into a high-SNR full-spectrum image, we establish a unified structural reference that guides the reconstruction across all energy bins. 3) Efficient Latent Diffusion Synthesis: To alleviate the high computational burden of high-dimensional spectral data, multi-path features are embedded into a compact latent space. This allows the diffusion process to facilitate interactive feature fusion in a lower-dimensional manifold, achieving accelerated reconstruction while maintaining fine-grained detail restoration. Extensive experiments on simulated and real-world datasets demonstrate that FSP-Diff significantly outperforms state-of-the-art methods in both image quality and computational efficiency, underscoring its potential for clinically viable ultra-low-dose spectral CT imaging.

</details>


### [87] [Continuity-driven Synergistic Diffusion with Neural Priors for Ultra-Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2602.07980)
*Junlin Wang,Jiancheng Fang,Peng Peng,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出CSDN方法用于超稀疏角采样CBCT重建，通过神经先验编码连续3D衰减表示，结合正弦图细化扩散和数字放射摄影细化扩散的双路径协同扩散策略，有效抑制伪影并恢复细节纹理。


<details>
  <summary>Details</summary>
Motivation: CBCT临床应用受限于辐射暴露与图像质量之间的固有权衡。超稀疏角采样虽能降低剂量，但会引入严重的欠采样伪影和切片间不一致性，影响诊断可靠性。现有重建方法难以平衡角度连续性和空间细节保真度。

Method: 提出连续性驱动的协同扩散与神经先验（CSDN）方法：1）引入神经先验作为结构基础，编码连续3D衰减表示，从超稀疏测量合成物理一致的密集投影；2）基于神经先验初始化，开发协同扩散策略，包含正弦图细化扩散（恢复角度连续性）和数字放射摄影细化扩散（从投影图像视角增强切片间一致性）；3）通过双投影重建融合模块自适应融合两个扩散路径的输出，实现连贯的体积重建。

Result: 大量实验表明，CSDN在超稀疏视角条件下能有效抑制伪影并恢复精细纹理，性能优于现有最先进技术。

Conclusion: CSDN方法通过神经先验和协同扩散策略，成功解决了超稀疏角采样CBCT重建中的角度连续性和切片一致性问题，为低剂量高质量CBCT成像提供了有效解决方案。

Abstract: The clinical application of cone-beam computed tomography (CBCT) is constrained by the inherent trade-off between radiation exposure and image quality. Ultra-sparse angular sampling, employed to reduce dose, introduces severe undersampling artifacts and inter-slice inconsistencies, compromising diagnostic reliability. Existing reconstruction methods often struggle to balance angular continuity with spatial detail fidelity. To address these challenges, we propose a Continuity-driven Synergistic Diffusion with Neural priors (CSDN) for ultra-sparse-view CBCT reconstruction. Neural priors are introduced as a structural foundation to encode a continuous threedimensional attenuation representation, enabling the synthesis of physically consistent dense projections from ultra-sparse measurements. Building upon this neural-prior-based initialization, a synergistic diffusion strategy is developed, consisting of two collaborative refinement paths: a Sinogram Refinement Diffusion (Sino-RD) process that restores angular continuity and a Digital Radiography Refinement Diffusion (DR-RD) process that enforces inter-slice consistency from the projection image perspective. The outputs of the two diffusion paths are adaptively fused by the Dual-Projection Reconstruction Fusion (DPRF) module to achieve coherent volumetric reconstruction. Extensive experiments demonstrate that the proposed CSDN effectively suppresses artifacts and recovers fine textures under ultra-sparse-view conditions, outperforming existing state-of-the-art techniques.

</details>


### [88] [Deepfake Synthesis vs. Detection: An Uneven Contest](https://arxiv.org/abs/2602.07986)
*Md. Tarek Hasan,Sanjay Saha,Shaojing Fan,Swakkhar Shatabda,Terence Sim*

Main category: cs.CV

TL;DR: 该研究对最新深度伪造检测技术进行实证分析，发现现有检测模型在面对现代合成技术生成的深度伪造内容时表现显著下降，甚至人类参与者也难以识别最高质量的深度伪造内容，揭示了检测方法与生成技术之间的严重差距。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型、神经辐射场（NeRF）和增强型GAN等深度伪造生成技术的快速发展，合成媒体的真实性和可访问性显著提升。同时，基于Transformer架构、对比学习等方法的检测技术也取得进展。研究旨在评估当前最先进的深度伪造检测技术在实际对抗现代合成技术时的有效性。

Method: 采用全面的实证分析方法，包括对最先进的深度伪造检测技术进行评估，并设计人类评估实验来测试参与者对抗尖端合成方法生成的深度伪造内容的能力。通过大量实验对比不同检测模型在面对现代合成技术时的表现。

Result: 研究发现令人担忧的趋势：许多最先进的检测模型在面对现代合成技术（包括扩散模型、NeRF等）生成的深度伪造内容时表现显著下降。人类参与者在面对最高质量的深度伪造内容时也表现不佳。实验证据表明当前检测方法已落后于生成技术的发展。

Conclusion: 研究强调了深度伪造检测模型与不断发展的生成技术之间存在严重差距，迫切需要持续改进检测模型以跟上深度伪造生成技术的演进。这呼吁在该关键研究领域加强努力，以应对日益复杂的深度伪造威胁。

Abstract: The rapid advancement of deepfake technology has significantly elevated the realism and accessibility of synthetic media. Emerging techniques, such as diffusion-based models and Neural Radiance Fields (NeRF), alongside enhancements in traditional Generative Adversarial Networks (GANs), have contributed to the sophisticated generation of deepfake videos. Concurrently, deepfake detection methods have seen notable progress, driven by innovations in Transformer architectures, contrastive learning, and other machine learning approaches. In this study, we conduct a comprehensive empirical analysis of state-of-the-art deepfake detection techniques, including human evaluation experiments against cutting-edge synthesis methods. Our findings highlight a concerning trend: many state-of-the-art detection models exhibit markedly poor performance when challenged with deepfakes produced by modern synthesis techniques, including poor performance by human participants against the best quality deepfakes. Through extensive experimentation, we provide evidence that underscores the urgent need for continued refinement of detection models to keep pace with the evolving capabilities of deepfake generation technologies. This research emphasizes the critical gap between current detection methodologies and the sophistication of new generation techniques, calling for intensified efforts in this crucial area of study.

</details>


### [89] [Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning](https://arxiv.org/abs/2512.22730)
*Youssef Megahed,Robin Ducharme,Inok Lee,Inbal Willner,Adrian D. C. Chan,Mark Walker,Steven Hawken*

Main category: cs.CV

TL;DR: 本研究评估了超声特异性自监督预训练模型USF-MAE在早孕期超声图像中检测囊性水瘤的性能，相比传统DenseNet-169基线模型，在所有评估指标上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 囊性水瘤是高风险产前超声发现，与染色体异常、结构畸形和不良妊娠结局密切相关。自动检测可提高可重复性并支持可扩展的早期筛查，但监督式深度学习方法受限于小规模标注数据集。

Method: 使用基于掩码自编码（MAE）的超声自监督基础模型（USF-MAE），该模型在超过37万张未标注超声图像上预训练，然后针对囊性水瘤与正常对照的二分类任务进行微调。采用与DenseNet-169基线相同的超声数据集、预处理流程和4折交叉验证协议进行评估。

Result: USF-MAE在所有评估指标上均优于DenseNet-169基线：平均准确率0.96 vs 0.93，灵敏度0.94 vs 0.92，特异性0.98 vs 0.94，ROC-AUC 0.98 vs 0.94。Score-CAM可视化显示模型关注胎儿颈部相关区域，Wilcoxon符号秩检验证实性能提升具有统计学显著性（p=0.0057）。

Conclusion: 超声特异性自监督预训练能够促进准确、稳健的深度学习方法检测早孕期超声图像中的囊性水瘤，为可扩展的早期筛查项目提供了有前景的技术支持。

Abstract: Cystic hygroma is a high-risk prenatal ultrasound finding that portends high rates of chromosomal abnormalities, structural malformations, and adverse pregnancy outcomes. Automated detection can increase reproducibility and support scalable early screening programs, but supervised deep learning methods are limited by small labelled datasets. This study assesses whether ultrasound-specific self-supervised pretraining can facilitate accurate, robust deep learning detection of cystic hygroma in first-trimester ultrasound images. We fine-tuned the Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), pretrained on over 370,000 unlabelled ultrasound images, for binary classification of normal controls and cystic hygroma cases used in this study. Performance was evaluated on the same curated ultrasound dataset, preprocessing pipeline, and 4-fold cross-validation protocol as for the DenseNet-169 baseline, using accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (ROC-AUC). Model interpretability was analyzed qualitatively using Score-CAM visualizations. USF-MAE outperformed the DenseNet-169 baseline on all evaluation metrics. The proposed model yielded a mean accuracy of 0.96, sensitivity of 0.94, specificity of 0.98, and ROC-AUC of 0.98 compared to 0.93, 0.92, 0.94, and 0.94 for the DenseNet-169 baseline, respectively. Qualitative Score-CAM visualizations of model predictions demonstrated clinical relevance by highlighting expected regions in the fetal neck for both positive and negative cases. Paired statistical analysis using a Wilcoxon signed-rank test confirmed that performance improvements achieved by USF-MAE were statistically significant (p = 0.0057).

</details>


### [90] [FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging](https://arxiv.org/abs/2602.08024)
*Ziyang Fan,Keyu Chen,Ruilong Xing,Yulin Li,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: FlashVID是一个无需训练的视频大语言模型推理加速框架，通过注意力与多样性令牌选择和树状时空令牌合并，在保留10%视觉令牌的情况下保持99.1%性能，实现10倍视频帧输入扩展。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型需要处理大量视觉令牌，计算效率低下。现有加速框架独立压缩空间和时间冗余，忽略了时空关系，导致次优压缩效果。视频的动态特性使得视觉特征在时空位置、尺度、方向等属性上随时间变化。

Method: FlashVID采用训练免费的推理加速框架：1) 注意力与多样性令牌选择(ADTS)选择最具代表性的令牌进行基础视频表示；2) 树状时空令牌合并(TSTM)进行细粒度时空冗余消除。

Result: 在三个代表性VLLM和五个视频理解基准上的实验证明了方法的有效性和泛化性。仅保留10%视觉令牌时，FlashVID保持了LLaVA-OneVision 99.1%的性能。使Qwen2.5-VL的视频帧输入增加10倍，在相同计算预算下相对提升8.6%。

Conclusion: FlashVID可作为无需训练、即插即用的模块扩展长视频帧处理能力，显著提升视频大语言模型的推理效率，同时保持高性能。

Abstract: Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visual features are likely to change in spatial position, scale, orientation, and other attributes over time due to the dynamic nature of video. Building on this insight, we introduce FlashVID, a training-free inference acceleration framework for VLLMs. Specifically, FlashVID utilizes Attention and Diversity-based Token Selection (ADTS) to select the most representative tokens for basic video representation, then applies Tree-based Spatiotemporal Token Merging (TSTM) for fine-grained spatiotemporal redundancy elimination. Extensive experiments conducted on three representative VLLMs across five video understanding benchmarks demonstrate the effectiveness and generalization of our method. Notably, by retaining only 10% of visual tokens, FlashVID preserves 99.1% of the performance of LLaVA-OneVision. Consequently, FlashVID can serve as a training-free and plug-and-play module for extending long video frames, which enables a 10x increase in video frame input to Qwen2.5-VL, resulting in a relative improvement of 8.6% within the same computational budget. Code is available at https://github.com/Fanziyang-v/FlashVID.

</details>


### [91] [MIND: Benchmarking Memory Consistency and Action Control in World Models](https://arxiv.org/abs/2602.08025)
*Yixuan Ye,Xuanyu Lu,Yuxin Jiang,Yuchao Gu,Rui Zhao,Qiwei Liang,Jiachun Pan,Fengda Zhang,Weijia Wu,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: MIND是首个开放域闭环重访基准，用于评估世界模型的记忆一致性和动作控制能力，包含250个高质量视频，设计了评估框架和基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估世界模型核心能力的统一基准，世界模型需要理解、记忆和预测动态视觉环境，但现有基准无法全面评估其记忆一致性和动作控制能力。

Method: 创建MIND基准：包含250个1080p、24FPS高质量视频（第一人称和第三人称），设计高效评估框架测量记忆一致性和动作控制能力，引入MIND-World作为基线模型。

Result: 实验证明MIND基准的完整性，揭示了当前世界模型的关键挑战：难以维持长期记忆一致性，以及在共享场景下跨动作空间的泛化能力不足。

Conclusion: MIND为世界模型评估提供了首个开放域闭环重访基准，有助于推动世界模型在记忆一致性和动作控制方面的研究，并揭示了当前模型的局限性。

Abstract: World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models. MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video clips under a shared action space and 25 + 25 clips across varied action spaces covering eight diverse scenes. We design an efficient evaluation framework to measure two core abilities: memory consistency and action control, capturing temporal stability and contextual coherence across viewpoints. Furthermore, we design various action spaces, including different character movement speeds and camera rotation angles, to evaluate the action generalization capability across different action spaces under shared scenes. To facilitate future performance benchmarking on MIND, we introduce MIND-World, a novel interactive Video-to-World baseline. Extensive experiments demonstrate the completeness of MIND and reveal key challenges in current world models, including the difficulty of maintaining long-term memory consistency and generalizing across action spaces. Project page: https://csu-jpg.github.io/MIND.github.io/

</details>


### [92] [Vanilla Group Equivariant Vision Transformer: Simple and Effective](https://arxiv.org/abs/2602.08047)
*Jiahong Fu,Qi Xie,Deyu Meng,Zongben Xu*

Main category: cs.CV

TL;DR: 提出一种系统化构建等变视觉Transformer的框架，通过使ViT关键组件（包括patch embedding、自注意力、位置编码和上下采样）等变化，实现理论保证的等变性，提升性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有等变ViT在性能和等变性之间难以平衡，主要因为难以在ViT的多样化模块中实现整体等变修改，特别是协调自注意力机制与patch embedding的等变性。

Method: 提出一个简单框架，系统化地使ViT关键组件等变化，包括patch embedding、自注意力、位置编码和Down/Up-Sampling，构建具有理论保证等变性的ViT架构，可作为即插即用替代方案，并可扩展到Swin Transformers。

Result: 大量实验表明，所提出的等变ViT在各种视觉任务中持续提升性能和数据效率。

Conclusion: 该框架提供了一种系统化构建等变ViT的方法，实现了理论保证的等变性，同时提升了模型性能和数据效率，具有广泛的实用性和可扩展性。

Abstract: Incorporating symmetry priors as inductive biases to design equivariant Vision Transformers (ViTs) has emerged as a promising avenue for enhancing their performance. However, existing equivariant ViTs often struggle to balance performance with equivariance, primarily due to the challenge of achieving holistic equivariant modifications across the diverse modules in ViTs-particularly in harmonizing the Self-Attention mechanism with Patch Embedding. To address this, we propose a straightforward framework that systematically renders key ViT components, including patch embedding, self-attention, positional encodings, and Down/Up-Sampling, equivariant, thereby constructing ViTs with guaranteed equivariance. The resulting architecture serves as a plug-and-play replacement that is both theoretically grounded and practically versatile, scaling seamlessly even to Swin Transformers. Extensive experiments demonstrate that our equivariant ViTs consistently improve performance and data efficiency across a wide spectrum of vision tasks.

</details>


### [93] [Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling](https://arxiv.org/abs/2602.08058)
*Xihang Yu,Rajat Talak,Lorenzo Shaikewitz,Luca Carlone*

Main category: cs.CV

TL;DR: Picasso是一个物理约束的重建管道，通过考虑几何、非穿透性和物理原理来构建多物体场景重建，在接触丰富的场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在遮挡和测量噪声存在的情况下，几何上准确的场景重建可能仍然在物理上不正确。小的误差可能导致物体相互穿透或不稳定平衡等不可信的配置，这使得使用数字孪生预测场景动态行为变得困难。

Method: 提出Picasso物理约束重建管道，使用快速拒绝采样方法考虑多物体交互，利用推断的物体接触图来指导采样。同时创建了Picasso数据集和物理可信性度量基准。

Result: 在新建的Picasso数据集和YCB-V数据集上的广泛评估表明，Picasso大幅优于现有技术，提供既物理可信又更符合人类直觉的重建结果。

Conclusion: 物体姿态和形状估计需要对场景进行整体推理，考虑物体交互和物理可信性。Picasso方法通过物理约束重建管道实现了这一目标，为基于仿真的规划和接触丰富行为控制提供了重要工具。

Abstract: In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict the dynamic behavior of the scene using a digital twin, an important step in simulation-based planning and control of contact-rich behaviors. In this paper, we posit that object pose and shape estimation requires reasoning holistically over the scene (instead of reasoning about each object in isolation), accounting for object interactions and physical plausibility. Towards this goal, our first contribution is Picasso, a physics-constrained reconstruction pipeline that builds multi-object scene reconstructions by considering geometry, non-penetration, and physics. Picasso relies on a fast rejection sampling method that reasons over multi-object interactions, leveraging an inferred object contact graph to guide samples. Second, we propose the Picasso dataset, a collection of 10 contact-rich real-world scenes with ground truth annotations, as well as a metric to quantify physical plausibility, which we open-source as part of our benchmark. Finally, we provide an extensive evaluation of Picasso on our newly introduced dataset and on the YCB-V dataset, and show it largely outperforms the state of the art while providing reconstructions that are both physically plausible and more aligned with human intuition.

</details>


### [94] [When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning](https://arxiv.org/abs/2602.08236)
*Shoubin Yu,Yue Zhang,Zun Wang,Jaehong Yoon,Huaxiu Yao,Mingyu Ding,Mohit Bansal*

Main category: cs.CV

TL;DR: 本文提出AVIC框架，通过自适应控制视觉想象来提升多模态大语言模型的空间推理能力，分析何时需要想象、需要多少想象，以及何时想象反而有害。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉空间推理中存在局限性，特别是在需要从未见过或替代视角理解场景时。现有方法通过世界模型增强视觉想象，但缺乏对何时需要想象、需要多少想象以及何时想象反而有害的系统分析。不加选择的想象会增加计算成本，甚至因引入误导性证据而降低性能。

Method: 提出AVIC自适应测试时框架，该框架使用世界模型，在选择性调用和扩展视觉想象之前，明确推理当前视觉证据的充分性。通过分析静态视觉证据何时足够、想象何时能改善推理，以及过度或不必要的想象如何影响准确性和效率。

Result: 在空间推理基准测试（SAT、MMSI）和具身导航基准测试（R2R）中，结果显示存在明确场景：想象是关键的、边际的或有害的。选择性控制策略能够匹配或优于固定想象策略，同时显著减少世界模型调用和语言标记数量。

Conclusion: 研究强调了分析和控制测试时想象对于高效可靠的空间推理的重要性。自适应控制视觉想象可以平衡准确性和效率，避免不必要的计算开销和性能下降。

Abstract: Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.

</details>


### [95] [DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models](https://arxiv.org/abs/2602.08059)
*Tong Zhang,Ru Zhang,Jianyi Liu*

Main category: cs.CV

TL;DR: DICE是一个无需训练的艺术风格擦除框架，通过对比子空间分解实现风格与内容的解耦，有效防止未经授权的艺术风格模仿，同时保持内容完整性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的普及使得艺术风格模仿变得容易，引发版权和知识产权风险。现有对策要么需要昂贵的权重编辑，要么依赖明确指定的编辑风格，限制了实际部署的可行性。

Method: DICE采用训练自由的框架，通过构建对比三元组让模型区分风格与非风格特征，将解耦过程形式化为可解的广义特征值问题，精确定位风格子空间。同时引入自适应注意力解耦编辑策略，动态评估每个token的风格浓度，对QKV向量进行差异化抑制和内容增强。

Result: 实验表明DICE在风格擦除彻底性和内容完整性保护之间实现了优越的平衡。风格解耦仅增加3秒额外开销，为遏制风格模仿提供了实用高效的技术方案。

Conclusion: DICE通过对比子空间分解实现了艺术风格与内容的有效解耦，为部署侧安全提供了实用、高效的风格擦除解决方案，能够有效保护艺术家的独特风格免遭未经授权的模仿。

Abstract: The recent proliferation of diffusion models has made style mimicry effortless, enabling users to imitate unique artistic styles without authorization. In deployed platforms, this raises copyright and intellectual-property risks and calls for reliable protection. However, existing countermeasures either require costly weight editing as new styles emerge or rely on an explicitly specified editing style, limiting their practicality for deployment-side safety. To address this challenge, we propose DICE (Disentanglement of artist Style from Content via Contrastive Subspace Decomposition), a training-free framework for on-the-fly artist style erasure. Unlike style editing that require an explicitly specified replacement style, DICE performs style purification, removing the artist's characteristics while preserving the user-intended content. Our core insight is that a model cannot truly comprehend the artist style from a single text or image alone. Consequently, we abandon the traditional paradigm of identifying style from isolated samples. Instead, we construct contrastive triplets to compel the model to distinguish between style and non-style features in the latent space. By formalizing this disentanglement process as a solvable generalized eigenvalue problem, we achieve precise identification of the style subspace. Furthermore, we introduce an Adaptive Attention Decoupling Editing strategy dynamically assesses the style concentration of each token and performs differential suppression and content enhancement on the QKV vectors. Extensive experiments demonstrate that DICE achieves a superior balance between the thoroughness of style erasure and the preservation of content integrity. DICE introduces an additional overhead of only 3 seconds to disentangle style, providing a practical and efficient technique for curbing style mimicry.

</details>


### [96] [ReRoPE: Repurposing RoPE for Relative Camera Control](https://arxiv.org/abs/2602.08068)
*Chunyang Li,Yuanbo Yang,Jiahao Shao,Hongyu Zhou,Katja Schwarz,Yiyi Liao*

Main category: cs.CV

TL;DR: ReRoPE是一个即插即用框架，通过将相对相机姿态信息注入预训练视频扩散模型中未充分利用的RoPE低频分量，实现可控视角视频生成，无需大量训练或架构修改。


<details>
  <summary>Details</summary>
Motivation: 现有可控视角视频生成方法通常使用相对于固定参考帧（如第一帧）的相机姿态编码，但这些编码缺乏平移不变性，导致泛化能力差和累积漂移问题。相对相机姿态嵌入虽然更鲁棒，但将其集成到预训练视频扩散模型中需要高昂训练成本或架构修改。

Method: ReRoPE基于一个关键洞察：现有模型中的旋转位置嵌入（RoPE）未充分利用其全频谱带宽，特别是低频分量。通过将相对相机姿态信息无缝注入这些未充分利用的频带，在保持预训练生成先验的同时实现精确相机控制。

Result: 在图像到视频（I2V）和视频到视频（V2V）任务上的评估显示，ReRoPE在相机控制精度和视觉保真度方面表现优异，提供了训练高效的可控高保真视频生成路径。

Conclusion: ReRoPE是一个即插即用框架，通过巧妙利用RoPE的未充分利用频谱资源，实现了对预训练视频扩散模型的高效相对相机姿态控制，为可控视频生成提供了训练成本低、性能优越的解决方案。

Abstract: Video generation with controllable camera viewpoints is essential for applications such as interactive content creation, gaming, and simulation. Existing methods typically adapt pre-trained video models using camera poses relative to a fixed reference, e.g., the first frame. However, these encodings lack shift-invariance, often leading to poor generalization and accumulated drift. While relative camera pose embeddings defined between arbitrary view pairs offer a more robust alternative, integrating them into pre-trained video diffusion models without prohibitive training costs or architectural changes remains challenging. We introduce ReRoPE, a plug-and-play framework that incorporates relative camera information into pre-trained video diffusion models without compromising their generation capability. Our approach is based on the insight that Rotary Positional Embeddings (RoPE) in existing models underutilize their full spectral bandwidth, particularly in the low-frequency components. By seamlessly injecting relative camera pose information into these underutilized bands, ReRoPE achieves precise control while preserving strong pre-trained generative priors. We evaluate our method on both image-to-video (I2V) and video-to-video (V2V) tasks in terms of camera control accuracy and visual fidelity. Our results demonstrate that ReRoPE offers a training-efficient path toward controllable, high-fidelity video generation. See project page for more results: https://sisyphe-lee.github.io/ReRoPE/

</details>


### [97] [Learning Self-Correction in Vision-Language Models via Rollout Augmentation](https://arxiv.org/abs/2602.08503)
*Yi Ding,Ziliang Qiu,Bolian Li,Ruqi Zhang*

Main category: cs.CV

TL;DR: 本文提出Octopus框架，通过重组现有rollouts合成密集的自校正示例，解决VLMs中自校正学习信号稀疏的问题，并开发了具有可控自校正能力的Octopus-8B模型。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在视觉语言模型中学习自校正行为困难，因为有效的自校正行为出现频率低，导致学习信号极其稀疏。

Method: 提出校正特定rollouts（Octopus）框架：1）通过重组现有rollouts合成密集的自校正示例；2）引入响应掩码策略，将自校正与直接推理解耦；3）开发Octopus-8B模型。

Result: 在7个基准测试中，Octopus-8B在开源VLMs中达到最先进性能，比最佳RLVR基线提高1.0分，同时每个训练步骤仅需0.72倍时间。

Conclusion: Octopus框架通过rollout重组和响应掩码策略有效解决了VLMs中自校正学习的稀疏信号问题，实现了高效且稳定的强化学习优化。

Abstract: Self-correction is essential for solving complex reasoning problems in vision-language models (VLMs). However, existing reinforcement learning (RL) methods struggle to learn it, as effective self-correction behaviors emerge only rarely, making learning signals extremely sparse. To address this challenge, we propose correction-specific rollouts (Octopus), an RL rollout augmentation framework that synthesizes dense self-correction examples by recombining existing rollouts. This augmentation simultaneously improves sample efficiency due to rollout reuse and stabilizes RL optimization through balanced supervision. Furthermore, we introduce a response-masking strategy that decouples self-correction from direct reasoning, avoiding signal conflicts and enabling both behaviors to be learned effectively. Building on this, we introduce Octopus-8B, a reasoning VLM with controllable self-correction capability. Across 7 benchmarks, it achieves SoTA performance among open-source VLMs, outperforming the best RLVR baseline by 1.0 score while requiring only $0.72\times$ training time per step.

</details>


### [98] [VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval](https://arxiv.org/abs/2602.08099)
*Issar Tzachor,Dvir Samuel,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 该论文提出了一种利用多模态大语言模型进行视频文本嵌入和检索的新方法，通过中间层分析和轻量级文本对齐策略，在零样本设置下实现了最先进的视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究将生成式多模态大语言模型适配为视觉任务的嵌入提取器，但它们在视频任务上的表现仍不如专门的视频基础模型。本文旨在探索如何更好地利用MLLMs进行视频文本嵌入和检索。

Method: 首先进行系统性的层间分析，发现MLLMs的中间层已编码大量任务相关信息；然后结合中间层嵌入和校准的MLLM头部实现零样本检索；最后引入轻量级文本对齐策略，将密集视频描述映射为简短摘要，实现无需视觉监督的任务相关视频文本嵌入学习。

Result: 该方法在零样本设置下超越了当前方法，通常具有显著优势，在常见视频检索基准测试中取得了最先进的结果，且无需任何视觉监督的微调。

Conclusion: 研究表明，通过利用MLLMs中间层的丰富表示能力和轻量级文本对齐策略，可以在无需视觉监督的情况下实现强大的视频文本检索性能，为视频理解任务提供了新的有效途径。

Abstract: Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks.

</details>


### [99] [MMLSv2: A Multimodal Dataset for Martian Landslide Detection in Remote Sensing Imagery](https://arxiv.org/abs/2602.08112)
*Sidike Paheding,Abel Reyes-Angulo,Leo Thomas Ramos,Angel D. Sappa,Rajaneesh A.,Hiral P. B.,Sajin Kumar K. S.,Thomas Oommen*

Main category: cs.CV

TL;DR: MMLSv2是一个用于火星表面滑坡分割的多模态数据集，包含7个波段图像和664张图像，还有一个276张图像的独立测试集用于评估空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 需要创建专门的火星滑坡分割数据集来支持相关研究，现有数据集可能不足以评估模型在火星环境中的泛化能力和鲁棒性。

Method: 构建包含RGB、数字高程模型、坡度、热惯性和灰度通道的七波段多模态图像数据集，分为训练、验证和测试集，并创建地理隔离的独立测试集。

Result: 数据集支持稳定训练并达到竞争性性能，但在碎片化、细长和小规模滑坡区域仍存在挑战；在独立测试集上性能显著下降，表明其能有效评估模型泛化能力。

Conclusion: MMLSv2数据集为火星滑坡分割研究提供了有价值的基准，特别适合评估模型在分布外场景下的鲁棒性和泛化能力。

Abstract: We present MMLSv2, a dataset for landslide segmentation on Martian surfaces. MMLSv2 consists of multimodal imagery with seven bands: RGB, digital elevation model, slope, thermal inertia, and grayscale channels. MMLSv2 comprises 664 images distributed across training, validation, and test splits. In addition, an isolated test set of 276 images from a geographically disjoint region from the base dataset is released to evaluate spatial generalization. Experiments conducted with multiple segmentation models show that the dataset supports stable training and achieves competitive performance, while still posing challenges in fragmented, elongated, and small-scale landslide regions. Evaluation on the isolated test set leads to a noticeable performance drop, indicating increased difficulty and highlighting its value for assessing model robustness and generalization beyond standard in-distribution settings. Dataset will be available at: https://github.com/MAIN-Lab/MMLS_v2

</details>


### [100] [Building Damage Detection using Satellite Images and Patch-Based Transformer Methods](https://arxiv.org/abs/2602.08117)
*Smriti Siva,Jan Cross-Zamirski*

Main category: cs.CV

TL;DR: 本研究评估了Vision Transformer模型在xBD数据集上的建筑损伤分类性能，提出了一种针对性的补丁预处理流程和冻结头微调策略，在噪声和不平衡数据上取得了与CNN基线相当的F1分数。


<details>
  <summary>Details</summary>
Motivation: 灾后快速建筑损伤评估对应急响应至关重要，但卫星图像数据存在标签噪声和严重类别不平衡问题，这给损伤分类模型带来了重大挑战。xBD数据集提供了跨地理区域的标准化基准，本研究旨在评估ViT模型在该数据集上的性能，特别是在噪声和不平衡数据下区分结构损伤类型的能力。

Method: 研究评估了DINOv2-small和DeiT模型进行多类别损伤分类。提出了针对性的补丁预处理流程来隔离结构特征并最小化训练中的背景噪声。采用冻结头微调策略以保持计算需求可控。通过准确率、精确率、召回率和宏观平均F1分数评估模型性能。

Result: 研究表明，采用新颖训练方法的小型ViT架构在灾害分类任务中，相对于先前的CNN基线模型，取得了具有竞争力的宏观平均F1分数。

Conclusion: 小型Vision Transformer架构配合针对性的预处理和微调策略，能够在噪声和不平衡的卫星图像数据上实现有效的建筑损伤分类，为灾后快速评估提供了可行的技术方案。

Abstract: Rapid building damage assessment is critical for post-disaster response. Damage classification models built on satellite imagery provide a scalable means of obtaining situational awareness. However, label noise and severe class imbalance in satellite data create major challenges. The xBD dataset offers a standardized benchmark for building-level damage across diverse geographic regions. In this study, we evaluate Vision Transformer (ViT) model performance on the xBD dataset, specifically investigating how these models distinguish between types of structural damage when training on noisy, imbalanced data.
  In this study, we specifically evaluate DINOv2-small and DeiT for multi-class damage classification. We propose a targeted patch-based pre-processing pipeline to isolate structural features and minimize background noise in training. We adopt a frozen-head fine-tuning strategy to keep computational requirements manageable. Model performance is evaluated through accuracy, precision, recall, and macro-averaged F1 scores. We show that small ViT architectures with our novel training method achieves competitive macro-averaged F1 relative to prior CNN baselines for disaster classification.

</details>


### [101] [Fields of The World: A Field Guide for Extracting Agricultural Field Boundaries](https://arxiv.org/abs/2602.08131)
*Isaac Corley,Hannah Kerner,Caleb Robinson,Jennifer Marcus*

Main category: cs.CV

TL;DR: Fields of The World (FTW)生态系统提供了包含160万农田边界的基准数据集、预训练分割模型和命令行工具，支持农田边界提取、作物分类和森林损失归因等农业应用。


<details>
  <summary>Details</summary>
Motivation: 农田边界地图是农业数据产品的基础，对于作物监测、产量估算和病害评估至关重要。现有方法在覆盖范围和可扩展性方面存在局限，需要更全面的解决方案。

Method: 构建了FTW生态系统，包含：1）覆盖24个国家160万农田多边形的基准数据集；2）预训练分割模型；3）命令行推理工具；4）两个笔记本分别处理局部尺度和国家尺度的推理；5）使用MOSAIKS随机卷积特征和FTW农田边界进行作物类型分类。

Result: 作物类型分类的宏观F1分数达到0.65-0.75（使用有限标签）；在五个国家（476万平方公里）进行了预测，预测农田面积中位数从卢旺达的0.06公顷到瑞士的0.28公顷不等。

Conclusion: FTW生态系统为农田边界提取和作物分类提供了全面的工具和基准，支持从局部到国家尺度的农业监测应用，在有限标签下仍能获得良好的分类性能。

Abstract: Field boundary maps are a building block for agricultural data products and support crop monitoring, yield estimation, and disease estimation. This tutorial presents the Fields of The World (FTW) ecosystem: a benchmark of 1.6M field polygons across 24 countries, pre-trained segmentation models, and command-line inference tools. We provide two notebooks that cover (1) local-scale field boundary extraction with crop classification and forest loss attribution, and (2) country-scale inference using cloud-optimized data. We use MOSAIKS random convolutional features and FTW derived field boundaries to map crop type at the field level and report macro F1 scores of 0.65--0.75 for crop type classification with limited labels. Finally, we show how to explore pre-computed predictions over five countries (4.76M km\textsuperscript{2}), with median predicted field areas from 0.06 ha (Rwanda) to 0.28 ha (Switzerland).

</details>


### [102] [Robustness of Vision Language Models Against Split-Image Harmful Input Attacks](https://arxiv.org/abs/2602.08136)
*Md Rafi Ur Rashid,MD Sadik Hossain Shanto,Vishnu Asutosh Dasu,Shagufta Mehnaz*

Main category: cs.CV

TL;DR: 该论文发现视觉语言模型(VLMs)在安全对齐方面存在漏洞：虽然模型训练能处理分割图像，但安全对齐只在完整图像上进行，导致无法识别跨多个图像片段的有害语义。研究者提出了SIVA分割图像视觉越狱攻击，利用这种不对齐性，通过对抗知识蒸馏实现高达60%的跨模型攻击成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型(VLMs)经过广泛的安全对齐（如RLHF）后，对传统的单图像/完整图像越狱攻击表现出强鲁棒性。然而，研究者发现了一个新的安全漏洞：虽然VLM的预训练和指令调优能很好地泛化到分割图像输入，但安全对齐通常只在完整图像上进行，没有考虑有害语义分布在多个图像片段中的情况。这导致VLMs往往无法检测和拒绝有害的分割图像输入，因为不安全线索只有在组合图像后才显现。

Method: 提出了新颖的分割图像视觉越狱攻击(SIVA)，该方法从简单的图像分割开始，逐步发展到自适应白盒攻击，最终形成黑盒迁移攻击。最强的攻击策略采用了一种新颖的对抗知识蒸馏(Adv-KD)算法，通过知识蒸馏技术将攻击从一个模型迁移到另一个模型，显著提高了跨模型的可迁移性。

Result: 在三个最先进的现代VLMs和三个越狱数据集上的评估表明，最强的攻击策略比现有基线实现了高达60%的迁移成功率提升。这证明了当前VLM安全对齐中存在的严重漏洞。

Conclusion: 当前视觉语言模型的安全对齐存在关键漏洞，无法有效处理有害语义分布在多个图像片段中的情况。SIVA攻击利用这种不对齐性实现了高效的越狱攻击。论文最后提出了解决这一关键漏洞的有效方法，强调了需要改进VLM安全对齐以覆盖分割图像场景的重要性。

Abstract: Vision-Language Models (VLMs) are now a core part of modern AI. Recent work proposed several visual jailbreak attacks using single/ holistic images. However, contemporary VLMs demonstrate strong robustness against such attacks due to extensive safety alignment through preference optimization (e.g., RLHF). In this work, we identify a new vulnerability: while VLM pretraining and instruction tuning generalize well to split-image inputs, safety alignment is typically performed only on holistic images and does not account for harmful semantics distributed across multiple image fragments. Consequently, VLMs often fail to detect and refuse harmful split-image inputs, where unsafe cues emerge only after combining images. We introduce novel split-image visual jailbreak attacks (SIVA) that exploit this misalignment. Unlike prior optimization-based attacks, which exhibit poor black-box transferability due to architectural and prior mismatches across models, our attacks evolve in progressive phases from naive splitting to an adaptive white-box attack, culminating in a black-box transfer attack. Our strongest strategy leverages a novel adversarial knowledge distillation (Adv-KD) algorithm to substantially improve cross-model transferability. Evaluations on three state-of-the-art modern VLMs and three jailbreak datasets demonstrate that our strongest attack achieves up to 60% higher transfer success than existing baselines. Lastly, we propose efficient ways to address this critical vulnerability in the current VLM safety alignment.

</details>


### [103] [PEGAsus: 3D Personalization of Geometry and Appearance](https://arxiv.org/abs/2602.08198)
*Jingyu Hu,Bin Hu,Ka-Hei Hui,Haipeng Li,Zhengzhe Liu,Daniel Cohen-Or,Chi-Wing Fu*

Main category: cs.CV

TL;DR: PEGAsus是一个能够生成个性化3D形状的新框架，通过几何和外观层面的概念学习，从参考形状提取可重用的属性并与文本结合生成新形状。


<details>
  <summary>Details</summary>
Motivation: 现有3D形状生成方法在个性化控制方面存在局限，难以实现细粒度的几何和外观属性提取与组合，特别是在跨类别场景中缺乏灵活性。

Method: 1) 将3D形状个性化定义为提取类别无关的几何和外观属性；2) 设计渐进优化策略分离几何和外观概念学习；3) 扩展到区域级概念学习，使用上下文感知和无上下文损失。

Result: PEGAsus能够从广泛的参考形状中有效提取属性，并与文本灵活组合生成新形状，实现细粒度控制，在跨类别场景中也能产生多样化的个性化结果，在定量和定性实验中均优于现有方法。

Conclusion: 该框架通过几何和外观层面的概念学习，实现了3D形状生成的细粒度个性化控制，为跨类别形状合成提供了有效的解决方案。

Abstract: We present PEGAsus, a new framework capable of generating Personalized 3D shapes by learning shape concepts at both Geometry and Appearance levels. First, we formulate 3D shape personalization as extracting reusable, category-agnostic geometric and appearance attributes from reference shapes, and composing these attributes with text to generate novel shapes. Second, we design a progressive optimization strategy to learn shape concepts at both the geometry and appearance levels, decoupling the shape concept learning process. Third, we extend our approach to region-wise concept learning, enabling flexible concept extraction, with context-aware and context-free losses. Extensive experimental results show that PEGAsus is able to effectively extract attributes from a wide range of reference shapes and then flexibly compose these concepts with text to synthesize new shapes. This enables fine-grained control over shape generation and supports the creation of diverse, personalized results, even in challenging cross-category scenarios. Both quantitative and qualitative experiments demonstrate that our approach outperforms existing state-of-the-art solutions.

</details>


### [104] [Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video](https://arxiv.org/abs/2602.08202)
*Jinrong Lv,Xun Gong,Zhaohuan Li,Weili Jiang*

Main category: cs.CV

TL;DR: 提出MCSDR模型，使用基于分数的扩散模型进行多模态条件回归，用于从超声心动图视频中估计左心室射血分数，解决传统回归方法在处理多模态后验分布时的局限性。


<details>
  <summary>Details</summary>
Motivation: 从超声心动图估计左心室射血分数是一个不适定逆问题，存在噪声、伪影和有限视角带来的模糊性。传统深度学习方法使用均方误差回归，强制模型学习条件期望，当后验分布呈现多模态或重尾分布时（常见于病理情况），会产生误导性预测。

Method: 提出多模态条件基于分数的扩散回归模型（MCSDR），这是一个概率框架，旨在建模以超声心动图视频和患者人口统计学属性先验为条件的LVEF连续后验分布。使用基于分数的扩散模型进行生成式回归。

Result: 在EchoNet-Dynamic、EchoNet-Pediatric和CAMUS数据集上的广泛实验表明，MCSDR实现了最先进的性能。定性分析显示，在高噪声或显著生理变异性的情况下，模型的生成轨迹表现出独特行为，为AI辅助诊断提供了新的可解释性层。

Conclusion: 从确定性回归向生成式回归的范式转变是有效的。MCSDR能够建模LVEF的连续后验分布，在处理超声心动图估计中的不确定性和多模态性方面表现出色，同时提供了更好的可解释性。

Abstract: Estimating Left Ventricular Ejection Fraction (LVEF) from echocardiograms constitutes an ill-posed inverse problem. Inherent noise, artifacts, and limited viewing angles introduce ambiguity, where a single video sequence may map not to a unique ground truth, but rather to a distribution of plausible physiological values. Prevailing deep learning approaches typically formulate this task as a standard regression problem that minimizes the Mean Squared Error (MSE). However, this paradigm compels the model to learn the conditional expectation, which may yield misleading predictions when the underlying posterior distribution is multimodal or heavy-tailed -- a common phenomenon in pathological scenarios. In this paper, we investigate the paradigm shift from deterministic regression toward generative regression. We propose the Multimodal Conditional Score-based Diffusion model for Regression (MCSDR), a probabilistic framework designed to model the continuous posterior distribution of LVEF conditioned on echocardiogram videos and patient demographic attribute priors. Extensive experiments conducted on the EchoNet-Dynamic, EchoNet-Pediatric, and CAMUS datasets demonstrate that MCSDR achieves state-of-the-art performance. Notably, qualitative analysis reveals that the generation trajectories of our model exhibit distinct behaviors in cases characterized by high noise or significant physiological variability, thereby offering a novel layer of interpretability for AI-aided diagnosis.

</details>


### [105] [Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2602.08206)
*Chufeng Zhou,Jian Wang,Xinyuan Liu,Xiaokang Zhang*

Main category: cs.CV

TL;DR: 提出GR-CoT框架，通过地理空间推理增强MLLM的场景理解能力，解决遥感开放词汇分割中因相似光谱特征导致的语义歧义问题。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇语义分割方法主要依赖视觉特征与文本嵌入的被动映射，这种"基于外观"的范式缺乏地理空间上下文意识，导致遇到光谱特征相似但语义属性不同的地物类别时产生严重语义歧义和误分类。

Method: 提出地理空间推理思维链（GR-CoT）框架，包含两个协作组件：离线知识蒸馏流和在线实例推理流。离线流建立细粒度类别解释标准以解决相似地物类型间的语义冲突；在线推理执行顺序推理过程，包括宏观场景锚定、视觉特征解耦和知识驱动决策合成，生成图像自适应词汇表指导下游模型实现像素级地理语义对齐。

Result: 在LoveDA和GID5基准测试上进行了广泛实验，证明了所提方法的优越性。

Conclusion: GR-CoT框架通过增强MLLM的场景理解能力，有效解决了遥感开放词汇分割中的语义歧义问题，实现了更精确的地物分类映射。

Abstract: Open-vocabulary semantic segmentation has emerged as a promising research direction in remote sensing, enabling the recognition of diverse land-cover types beyond pre-defined category sets. However, existing methods predominantly rely on the passive mapping of visual features and textual embeddings. This ``appearance-based" paradigm lacks geospatial contextual awareness, leading to severe semantic ambiguity and misclassification when encountering land-cover classes with similar spectral features but distinct semantic attributes. To address this, we propose a Geospatial Reasoning Chain-of-Thought (GR-CoT) framework designed to enhance the scene understanding capabilities of Multimodal Large Language Models (MLLMs), thereby guiding open-vocabulary segmentation models toward precise mapping. The framework comprises two collaborative components: an offline knowledge distillation stream and an online instance reasoning stream. The offline stream establishes fine-grained category interpretation standards to resolve semantic conflicts between similar land-cover types. During online inference, the framework executes a sequential reasoning process involving macro-scenario anchoring, visual feature decoupling, and knowledge-driven decision synthesis. This process generates an image-adaptive vocabulary that guides downstream models to achieve pixel-level alignment with correct geographical semantics. Extensive experiments on the LoveDA and GID5 benchmarks demonstrate the superiority of our approach.

</details>


### [106] [Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension](https://arxiv.org/abs/2602.08211)
*Yik Lung Pang,Changjae Oh*

Main category: cs.CV

TL;DR: 本文提出了一种名为Chain-of-Caption的训练免费框架，通过结合多种视觉和文本上下文来提升多模态大语言模型在指代表达理解任务上的性能，在多个数据集上实现了5%到30%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 指代表达理解任务需要根据文本描述在图像中定位目标对象。虽然多模态大语言模型通过扩大模型规模和训练数据在REC基准测试中取得了高准确率，但现有技术如思维链和工具使用可以通过提供额外的视觉或文本上下文来进一步提升性能。本文旨在分析通过工具使用提供额外上下文的各种技术对REC任务的影响。

Method: 提出了一种训练免费的Chain-of-Caption框架，该框架通过工具使用为多模态大语言模型提供多种视觉和文本上下文。研究分析了单独使用文本或视觉上下文的效果，并展示了结合多种上下文的方法。

Result: 在RefCOCO、RefCOCOg、RefCOCO+和Ref-L4数据集上的实验表明，单独的文本或视觉上下文可以在不进行微调的情况下提升REC性能。通过结合多种上下文，该训练免费框架在不同IoU阈值下的准确率比基线模型提升了5%到30%。

Conclusion: Chain-of-Caption框架通过有效结合多种视觉和文本上下文，显著提升了多模态大语言模型在指代表达理解任务上的性能，且无需额外训练，为REC任务提供了一种高效实用的解决方案。

Abstract: Given a textual description, the task of referring expression comprehension (REC) involves the localisation of the referred object in an image. Multimodal large language models (MLLMs) have achieved high accuracy on REC benchmarks through scaling up the model size and training data. Moreover, the performance of MLLMs can be further improved using techniques such as Chain-of-Thought and tool use, which provides additional visual or textual context to the model. In this paper, we analyse the effect of various techniques for providing additional visual and textual context via tool use to the MLLM and its effect on the REC task. Furthermore, we propose a training-free framework named Chain-of-Caption to improve the REC performance of MLLMs. We perform experiments on RefCOCO/RefCOCOg/RefCOCO+ and Ref-L4 datasets and show that individual textual or visual context can improve the REC performance without any fine-tuning. By combining multiple contexts, our training-free framework shows between 5% to 30% performance gain over the baseline model on accuracy at various Intersection over Union (IoU) thresholds.

</details>


### [107] [Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2602.08262)
*Guoqi Yu,Xiaowei Hu,Angelica I. Aviles-Rivero,Anqi Qiu,Shujun Wang*

Main category: cs.CV

TL;DR: 该论文提出DeCI框架，通过周期-漂移分解和通道独立性建模原始BOLD信号，在fMRI脑疾病分类中优于传统功能连接方法。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI脑疾病分类方法大多基于Pearson相关性的功能连接，将4D BOLD信号简化为静态2D矩阵，丢失了时间动态信息且只能捕捉线性关系。

Method: 提出DeCI框架：1) 周期-漂移分解：将每个ROI的BOLD信号分解为周期性和漂移成分；2) 通道独立性：独立建模每个ROI，提高鲁棒性和减少过拟合。

Result: 在五个公共数据集上的实验表明，DeCI在分类准确率和泛化能力上优于传统FC方法和现有时间序列模型。

Conclusion: 研究结果表明，在fMRI分析中应采用端到端的时间建模方法，以更好地捕捉复杂的大脑动态。DeCI框架为这一方向提供了有效解决方案。

Abstract: Functional magnetic resonance imaging (fMRI) enables non-invasive brain disorder classification by capturing blood-oxygen-level-dependent (BOLD) signals. However, most existing methods rely on functional connectivity (FC) via Pearson correlation, which reduces 4D BOLD signals to static 2D matrices, discarding temporal dynamics and capturing only linear inter-regional relationships. In this work, we benchmark state-of-the-art temporal models (e.g., time-series models such as PatchTST, TimesNet, and TimeMixer) on raw BOLD signals across five public datasets. Results show these models consistently outperform traditional FC-based approaches, highlighting the value of directly modeling temporal information such as cycle-like oscillatory fluctuations and drift-like slow baseline trends. Building on this insight, we propose DeCI, a simple yet effective framework that integrates two key principles: (i) Cycle and Drift Decomposition to disentangle cycle and drift within each ROI (Region of Interest); and (ii) Channel-Independence to model each ROI separately, improving robustness and reducing overfitting. Extensive experiments demonstrate that DeCI achieves superior classification accuracy and generalization compared to both FC-based and temporal baselines. Our findings advocate for a shift toward end-to-end temporal modeling in fMRI analysis to better capture complex brain dynamics. The code is available at https://github.com/Levi-Ackman/DeCI.

</details>


### [108] [PISCO: Precise Video Instance Insertion with Sparse Control](https://arxiv.org/abs/2602.08277)
*Xiangbo Gao,Renjie Li,Xinghao Chen,Yuheng Wu,Suofei Feng,Qing Yin,Zhengzhong Tu*

Main category: cs.CV

TL;DR: PISCO是一个视频扩散模型，用于通过任意稀疏关键帧控制实现精确的视频实例插入，解决了传统视频编辑中空间-时间定位、物理一致性场景交互和原始动态保持的挑战。


<details>
  <summary>Details</summary>
Motivation: AI视频生成正从依赖大量提示工程和"挑选"的通用生成，转向细粒度可控生成和高保真后处理。在专业AI辅助电影制作中，需要进行精确、有针对性的修改，视频实例插入是这一转变的关键，需要在保持场景完整性的同时将特定实例插入现有素材。

Method: PISCO采用视频扩散模型，支持单关键帧、起始-结束关键帧或任意时间戳的稀疏关键帧控制。为解决预训练视频扩散模型中稀疏条件引起的严重分布偏移，引入了变量信息引导以实现鲁棒条件，以及分布保持时间掩码以稳定时间生成，同时使用几何感知条件实现真实场景适应。

Result: 构建了PISCO-Bench基准测试集，包含已验证的实例标注和配对的干净背景视频。实验表明，PISCO在稀疏控制下始终优于强大的修复和视频编辑基线方法，并且在提供额外控制信号时表现出清晰、单调的性能提升。

Conclusion: PISCO通过稀疏关键帧控制实现了精确的视频实例插入，解决了AI视频生成向可控生成和高质量后处理转变中的关键技术挑战，为专业AI辅助电影制作提供了有效的解决方案。

Abstract: The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and "cherry-picking" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.

</details>


### [109] [Language-Guided Transformer Tokenizer for Human Motion Generation](https://arxiv.org/abs/2602.08337)
*Sheng Yan,Yong Wang,Xin Du,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: LG-Tok：一种语言引导的运动离散化方法，通过Transformer架构实现语言与运动的对齐，在保持高质量重建的同时减少生成复杂度


<details>
  <summary>Details</summary>
Motivation: 传统运动离散化方法通过增加token数量来提高重建质量，但这会增加生成模型的复杂度。需要一种既能保持高质量重建又能降低生成复杂度的tokenization方法

Method: 提出语言引导的tokenization（LG-Tok），使用Transformer架构实现语言与运动的对齐，设计语言丢弃方案使detokenizer支持无语言引导的生成

Result: 在HumanML3D和Motion-X基准测试中，LG-Tok获得Top-1分数0.542和0.582，优于SOTA方法（MARDM：0.500和0.528）；FID分数分别为0.057和0.088，优于0.114和0.147。LG-Tok-mini仅使用一半token仍保持竞争力

Conclusion: LG-Tok通过语言引导实现了紧凑、高语义的运动表示，在保持高质量重建的同时降低了生成复杂度，为高效运动生成提供了有效解决方案

Abstract: In this paper, we focus on motion discrete tokenization, which converts raw motion into compact discrete tokens--a process proven crucial for efficient motion generation. In this paradigm, increasing the number of tokens is a common approach to improving motion reconstruction quality, but more tokens make it more difficult for generative models to learn. To maintain high reconstruction quality while reducing generation complexity, we propose leveraging language to achieve efficient motion tokenization, which we term Language-Guided Tokenization (LG-Tok). LG-Tok aligns natural language with motion at the tokenization stage, yielding compact, high-level semantic representations. This approach not only strengthens both tokenization and detokenization but also simplifies the learning of generative models. Furthermore, existing tokenizers predominantly adopt convolutional architectures, whose local receptive fields struggle to support global language guidance. To this end, we propose a Transformer-based Tokenizer that leverages attention mechanisms to enable effective alignment between language and motion. Additionally, we design a language-drop scheme, in which language conditions are randomly removed during training, enabling the detokenizer to support language-free guidance during generation. On the HumanML3D and Motion-X generation benchmarks, LG-Tok achieves Top-1 scores of 0.542 and 0.582, outperforming state-of-the-art methods (MARDM: 0.500 and 0.528), and with FID scores of 0.057 and 0.088, respectively, versus 0.114 and 0.147. LG-Tok-mini uses only half the tokens while maintaining competitive performance (Top-1: 0.521/0.588, FID: 0.085/0.071), validating the efficiency of our semantic representations.

</details>


### [110] [UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science](https://arxiv.org/abs/2602.08342)
*Jie Zhang,Xingtong Yu,Yuan Fang,Rudi Stouffs,Zdravko Trivic*

Main category: cs.CV

TL;DR: UGData数据集将街景图像与空间图对齐，UGE训练策略对齐图像、文本和空间结构，UGBench评估空间嵌入在多种城市理解任务中的表现，在Qwen2.5-VL-7B上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 城市理解本质上是空间性的，但现有数据集和基准缺乏街景图像与城市结构之间的显式对齐，这限制了可迁移多模态嵌入的学习。

Method: 1) 引入UGData数据集，将街景图像锚定到结构化空间图，通过空间推理路径和空间上下文描述提供图对齐监督；2) 提出UGE两阶段训练策略，结合指令引导对比学习和基于图的空间编码，逐步稳定地对齐图像、文本和空间结构；3) 使用LoRA调优在多个先进VLM骨干上训练固定维度空间嵌入。

Result: 基于Qwen2.5-VL-7B骨干的UGE在训练城市上图像检索提升44%，地理位置排名提升30%；在未见城市上分别获得超过30%和22%的增益，证明了显式空间接地对空间密集型城市任务的有效性。

Conclusion: 通过显式空间接地（UGData数据集）、渐进式对齐策略（UGE）和全面评估基准（UGBench），能够有效学习可迁移的城市多模态嵌入，显著提升空间密集型城市理解任务的性能。

Abstract: Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions, exposing distance, directionality, connectivity, and neighborhood context beyond image content. Building on UGData, we propose UGE, a two-stage training strategy that progressively and stably aligns images, text, and spatial structures by combining instruction-guided contrastive learning with graph-based spatial encoding. We finally introduce UGBench, a comprehensive benchmark to evaluate how spatially grounded embeddings support diverse urban understanding tasks -- including geolocation ranking, image retrieval, urban perception, and spatial grounding. We develop UGE on multiple state-of-the-art VLM backbones, including Qwen2-VL, Qwen2.5-VL, Phi-3-Vision, and LLaVA1.6-Mistral, and train fixed-dimensional spatial embeddings with LoRA tuning. UGE built upon Qwen2.5-VL-7B backbone achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and over 30% and 22% gains respectively on held-out cities, demonstrating the effectiveness of explicit spatial grounding for spatially intensive urban tasks.

</details>


### [111] [What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning](https://arxiv.org/abs/2602.08346)
*Yujin Zhou,Pengcheng Wen,Jiale Chen,Boqin Yin,Han Zhu,Jiaming Ji,Juntao Dai,Chi-Min Chan,Sirui Han*

Main category: cs.CV

TL;DR: 该研究针对大视觉语言模型中的"图像思维"范式，首次构建了专门评估过程奖励模型的综合基准，包含1,206条人工标注的推理轨迹，定义了7种细粒度错误类型，并发现当前LVLMs作为PRMs存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 随着大视觉语言模型的发展，"图像思维"范式使模型能够在推理过程中动态编辑和重新编码视觉信息。然而，这种范式在推理过程中会产生各种错误，需要过程奖励模型来区分正负推理步骤。现有的PRM基准主要是文本中心的，缺乏针对这一范式的全面评估。

Method: 1) 通过分析推理轨迹和PRMs引导搜索实验，定义7种细粒度错误类型；2) 构建包含1,206条人工标注的"图像思维"推理轨迹的基准，涵盖4个类别和16个子类别；3) 进行实验分析，评估当前LVLMs作为PRMs的性能。

Result: 研究发现当前LVLMs作为PRMs效果不佳：在视觉推理过程评估中能力有限，在不同错误类型间表现差异显著，存在正向评估偏见，对推理步骤位置敏感。这些发现证明了所构建基准的有效性。

Conclusion: 该工作为"图像思维"范式下的过程奖励模型评估提供了首个综合基准，揭示了当前LVLMs作为PRMs的局限性，为推进LVLMs中PRMs的发展奠定了重要基础。

Abstract: The rapid advancement of Large Vision Language Models (LVLMs) has demonstrated excellent abilities in various visual tasks. Building upon these developments, the thinking with images paradigm has emerged, enabling models to dynamically edit and re-encode visual information at each reasoning step, mirroring human visual processing. However, this paradigm introduces significant challenges as diverse errors may occur during reasoning processes. This necessitates Process Reward Models (PRMs) for distinguishing positive and negative reasoning steps, yet existing benchmarks for PRMs are predominantly text-centric and lack comprehensive assessment under this paradigm. To address these gaps, this work introduces the first comprehensive benchmark specifically designed for evaluating PRMs under the thinking with images paradigm. Our main contributions are: (1) Through extensive analysis of reasoning trajectories and guided search experiments with PRMs, we define 7 fine-grained error types and demonstrate both the necessity for specialized PRMs and the potential for improvement. (2) We construct a comprehensive benchmark comprising 1,206 manually annotated thinking with images reasoning trajectories spanning 4 categories and 16 subcategories for fine-grained evaluation of PRMs. (3) Our experimental analysis reveals that current LVLMs fall short as effective PRMs, exhibiting limited capabilities in visual reasoning process evaluation with significant performance disparities across error types, positive evaluation bias, and sensitivity to reasoning step positions. These findings demonstrate the effectiveness of our benchmark and establish crucial foundations for advancing PRMs in LVLMs.

</details>


### [112] [Geometric Image Editing via Effects-Sensitive In-Context Inpainting with Diffusion Transformers](https://arxiv.org/abs/2602.08388)
*Shuo Zhang,Wenzhuo Wu,Huayu Zhang,Jiarong Cheng,Xianghao Zang,Chao Ban,Hao Sun,Zhongjiang He,Tianwei Cao,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: GeoEdit是一个基于扩散模型的图像编辑框架，通过扩散transformer模块实现精确的几何变换编辑，并引入效果敏感注意力机制来改善光照和阴影效果，在大型数据集上训练后显著提升了图像编辑的几何精度和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像编辑中处理几何变换（如平移、旋转、缩放）时存在困难，特别是在复杂场景中。主要问题包括：1）难以实现准确的几何编辑；2）对复杂光照和阴影效果建模不足，导致结果不真实。

Method: 提出GeoEdit框架，包含两个核心组件：1）基于扩散transformer的上下文生成模块，集成几何变换实现精确对象编辑；2）效果敏感注意力机制，增强复杂光照和阴影效果的建模。此外构建了包含12万高质量图像对的大规模几何编辑数据集RS-Objects用于训练。

Result: 在公开基准测试上的大量实验表明，GeoEdit在视觉质量、几何精度和真实感方面持续优于最先进的方法。

Conclusion: GeoEdit通过创新的扩散transformer架构和效果敏感注意力机制，成功解决了图像几何编辑中的关键挑战，显著提升了编辑结果的几何准确性和视觉真实感。

Abstract: Recent advances in diffusion models have significantly improved image editing. However, challenges persist in handling geometric transformations, such as translation, rotation, and scaling, particularly in complex scenes. Existing approaches suffer from two main limitations: (1) difficulty in achieving accurate geometric editing of object translation, rotation, and scaling; (2) inadequate modeling of intricate lighting and shadow effects, leading to unrealistic results. To address these issues, we propose GeoEdit, a framework that leverages in-context generation through a diffusion transformer module, which integrates geometric transformations for precise object edits. Moreover, we introduce Effects-Sensitive Attention, which enhances the modeling of intricate lighting and shadow effects for improved realism. To further support training, we construct RS-Objects, a large-scale geometric editing dataset containing over 120,000 high-quality image pairs, enabling the model to learn precise geometric editing while generating realistic lighting and shadows. Extensive experiments on public benchmarks demonstrate that GeoEdit consistently outperforms state-of-the-art methods in terms of visual quality, geometric accuracy, and realism.

</details>


### [113] [D$^2$-VR: Degradation-Robust and Distilled Video Restoration with Synergistic Optimization Strategy](https://arxiv.org/abs/2602.08395)
*Jianfeng Liang,Shaocheng Shen,Botao Xu,Qiang Hu,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: D²-VR：一种基于单图像扩散的视频修复框架，通过退化鲁棒流对齐和对抗蒸馏实现12倍加速，在保持感知质量的同时提升时间稳定性


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散先验和时间对齐的视频修复方法虽然能提供出色的感知质量，但在面对复杂真实世界退化时存在推理延迟高和时间不稳定的问题，限制了实际部署

Method: 1) 设计退化鲁棒流对齐模块，利用置信感知注意力过滤不可靠运动线索；2) 采用对抗蒸馏范式将扩散采样轨迹压缩到快速少步机制；3) 设计协同优化策略平衡感知质量和时间一致性

Result: D²-VR在保持最先进性能的同时，将采样过程加速12倍，有效解决了复杂退化下的时间不稳定问题

Conclusion: 该框架成功解决了扩散基视频修复方法的延迟和稳定性问题，为实际部署提供了可行的解决方案

Abstract: The integration of diffusion priors with temporal alignment has emerged as a transformative paradigm for video restoration, delivering fantastic perceptual quality, yet the practical deployment of such frameworks is severely constrained by prohibitive inference latency and temporal instability when confronted with complex real-world degradations. To address these limitations, we propose \textbf{D$^2$-VR}, a single-image diffusion-based video-restoration framework with low-step inference. To obtain precise temporal guidance under severe degradation, we first design a Degradation-Robust Flow Alignment (DRFA) module that leverages confidence-aware attention to filter unreliable motion cues. We then incorporate an adversarial distillation paradigm to compress the diffusion sampling trajectory into a rapid few-step regime. Finally, a synergistic optimization strategy is devised to harmonize perceptual quality with rigorous temporal consistency. Extensive experiments demonstrate that D$^2$-VR achieves state-of-the-art performance while accelerating the sampling process by \textbf{12$\times$}

</details>


### [114] [RealSynCol: a high-fidelity synthetic colon dataset for 3D reconstruction applications](https://arxiv.org/abs/2602.08397)
*Chiara Lena,Davide Milesi,Alessandro Casella,Luca Carlini,Joseph C. Norton,James Martin,Bruno Scaglioni,Keith L. Obstein,Roberto De Sire,Marco Spadaccini,Cesare Hassan,Pietro Valdastri,Elena De Momi*

Main category: cs.CV

TL;DR: RealSynCol是一个高度逼真的合成结肠镜数据集，用于解决深度学习在结肠镜3D重建中缺乏大规模真实数据的问题，显著提升了在临床图像上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习可以改进结肠镜检查，通过3D重建提供全面的黏膜表面和病变视图，并帮助识别未探索区域。但现有方法的发展受到大规模真实数据稀缺的限制。

Method: 从10个CT扫描中提取结肠几何结构，导入到模拟术中条件的虚拟环境中，使用逼真的血管纹理进行渲染。生成了28,130帧图像，配有深度图、光流、3D网格和相机轨迹等真实标注。

Result: 基准研究表明，RealSynCol的高真实感和多样性显著提升了在临床图像上的泛化性能，证明它是开发支持内镜诊断的深度学习算法的有力工具。

Conclusion: RealSynCol是一个高度逼真的合成结肠镜数据集，能够有效解决真实数据稀缺问题，为开发结肠镜3D重建和病变识别的深度学习算法提供了重要资源。

Abstract: Deep learning has the potential to improve colonoscopy by enabling 3D reconstruction of the colon, providing a comprehensive view of mucosal surfaces and lesions, and facilitating the identification of unexplored areas. However, the development of robust methods is limited by the scarcity of large-scale ground truth data. We propose RealSynCol, a highly realistic synthetic dataset designed to replicate the endoscopic environment. Colon geometries extracted from 10 CT scans were imported into a virtual environment that closely mimics intraoperative conditions and rendered with realistic vascular textures. The resulting dataset comprises 28\,130 frames, paired with ground truth depth maps, optical flow, 3D meshes, and camera trajectories. A benchmark study was conducted to evaluate the available synthetic colon datasets for the tasks of depth and pose estimation. Results demonstrate that the high realism and variability of RealSynCol significantly enhance generalization performance on clinical images, proving it to be a powerful tool for developing deep learning algorithms to support endoscopic diagnosis.

</details>


### [115] [Understanding and Optimizing Attention-Based Sparse Matching for Diverse Local Features](https://arxiv.org/abs/2602.08430)
*Qiang Wang*

Main category: cs.CV

TL;DR: 研究发现注意力稀疏图像匹配模型的关键设计选择，发现检测器比描述符对性能影响更大，提出用多种检测器关键点微调现有模型的方法，创建通用检测器无关的匹配模型。


<details>
  <summary>Details</summary>
Motivation: 重新审视基于注意力的稀疏图像匹配模型训练问题，识别先前被忽视的关键设计选择，探究检测器和描述符在基于transformer的匹配框架中的作用，旨在开发通用、检测器无关的匹配模型。

Method: 首先识别影响LightGlue模型性能的关键设计选择；然后研究检测器和描述符在transformer匹配框架中的作用；最后提出使用多种检测器关键点微调现有图像匹配模型的新方法。

Result: 发现检测器（而非描述符）通常是性能差异的主要原因；提出的通用检测器无关模型在作为零样本匹配器用于新检测器时，达到或超过专门为这些特征训练的模型的准确性。

Conclusion: 研究结果为基于transformer的匹配模型部署和未来局部特征设计提供了有价值的见解，表明通过适当的微调方法可以创建通用的检测器无关匹配模型。

Abstract: We revisit the problem of training attention-based sparse image matching models for various local features. We first identify one critical design choice that has been previously overlooked, which significantly impacts the performance of the LightGlue model. We then investigate the role of detectors and descriptors within the transformer-based matching framework, finding that detectors, rather than descriptors, are often the primary cause for performance difference. Finally, we propose a novel approach to fine-tune existing image matching models using keypoints from a diverse set of detectors, resulting in a universal, detector-agnostic model. When deployed as a zero-shot matcher for novel detectors, the resulting model achieves or exceeds the accuracy of models specifically trained for those features. Our findings offer valuable insights for the deployment of transformer-based matching models and the future design of local features.

</details>


### [116] [Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition](https://arxiv.org/abs/2602.08439)
*Yuhao Dong,Shulin Tian,Shuai Liu,Shuangrui Ding,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了Demo驱动的视频上下文学习新任务和Demo-ICL-Bench基准，用于评估多模态大语言模型从少量示例中学习动态新知识的能力，并开发了Demo-ICL模型来解决这一挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要评估模型基于静态内部知识理解视频的能力，而非从动态新上下文中通过少量示例学习和适应的能力，这限制了模型的实际应用价值。

Method: 提出了Demo-ICL-Bench基准，包含1200个教学YouTube视频及相关问题，提供文本和视频两种演示类型；开发了Demo-ICL模型，采用两阶段训练策略：视频监督微调和信息辅助直接偏好优化。

Result: 实验表明Demo-ICL-Bench对现有最先进MLLM具有挑战性，而Demo-ICL模型在该基准上表现出有效性，揭示了未来研究方向。

Conclusion: 本文填补了视频上下文学习评估的空白，提出的任务、基准和模型为多模态大语言模型从动态上下文中学习新知识的能力评估提供了新方向。

Abstract: Despite the growing video understanding capabilities of recent Multimodal Large Language Models (MLLMs), existing video benchmarks primarily assess understanding based on models' static, internal knowledge, rather than their ability to learn and adapt from dynamic, novel contexts from few examples. To bridge this gap, we present Demo-driven Video In-Context Learning, a novel task focused on learning from in-context demonstrations to answer questions about the target videos. Alongside this, we propose Demo-ICL-Bench, a challenging benchmark designed to evaluate demo-driven video in-context learning capabilities. Demo-ICL-Bench is constructed from 1200 instructional YouTube videos with associated questions, from which two types of demonstrations are derived: (i) summarizing video subtitles for text demonstration; and (ii) corresponding instructional videos as video demonstrations. To effectively tackle this new challenge, we develop Demo-ICL, an MLLM with a two-stage training strategy: video-supervised fine-tuning and information-assisted direct preference optimization, jointly enhancing the model's ability to learn from in-context examples. Extensive experiments with state-of-the-art MLLMs confirm the difficulty of Demo-ICL-Bench, demonstrate the effectiveness of Demo-ICL, and thereby unveil future research directions.

</details>


### [117] [TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation](https://arxiv.org/abs/2602.08462)
*Yiyang Cao,Yunze Deng,Ziyu Lin,Bin Feng,Xinggang Wang,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: TriC-Motion是一个新颖的基于扩散的文本到动作生成框架，通过整合时空频域建模与因果干预，解决了现有方法在联合优化和噪声解耦方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到动作生成方法主要关注时空建模或独立的频域分析，缺乏跨空间、时间和频率域的联合优化框架，这限制了模型同时利用所有域信息的能力，导致生成质量不理想。此外，动作生成框架中由噪声引起的动作无关线索常常与对生成有积极贡献的特征纠缠在一起，导致动作失真。

Method: 提出Tri-Domain Causal Text-to-Motion Generation (TriC-Motion)框架，包含三个核心建模模块：时间动作编码、空间拓扑建模和混合频率分析。通过Score-guided Tri-domain Fusion模块整合三个域的有价值信息，同时确保时间一致性、空间拓扑、动作趋势和动态特性。此外，设计了基于因果关系的反事实动作解耦器来暴露动作无关线索以消除噪声。

Result: 在HumanML3D数据集上取得了出色的性能，R@1达到0.612，优于现有最先进方法。实验结果表明该框架能够生成高保真、连贯、多样且与文本对齐的动作序列。

Conclusion: TriC-Motion通过整合时空频域建模与因果干预，成功解决了文本到动作生成中的联合优化和噪声解耦问题，实现了高质量的动作生成，为相关领域提供了新的解决方案。

Abstract: Text-to-motion generation, a rapidly evolving field in computer vision, aims to produce realistic and text-aligned motion sequences. Current methods primarily focus on spatial-temporal modeling or independent frequency domain analysis, lacking a unified framework for joint optimization across spatial, temporal, and frequency domains. This limitation hinders the model's ability to leverage information from all domains simultaneously, leading to suboptimal generation quality. Additionally, in motion generation frameworks, motion-irrelevant cues caused by noise are often entangled with features that contribute positively to generation, thereby leading to motion distortion. To address these issues, we propose Tri-Domain Causal Text-to-Motion Generation (TriC-Motion), a novel diffusion-based framework integrating spatial-temporal-frequency-domain modeling with causal intervention. TriC-Motion includes three core modeling modules for domain-specific modeling, namely Temporal Motion Encoding, Spatial Topology Modeling, and Hybrid Frequency Analysis. After comprehensive modeling, a Score-guided Tri-domain Fusion module integrates valuable information from the triple domains, simultaneously ensuring temporal consistency, spatial topology, motion trends, and dynamics. Moreover, the Causality-based Counterfactual Motion Disentangler is meticulously designed to expose motion-irrelevant cues to eliminate noise, disentangling the real modeling contributions of each domain for superior generation. Extensive experimental results validate that TriC-Motion achieves superior performance compared to state-of-the-art methods, attaining an outstanding R@1 of 0.612 on the HumanML3D dataset. These results demonstrate its capability to generate high-fidelity, coherent, diverse, and text-aligned motion sequences. Code is available at: https://caoyiyang1105.github.io/TriC-Motion/.

</details>


### [118] [Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation](https://arxiv.org/abs/2602.08479)
*Alif Rizqullah Mahdi,Mahdi Rezaei,Natasha Merat*

Main category: cs.CV

TL;DR: 该研究提出基于2D姿态估计的手势分类框架，用于自动驾驶车辆识别行人手势，在真实世界视频数据上达到87%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 手势是交通中非语言交流的关键组成部分，有助于行人与驾驶员互动，但自动驾驶车辆难以解释这些手势。当正式交通规则不足时，这个问题更加明显。

Method: 使用2D姿态估计技术处理WIVW数据集的真实世界视频序列，将手势分为四类（停止、通行、感谢与问候、无手势），从归一化的关键点中提取76个静态和动态特征。

Result: 分析表明手部位置和移动速度在区分手势类别方面特别具有判别力，分类准确率达到87%。

Conclusion: 这些发现不仅提升了自动驾驶系统的感知能力，还有助于更广泛地理解交通环境中的行人行为。

Abstract: Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank & Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts.

</details>


### [119] [Enhanced Food Category Recognition under Illumination-Induced Domain Shift](https://arxiv.org/abs/2602.08491)
*Keonvin Park,Aditya Pal,Jin Hong Mok*

Main category: cs.CV

TL;DR: 该研究探讨了光照变化对多类别食物识别系统的影响，通过合成光照增强数据集和跨数据集评估，提出了提升光照鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉食物识别系统（如自动传送带检测）对光照变化引起的领域偏移非常敏感。现有研究通常局限于单一食物类别或受控环境，且大多数公共食物数据集缺乏明确的光照标注，因此需要研究光照变化对多类别食物识别的影响。

Method: 使用Food-101和Fruits-360两个广泛采用的数据集，通过系统变化光温和强度构建合成光照增强数据集，进行跨数据集评估。同时评估跨数据集迁移学习和领域泛化方法，特别关注对光照敏感的苹果类食物。

Result: 实验结果显示，由于视觉条件不匹配，跨数据集评估导致准确率显著下降。光照感知增强显著提高了在领域偏移下的识别鲁棒性，同时保持了实时性能。

Conclusion: 光照鲁棒性对于部署可靠的现实世界食物识别系统至关重要。光照感知增强方法能有效提升系统在光照变化环境中的性能，为实际应用提供了实用见解。

Abstract: Visual food recognition systems deployed in real-world environments, such as automated conveyor-belt inspection, are highly sensitive to domain shifts caused by illumination changes. While recent studies have shown that lighting variations can significantly distort food perception by both humans and AI, existing works are often limited to single food categories or controlled settings, and most public food datasets lack explicit illumination annotations.
  In this work, we investigate illumination-induced domain shift in multi-class food category recognition using two widely adopted datasets, Food-101 and Fruits-360. We demonstrate substantial accuracy degradation under cross-dataset evaluation due to mismatched visual conditions. To address this challenge, we construct synthetic illumination-augmented datasets by systematically varying light temperature and intensity, enabling controlled robustness analysis without additional labels.
  We further evaluate cross-dataset transfer learning and domain generalization, with a focus on illumination-sensitive target categories such as apple-based classes. Experimental results show that illumination-aware augmentation significantly improves recognition robustness under domain shift while preserving real-time performance. Our findings highlight the importance of illumination robustness and provide practical insights for deploying reliable food recognition systems in real-world inspection scenarios.

</details>


### [120] [GeoFocus: Blending Efficient Global-to-Local Perception for Multimodal Geometry Problem-Solving](https://arxiv.org/abs/2602.08524)
*Linger Deng,Yuliang Liu,Wenwen Yu,Zujia Zhang,Jianzhong Ju,Zhenbo Luo,Xiang Bai*

Main category: cs.CV

TL;DR: GeoFocus是一个解决几何问题的多模态模型框架，通过关键局部感知器和顶点语言编码，显著提升了几何问题求解的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 几何问题求解对大型多模态模型具有挑战性，需要全局形状识别和局部几何关系的精细关注。现有方法在关键局部特征覆盖和全局拓扑编码方面存在不足。

Method: 提出GeoFocus框架，包含两个核心模块：1) 关键局部感知器，通过13个基于理论的感知模板自动识别和强调关键局部结构；2) VertexLang，一种紧凑的拓扑形式语言，通过顶点坐标和连接关系编码全局图形。

Result: 在Geo3K、GeoQA和FormalGeo7K数据集上，GeoFocus比领先的专用模型准确率提升4.7%；关键局部特征覆盖提升61%；全局感知训练时间减少20%；在MATHVERSE中展现出优越的鲁棒性。

Conclusion: GeoFocus通过结合局部感知增强和高效全局编码，显著提升了几何问题求解能力，为多模态几何推理提供了有效的解决方案。

Abstract: Geometry problem-solving remains a significant challenge for Large Multimodal Models (LMMs), requiring not only global shape recognition but also attention to intricate local relationships related to geometric theory. To address this, we propose GeoFocus, a novel framework comprising two core modules. 1) Critical Local Perceptor, which automatically identifies and emphasizes critical local structure (e.g., angles, parallel lines, comparative distances) through thirteen theory-based perception templates, boosting critical local feature coverage by 61% compared to previous methods. 2) VertexLang, a compact topology formal language, encodes global figures through vertex coordinates and connectivity relations. By replacing bulky code-based encodings, VertexLang reduces global perception training time by 20% while improving topology recognition accuracy. When evaluated in Geo3K, GeoQA, and FormalGeo7K, GeoFocus achieves a 4.7% accuracy improvement over leading specialized models and demonstrates superior robustness in MATHVERSE under diverse visual conditions. Project Page -- https://github.com/dle666/GeoFocus

</details>


### [121] [Automatic regularization parameter choice for tomography using a double model approach](https://arxiv.org/abs/2602.08528)
*Chuyang Wu,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出了一种基于双网格离散化的自动正则化参数选择方法，通过反馈控制算法动态调整正则化强度，在X射线断层扫描图像重建中实现参数自动优化。


<details>
  <summary>Details</summary>
Motivation: X射线断层扫描图像重建是一个病态逆问题，特别是在数据有限的情况下。正则化是必要的，但其效果依赖于正则化参数的选择，该参数需要在数据保真度和先验信息之间取得平衡。目前缺乏有效的自动参数选择方法。

Method: 提出了一种新颖的自动参数选择方法，基于同一问题的两种不同计算离散化。使用反馈控制算法动态调整正则化强度，驱动迭代重建趋向于能够使两个网格上的重建结果达到足够相似度的最小参数值。

Result: 该方法在实际断层扫描数据上得到了验证，证明了其有效性。

Conclusion: 提出的双网格离散化结合反馈控制算法的方法能够有效实现正则化参数的自动选择，解决了X射线断层扫描图像重建中的参数选择难题，在实际应用中表现出良好效果。

Abstract: Image reconstruction in X-ray tomography is an ill-posed inverse problem, particularly with limited available data. Regularization is thus essential, but its effectiveness hinges on the choice of a regularization parameter that balances data fidelity against a priori information. We present a novel method for automatic parameter selection based on the use of two distinct computational discretizations of the same problem. A feedback control algorithm dynamically adjusts the regularization strength, driving an iterative reconstruction toward the smallest parameter that yields sufficient similarity between reconstructions on the two grids. The effectiveness of the proposed approach is demonstrated using real tomographic data.

</details>


### [122] [Thegra: Graph-based SLAM for Thermal Imagery](https://arxiv.org/abs/2602.08531)
*Anastasiia Kornilova,Ivan Moskalenko,Arabella Gromova,Gonzalo Ferrer,Alexander Menshchikov*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏单目图的热成像SLAM系统，利用可见光谱训练的通用学习特征（SuperPoint检测器和LightGlue匹配器），通过预处理和置信度加权因子图提高在低纹理热图像上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 热成像在视觉退化环境（如低光照、烟雾、恶劣天气）中具有实用价值，但热图像通常具有低纹理、低对比度和高噪声的特点，这使得基于特征的SLAM变得复杂。现有方法在热图像上表现不佳，且缺乏高质量的热成像训练数据。

Method: 1. 使用在可见光谱大规模数据上训练的SuperPoint特征检测器和LightGlue匹配器，利用其跨域泛化能力；2. 引入预处理管道增强热图像输入适应性；3. 修改核心SLAM模块以处理稀疏和异常值较多的特征匹配；4. 将SuperPoint的关键点置信度分数整合到置信度加权因子图中，提高估计鲁棒性。

Result: 在公开热成像数据集上的评估表明，所提出的系统实现了可靠的性能，无需进行数据集特定的训练或微调特征检测器，这在高质量热数据稀缺的情况下尤为重要。

Conclusion: 该研究提出了一种有效的热成像SLAM方法，通过利用可见光谱训练的通用学习特征和专门的预处理与优化技术，成功解决了热图像低纹理、低对比度带来的挑战，为视觉退化环境下的定位与建图提供了实用解决方案。

Abstract: Thermal imaging provides a practical sensing modality for visual SLAM in visually degraded environments such as low illumination, smoke, or adverse weather. However, thermal imagery often exhibits low texture, low contrast, and high noise, complicating feature-based SLAM. In this work, we propose a sparse monocular graph-based SLAM system for thermal imagery that leverages general-purpose learned features -- the SuperPoint detector and LightGlue matcher, trained on large-scale visible-spectrum data to improve cross-domain generalization. To adapt these components to thermal data, we introduce a preprocessing pipeline to enhance input suitability and modify core SLAM modules to handle sparse and outlier-prone feature matches. We further incorporate keypoint confidence scores from SuperPoint into a confidence-weighted factor graph to improve estimation robustness. Evaluations on public thermal datasets demonstrate that the proposed system achieves reliable performance without requiring dataset-specific training or fine-tuning a desired feature detector, given the scarcity of quality thermal data. Code will be made available upon publication.

</details>


### [123] [TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation](https://arxiv.org/abs/2602.08540)
*He Wu,Xia Yan,Yanghui Xu,Liegang Xia,Jiazhou Chen*

Main category: cs.CV

TL;DR: 提出TIBR4D框架，通过两阶段迭代边界精炼实现动态4D高斯场景的无学习对象分割，提升边界精度和处理遮挡能力。


<details>
  <summary>Details</summary>
Motivation: 动态4D高斯场景中的对象级分割面临复杂运动、遮挡和模糊边界的挑战，现有方法难以有效处理这些问题。

Method: 采用两阶段迭代边界精炼：1) IGIT阶段在时间片段级迭代追踪高斯实例，精炼概率并提取点云；2) RCC阶段通过抑制边界附近不确定高斯实现帧级渲染范围控制；结合时间分割合并策略平衡身份一致性和动态感知。

Result: 在HyperNeRF和Neu3D数据集上实验表明，相比SOTA方法，该方法能生成边界更清晰、精度更高的对象高斯点云，且效率更高。

Conclusion: TIBR4D框架通过迭代边界精炼有效解决了动态4D高斯场景中的对象分割问题，在边界精度、遮挡处理和效率方面均有显著提升。

Abstract: Object-level segmentation in dynamic 4D Gaussian scenes remains challenging due to complex motion, occlusions, and ambiguous boundaries. In this paper, we present an efficient learning-free 4D Gaussian segmentation framework that lifts video segmentation masks to 4D spaces, whose core is a two-stage iterative boundary refinement, TIBR4D. The first stage is an Iterative Gaussian Instance Tracing (IGIT) at the temporal segment level. It progressively refines Gaussian-to-instance probabilities through iterative tracing, and extracts corresponding Gaussian point clouds that better handle occlusions and preserve completeness of object structures compared to existing one-shot threshold-based methods. The second stage is a frame-wise Gaussian Rendering Range Control (RCC) via suppressing highly uncertain Gaussians near object boundaries while retaining their core contributions for more accurate boundaries. Furthermore, a temporal segmentation merging strategy is proposed for IGIT to balance identity consistency and dynamic awareness. Longer segments enforce stronger multi-frame constraints for stable identities, while shorter segments allow identity changes to be captured promptly. Experiments on HyperNeRF and Neu3D demonstrate that our method produces accurate object Gaussian point clouds with clearer boundaries and higher efficiency compared to SOTA methods.

</details>


### [124] [GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing](https://arxiv.org/abs/2602.08550)
*Shih-Fang Chen,Jun-Cheng Chen,I-Hong Jhuo,Yen-Yu Lin*

Main category: cs.CV

TL;DR: GOT-Edit：一种在线跨模态模型编辑方法，通过将几何感知线索整合到通用目标跟踪器中，结合2D语义与3D几何推理提升跟踪性能


<details>
  <summary>Details</summary>
Motivation: 人类感知在2D视频流中进行有效目标跟踪时，会隐式使用先验3D知识结合语义推理。而大多数通用目标跟踪方法主要依赖目标的2D特征及其周围环境，忽略了3D几何线索，这使得它们容易受到部分遮挡、干扰物以及几何和外观变化的影响。

Method: GOT-Edit采用在线跨模态模型编辑方法，从预训练的视觉几何基础Transformer中提取特征，仅从少量2D图像推断几何线索。通过零空间约束更新进行在线模型编辑，无缝结合几何和语义信息，在保持语义区分能力的同时融入几何信息。

Result: 在多个通用目标跟踪基准测试上的广泛实验表明，GOT-Edit实现了卓越的鲁棒性和准确性，特别是在遮挡和杂乱场景下，为结合2D语义与3D几何推理的通用目标跟踪建立了新范式。

Conclusion: GOT-Edit通过在线模型编辑将几何感知线索整合到通用目标跟踪器中，有效解决了现有方法忽略3D几何线索的问题，在遮挡和杂乱场景下表现出色，为2D语义与3D几何推理的结合提供了新范式。

Abstract: Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.

</details>


### [125] [SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning](https://arxiv.org/abs/2602.08582)
*Melany Yang,Yuhang Yu,Diwang Weng,Jinwei Chen,Wei Dong*

Main category: cs.CV

TL;DR: SemiNFT是一个基于扩散Transformer的参考式色彩修图框架，通过模仿人类艺术训练轨迹（从刚性模仿到直觉创作），结合配对数据学习和无配对强化学习，实现语义感知的色彩迁移。


<details>
  <summary>Details</summary>
Motivation: 当前参考式色彩修图方法主要基于像素级统计的全局色彩映射，缺乏对语义上下文和人类美学的真正理解，无法实现专业级的修图效果。

Method: SemiNFT采用两阶段训练：1）使用配对三元组学习基本结构保持和色彩映射技能；2）在无配对数据上进行强化学习以培养细致的美学感知，并设计混合在线-离线奖励机制防止灾难性遗忘。

Result: SemiNFT在标准预设迁移基准测试中优于现有方法，并在黑白照片着色和跨域（动漫到照片）预设迁移等零样本任务中表现出色，证实其超越了简单的统计匹配。

Conclusion: SemiNFT通过模仿人类艺术学习轨迹，实现了对美学理解的更高层次，为参考式色彩修图提供了更智能、语义感知的解决方案。

Abstract: Photorealistic color retouching plays a vital role in visual content creation, yet manual retouching remains inaccessible to non-experts due to its reliance on specialized expertise. Reference-based methods offer a promising alternative by transferring the preset color of a reference image to a source image. However, these approaches often operate as novice learners, performing global color mappings derived from pixel-level statistics, without a true understanding of semantic context or human aesthetics. To address this issue, we propose SemiNFT, a Diffusion Transformer (DiT)-based retouching framework that mirrors the trajectory of human artistic training: beginning with rigid imitation and evolving into intuitive creation. Specifically, SemiNFT is first taught with paired triplets to acquire basic structural preservation and color mapping skills, and then advanced to reinforcement learning (RL) on unpaired data to cultivate nuanced aesthetic perception. Crucially, during the RL stage, to prevent catastrophic forgetting of old skills, we design a hybrid online-offline reward mechanism that anchors aesthetic exploration with structural review. % experiments Extensive experiments show that SemiNFT not only outperforms state-of-the-art methods on standard preset transfer benchmarks but also demonstrates remarkable intelligence in zero-shot tasks, such as black-and-white photo colorization and cross-domain (anime-to-photo) preset transfer. These results confirm that SemiNFT transcends simple statistical matching and achieves a sophisticated level of aesthetic comprehension. Our project can be found at https://melanyyang.github.io/SemiNFT/.

</details>


### [126] [Overview and Comparison of AVS Point Cloud Compression Standard](https://arxiv.org/abs/2602.08613)
*Wei Gao,Wenxu Gao,Xingming Mu,Changhao Peng,Ge Li*

Main category: cs.CV

TL;DR: 本文回顾了中国AVS工作组开发的第一代点云压缩标准AVS PCC，从技术特点和性能比较两个角度进行分析，展示了该标准与MPEG的G-PCC和V-PCC标准的不同之处。


<details>
  <summary>Details</summary>
Motivation: 点云作为重要的3D数据表示格式，在沉浸式媒体、自动驾驶、数字遗产保护等领域有广泛应用价值，但其大数据量给传输和存储带来挑战。为优化人类和机器感知，点云压缩在实际应用中至关重要，因此需要制定相关标准。

Method: 本文采用综述分析方法，从两个角度回顾AVS PCC标准：1）相关技术特点，分析AVS PCC采用的新编码工具和技术；2）性能比较，将AVS PCC与MPEG的G-PCC和V-PCC标准进行对比。

Result: AVS PCC作为中国自主开发的第一代点云压缩标准，采用了与MPEG标准不同的新编码工具和技术，形成了具有自身特色的标准化解决方案。

Conclusion: AVS PCC标准的开发完成填补了中国在点云压缩标准领域的空白，为点云数据的传输和存储提供了新的标准化解决方案，有助于推动点云技术在各领域的广泛应用。

Abstract: Point cloud is a prevalent 3D data representation format with significant application values in immersive media, autonomous driving, digital heritage protection, etc. However, the large data size of point clouds poses challenges to transmission and storage, which influences the wide deployments. Therefore, point cloud compression plays a crucial role in practical applications for both human and machine perception optimization. To this end, the Moving Picture Experts Group (MPEG) has established two standards for point cloud compression, including Geometry-based Point Cloud Compression (G-PCC) and Video-based Point Cloud Compression (V-PCC). In the meantime, the Audio Video coding Standard (AVS) Workgroup of China also have launched and completed the development for its first generation point cloud compression standard, namely AVS PCC. This new standardization effort has adopted many new coding tools and techniques, which are different from the other counterpart standards. This paper reviews the AVS PCC standard from two perspectives, i.e., the related technologies and performance comparisons.

</details>


### [127] [Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration](https://arxiv.org/abs/2602.08615)
*Kfir Goldberg,Elad Richardson,Yael Vinker*

Main category: cs.CV

TL;DR: 提出Inspiration Seeds框架，将图像生成从最终执行转向探索性构思，通过视觉输入而非文本提示生成多样组合，揭示输入图像间的潜在关系


<details>
  <summary>Details</summary>
Motivation: 当前生成模型主要针对精心设计的文本提示进行优化，缺乏对开放式视觉探索的支持，而设计师经常从松散连接的视觉参考中寻找灵感，寻求激发新想法的涌现连接

Method: 使用CLIP稀疏自编码器提取CLIP潜在空间中的编辑方向，通过纯视觉手段分解视觉方面，生成合成三元组进行训练，实现无需用户指定文本提示的前馈生成

Result: 模型能够从两个输入图像生成多样且视觉连贯的组合，揭示输入之间的潜在关系，支持快速直观的视觉重组

Conclusion: 该方法摆脱了对语言的依赖，实现了快速直观的视觉重组，支持创意工作早期和模糊阶段的视觉构思

Abstract: While generative models have become powerful tools for image synthesis, they are typically optimized for executing carefully crafted textual prompts, offering limited support for the open-ended visual exploration that often precedes idea formation. In contrast, designers frequently draw inspiration from loosely connected visual references, seeking emergent connections that spark new ideas. We propose Inspiration Seeds, a generative framework that shifts image generation from final execution to exploratory ideation. Given two input images, our model produces diverse, visually coherent compositions that reveal latent relationships between inputs, without relying on user-specified text prompts. Our approach is feed-forward, trained on synthetic triplets of decomposed visual aspects derived entirely through visual means: we use CLIP Sparse Autoencoders to extract editing directions in CLIP latent space and isolate concept pairs. By removing the reliance on language and enabling fast, intuitive recombination, our method supports visual ideation at the early and ambiguous stages of creative work.

</details>


### [128] [Improving Reconstruction of Representation Autoencoder](https://arxiv.org/abs/2602.08620)
*Siyu Liu,Chujie Qin,Hubery Yin,Qixin Yan,Zheng-Peng Duan,Chen Li,Jing Lyu,Chun-Le Guo,Chongyi Li*

Main category: cs.CV

TL;DR: LV-RAE是一种表示自编码器，通过增强语义特征的低级信息来提升潜在扩散模型的重建保真度，同时通过增强解码器鲁棒性和平滑潜在空间来改善生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用视觉基础模型作为图像编码器来提升潜在扩散模型的生成性能，但这些语义特征缺乏低级信息（如颜色和纹理），导致重建保真度下降，成为进一步扩展LDMs的主要瓶颈。

Method: 提出LV-RAE表示自编码器，通过增强语义特征的低级信息来实现高保真重建；同时通过微调解码器增强其鲁棒性，并通过受控噪声注入平滑生成的潜在表示。

Result: 实验表明LV-RAE显著提高了重建保真度，同时保持了语义抽象能力，并实现了强大的生成质量。

Conclusion: LV-RAE通过增强语义特征的低级信息和改善解码器鲁棒性，有效解决了潜在扩散模型中重建保真度与生成质量之间的权衡问题。

Abstract: Recent work leverages Vision Foundation Models as image encoders to boost the generative performance of latent diffusion models (LDMs), as their semantic feature distributions are easy to learn. However, such semantic features often lack low-level information (\eg, color and texture), leading to degraded reconstruction fidelity, which has emerged as a primary bottleneck in further scaling LDMs. To address this limitation, we propose LV-RAE, a representation autoencoder that augments semantic features with missing low-level information, enabling high-fidelity reconstruction while remaining highly aligned with the semantic distribution. We further observe that the resulting high-dimensional, information-rich latent make decoders sensitive to latent perturbations, causing severe artifacts when decoding generated latent and consequently degrading generation quality. Our analysis suggests that this sensitivity primarily stems from excessive decoder responses along directions off the data manifold. Building on these insights, we propose fine-tuning the decoder to increase its robustness and smoothing the generated latent via controlled noise injection, thereby enhancing generation quality. Experiments demonstrate that LV-RAE significantly improves reconstruction fidelity while preserving the semantic abstraction and achieving strong generative quality. Our code is available at https://github.com/modyu-liu/LVRAE.

</details>


### [129] [Revisiting [CLS] and Patch Token Interaction in Vision Transformers](https://arxiv.org/abs/2602.08626)
*Alexis Marouani,Oriane Siméoni,Hervé Jégou,Piotr Bojanowski,Huy V. Vo*

Main category: cs.CV

TL;DR: 论文提出通过专门处理路径分离类别token和补丁token的计算流，特别是标准化层和早期QKV投影，显著提升密集预测任务的补丁表示质量，在分割任务上获得超过2 mIoU的性能提升，同时保持强分类精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中，可学习的[CLS]类别token和补丁token虽然性质不同，但在整个模型中采用相同的处理方式。作者研究了不同预训练策略下全局和局部特征学习之间的冲突，发现标准标准化层在这两种token类型之间引入了隐式区分。

Method: 基于分析发现，提出专门的处理路径，选择性地解耦类别token和补丁token的计算流，特别是在标准化层和早期查询-键-值投影中。这种针对性专门化显著提升了密集预测任务的补丁表示质量。

Result: 实验表明，在标准基准测试中分割性能提升超过2 mIoU点，同时保持强分类精度。提出的修改仅增加8%的参数，没有额外的计算开销。通过全面消融研究，提供了哪些架构组件从专门化中获益最多以及该方法如何跨模型规模和学框架泛化的见解。

Conclusion: 通过专门处理路径分离类别token和补丁token的计算流，特别是在标准化层和早期QKV投影中，可以显著提升Vision Transformers在密集预测任务中的性能，同时保持分类能力，且计算开销很小。

Abstract: Vision Transformers have emerged as powerful, scalable and versatile representation learners. To capture both global and local features, a learnable [CLS] class token is typically prepended to the input sequence of patch tokens. Despite their distinct nature, both token types are processed identically throughout the model. In this work, we investigate the friction between global and local feature learning under different pre-training strategies by analyzing the interactions between class and patch tokens. Our analysis reveals that standard normalization layers introduce an implicit differentiation between these token types. Building on this insight, we propose specialized processing paths that selectively disentangle the computational flow of class and patch tokens, particularly within normalization layers and early query-key-value projections. This targeted specialization leads to significantly improved patch representation quality for dense prediction tasks. Our experiments demonstrate segmentation performance gains of over 2 mIoU points on standard benchmarks, while maintaining strong classification accuracy. The proposed modifications introduce only an 8% increase in parameters, with no additional computational overhead. Through comprehensive ablations, we provide insights into which architectural components benefit most from specialization and how our approach generalizes across model scales and learning frameworks.

</details>


### [130] [Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology](https://arxiv.org/abs/2602.08652)
*Oskar Thaeter,Tanja Niedermair,Johannes Raffler,Ralf Huss,Peter J. Schüffler*

Main category: cs.CV

TL;DR: 提出基于深度学习的方法，使用低分辨率预扫描缩略图预测病理切片固定类型，相比传统高分辨率方法处理速度快400倍，在多个数据集上验证有效


<details>
  <summary>Details</summary>
Motivation: 病理切片固定类型（FFPE和FS）的手动标注容易出错，影响下游分析和诊断准确性。现有验证方法需要全分辨率全玻片图像，限制了高通量质量控制的可扩展性。

Method: 开发深度学习模型，利用低分辨率预扫描缩略图像预测固定类型。模型在TUM病理研究所的1200张WSI上训练，在TCGA数据集（8800张）以及Augsburg（695张）和Regensburg（202张）数据集上评估。

Result: 模型在TCGA数据集上AUROC达到0.88，比同类预扫描方法提升4.8%。在Regensburg和Augsburg数据集上AUROC为0.72，显示扫描仪引起的域偏移挑战。每张切片处理时间仅21毫秒，比现有高倍率全分辨率方法快400倍。

Conclusion: 该方法为高通量病理工作流程提供了无需高倍率扫描的标签错误检测高效解决方案。未来工作将改进模型对不同扫描仪类型的泛化能力，该方法可提高数字病理工作流程的准确性和效率，并可扩展到其他低分辨率切片标注任务。

Abstract: Accurate annotation of fixation type is a critical step in slide preparation for pathology laboratories. However, this manual process is prone to
  errors, impacting downstream analyses and diagnostic accuracy. Existing methods for verifying formalin-fixed, paraffin-embedded (FFPE), and frozen
  section (FS) fixation types typically require full-resolution whole-slide images (WSIs), limiting scalability for high-throughput quality control.
  We propose a deep-learning model to predict fixation types using low-resolution, pre-scan thumbnail images. The model was trained on WSIs from
  the TUM Institute of Pathology (n=1,200, Leica GT450DX) and evaluated on a class-balanced subset of The Cancer Genome Atlas dataset (TCGA, n=8,800,
  Leica AT2), as well as on class-balanced datasets from Augsburg (n=695 [392 FFPE, 303 FS], Philips UFS) and Regensburg (n=202, 3DHISTECH P1000).
  Our model achieves an AUROC of 0.88 on TCGA, outperforming comparable pre-scan methods by 4.8%. It also achieves AUROCs of 0.72 on Regensburg and
  Augsburg slides, underscoring challenges related to scanner-induced domain shifts. Furthermore, the model processes each slide in 21 ms, $400\times$
  faster than existing high-magnification, full-resolution methods, enabling rapid, high-throughput processing.
  This approach provides an efficient solution for detecting labelling errors without relying on high-magnification scans, offering a valuable tool for
  quality control in high-throughput pathology workflows. Future work will improve and evaluate the model's generalisation to additional scanner
  types. Our findings suggest that this method can increase accuracy and efficiency in digital pathology workflows and may be extended to other
  low-resolution slide annotations.

</details>


### [131] [WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling](https://arxiv.org/abs/2602.08661)
*Yi Dao,Lankai Zhang,Hao Liu,Haiwei Zhang,Wenbo Wang*

Main category: cs.CV

TL;DR: WiFlow是一个基于WiFi信号的连续人体姿态估计框架，采用编码器-解码器架构，通过时空特征提取和轴向注意力机制，在减少计算开销的同时实现了高精度姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi姿态估计方法在处理连续运动时存在困难且计算开销大，而视觉方法将CSI视为图像处理可能丢失信号原始时序结构。需要一种能处理连续运动、保留信号时序特性且计算高效的WiFi姿态估计方法。

Method: 提出WiFlow框架，采用编码器-解码器架构：编码器使用时序和非对称卷积捕获CSI的时空特征，保留信号原始序列结构；通过轴向注意力机制精炼人体关键点特征并捕获结构依赖关系；解码器将编码的高维特征映射为关键点坐标。

Result: 在自收集的36万同步CSI-姿态样本数据集上，WiFlow在PCK@20达到97.00%，PCK@50达到99.48%，平均关节位置误差为0.008米。模型仅需482万参数，显著降低了复杂度和计算成本。

Conclusion: WiFlow为实用的WiFi人体姿态估计建立了新的性能基准，在保持高精度的同时大幅降低了模型复杂度和计算开销，为物联网智能感知应用提供了有效解决方案。

Abstract: Human pose estimation is fundamental to intelligent perception in the Internet of Things (IoT), enabling applications ranging from smart healthcare to human-computer interaction. While WiFi-based methods have gained traction, they often struggle with continuous motion and high computational overhead. This work presents WiFlow, a novel framework for continuous human pose estimation using WiFi signals. Unlike vision-based approaches such as two-dimensional deep residual networks that treat Channel State Information (CSI) as images, WiFlow employs an encoder-decoder architecture. The encoder captures spatio-temporal features of CSI using temporal and asymmetric convolutions, preserving the original sequential structure of signals. It then refines keypoint features of human bodies to be tracked and capture their structural dependencies via axial attention. The decoder subsequently maps the encoded high-dimensional features into keypoint coordinates. Trained on a self-collected dataset of 360,000 synchronized CSI-pose samples from 5 subjects performing continuous sequences of 8 daily activities, WiFlow achieves a Percentage of Correct Keypoints (PCK) of 97.00% at a threshold of 20% (PCK@20) and 99.48% at PCK@50, with a mean per-joint position error of 0.008m. With only 4.82M parameters, WiFlow significantly reduces model complexity and computational cost, establishing a new performance baseline for practical WiFi-based human pose estimation. Our code and datasets are available at https://github.com/DY2434/WiFlow-WiFi-Pose-Estimation-with-Spatio-Temporal-Decoupling.git.

</details>


### [132] [ALIVE: Animate Your World with Lifelike Audio-Video Generation](https://arxiv.org/abs/2602.08682)
*Ying Guo,Qijun Gan,Yifu Zhang,Jinlai Liu,Yifei Hu,Pan Xie,Dongjun Qian,Yu Zhang,Ruiqi Li,Yuqi Zhang,Ruibiao Lu,Xiaofeng Mei,Bo Han,Xiang Yin,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: ALIVE是一个音频-视频生成模型，通过改造预训练的文本到视频模型，实现了类似Sora的音频视频生成和动画功能，支持文本到音视频和参考动画生成。


<details>
  <summary>Details</summary>
Motivation: 视频生成正在快速向统一的音频-视频生成发展，现有文本到视频基础模型缺乏音频生成和动画能力，需要开发能够同时处理音频和视频的生成模型。

Method: 1. 基于MMDiT架构扩展联合音频-视频分支，包含TA-CrossAttn用于时间对齐的跨模态融合和UniTemp-RoPE用于精确的音频-视觉对齐；2. 设计全面的数据管道，包括音频-视频字幕、质量控制等，收集高质量微调数据；3. 在百万级别高质量数据上进行持续预训练和微调。

Result: ALIVE表现出色，在性能上一致优于开源模型，匹配或超越了最先进的商业解决方案。模型解锁了文本到音视频和参考动画能力。

Conclusion: ALIVE通过详细的技术方案和基准测试，帮助社区更高效地开发音频-视频生成模型，推动了统一的音频-视频生成技术的发展。

Abstract: Video generation is rapidly evolving towards unified audio-video generation. In this paper, we present ALIVE, a generation model that adapts a pretrained Text-to-Video (T2V) model to Sora-style audio-video generation and animation. In particular, the model unlocks the Text-to-Video&Audio (T2VA) and Reference-to-Video&Audio (animation) capabilities compared to the T2V foundation models. To support the audio-visual synchronization and reference animation, we augment the popular MMDiT architecture with a joint audio-video branch which includes TA-CrossAttn for temporally-aligned cross-modal fusion and UniTemp-RoPE for precise audio-visual alignment. Meanwhile, a comprehensive data pipeline consisting of audio-video captioning, quality control, etc., is carefully designed to collect high-quality finetuning data. Additionally, we introduce a new benchmark to perform a comprehensive model test and comparison. After continue pretraining and finetuning on million-level high-quality data, ALIVE demonstrates outstanding performance, consistently outperforming open-source models and matching or surpassing state-of-the-art commercial solutions. With detailed recipes and benchmarks, we hope ALIVE helps the community develop audio-video generation models more efficiently. Official page: https://github.com/FoundationVision/Alive.

</details>


### [133] [OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence](https://arxiv.org/abs/2602.08683)
*Feilong Tang,Xiang An,Yunyao Yan,Yin Xie,Bin Qin,Kaicheng Yang,Yifei Shen,Yuanhan Zhang,Chunyuan Li,Shikun Feng,Changrui Chen,Huajie Tan,Ming Hu,Manyuan Zhang,Bo Li,Ziyong Feng,Ziwei Liu,Zongyuan Ge,Jiankang Deng*

Main category: cs.CV

TL;DR: OneVision-Encoder提出将视频压缩作为AGI的核心问题，通过Codec Patchification只处理信号熵丰富的区域（3.1%-25%），在减少视觉token和数据量的情况下，在16个基准测试中超越现有视觉骨干模型。


<details>
  <summary>Details</summary>
Motivation: 现代视觉架构偏离了信息论基本原则：视觉信号高度冗余，而判别信息稀疏。当前模型均匀处理密集像素网格，浪费大量计算在静态背景上，而不是关注定义运动和意义的预测残差。需要使架构与视频的信息论原则（即编解码器）对齐。

Method: 采用Codec Patchification，放弃均匀计算，只关注信号熵丰富的区域（3.1%-25%）。使用共享3D RoPE统一空间和时间推理，通过超过100万个语义概念的大规模聚类判别目标进行训练，联合捕捉对象持久性和运动动态。

Result: 在集成到LLM后，在16个图像、视频和文档理解基准测试中一致优于Qwen3-ViT和SigLIP2等强视觉骨干模型，尽管使用了显著更少的视觉token和预训练数据。在视频理解任务上，平均比Qwen3-ViT提升4.1%。

Conclusion: 效率与准确性不是权衡关系，而是正相关的。编解码器对齐的补丁级稀疏性是基本原则，使OV-Encoder成为下一代视觉通用模型的扩展引擎。

Abstract: Hypothesis. Artificial general intelligence is, at its core, a compression problem. Effective compression demands resonance: deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information, the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs.
  Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification, OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts, jointly capturing object permanence and motion dynamics.
  Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM, it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data. Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists.

</details>


### [134] [TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions](https://arxiv.org/abs/2602.08711)
*Linli Yao,Yuancheng Wei,Yaojie Zhang,Lei Li,Xinlong Chen,Feifan Song,Ziyue Wang,Kun Ouyang,Yuanxin Liu,Lingpeng Kong,Qi Liu,Pengfei Wan,Kun Gai,Yuanxing Zhang,Xu Sun*

Main category: cs.CV

TL;DR: 提出Omni Dense Captioning新任务，构建高质量基准数据集和评估指标，开发TimeChat-Captioner-7B模型，在多个下游任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频描述任务通常生成简短、离散的文本，缺乏连续、细粒度、结构化的视听叙事能力。需要一种能够生成类似电影剧本的详细描述，让读者能够逐场景生动想象视频内容的方法。

Method: 1. 提出六维结构模式创建"脚本式"描述；2. 构建高质量人工标注基准OmniDCBench；3. 提出SodaM统一评估指标；4. 构建训练数据集TimeChatCap-42K；5. 开发TimeChat-Captioner-7B模型，采用SFT和GRPO训练，配合任务特定奖励。

Result: TimeChat-Captioner-7B在密集描述生成上超越Gemini-2.5-Pro，达到SOTA性能。生成的密集描述显著提升下游任务能力：视听推理（DailyOmni和WorldSense）和时间定位（Charades-STA）。

Conclusion: Omni Dense Captioning是一个有前景的新任务，提出的基准、指标和模型为连续、细粒度、结构化视听叙事生成提供了有效解决方案，显著提升下游视听理解任务性能。

Abstract: This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create "script-like" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner.

</details>


### [135] [Towards Understanding Multimodal Fine-Tuning: Spatial Features](https://arxiv.org/abs/2602.08713)
*Lachin Naghashyar,Hunar Batra,Ashkan Khakzar,Philip Torr,Ronald Clark,Christian Schroeder de Witt,Constantin Venhoff*

Main category: cs.CV

TL;DR: 该研究首次对视觉语言模型(VLMs)进行机制分析，通过阶段式模型差异技术揭示语言模型如何学习"看"的能力，识别出在微调过程中出现的视觉偏好特征及其空间关系编码机制。


<details>
  <summary>Details</summary>
Motivation: 尽管现代视觉语言模型在各种任务上表现出色，但语言主干表示在多模态训练中如何适应以及视觉特定能力何时出现仍不清楚。研究者希望揭示语言模型学习视觉能力的机制。

Method: 采用阶段式模型差异技术，该技术能够隔离多模态微调过程中引入的表征变化。通过识别在微调过程中出现或重新定向的视觉偏好特征，分析这些特征如何编码空间关系，并追踪这些特征的因果激活到特定的注意力头。

Result: 研究发现：1) 识别出在微调过程中出现或重新定向的视觉偏好特征；2) 这些特征的一个选择性子集可靠地编码空间关系，通过对空间提示的受控偏移揭示；3) 这些特征的因果激活可追溯到一小群注意力头。

Conclusion: 阶段式模型差异技术揭示了何时何地出现空间基础的多模态特征，为理解模态融合提供了更清晰的视角，展示了视觉基础如何重塑先前仅用于文本的特征。该方法增强了多模态训练的可解释性，为理解和改进预训练语言模型获取视觉基础能力奠定了基础。

Abstract: Contemporary Vision-Language Models (VLMs) achieve strong performance on a wide range of tasks by pairing a vision encoder with a pre-trained language model, fine-tuned for visual-text inputs. Yet despite these gains, it remains unclear how language backbone representations adapt during multimodal training and when vision-specific capabilities emerge. In this work, we present the first mechanistic analysis of VLM adaptation. Using stage-wise model diffing, a technique that isolates representational changes introduced during multimodal fine-tuning, we reveal how a language model learns to "see". We first identify vision-preferring features that emerge or reorient during fine-tuning. We then show that a selective subset of these features reliably encodes spatial relations, revealed through controlled shifts to spatial prompts. Finally, we trace the causal activation of these features to a small group of attention heads. Our findings show that stage-wise model diffing reveals when and where spatially grounded multimodal features arise. It also provides a clearer view of modality fusion by showing how visual grounding reshapes features that were previously text-only. This methodology enhances the interpretability of multimodal training and provides a foundation for understanding and refining how pretrained language models acquire vision-grounded capabilities.

</details>


### [136] [Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images](https://arxiv.org/abs/2602.08717)
*Farnaz Khun Jush,Grit Werner,Mark Klemens,Matthias Lenga*

Main category: cs.CV

TL;DR: 本文研究了在零样本条件下使用预训练基础模型进行CT和MR图像解剖区域检测的方法，提出了三种无需训练的方法，其中基于分割的规则系统表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像解剖区域识别主要依赖不可靠的DICOM元数据或监督学习，限制了在实际场景中的应用。本文旨在探索是否可以利用预训练基础模型的知识，在零样本条件下实现可靠的解剖区域检测。

Method: 提出了三种无需训练的流程：1）基于预训练多器官分割模型的分割驱动规则系统；2）基于放射科医生定义规则的多模态大语言模型；3）结合视觉输入和解剖证据的分割感知多模态大语言模型。在887个CT和MR扫描上进行了系统评估。

Result: 分割驱动的规则方法表现最佳且最一致，加权F1分数分别为0.947（CT）和0.914（MR），在不同模态和非典型扫描覆盖下都表现出鲁棒性。多模态大语言模型在视觉特征明显的区域表现有竞争力，而分割感知的多模态大语言模型显示出基本局限性。

Conclusion: 研究表明，利用预训练基础模型的知识可以在零样本条件下实现可靠的解剖区域检测，其中基于分割的规则方法是最有效的解决方案，为医学影像工作流程提供了不依赖DICOM元数据的可靠替代方案。

Abstract: Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using knowledge embedded in large pre-trained foundation models. We propose and systematically evaluate three training-free pipelines: (1) a segmentation-driven rule-based system leveraging pre-trained multi-organ segmentation models, (2) a Multimodal Large Language Model (MLLM) guided by radiologist-defined rules, and (3) a segmentation-aware MLLM that combines visual input with explicit anatomical evidence. All methods are evaluated on 887 heterogeneous CT and MR scans with manually verified anatomical region labels. The segmentation-driven rule-based approach achieves the strongest and most consistent performance, with weighted F1-scores of 0.947 (CT) and 0.914 (MR), demonstrating robustness across modalities and atypical scan coverage. The MLLM performs competitively in visually distinctive regions, while the segmentation-aware MLLM reveals fundamental limitations.

</details>


### [137] [FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing](https://arxiv.org/abs/2602.08725)
*Yongwen Lai,Chaoqun Wang,Shaobo Min*

Main category: cs.CV

TL;DR: FusionEdit是一个无需训练的文本引导图像编辑框架，通过软掩码融合和统计注意力融合实现精确可控的编辑，解决了硬掩码边界带来的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用显式二值掩码约束编辑，但硬掩码边界会引入伪影并降低可编辑性。需要一种既能精确控制编辑区域又能保持图像自然过渡的方法。

Method: 1) 通过测量源提示词和目标提示词语义差异自动识别编辑和保留区域；2) 沿边界进行距离感知的潜在融合生成软掩码，并使用总变差损失确保平滑过渡；3) 在DiT注意力层中使用AdaIN调制进行统计注意力融合，增强可编辑性同时保持全局一致性。

Result: 大量实验表明，FusionEdit在文本引导图像编辑任务上显著优于现有最先进方法，能够实现更精确、更自然的编辑效果。

Conclusion: FusionEdit通过软掩码融合和统计注意力融合，解决了硬掩码边界带来的伪影问题，实现了精确可控的图像编辑，同时保持了编辑的自然性和全局一致性。

Abstract: Text-guided image editing aims to modify specific regions according to the target prompt while preserving the identity of the source image. Recent methods exploit explicit binary masks to constrain editing, but hard mask boundaries introduce artifacts and reduce editability. To address these issues, we propose FusionEdit, a training-free image editing framework that achieves precise and controllable edits. First, editing and preserved regions are automatically identified by measuring semantic discrepancies between source and target prompts. To mitigate boundary artifacts, FusionEdit performs distance-aware latent fusion along region boundaries to yield the soft and accurate mask, and employs a total variation loss to enforce smooth transitions, obtaining natural editing results. Second, FusionEdit leverages AdaIN-based modulation within DiT attention layers to perform a statistical attention fusion in the editing region, enhancing editability while preserving global consistency with the source image. Extensive experiments demonstrate that our FusionEdit significantly outperforms state-of-the-art methods. Code is available at \href{https://github.com/Yvan1001/FusionEdit}{https://github.com/Yvan1001/FusionEdit}.

</details>


### [138] [Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework](https://arxiv.org/abs/2602.08727)
*Johannes Thalhammer,Tina Dorosti,Sebastian Peterhansl,Daniela Pfeiffer,Franz Pfeiffer,Florian Schaff*

Main category: cs.CV

TL;DR: 提出了一种结合2D和3D模型的混合深度学习框架，用于从欠采样CT体积中去除伪影，在保持计算效率的同时提高图像质量和诊断价值。


<details>
  <summary>Details</summary>
Motivation: 欠采样CT扫描虽然减少了采集时间和辐射暴露，但会引入伪影，降低图像质量和诊断效用。消除这些伪影对于高质量成像至关重要。

Method: 采用两阶段混合框架：首先使用2D U-Net处理欠采样CT体积的单个切片提取特征图，然后将这些切片特征图堆叠成体积，输入到3D解码器中，利用跨切片上下文信息预测无伪影的3D CT体积。

Result: 该方法在冠状面和矢状面方向上显著提高了切片间一致性，同时保持了较低的计算开销，为高质量3D CT图像后处理提供了稳健高效的解决方案。

Conclusion: 提出的混合框架平衡了2D处理的计算效率和3D建模的体积一致性，是高质量3D CT图像后处理的稳健高效解决方案。

Abstract: Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise feature maps are then stacked across the volume and used as input to a 3D decoder, which utilizes contextual information across slices to predict an artifact-free 3D CT volume. The proposed two-stage approach balances the computational efficiency of 2D processing with the volumetric consistency provided by 3D modeling. The results show substantial improvements in inter-slice consistency in coronal and sagittal direction with low computational overhead. This hybrid framework presents a robust and efficient solution for high-quality 3D CT image post-processing. The code of this project can be found on github: https://github.com/J-3TO/2D-3DCNN_sparseview/.

</details>


### [139] [Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation](https://arxiv.org/abs/2602.08730)
*Shanshan Wang,Ziying Feng,Xiaozheng Shen,Xun Yang,Pichao Wang,Zhenwei He,Xingyi Zhang*

Main category: cs.CV

TL;DR: 论文提出CLIP引导对齐(CGA)框架，通过显式建模和缓解类别混淆来解决源自由域适应中的伪标签噪声问题，在细粒度场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 源自由域适应中，现有伪标签策略在细粒度场景下因类别间相似性而失效，特别是存在不对称和动态的类别混淆问题，导致伪标签噪声和目标判别能力差。

Method: CGA包含三个核心组件：MCA检测目标域中的方向性混淆对；MCC利用CLIP构建混淆感知的文本提示；FAM建立混淆引导的特征库并通过对比学习对齐CLIP和源模型的表示空间。

Result: 在多个数据集上的实验表明，CGA持续超越最先进的SFDA方法，在易混淆和细粒度场景下取得特别显著的性能提升。

Conclusion: 显式建模类别间混淆对于有效的源自由域适应至关重要，CGA框架通过结合CLIP的语义理解和混淆感知策略，成功缓解了伪标签噪声问题。

Abstract: Source-Free Domain Adaptation (SFDA) tackles the problem of adapting a pre-trained source model to an unlabeled target domain without accessing any source data, which is quite suitable for the field of data security. Although recent advances have shown that pseudo-labeling strategies can be effective, they often fail in fine-grained scenarios due to subtle inter-class similarities. A critical but underexplored issue is the presence of asymmetric and dynamic class confusion, where visually similar classes are unequally and inconsistently misclassified by the source model. Existing methods typically ignore such confusion patterns, leading to noisy pseudo-labels and poor target discrimination. To address this, we propose CLIP-Guided Alignment(CGA), a novel framework that explicitly models and mitigates class confusion in SFDA. Generally, our method consists of three parts: (1) MCA: detects first directional confusion pairs by analyzing the predictions of the source model in the target domain; (2) MCC: leverages CLIP to construct confusion-aware textual prompts (e.g. a truck that looks like a bus), enabling more context-sensitive pseudo-labeling; and (3) FAM: builds confusion-guided feature banks for both CLIP and the source model and aligns them using contrastive learning to reduce ambiguity in the representation space. Extensive experiments on various datasets demonstrate that CGA consistently outperforms state-of-the-art SFDA methods, with especially notable gains in confusion-prone and fine-grained scenarios. Our results highlight the importance of explicitly modeling inter-class confusion for effective source-free adaptation. Our code can be find at https://github.com/soloiro/CGA

</details>


### [140] [From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models](https://arxiv.org/abs/2602.08735)
*Masanari Oi,Koki Maeda,Ryuto Koike,Daisuke Oba,Nakamasa Inoue,Naoaki Okazaki*

Main category: cs.CV

TL;DR: HATCH训练框架通过补丁级空间对齐和行动-答案推理，提升多模态大语言模型在多图像空间推理任务中的表现，在保持单图像推理能力的同时，显著优于同规模基线模型。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在单图像空间推理方面取得进展，但在需要整合多个视角信息的多图像空间推理方面仍面临挑战。认知研究表明人类通过跨视图对应和逐步视角变换两种机制解决此类任务，但现有研究仅部分且隐式地融入这些机制，缺乏对两者的显式监督。

Method: 提出HATCH训练框架，包含两个互补目标：1) 补丁级空间对齐 - 鼓励不同视图中空间对应区域的补丁表示对齐；2) 行动-答案推理 - 要求模型在预测最终答案前生成显式的视角转换行动。

Result: 在三个基准测试上的实验表明，HATCH始终以明显优势优于同规模基线模型，并与更大模型取得竞争性结果，同时保持了单图像推理能力。

Conclusion: HATCH框架通过显式监督跨视图对应和逐步视角变换，有效提升了多模态大语言模型在多图像空间推理任务中的性能，为多视角空间理解提供了系统化训练方法。

Abstract: While multimodal large language models (MLLMs) have made substantial progress in single-image spatial reasoning, multi-image spatial reasoning, which requires integration of information from multiple viewpoints, remains challenging. Cognitive studies suggest that humans address such tasks through two mechanisms: cross-view correspondence, which identifies regions across different views that correspond to the same physical locations, and stepwise viewpoint transformation, which composes relative viewpoint changes sequentially. However, existing studies incorporate these mechanisms only partially and often implicitly, without explicit supervision for both. We propose Human-Aware Training for Cross-view correspondence and viewpoint cHange (HATCH), a training framework with two complementary objectives: (1) Patch-Level Spatial Alignment, which encourages patch representations to align across views for spatially corresponding regions, and (2) Action-then-Answer Reasoning, which requires the model to generate explicit viewpoint transition actions before predicting the final answer. Experiments on three benchmarks demonstrate that HATCH consistently outperforms baselines of comparable size by a clear margin and achieves competitive results against much larger models, while preserving single-image reasoning capabilities.

</details>


### [141] [Shifting the Breaking Point of Flow Matching for Multi-Instance Editing](https://arxiv.org/abs/2602.08749)
*Carmine Zaccagnino,Fabio Quattrini,Enis Simsar,Marta Tintoré Gazulla,Rita Cucchiara,Alessio Tonioni,Silvia Cascianelli*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Instance-Disentangled Attention的新机制，用于解决现有基于流的图像编辑模型在多实例编辑场景中的局限性，能够实现单次推理中的实例级编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的图像编辑模型主要支持全局或单指令编辑，但在多实例场景中存在局限性，即当需要对参考输入的多个部分进行独立编辑时，会产生语义干扰。这种局限性源于全局条件化的速度场和联合注意力机制，导致并发编辑相互纠缠。

Method: 提出了Instance-Disentangled Attention机制，该机制通过划分联合注意力操作，在速度场估计过程中强制建立实例特定文本指令与空间区域之间的绑定关系，从而实现编辑的解耦。

Result: 实验结果表明，该方法在自然图像编辑和文本密集信息图编辑任务中都能促进编辑的解耦和局部性，同时保持全局输出的连贯性，实现了单次推理中的实例级编辑。

Conclusion: Instance-Disentangled Attention机制有效解决了基于流的图像编辑模型在多实例编辑中的局限性，实现了更精细的实例级编辑控制，为文本引导的图像生成和编辑提供了新的解决方案。

Abstract: Flow matching models have recently emerged as an efficient alternative to diffusion, especially for text-guided image generation and editing, offering faster inference through continuous-time dynamics. However, existing flow-based editors predominantly support global or single-instruction edits and struggle with multi-instance scenarios, where multiple parts of a reference input must be edited independently without semantic interference. We identify this limitation as a consequence of globally conditioned velocity fields and joint attention mechanisms, which entangle concurrent edits. To address this issue, we introduce Instance-Disentangled Attention, a mechanism that partitions joint attention operations, enforcing binding between instance-specific textual instructions and spatial regions during velocity field estimation. We evaluate our approach on both natural image editing and a newly introduced benchmark of text-dense infographics with region-level editing instructions. Experimental results demonstrate that our approach promotes edit disentanglement and locality while preserving global output coherence, enabling single-pass, instance-level editing.

</details>


### [142] [MVAnimate: Enhancing Character Animation with Multi-View Optimization](https://arxiv.org/abs/2602.08753)
*Tianyu Sun,Zhoujie Fu,Bang Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: MVAnimate是一个利用多视角先验信息生成高质量2D和3D角色动画的新框架，解决了现有动画生成算法输出质量低和训练数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于2D或3D结构建模人体姿态的动画生成算法面临输出质量低和训练数据不足的问题，无法生成高质量动画视频。需要一种新方法来提升动画生成质量。

Method: MVAnimate是一个新颖框架，基于多视角先验信息合成动态人物的2D和3D信息。该方法利用多视角先验信息生成时间一致和空间连贯的动画输出，并优化目标角色的多视角视频质量。

Result: 实验结果表明，该方法在多样数据集上表现出色，能够处理各种运动模式和外观，相比现有动画方法有显著改进。

Conclusion: MVAnimate通过整合多视角信息有效提升了动画生成质量，为高质量角色动画生成提供了新的解决方案。

Abstract: The demand for realistic and versatile character animation has surged, driven by its wide-ranging applications in various domains. However, the animation generation algorithms modeling human pose with 2D or 3D structures all face various problems, including low-quality output content and training data deficiency, preventing the related algorithms from generating high-quality animation videos. Therefore, we introduce MVAnimate, a novel framework that synthesizes both 2D and 3D information of dynamic figures based on multi-view prior information, to enhance the generated video quality. Our approach leverages multi-view prior information to produce temporally consistent and spatially coherent animation outputs, demonstrating improvements over existing animation methods. Our MVAnimate also optimizes the multi-view videos of the target character, enhancing the video quality from different views. Experimental results on diverse datasets highlight the robustness of our method in handling various motion patterns and appearances.

</details>


### [143] [VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars](https://arxiv.org/abs/2602.08775)
*Vineet Kumar Rakesh,Ahana Bhattacharjee,Soumya Mazumdar,Tapas Samanta,Hemendra Kumar Pandey,Amitabha Das,Sarbajit Pal*

Main category: cs.CV

TL;DR: 提出了一种基于符号吠陀计算的轻量级说话头生成框架，可在CPU上实时运行，适用于资源受限的教育环境


<details>
  <summary>Details</summary>
Motivation: 当前说话头生成方法依赖GPU渲染、大量训练数据或高容量扩散模型，难以在离线或资源受限的学习环境中部署，需要一种轻量级、CPU友好的解决方案

Method: 采用符号吠陀计算方法：1) 语音转时间对齐音素流；2) 音素映射到紧凑视素库；3) 基于吠陀经Urdhva Tiryakbhyam原理的符号协同发音生成平滑视素轨迹；4) 轻量级2D渲染器进行ROI扭曲和嘴部合成

Result: 在仅CPU执行下实现了可接受的唇同步质量，显著降低计算负载和延迟，支持在低端硬件上运行教育用虚拟形象

Conclusion: 提出的符号吠陀计算框架为资源受限环境提供了一种实用的说话头生成解决方案，平衡了质量与计算效率，支持教育虚拟形象在低端硬件上的部署

Abstract: Talking-head avatars are increasingly adopted in educational technology to deliver content with social presence and improved engagement. However, many recent talking-head generation (THG) methods rely on GPU-centric neural rendering, large training sets, or high-capacity diffusion models, which limits deployment in offline or resource-constrained learning environments. A deterministic and CPU-oriented THG framework is described, termed Symbolic Vedic Computation, that converts speech to a time-aligned phoneme stream, maps phonemes to a compact viseme inventory, and produces smooth viseme trajectories through symbolic coarticulation inspired by Vedic sutra Urdhva Tiryakbhyam. A lightweight 2D renderer performs region-of-interest (ROI) warping and mouth compositing with stabilization to support real-time synthesis on commodity CPUs. Experiments report synchronization accuracy, temporal stability, and identity consistency under CPU-only execution, alongside benchmarking against representative CPU-feasible baselines. Results indicate that acceptable lip-sync quality can be achieved while substantially reducing computational load and latency, supporting practical educational avatars on low-end hardware. GitHub: https://vineetkumarrakesh.github.io/vedicthg

</details>


### [144] [Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems](https://arxiv.org/abs/2602.08792)
*Hao Dong,Eleni Chatzi,Olga Fink*

Main category: cs.CV

TL;DR: 提出了一种结合高分辨率图像和力测量的多模态框架，用于更准确、鲁棒地检测受电弓-接触网接口的电弧事件，解决了电弧检测中的瞬态性、噪声环境、数据稀缺等挑战。


<details>
  <summary>Details</summary>
Motivation: 受电弓-接触网接口的电弧现象对铁路供电系统构成严重风险，包括加速接触部件磨损、系统性能下降和服务中断。电弧检测面临瞬态性、噪声环境、数据稀缺以及难以区分电弧与其他瞬态现象等挑战。

Method: 构建了两个电弧检测数据集（瑞士联邦铁路数据和公开视频+合成力数据），提出了MultiDeepSAD多模态扩展算法，并针对每种数据类型设计了专门的伪异常生成技术（如图像中的合成电弧伪影和模拟力不规则性）。

Result: 通过大量实验和消融研究，证明该框架显著优于基线方法，即使在域偏移和真实电弧观测数据有限的情况下，对真实电弧事件也表现出增强的敏感性。

Conclusion: 提出的多模态框架结合视觉和力测量，能够更准确、鲁棒地检测受电弓-接触网接口的电弧事件，为解决铁路供电系统中的电弧检测挑战提供了有效方案。

Abstract: The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.

</details>


### [145] [MOVA: Towards Scalable and Synchronized Video-Audio Generation](https://arxiv.org/abs/2602.08794)
*SII-OpenMOSS Team,:,Donghua Yu,Mingshu Chen,Qi Chen,Qi Luo,Qianyi Wu,Qinyuan Cheng,Ruixiao Li,Tianyi Liang,Wenbo Zhang,Wenming Tu,Xiangyu Peng,Yang Gao,Yanru Huo,Ying Zhu,Yinze Luo,Yiyang Zhang,Yuerong Song,Zhe Xu,Zhiyu Zhang,Chenchen Yang,Cheng Chang,Chushu Zhou,Hanfu Chen,Hongnan Ma,Jiaxi Li,Jingqi Tong,Junxi Liu,Ke Chen,Shimin Li,Songlin Wang,Wei Jiang,Zhaoye Fei,Zhiyuan Ning,Chunguo Li,Chenhui Li,Ziwei He,Zengfeng Huang,Xie Chen,Xipeng Qiu*

Main category: cs.CV

TL;DR: MOVA是一个开源的音频-视频联合生成模型，采用混合专家架构，能够生成高质量、同步的视听内容，包括唇语同步的语音、环境感知音效和内容对齐的音乐。


<details>
  <summary>Details</summary>
Motivation: 当前音频-视频生成方法主要依赖级联管道，导致成本增加、错误累积和质量下降。现有系统如Veo 3和Sora 2虽然强调同时生成的重要性，但联合多模态建模面临架构、数据和训练方面的挑战，且闭源性质限制了该领域的发展。

Method: 采用混合专家架构，总参数量320亿，推理时激活180亿参数。支持图像-文本到视频-音频的生成任务，具备高效推理、LoRA微调和提示增强等功能。

Result: 开发出能够生成高质量同步视听内容的开源模型，包括真实的唇语同步语音、环境感知音效和内容对齐音乐。通过开源模型权重和代码促进研究和创作者社区发展。

Conclusion: MOVA作为开源音频-视频联合生成模型，解决了现有方法的局限性，通过混合专家架构实现了高质量的同步视听内容生成，有望推动该领域的研究和应用发展。

Abstract: Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.

</details>


### [146] [Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework](https://arxiv.org/abs/2602.08797)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种半监督师生框架，结合不确定性感知伪标签教师和基于置信度的渐进课程学习，用于MRI脑肿瘤分割，在有限标注下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: MRI脑肿瘤分割面临标注成本高和数据异质性（不同扫描仪和站点）的挑战，需要开发在有限监督下鲁棒的分割方法。

Method: 采用师生框架：教师模型生成概率掩码和逐像素不确定性；基于图像级置信度对未标注扫描排序并分阶段引入；学生模型使用双损失目标，学习高置信区域并"遗忘"低置信区域；通过一致性精炼提升伪标签质量。

Result: 在BraTS 2021上，验证集DSC从0.393（10%数据）提升到0.872（100%），早期阶段提升最大；教师模型DSC达0.922，学生在肿瘤亚区域超越教师（NCR/NET 0.797，Edema 0.980），特别是在教师失败的增强类别上恢复性能（DSC 0.620）。

Conclusion: 置信度驱动的课程学习和选择性遗忘能够在有限监督和噪声伪标签下提供鲁棒的分割性能，展示了数据效率和模型改进潜力。

Abstract: Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels.

</details>


### [147] [Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing](https://arxiv.org/abs/2602.08820)
*Hao Yang,Zhiyu Tan,Jia Gong,Luozheng Qin,Hesen Chen,Xiaomeng Yang,Yuqing Sun,Yuetan Lin,Mengping Yang,Hao Li*

Main category: cs.CV

TL;DR: Omni-Video 2是一个可扩展的高效视频生成与编辑模型，通过连接预训练多模态大语言模型和视频扩散模型，利用MLLM的理解能力生成明确的目标描述来指导生成过程，实现高质量的视频生成和复杂编辑任务。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成和编辑面临复杂组合指令理解不足的问题，需要更有效地利用多模态理解能力来指导生成过程，同时保持计算效率和模型可扩展性。

Method: 1. 利用预训练多模态大语言模型的理解和推理能力生成明确的目标描述来解释用户指令；2. 开发轻量级适配器将多模态条件标记注入预训练文本到视频扩散模型；3. 在精心策划的训练数据上扩展到14B参数规模。

Result: 在FiVE基准测试中展示了处理复杂组合指令的卓越能力，在VBench基准测试中实现了竞争性或更优的视频生成质量，支持高质量文本到视频生成和各种视频编辑任务。

Conclusion: Omni-Video 2通过有效连接多模态理解和生成模型，实现了高质量、可扩展的视频生成与编辑，在复杂组合指令理解和生成质量方面表现出色。

Abstract: We present Omni-Video 2, a scalable and computationally efficient model that connects pretrained multimodal large-language models (MLLMs) with video diffusion models for unified video generation and editing. Our key idea is to exploit the understanding and reasoning capabilities of MLLMs to produce explicit target captions to interpret user instructions. In this way, the rich contextual representations from the understanding model are directly used to guide the generative process, thereby improving performance on complex and compositional editing. Moreover, a lightweight adapter is developed to inject multimodal conditional tokens into pretrained text-to-video diffusion models, allowing maximum reuse of their powerful generative priors in a parameter-efficient manner. Benefiting from these designs, we scale up Omni-Video 2 to a 14B video diffusion model on meticulously curated training data with quality, supporting high quality text-to-video generation and various video editing tasks such as object removal, addition, background change, complex motion editing, \emph{etc.} We evaluate the performance of Omni-Video 2 on the FiVE benchmark for fine-grained video editing and the VBench benchmark for text-to-video generation. The results demonstrate its superior ability to follow complex compositional instructions in video editing, while also achieving competitive or superior quality in video generation tasks.

</details>


### [148] [Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications](https://arxiv.org/abs/2602.08822)
*Yao Pu,Yiming Shi,Zhenxi Zhang,Peixin Yu,Yitao Zhuang,Xiang Wang,Hongzhao Chen,Jing Cai,Ge Ren*

Main category: cs.CV

TL;DR: 开发了一个统一的基础模型，通过对比视觉表示学习和视觉语言对齐，实现任意到所有MRI序列合成，提升鼻咽癌放疗规划准确性。


<details>
  <summary>Details</summary>
Motivation: 临床实践中，由于患者不适、扫描时间长和成本高等限制，鼻咽癌放疗常面临MRI模态不完整的问题，影响放疗规划准确性。传统MRI合成方法存在模态特异性、解剖适应性有限和缺乏临床可解释性等局限。

Method: 开发了一个统一的基础模型，整合对比视觉表示学习和视觉语言对齐。使用对比编码器获取模态不变表示，基于CLIP的文本信息解码器实现语义一致的合成，支持通过单一模型实现任意到所有MRI序列合成。

Result: 在13个机构的40,825张图像上训练，在26个内部/外部验证站点（15,748张图像）上获得一致高性能（平均SSIM 0.90，PSNR 27），合成保真度高，对噪声和域偏移具有鲁棒性。统一表示还增强了放疗相关下游任务（如分割）的性能。

Conclusion: 该工作通过利用基础模型桥接技术合成和临床实用性，推进了鼻咽癌护理的数字医学解决方案，为临床实践提供了更完整、准确的MRI信息支持。

Abstract: Magnetic resonance imaging (MRI) is essential for nasopharyngeal carcinoma (NPC) radiotherapy (RT), but practical constraints, such as patient discomfort, long scan times, and high costs often lead to incomplete modalities in clinical practice, compromising RT planning accuracy. Traditional MRI synthesis methods are modality-specific, limited in anatomical adaptability, and lack clinical interpretability-failing to meet NPC's RT needs. Here, we developed a unified foundation model integrating contrastive visual representation learning and vision-language alignment (VLA) to enable any-to-all MRI synthesis. The model uses a contrastive encoder for modality-invariant representations and a CLIP-based text-informed decoder for semantically consistent synthesis, supporting any-to-all MRI synthesis via one unified foundation model. Trained on 40,825 images from 13 institutions, it achieves consistently high performance (average SSIM 0.90, PSNR 27) across 26 internal/external validation sites (15,748 images), with superior synthesis fidelity and robustness to noise and domain shifts. Meanwhile, its unified representation enhances downstream RT-relevant tasks (e.g., segmentation). This work advances digital medicine solutions for NPC care by leveraging foundation models to bridge technical synthesis and clinical utility.

</details>


### [149] [VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning](https://arxiv.org/abs/2602.08828)
*Hao Tan,Jun Lan,Senyuan Shi,Zichang Tan,Zijian Yu,Huijia Zhu,Weiqiang Wang,Jun Wan,Zhen Lei*

Main category: cs.CV

TL;DR: VideoVeritas框架通过联合偏好对齐和感知预文本强化学习，结合细粒度感知与事实推理，提升视频生成内容的检测能力，并在新数据集MintVid上验证了其平衡性能。


<details>
  <summary>Details</summary>
Motivation: 视频生成能力的不断增强带来了日益增长的安全风险，需要可靠的检测方法。当前多模态大语言模型虽然推理能力强，但细粒度感知能力有限，需要改进。

Method: 提出VideoVeritas框架，集成细粒度感知和基于事实的推理。引入联合偏好对齐和感知预文本强化学习(PPRL)，通过通用时空定位和自监督物体计数等感知预文本任务增强检测性能。创建MintVid数据集，包含9个最先进生成器的3K视频和具有事实错误的内容。

Result: 实验结果表明，现有方法倾向于偏向表面推理或机械分析，而VideoVeritas在多样化基准测试中实现了更平衡的性能表现。

Conclusion: VideoVeritas框架通过结合细粒度感知和事实推理，有效提升了视频生成内容的检测能力，为解决视频生成安全风险提供了有效解决方案。

Abstract: The growing capability of video generation poses escalating security risks, making reliable detection increasingly essential. In this paper, we introduce VideoVeritas, a framework that integrates fine-grained perception and fact-based reasoning. We observe that while current multi-modal large language models (MLLMs) exhibit strong reasoning capacity, their granular perception ability remains limited. To mitigate this, we introduce Joint Preference Alignment and Perception Pretext Reinforcement Learning (PPRL). Specifically, rather than directly optimizing for detection task, we adopt general spatiotemporal grounding and self-supervised object counting in the RL stage, enhancing detection performance with simple perception pretext tasks. To facilitate robust evaluation, we further introduce MintVid, a light yet high-quality dataset containing 3K videos from 9 state-of-the-art generators, along with a real-world collected subset that has factual errors in content. Experimental results demonstrate that existing methods tend to bias towards either superficial reasoning or mechanical analysis, while VideoVeritas achieves more balanced performance across diverse benchmarks.

</details>


### [150] [TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models](https://arxiv.org/abs/2602.08861)
*Xiangtian Zheng,Zishuo Wang,Yuxin Peng*

Main category: cs.CV

TL;DR: TiFRe是一个文本引导的视频帧缩减框架，通过智能选择关键帧并合并非关键帧信息来降低计算成本，同时保持视频语义完整性。


<details>
  <summary>Details</summary>
Motivation: 视频多模态大语言模型在处理大量视频帧时面临高计算成本问题，传统固定帧率的关键帧选择方法会丢失非关键帧的重要信息，导致性能下降。

Method: 提出文本引导的视频帧缩减框架，包含文本引导的帧采样策略（使用LLM生成CLIP风格提示，通过CLIP编码器计算语义相似度选择关键帧）和帧匹配与合并机制（将非关键帧信息整合到关键帧中）。

Result: 实验表明TiFRe能有效降低计算成本，同时在视频语言任务上提升性能。

Conclusion: TiFRe通过智能帧选择和语义保留机制，解决了视频MLLMs计算成本高的问题，在减少输入帧数的同时保持了视频理解能力。

Abstract: With the rapid development of Large Language Models (LLMs), Video Multi-Modal Large Language Models (Video MLLMs) have achieved remarkable performance in video-language tasks such as video understanding and question answering. However, Video MLLMs face high computational costs, particularly in processing numerous video frames as input, which leads to significant attention computation overhead. A straightforward approach to reduce computational costs is to decrease the number of input video frames. However, simply selecting key frames at a fixed frame rate (FPS) often overlooks valuable information in non-key frames, resulting in notable performance degradation. To address this, we propose Text-guided Video Frame Reduction (TiFRe), a framework that reduces input frames while preserving essential video information. TiFRe uses a Text-guided Frame Sampling (TFS) strategy to select key frames based on user input, which is processed by an LLM to generate a CLIP-style prompt. Pre-trained CLIP encoders calculate the semantic similarity between the prompt and each frame, selecting the most relevant frames as key frames. To preserve video semantics, TiFRe employs a Frame Matching and Merging (FMM) mechanism, which integrates non-key frame information into the selected key frames, minimizing information loss. Experiments show that TiFRe effectively reduces computational costs while improving performance on video-language tasks.

</details>


### [151] [Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit](https://arxiv.org/abs/2602.08909)
*Zhendong Wang,Cihan Ruan,Jingchuan Xiao,Chuqing Shi,Wei Jiang,Wei Wang,Wenjie Liu,Nam Ling*

Main category: cs.CV

TL;DR: 论文分析了3D高斯泼溅（3DGS）标准多视图优化中出现的结构模式，称为渲染最优参考（RORs），揭示了其统计特性，并通过可学习性探针发现密度分层现象：密集区域参数可预测，稀疏区域需要多视图约束。


<details>
  <summary>Details</summary>
Motivation: 研究3D高斯泼溅（3DGS）在多视图优化中形成的结构模式，理解这些渲染最优参考（RORs）的统计特性，探究决定这些参数的因素，为改进训练鲁棒性和系统架构提供理论基础。

Method: 1) 分析3DGS标准多视图优化产生的RORs统计特性；2) 使用可学习性探针训练预测器从点云重建RORs；3) 通过方差分解分析密度分层现象；4) 提出密度感知策略改进训练鲁棒性。

Result: 发现RORs具有稳定的统计模式：混合结构的尺度和双峰辐射分布；揭示密度分层现象：密集区域参数与几何相关可预测，稀疏区域参数受可见性异质性影响需要多视图约束；通过方差分解证明稀疏区域几何与外观参数存在协方差主导的耦合。

Conclusion: RORs具有双重特性：在密集区域表现为几何基元（点云足够预测），在稀疏区域表现为视图合成基元（需要多视图约束）；这为自适应平衡前馈预测和渲染优化的系统架构提供了理论基础。

Abstract: We investigate what structure emerges in 3D Gaussian Splatting (3DGS) solutions from standard multi-view optimization. We term these Rendering-Optimal References (RORs) and analyze their statistical properties, revealing stable patterns: mixture-structured scales and bimodal radiance across diverse scenes. To understand what determines these parameters, we apply learnability probes by training predictors to reconstruct RORs from point clouds without rendering supervision. Our analysis uncovers fundamental density-stratification. Dense regions exhibit geometry-correlated parameters amenable to render-free prediction, while sparse regions show systematic failure across architectures. We formalize this through variance decomposition, demonstrating that visibility heterogeneity creates covariance-dominated coupling between geometric and appearance parameters in sparse regions. This reveals the dual character of RORs: geometric primitives where point clouds suffice, and view synthesis primitives where multi-view constraints are essential. We provide density-aware strategies that improve training robustness and discuss architectural implications for systems that adaptively balance feed-forward prediction and rendering-based refinement.

</details>


### [152] [Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields](https://arxiv.org/abs/2602.08958)
*Weihan Luo,Lily Goli,Sherwin Bahmani,Felix Taubner,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 提出了一种用于植物生长建模的3D高斯流场表示方法，通过反向生长过程初始化高斯基元，实现了连续时间的非线性生长动态建模。


<details>
  <summary>Details</summary>
Motivation: 植物生长建模面临独特挑战：植物会随时间产生新几何结构，而现有动态场景建模方法（如变形场、4D高斯溅射）无法处理这种几何生成问题，需要专门针对植物生长特性的新表示方法。

Method: 引入3D高斯流场表示，将植物生长建模为高斯参数（位置、尺度、方向、颜色、不透明度）随时间变化的导数；通过重建成熟植物并学习反向生长过程来初始化足够的高斯基元。

Result: 在植物生长的多视角时序数据集上，该方法相比先前方法获得了更优的图像质量和几何精度，为生长中的3D结构外观建模提供了新方法。

Conclusion: 提出的3D高斯流场表示能够有效建模植物生长过程中的非线性连续时间动态，解决了现有方法无法处理几何生成的问题，为植物生长建模提供了新途径。

Abstract: Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures.

</details>


### [153] [MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE](https://arxiv.org/abs/2602.08961)
*Ruijie Zhu,Jiahao Lu,Wenbo Hu,Xiaoguang Han,Jianfei Cai,Ying Shan,Chuanxia Zheng*

Main category: cs.CV

TL;DR: MotionCrafter是一个基于视频扩散的框架，能够从单目视频中联合重建4D几何并估计密集运动，通过新的联合表示和4D VAE实现，无需后优化即可达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法强制3D值和潜在变量与RGB VAE潜在变量严格对齐，尽管它们的分布根本不同，这导致次优性能。需要一种更好的方法来从单目视频中联合重建4D几何和估计密集运动。

Method: 提出了一种新颖的联合表示方法，将密集3D点图和3D场景流在共享坐标系中表示，并设计了新的4D VAE来有效学习这种表示。引入了新的数据归一化和VAE训练策略，更好地传递扩散先验，无需强制与RGB VAE潜在变量对齐。

Result: 在多个数据集上的广泛实验表明，MotionCrafter在几何重建和密集场景流估计方面都达到了最先进的性能，几何重建提升38.64%，运动重建提升25.0%，且无需任何后优化。

Conclusion: MotionCrafter通过创新的联合表示和4D VAE设计，成功解决了从单目视频中联合重建4D几何和估计密集运动的问题，证明了强制与RGB VAE潜在变量对齐是不必要的，并显著提升了重建质量。

Abstract: We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page

</details>


### [154] [WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models](https://arxiv.org/abs/2602.08971)
*Yu Shang,Zhuohang Li,Yiding Ma,Weikang Su,Xin Jin,Ziyou Wang,Xin Zhang,Yinzhou Tang,Chen Gao,Wei Wu,Xihui Liu,Dhruv Shah,Zhaoxiang Zhang,Zhibo Chen,Jun Zhu,Yonghong Tian,Tat-Seng Chua,Wenwu Zhu,Yong Li*

Main category: cs.CV

TL;DR: WorldArena是一个统一的基准测试，用于系统评估具身世界模型在感知和功能两个维度上的表现，揭示了感知质量与功能效用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前对具身世界模型的评估主要关注感知保真度（如视频生成质量），而忽视了这些模型在下游决策任务中的功能效用。这种碎片化的评估方式无法全面衡量世界模型的实际价值。

Method: 提出了WorldArena基准测试，通过三个维度评估模型：1）视频感知质量（使用16个指标在六个子维度上测量）；2）具身任务功能（评估世界模型作为数据引擎、策略评估器和动作规划器，并结合主观人类评估）；3）EWMScore综合指标，将多维性能整合为单一可解释指数。

Result: 通过对14个代表性模型的广泛实验，揭示了显著的感知-功能差距，表明高视觉质量并不一定转化为强大的具身任务能力。

Conclusion: WorldArena基准测试为追踪具身AI中真正功能性世界模型的进展提供了一个框架，有助于推动该领域向更实用的方向发展。

Abstract: While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.

</details>


### [155] [ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation](https://arxiv.org/abs/2602.09014)
*Zihan Yang,Shuyuan Tu,Licheng Zhang,Qi Dai,Yu-Gang Jiang,Zuxuan Wu*

Main category: cs.CV

TL;DR: ArcFlow提出了一种非线性轨迹蒸馏框架，通过参数化连续动量过程来逼近教师模型的推理轨迹，实现仅需2步推理就能达到40倍加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成质量优秀，但需要大量顺序去噪步骤导致推理成本高昂。现有蒸馏方法使用线性捷径逼近教师轨迹，难以匹配随时间步变化的切线方向，导致质量下降。

Method: ArcFlow将推理轨迹的底层速度场参数化为连续动量过程的混合，能够捕捉速度演化并外推连贯速度形成连续非线性轨迹。该参数化允许对非线性轨迹进行解析积分，避免数值离散误差。通过轻量级适配器在预训练教师模型上进行轨迹蒸馏训练。

Result: 在Qwen-Image-20B和FLUX.1-dev等大规模模型上，ArcFlow仅微调不到5%的原始参数，使用2步推理就实现了40倍加速，且没有显著的质量下降。基准测试在定性和定量上都验证了有效性。

Conclusion: ArcFlow通过非线性轨迹蒸馏成功解决了扩散模型推理加速问题，在保持生成质量的同时大幅减少推理步骤，为高效扩散模型部署提供了有效解决方案。

Abstract: Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.

</details>


### [156] [Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction](https://arxiv.org/abs/2602.09016)
*Hao Phung,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: Raster2Seq：将栅格化平面图重建为序列到序列任务，通过自回归解码器预测多边形角点，实现复杂平面图的结构和语义重建


<details>
  <summary>Details</summary>
Motivation: 现有技术在重建复杂平面图时难以准确生成结构和语义信息，特别是处理包含大量房间和不同多边形角点数量的室内空间平面图

Method: 将平面图重建定义为序列到序列任务，将房间、门窗等元素表示为带标签的多边形序列；引入自回归解码器，基于图像特征和已生成角点预测下一个角点；使用可学习锚点引导注意力机制聚焦信息丰富的图像区域

Result: 在Structure3D、CubiCasa5K和Raster2Graph等标准基准测试中达到最先进性能，在包含多样化房间结构和复杂几何变化的WAFFLE数据集上也表现出强大的泛化能力

Conclusion: Raster2Seq通过自回归序列建模方法，能够灵活处理复杂平面图，有效重建几何结构和语义信息，为自动化理解和CAD工作流程提供了更好的基础

Abstract: Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations.

</details>


### [157] [WorldCompass: Reinforcement Learning for Long-Horizon World Models](https://arxiv.org/abs/2602.09022)
*Zehan Wang,Tengfei Wang,Haiyu Zhang,Xuhui Zuo,Junta Wu,Haoyuan Wang,Wenqiang Sun,Zhenwei Wang,Chenjie Cao,Hengshuang Zhao,Chunchao Guo,Zhou Zhao*

Main category: cs.CV

TL;DR: WorldCompass是一个用于长时程交互式视频世界模型的强化学习后训练框架，通过创新的剪辑级策略、互补奖励函数和高效RL算法，显著提升模型探索准确性和视觉质量


<details>
  <summary>Details</summary>
Motivation: 现有的长时程交互式视频世界模型在探索世界时缺乏准确性和一致性，需要一种有效的后训练框架来基于交互信号引导模型更准确地探索世界

Method: 提出了三个核心创新：1)剪辑级策略：在单个目标剪辑生成和评估多个样本，提高效率并提供细粒度奖励信号；2)互补奖励函数：设计交互跟随准确性和视觉质量的奖励函数，抑制奖励黑客行为；3)高效RL算法：采用负感知微调策略结合多种效率优化

Result: 在SoTA开源世界模型WorldPlay上的评估表明，WorldCompass在各种场景下显著提高了交互准确性和视觉保真度

Conclusion: WorldCompass是一个有效的RL后训练框架，能够显著提升长时程交互式视频世界模型的探索准确性和视觉质量，为视频生成世界模型提供了新的强化学习优化方法

Abstract: This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively "steer" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.

</details>


### [158] [Autoregressive Image Generation with Masked Bit Modeling](https://arxiv.org/abs/2602.09024)
*Qihang Yu,Qihao Liu,Ju He,Xinyang Zhang,Yang Liu,Liang-Chieh Chen,Xi Chen*

Main category: cs.CV

TL;DR: 本文挑战了视觉生成中连续管道的统治地位，通过研究发现离散与连续方法的性能差距主要源于潜在空间的比特分配，提出通过扩大码本规模来弥合差距，并设计了BAR框架实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 挑战视觉生成领域连续管道的主导地位，系统研究离散与连续方法的性能差距，揭示离散标记器并非本质劣于连续方法，而是受限于潜在空间的比特分配。

Method: 提出掩码比特自回归建模(BAR)框架，通过为自回归变换器配备掩码比特建模头，支持任意码本规模，通过逐步生成比特来预测离散标记。

Result: BAR在ImageNet-256上实现了0.99的gFID新SOTA，超越了连续和离散范式的领先方法，同时显著降低了采样成本，收敛速度比之前的连续方法更快。

Conclusion: 离散标记器在视觉生成中具有与连续方法相当甚至更优的潜力，关键在于潜在空间的比特分配；BAR框架成功实现了这一潜力，为视觉生成提供了更高效的新范式。

Abstract: This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [159] [Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models](https://arxiv.org/abs/2602.06973)
*Lucky Susanto,Musa Izzanardi Wijanarko,Khumaisa Nur'aini,Farid Adilazuarda,Alham Fikri Aji,Derry Tanti Wijaya*

Main category: cs.CL

TL;DR: 像素语言建模旨在通过将文本渲染为图像来绕过子词分词瓶颈，但DualGPT等多模态变体重新引入文本分词器以提升自回归性能。研究发现，即使有视觉渲染，重新集成文本分词器仍会重新引入分词器对齐问题，特别是在印尼低资源本地语言中。


<details>
  <summary>Details</summary>
Motivation: 研究像素语言建模是否真正解除了模型对分词器的依赖，特别是在多模态变体如DualGPT重新引入文本分词器的情况下。关注印尼四种使用非拉丁文字的低资源本地语言（爪哇语、巴厘语、巽他语、楠榜语），评估脚本-分词器对齐对模型性能的影响。

Method: 在DualGPT架构中评估脚本-分词器对齐问题。使用四种印尼低资源本地语言（爪哇语、巴厘语、巽他语、楠榜语），比较Llama 2分词器与自定义分词器的性能差异。通过OOV（词汇外）率、生育率（fertility rates）和chrF++指标进行评估。

Result: 尽管视觉渲染，重新集成文本分词器仍会重新引入分词器对齐问题。Llama 2分词器虽然具有较低的OOV和生育率，但性能显著差于自定义分词器，chrF++指标提升高达30.15。这表明文本分词器仍然是实现公平模型的重要障碍。

Conclusion: 像素语言建模的多模态变体重新引入文本分词器会重新引入原本试图解决的问题。文本分词器对齐问题仍然是模型性能的关键瓶颈，特别是在处理低资源、非拉丁文字语言时。这对未来多模态变体设计提出了警告。

Abstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.

</details>


### [160] [Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks](https://arxiv.org/abs/2602.06976)
*Chen Shen,Wei Cheng,Jingyue Yang,Huan Zhang,Yuhan Wu,Wei Hu*

Main category: cs.CL

TL;DR: ILA-agent框架让大语言模型通过有限外部资源动态交互学习新编程语言，显著优于检索增强基线方法


<details>
  <summary>Details</summary>
Motivation: 大语言模型在编程任务中的能力依赖于大量预训练数据，但在面对不熟悉的编程语言时表现会急剧下降。传统的数据密集型微调方法成本高，因此需要研究推理时语言获取的新范式

Method: 提出ILA-agent框架，将人类关键行为建模为一组工具，使LLM能够通过结构化交互（访问官方文档和执行环境）来增量探索、应用和验证语言知识

Result: 在Cangjie-bench多任务基准测试中，ILA-agent在代码生成、翻译和程序修复任务上显著优于检索增强基线方法。轨迹分析揭示了涌现的行为模式，同时指出了持续存在的性能差距

Conclusion: ILA-agent为LLM学习新编程语言提供了一种有效的推理时获取范式，通过结构化交互和工具化行为建模，在低资源设置下实现了显著性能提升

Abstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.

</details>


### [161] [Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model](https://arxiv.org/abs/2602.07120)
*Jacqueline He,Jonathan Hayase,Wen-tau Yih,Sewoong Oh,Luke Zettlemoyer,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出Anchored Decoding方法，通过推理时约束生成文本与安全模型的接近度，抑制语言模型的逐字复制行为，平衡版权风险与模型效用。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型倾向于记忆训练数据并逐字输出，当数据涉及敏感或版权保护内容时，这引发了创作者同意与补偿问题以及开发者的合规风险。

Method: 提出Anchored Decoding方法：1）在推理时通过约束生成文本与许可训练的安全模型保持有限接近度；2）自适应分配用户选择的信息预算；3）引入字节级变体Anchored$_{\mathrm{Byte}}$ Decoding实现跨词汇融合；4）提供新的安全模型TinyComma 1.8B。

Result: 在六个模型对的长形式评估中，Anchored和Anchored$_{\mathrm{Byte}}$ Decoding定义了新的帕累托前沿：保持接近原始流畅性和事实性，同时消除高达75%的可测量复制差距（平均六个复制指标），推理开销适中。

Conclusion: Anchored Decoding是一种即插即用的推理时方法，能够有效抑制语言模型的逐字复制行为，在版权风险与模型效用之间实现可调平衡，为混合许可数据训练的语言模型提供实用的合规解决方案。

Abstract: Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.

</details>


### [162] [Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI](https://arxiv.org/abs/2602.07176)
*Mohamed El Hajji,Tarek Ait Baha,Aicha Dakir,Hammou Fadili,Youssef Es-Saady*

Main category: cs.CL

TL;DR: Open TutorAI是一个基于大语言模型和生成技术的开源教育平台，通过动态个性化辅导、3D虚拟化身集成和学习分析，提供自适应、沉浸式的学习体验。


<details>
  <summary>Details</summary>
Motivation: 现有教育聊天机器人系统缺乏上下文适应性、实时响应性和教学灵活性，限制了学习参与度和教学效果。需要开放、集成的平台结合AI和沉浸式技术来支持个性化、有意义的学习体验。

Method: 基于LLMs和生成技术构建开源教育平台，集成自然语言处理与可定制3D虚拟化身实现多模态交互。通过结构化入门流程捕获学习者目标和偏好，配置个性化AI助手。平台包含内容组织、嵌入式反馈工具，以及面向学习者、教育者和家长的专用界面。

Result: 开发了Open TutorAI平台，将模块化架构、生成式AI和学习分析统一在开源框架中。通过助手生成管道和虚拟化身集成增强参与度和情感存在感，嵌入式学习分析支持自我调节学习，跟踪参与模式并生成可操作的反馈。

Conclusion: Open TutorAI为下一代智能辅导系统的发展做出贡献，通过结合生成式AI、沉浸式技术和学习分析，创建了更加人性化、沉浸式的学习环境，支持个性化自适应学习。

Abstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.

</details>


### [163] [Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs](https://arxiv.org/abs/2602.07181)
*Tianyu Zhao,Siqi Li,Yasser Shoukry,Salma Elmalaki*

Main category: cs.CL

TL;DR: 论文提出PACIFIC框架，通过人格特质作为潜在信号来筛选用户偏好，显著提升个性化问答准确性（从29.25%提升至76%），并创建了包含1200条偏好陈述的人格标注数据集。


<details>
  <summary>Details</summary>
Motivation: 当前个性化LLM响应主要依赖用户偏好，但偏好信号可能存在噪声、不完整甚至误导性，直接应用会降低回答质量。研究发现稳定的人格特质是偏好背后的潜在信号，因此探索如何利用人格特质来可靠地利用偏好信号。

Method: 1）通过实验验证人格对齐偏好对个性化问答的改进效果；2）创建PACIFIC数据集，包含1200条跨领域偏好陈述，标注了Big-Five（OCEAN）人格特质方向；3）提出框架使LLM能自动检索人格对齐偏好并在答案生成中整合。

Result: 实验表明，选择与用户推断人格一致的偏好能显著提升答案选择准确性：从使用随机选择偏好的29.25%提升至76%。创建了人格标注的偏好数据集，并提出了有效的偏好整合框架。

Conclusion: 人格特质可作为可靠筛选用户偏好的潜在信号，人格对齐偏好能显著改善个性化问答质量。PACIFIC数据集和提出的框架为基于偏好的个性化LLM响应提供了更稳健的方法。

Abstract: User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.

</details>


### [164] [Long-Context Long-Form Question Answering for Legal Domain](https://arxiv.org/abs/2602.07190)
*Anagha Kulkarni,Parin Rajesh Jhaveri,Prasha Shrestha,Yu Tong Han,Reza Amini,Behrouz Madahian*

Main category: cs.CL

TL;DR: 本文提出了一种针对法律文档的长上下文问答系统，能够处理复杂文档布局、专业词汇，并生成全面的长格式答案。


<details>
  <summary>Details</summary>
Motivation: 法律文档具有复杂的文档布局（多级嵌套章节、冗长脚注）和特殊的语言特征（复杂句法、领域特定词汇），这使得问答任务具有挑战性，特别是当答案需要跨越多页（长上下文）且要求全面性（长格式答案）时。

Method: 提出一个问答系统，能够：(a) 解构领域特定词汇以改进从源文档的检索；(b) 解析复杂文档布局，同时隔离章节和脚注并适当链接它们；(c) 使用精确的领域特定词汇生成全面答案。还引入了一个覆盖率指标，将性能分类为基于召回的覆盖类别，便于人工评估召回率。

Result: 通过利用法律和公司税务等领域专业人士的专业知识，策划了一个QA数据集。通过全面的实验和消融研究，证明了所提出系统的可用性和优点。

Conclusion: 该系统有效解决了法律文档长上下文问答的挑战，特别是在需要全面长格式答案的场景下，通过专业词汇处理、复杂布局解析和全面的答案生成，为法律文档问答提供了实用解决方案。

Abstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.

</details>


### [165] [Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities](https://arxiv.org/abs/2602.07211)
*Ju Lin,Jing Pan,Ruizhi Li,Ming Sun,Yuzong Liu,Alaa Hassan,Jing Zheng,Florian Metze*

Main category: cs.CL

TL;DR: 该研究探索如何让大语言模型具备定向多说话者语音理解能力，特别是在智能眼镜应用场景中，提出了级联系统和端到端系统两种方法。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型主要基于单通道、单说话者数据训练，难以直接应用于多说话者和多通道的语音理解任务，特别是在智能眼镜等需要定向语音理解的实际应用场景中。

Method: 提出了两种新颖方法：1）级联系统，利用源分离前端模块；2）端到端系统，采用序列化输出训练。两种方法都利用智能眼镜中的多麦克风阵列，以流式方式优化定向解释和处理。

Result: 实验结果表明，所提方法能有效赋予大语言模型定向语音理解能力，在语音识别和语音翻译任务中都取得了强劲性能。

Conclusion: 该研究成功实现了让大语言模型具备定向多说话者语音理解能力，为智能眼镜等实际应用场景提供了有效的解决方案。

Abstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.

</details>


### [166] [Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice](https://arxiv.org/abs/2602.07319)
*Savan Doshi*

Main category: cs.CL

TL;DR: 提出风险敏感的幻觉评估框架，通过风险性语言量化医疗问答中的幻觉风险，而非仅关注事实正确性


<details>
  <summary>Details</summary>
Motivation: 现有幻觉评估标准主要关注事实正确性，将所有错误视为同等严重，这掩盖了临床相关的失败模式，特别是当模型生成无支持但可操作的医疗语言时

Method: 提出风险敏感评估框架，通过检测风险性语言（治疗指令、禁忌症、紧急提示、高风险药物提及）来量化幻觉，结合风险评分与相关性度量识别高风险、低基础性失败

Result: 应用该框架对三个指令调优语言模型进行测试，结果显示具有相似表面行为的模型表现出显著不同的风险特征，标准评估指标无法捕捉这些差异

Conclusion: 将风险敏感性纳入幻觉评估至关重要，评估有效性严重依赖于任务和提示设计

Abstract: Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.

</details>


### [167] [Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation](https://arxiv.org/abs/2602.07338)
*Geng Liu,Fei Zhu,Rong Feng,Changyi Ma,Shiqi Wang,Gaofeng Meng*

Main category: cs.CL

TL;DR: 论文提出"对话迷失"现象的根本原因不是模型能力缺陷，而是用户意图与模型理解之间的对齐差距，并提出了基于经验驱动调解器的解决方案。


<details>
  <summary>Details</summary>
Motivation: 多轮对话已成为LLMs的主要交互范式，但研究发现LLMs在多轮对话中的表现显著低于单轮完整指令，这种现象被称为"对话迷失"。现有研究将其归因于模型不可靠性，但本文认为根本原因在于意图对齐差距而非内在能力缺陷。

Method: 提出调解器-助手架构，通过经验驱动的调解器将模糊的用户输入转化为明确、结构化的指令。调解器基于历史交互模式来理解用户意图，将意图理解与任务执行解耦，从而弥合用户意图与模型解释之间的差距。

Result: 实验结果表明，该方法能显著减轻多种LLMs在多轮对话中的性能下降问题，验证了调解器-助手架构的有效性。

Conclusion: "对话迷失"现象源于交互过程中的意图对齐差距而非模型能力限制。通过调解器架构将意图理解与任务执行解耦，可以有效解决多轮对话中的性能下降问题，这为改进LLMs的对话交互提供了新的方向。

Abstract: Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.

</details>


### [168] [ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations](https://arxiv.org/abs/2602.07361)
*Long S. T. Nguyen,Quan M. Bui,Tin T. Ngo,Quynh T. N. Vo,Dung N. H. Le,Tho T. Quan*

Main category: cs.CL

TL;DR: 本文介绍了ViHERMES数据集，这是一个专门用于越南语医疗法规多跳问答的基准数据集，旨在解决医疗法规问答中跨文档推理的挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗法规文档具有层级结构和频繁修订的特点，需要进行多跳推理，但现有方法在低资源语言（如越南语）中缺乏系统评估，缺少明确支持医疗法规多跳推理的基准数据集。

Method: 提出了基于语义聚类和图启发数据挖掘的受控多跳问答生成流程，使用大语言模型生成带有结构化证据和推理标注的问题-答案对。同时提出了图感知检索框架，在法规单元层面建模正式法律关系，支持原则性的上下文扩展。

Result: ViHERMES为评估多跳法规问答系统提供了具有挑战性的基准，提出的图感知方法在实验中一致优于强检索基线方法。

Conclusion: ViHERMES填补了越南语医疗法规多跳推理基准数据集的空白，提出的图感知检索框架能有效支持法规文档的多跳问答任务，相关数据集和系统实现已公开提供。

Abstract: Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.

</details>


### [169] [TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling](https://arxiv.org/abs/2602.07374)
*Nisharg Nargund,Priyesh Shukla*

Main category: cs.CL

TL;DR: TernaryLM是一种132M参数的Transformer模型，采用原生1位三元量化{-1, 0, +1}训练，显著减少内存占用而不牺牲语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要大量计算资源，限制了在边缘设备和资源受限环境中的部署。需要开发更高效的模型来降低内存需求。

Method: 采用原生1位三元量化{-1, 0, +1}训练，使用直通估计器和自适应逐层缩放因子从头学习量化感知表示，而不是对预训练模型进行后训练量化。

Result: 1) TinyStories验证困惑度58.42；2) MRPC复述检测F1分数82.47%；3) 内存减少2.4倍(498MB vs 1197MB)，推理延迟相当；4) 在不同语料库上训练稳定；5) 中间Transformer层与极端量化兼容性最高。

Conclusion: 原生1位训练是高效神经语言模型的有前景方向，为未来非均匀精度策略提供指导。

Abstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.

</details>


### [170] [Efficient Post-Training Pruning of Large Language Models with Statistical Correction](https://arxiv.org/abs/2602.07375)
*Peiqi Yu,Jinhao Wang,Xinyi Sui,Nam Ling,Wei Wang,Wei Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种基于一阶统计特性的轻量级后训练剪枝框架，通过统计校准和能量补偿来提升LLM剪枝质量，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有后训练剪枝方法在剪枝质量和计算效率之间存在权衡：启发式方法效率高但对激活异常值敏感，重构方法保真度好但计算成本高。

Method: 提出基于模型权重和激活一阶统计特性的轻量级框架：1) 剪枝时使用通道级统计校准基于幅值的重要性分数，减少激活主导通道的偏差；2) 剪枝后应用解析能量补偿来纠正权重移除引起的分布失真。整个过程无需重训练、梯度或二阶信息。

Result: 在多个LLM家族、稀疏模式和评估任务上的实验表明，该方法提升了剪枝性能，同时保持了与启发式方法相当的计算成本。

Conclusion: 简单的统计校正对于LLM的后训练剪枝是有效的，能够在保持计算效率的同时提升剪枝质量。

Abstract: Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.

</details>


### [171] [Do Large Language Models Reflect Demographic Pluralism in Safety?](https://arxiv.org/abs/2602.07376)
*Usman Naseem,Gautam Siddharth Kashyap,Sushant Kumar Ray,Rafiq Ali,Ebad Shabbir,Abdullah Mohammad*

Main category: cs.CL

TL;DR: Demo-SafetyBench是一个解决LLM安全评估中人口统计学多样性不足的数据集，通过重新分类DICES数据集到14个安全领域，并采用平衡阈值实现高可靠性和低人口统计学敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐数据集（如ANTHROPIC-HH和DICES）使用人口统计学上狭窄的标注者群体，忽略了不同社区间安全感知的差异，无法反映安全评估的多元性。

Method: 采用两阶段方法：第一阶段将DICES提示重新分类到14个安全领域（基于BEAVERTAILS），保留人口统计学元数据，使用Mistral 7B-Instruct-v0.3和Llama-3.1-8B-Instruct进行扩展，通过SimHash去重得到43,050个样本；第二阶段使用LLMs-as-Raters（Gemma-7B、GPT-4o、LLaMA-2-7B）进行零样本推理评估，采用平衡阈值（delta=0.5，tau=10）。

Result: 实现了高可靠性（ICC=0.87）和低人口统计学敏感性（DS=0.12），证明多元安全评估可以同时具备可扩展性和人口统计学鲁棒性。

Conclusion: Demo-SafetyBench通过在提示层面直接建模人口统计学多元主义，将价值框架与响应解耦，为LLM安全评估提供了一个既考虑多元性又保持技术可行性的解决方案。

Abstract: Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.

</details>


### [172] [When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified](https://arxiv.org/abs/2602.07381)
*Gautam Siddharth Kashyap,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: AlignX是一个两阶段框架，通过提示注入微调和几何校准的MoE来解决大语言模型在多目标对齐中的轴崩溃问题，显著提升帮助性、无害性和诚实性，同时降低延迟和内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（SFT和MoE）在多目标设置中面临挑战：SFT导致冲突目标之间的干扰，MoE存在路由校准问题。这种失败模式被称为"轴崩溃"，表现为（1）特征空间分离导致灾难性遗忘，（2）专家误路由导致不可靠推理。

Method: AlignX采用两阶段框架：第一阶段使用提示注入微调提取轴特定任务特征，缓解灾难性遗忘；第二阶段部署MoCaE模块，利用分形和自然几何校准专家路由，提高推理可靠性。

Result: 在Alpaca（帮助性）、BeaverTails（无害性）和TruthfulQA（诚实性）上取得显著提升：胜率+171.5%，真实性-信息性+110.1%，安全违规减少4.3%。相比先前MoE方法，延迟和内存使用降低超过35%。在四个LLM上的结果验证了其泛化能力。

Conclusion: AlignX有效解决了大语言模型多目标对齐中的轴崩溃问题，通过特征提取和几何校准的路由机制，在保持模型性能的同时显著提升了效率，为安全部署提供了可行方案。

Abstract: Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.

</details>


### [173] [Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi](https://arxiv.org/abs/2602.07382)
*Debtanu Datta,Rajdeep Mukherjee,Adrijit Goswami,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 该研究提出了一种改进印度法律文本摘要的方法，通过注入领域知识到不同的摘要模型中，生成英语和印地语的法律判决摘要。


<details>
  <summary>Details</summary>
Motivation: 印度法律判决摘要面临复杂语言和非结构化文本的挑战，且大部分印度人口不理解法律文本使用的复杂英语，需要印度语言的摘要。

Method: 1. 提出框架增强抽取式神经摘要模型，通过融入针对法律文本的领域特定预训练编码器；2. 探索通过持续预训练在大型英语和印地语法律语料库上，将法律领域知识注入生成模型（包括大语言模型）。

Result: 提出的方法在英语到英语和英语到印地语的印度法律文档摘要中，在标准评估指标、事实一致性指标和法律领域特定指标上都取得了统计显著的改进，并通过领域专家验证了有效性。

Conclusion: 通过注入法律领域知识到摘要模型中，可以有效改进印度法律文本的跨语言摘要质量，特别是对于英语和印地语的法律文档摘要任务。

Abstract: Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.

</details>


### [174] [Measuring cross-language intelligibility between Romance languages with computational tools](https://arxiv.org/abs/2602.07447)
*Liviu P Dinu,Ana Sabina Uban,Bogdan Iordache,Anca Dinu,Simona Georgescu*

Main category: cs.CL

TL;DR: 该研究提出了一种基于词汇相似度的计算指标来评估罗曼语族语言间的相互可懂度，通过表面和语义相似性分析，验证了该指标与人类实验结果的显著相关性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种计算方法来量化相关语言间的相互可懂度，特别是针对罗曼语族语言，以验证计算指标与人类实际理解能力的一致性。

Method: 提出了一种基于词汇相似度的计算指标，结合表面相似性和语义相似性，使用正字形式和语音形式，并比较不同平行语料库和词向量表示模型。

Result: 计算得到的可懂度分数证实了语言间可懂度不对称的直觉，并且与人类完形填空测试结果显著相关，验证了该计算方法的有效性。

Conclusion: 基于词汇相似度的计算指标能够有效评估罗曼语族语言间的相互可懂度，为语言理解和语言教学提供了新的量化工具。

Abstract: We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.

</details>


### [175] [DLLM Agent: See Farther, Run Faster](https://arxiv.org/abs/2602.07451)
*Huiling Zhen,Weizhe Lin,Renxi Liu,Kai Han,Yiming Li,Yuchuan Tian,Hanting Chen,Xiaoguang Li,Xiaosong Li,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Youliang Yan,Peifeng Qin,Jun Wang,Yu Wang,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 扩散大语言模型在智能体决策中相比自回归模型能实现30%以上的端到端加速，减少交互轮次和工具调用，但需要更强的工具调用训练和注意力对齐


<details>
  <summary>Details</summary>
Motivation: 探索扩散大语言模型在智能体多步决策中的潜力，比较其与自回归模型在相同智能体框架和监督下的规划与工具使用行为差异，以及这些差异是否能转化为端到端效率提升

Method: 在相同智能体工作流（DeepDiver）中实例化扩散大语言模型和自回归模型骨干，使用相同的轨迹数据进行匹配的智能体导向微调，创建可直接比较的扩散智能体和自回归智能体

Result: 在准确率相当的情况下，扩散智能体端到端速度平均比自回归智能体快30%以上，某些情况下超过8倍加速；在正确完成任务时，扩散智能体需要更少的交互轮次和工具调用，表现出更高的规划命中率和更早收敛到正确行动路径

Conclusion: 扩散大语言模型在智能体决策中具有效率优势，但部署时需要注意两个实际问题：需要更强的工具调用特定训练以避免结构化工具调用失败，以及需要对齐注意力掩码以避免虚假的上下文-行动信息流；扩散智能体表现出更强的全局规划信号

Abstract: Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.

</details>


### [176] [SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning](https://arxiv.org/abs/2602.07464)
*Yijie Chen,Yijin Liu,Fandong Meng*

Main category: cs.CL

TL;DR: SED-SFT通过引入选择性熵正则化和掩码机制解决SFT中的模式崩溃问题，提升生成多样性，从而改善后续RL性能


<details>
  <summary>Details</summary>
Motivation: 传统的SFT使用交叉熵损失导致模式崩溃，模型过度集中在特定响应模式上，缺乏分布多样性，这严重限制了后续RL的探索效率。现有方法未能充分平衡多样性和准确性。

Method: 提出SED-SFT框架，基于标记探索空间自适应地鼓励多样性。在优化目标中引入带有选择性掩码机制的选择性熵正则化项。

Result: 在八个数学基准测试上的实验表明，SED-SFT显著提高了生成多样性，计算开销增加可忽略。相比标准CE基线，在Llama-3.2-3B-Instruct和Qwen2.5-Math-7B-Instruct上后续RL性能平均分别提升2.06和1.20个点。

Conclusion: SED-SFT有效解决了SFT中的模式崩溃问题，通过提升生成多样性改善了后续RL性能，为LLM后训练提供了更优的SFT方法。

Abstract: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT

</details>


### [177] [From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection](https://arxiv.org/abs/2602.07497)
*Mo Wang,Kaixuan Ren,Pratik Jalan,Ahmed Ashraf,Tuong Vy Vu,Rahul Seetharaman,Shah Nawaz,Usman Naseem*

Main category: cs.CL

TL;DR: 该研究提出了一个评估框架，用于诊断和量化视觉语言模型在多语言表情包数据集上的跨文化鲁棒性，发现翻译检测方法会降低性能，而文化对齐干预（本地语言提示和单样本学习）能显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 文化背景深刻影响人们对在线内容的理解，但当前的视觉语言模型主要基于西方或英语中心视角训练，这限制了它们在仇恨表情包检测等任务中的公平性和跨文化鲁棒性。

Method: 引入一个系统评估框架，通过三个维度分析最先进视觉语言模型的跨文化鲁棒性：(1) 学习策略（零样本 vs 单样本）；(2) 提示语言（本地语言 vs 英语）；(3) 翻译对意义和检测的影响。

Result: 结果显示常见的"先翻译再检测"方法会降低性能，而文化对齐干预（本地语言提示和单样本学习）能显著提升检测效果。研究发现模型系统性地趋向西方安全规范。

Conclusion: 研究揭示了视觉语言模型存在的系统性文化偏见，并提供了可操作的策略来减轻这种偏见，为设计全球鲁棒的多模态内容审核系统提供了指导。

Abstract: Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.

</details>


### [178] [Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification](https://arxiv.org/abs/2602.07499)
*Jingshen Zhang,Xin Ying Qiu,Lifang Lu,Zhuhua Huang,Yutao Hu,Yuechang Wu,JunYu Lu*

Main category: cs.CL

TL;DR: 该论文提出一个通过动态路径规划、语义感知示例选择和对话历史链式推理的框架，将复杂句子简化分解为可管理步骤，在五个语言的两个基准测试中提升简化效果并减少22-42%计算步骤。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在可控难度句子简化方面能力有限，特别是在跨越较大可读性水平进行简化时表现不佳，需要更有效的简化方法。

Method: 提出一个框架，通过动态路径规划将复杂简化分解为可管理步骤，结合语义感知的示例选择和基于对话历史的链式推理生成，实现连贯的推理过程。

Result: 在五个语言的两个基准测试中，该方法提高了简化效果，同时减少了22-42%的计算步骤。人类评估确认了简化效果与意义保留之间的基本权衡，并发现即使是人类标注者在语义保留判断上也难以达成一致。

Conclusion: 逐步简化方法确实能提高控制性，但在大规模简化过程中保持语义保真度仍然是一个开放挑战，这突显了该任务的内在复杂性。

Abstract: Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.

</details>


### [179] [Improving Variable-Length Generation in Diffusion Language Models via Length Regularization](https://arxiv.org/abs/2602.07546)
*Zicong Cheng,Ruixuan Jia,Jia Li,Guo-Wei Yang,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CL

TL;DR: LR-DLLM提出了一种长度正则化推理框架，解决了扩散大语言模型在变长生成中的长度偏差问题，通过显式长度正则化实现可靠的生成长度确定。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在变长生成中存在固有缺陷，因为其推理基于固定长度画布并隐含假设已知目标长度。当长度未知时（如实际补全和填充任务），在不同掩码长度间简单比较置信度会产生系统性偏差，导致生成不足或冗余延续。

Method: 提出LR-DLLM（长度正则化推理框架），将生成长度作为显式变量，通过显式长度正则化解耦语义兼容性和长度诱导的不确定性，修正有偏的置信度估计。该框架无需修改底层DLLM或其训练过程，即可实现生成跨度的动态扩展或收缩。

Result: 实验表明，LR-DLLM在完全未知长度的情况下，在HumanEvalInfilling上达到51.3% Pass@1（比DreamOn提升13.4%），在四语言McEval上平均达到51.5% Pass@1（比DreamOn提升14.3%）。

Conclusion: LR-DLLM有效解决了扩散大语言模型在变长生成中的长度偏差问题，通过长度正则化推理框架实现了可靠的生成长度确定，显著提升了填充和补全任务的性能。

Abstract: Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).

</details>


### [180] [Learning to Self-Verify Makes Language Models Better Reasoners](https://arxiv.org/abs/2602.07594)
*Yuxin Chen,Yu Wang,Yi Zhang,Ziang Ye,Zhengzhou Cai,Yaorui Shi,Qi Gu,Hui Su,Xunliang Cai,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: LLMs在生成推理路径方面表现优异，但在自我验证方面较弱，存在能力不对称性。研究发现自我验证训练能有效提升生成性能，而生成训练不能相应提升验证能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务中能生成有前景的推理路径，但在验证自身答案方面仍然薄弱，存在生成与自我验证之间的能力不对称问题。本研究旨在深入探究这种不对称性及其训练演化过程。

Method: 研究分析了训练演化过程中生成与验证能力的不对称性，发现自我验证学习能有效提升生成性能。基于此观察，提出了一个多任务强化学习框架，将生成和自我验证作为两个独立但互补的目标进行优化。

Result: 实验表明，即使在相同任务上，改进生成能力并不会相应提升自我验证能力。相反，学习自我验证能有效提高生成性能，达到与标准生成训练相当的准确率，同时产生更高效有效的推理轨迹。多任务强化学习框架在多个基准测试和模型上都显示出优于纯生成训练的性能提升。

Conclusion: 生成与自我验证之间存在显著的能力不对称性，自我验证训练对提升生成性能具有重要作用。通过多任务强化学习框架整合生成与验证目标，能同时提升模型的生成和验证能力，为LLM训练提供了新的有效方法。

Abstract: Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.

</details>


### [181] [Letting Tutor Personas "Speak Up" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization](https://arxiv.org/abs/2602.07639)
*Jaewook Lee,Alexander Scarlatos,Simon Woodhead,Andrew Lan*

Main category: cs.CL

TL;DR: 该研究探索如何利用人类导师-学生对话中的导师角色来指导大语言模型行为，通过修改双向偏好优化学习激活空间中的导向向量，使模型响应更符合特定导师风格，而无需显式提示指令。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的辅导系统通常学习单一导师策略，未能捕捉导师风格的多样性。现实中，导师会根据学生需求调整脚手架水平、指导方向性、反馈和情感支持等教学策略，这些差异会影响对话动态和学生参与度。

Method: 修改双向偏好优化方法，学习一个激活空间中的导向向量，该向量能够将模型响应引导向特定导师角色。这种方法直接从人类对话数据中提取信号，无需显式提示指令。

Result: 学习到的导向向量能够捕捉不同对话情境下的导师特定变化，提高与真实导师话语的语义对齐度，增加基于偏好的评估分数，同时基本保持词汇相似性。对学习到的方向系数分析揭示了跨导师的可解释结构，对应一致的辅导行为差异。

Conclusion: 激活导向提供了一种有效且可解释的方法，利用直接从人类对话数据中提取的信号来控制大语言模型中的导师特定变化。

Abstract: With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.

</details>


### [182] [Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation](https://arxiv.org/abs/2602.07673)
*Jiangnan Fang,Cheng-Tse Liu,Hanieh Deilamsalehy,Nesreen K. Ahmed,Puneet Mathur,Nedim Lipka,Franck Dernoncourt,Ryan A. Rossi*

Main category: cs.CL

TL;DR: LLM评估器在摘要任务中存在偏见：随着与人工摘要相似度降低，LLM评估器越来越偏好其他LLM生成的摘要而非人工摘要，且几乎所有测试模型都存在此模式。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM评估器在摘要任务中比传统算法指标更能捕捉语义信息、推理能力更强且对改写更鲁棒，但它们存在长度、顺序等偏见，且易受对抗性输入影响。现有研究很少在细粒度层面分析这些偏见与明确重叠度指标的关系。

Method: 在摘要领域，分析LLM评估器偏见与人工撰写回答重叠度的函数关系。测试9个近期LLM（参数从10亿到120亿），包括Gemma 3和LLaMA 3的变体，使用ROUGE和BLEU度量相似度。

Result: 发现随着被评估摘要之间相似度降低，LLM评估器越来越偏好其他LLM生成的摘要而非人工摘要，这一模式存在于除一个模型外的所有测试模型中，且不受模型自身位置偏见影响。此外，模型甚至难以评估重叠度有限的摘要。

Conclusion: 在摘要领域使用LLM作为评估器时，应依赖超越简单比较的技术，因为LLM评估器存在系统性偏见，难以准确评估与人工摘要相似度较低的摘要。

Abstract: Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.

</details>


### [183] [Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs](https://arxiv.org/abs/2602.07778)
*Shenglai Zeng,Tianqi Zheng,Chuan Tian,Dante Everaert,Yau-Shian Wang,Yupin Huang,Michael J. Morais,Rohit Patki,Jinjin Tian,Xinnan Dai,Kai Guo,Monica Xiao Cheng,Hui Liu*

Main category: cs.CL

TL;DR: Attn-GS：基于注意力引导的上下文压缩框架，利用LLM注意力模式识别重要个性化信号，在减少50倍token使用的同时保持接近完整上下文的性能


<details>
  <summary>Details</summary>
Motivation: 个性化大型语言模型需要整合大量用户交互历史和资料，但输入token限制导致推理延迟高、API成本高。现有启发式方法（如选择最近交互或使用摘要模型）将上下文视为整体，未能考虑LLM内部如何处理和优先处理不同资料组件

Method: 提出Attn-GS注意力引导上下文压缩框架：1）通过初步研究发现LLM注意力模式能自然揭示重要信号，微调能增强区分相关/无关信息的能力；2）利用标记模型的注意力反馈标记重要个性化句子；3）指导压缩模型生成任务相关、高质量的压缩用户上下文

Result: 在不同任务、token限制和设置下，Attn-GS显著优于各种基线方法，在减少50倍token使用的同时，性能接近使用完整上下文

Conclusion: LLM的注意力模式可以有效识别重要的个性化信号，用于智能上下文压缩。Attn-GS框架通过注意力引导的压缩，在保持性能的同时大幅降低token使用，为个性化LLM的实际应用提供了可行解决方案

Abstract: Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.

</details>


### [184] [Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models](https://arxiv.org/abs/2602.07794)
*Ningyu Xu,Qi Zhang,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: 研究发现大语言模型在上下文概念推理中会动态构建和使用结构化潜在表征，这些表征具有因果功能作用而非仅仅是伴随现象。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究发现大语言模型内部存在类似人类的结构化概念表征，但尚不清楚这些表征是否在推理过程中发挥功能性作用，还是仅仅是伴随现象。

Method: 通过分析大语言模型在上下文概念推理过程中的内部处理，识别概念子空间的出现位置和结构特征，并使用因果中介分析验证其功能性作用。

Result: 发现概念子空间在中后期层出现，其表征结构在不同上下文中保持稳定；因果分析证明该子空间对模型预测具有因果作用；观察到层间递进过程：早期到中期层的注意力头整合上下文线索构建和精炼子空间，后期层利用该子空间生成预测。

Conclusion: 大语言模型确实会动态构建和使用结构化的潜在表征进行上下文推理，这为理解模型灵活适应的计算过程提供了新见解。

Abstract: Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.

</details>


### [185] [LLMs Know More About Numbers than They Can Say](https://arxiv.org/abs/2602.07812)
*Fengting Yuchi,Li Du,Jason Eisner*

Main category: cs.CL

TL;DR: LLMs在混合表示的数字比较中表现不佳，但隐藏状态编码了数字大小信息，通过线性探测可提取数字大小和排序，且改进内部数值表示能提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管先进LLMs能解决数学问题，但研究发现它们在混合表示的数字比较中会出错（如"5.7×10² vs 580"），这引发了一个基本问题：LLMs是否真正理解这些数字的大小？

Method: 对多个开源LLMs的隐藏状态进行探测，使用线性投影提取数字的对数大小信息，构建线性分类器判断数字排序，并将分类器的对数损失作为辅助目标进行微调。

Result: 1) 适当隐藏层的线性投影能编码数字的对数大小，恢复数字的相对误差约2.3%（受限合成文本）或19.06%（科学论文）；2) 隐藏状态编码数字排序，线性分类器准确率超90%；3) 但LLMs直接回答排序时准确率仅50-70%；4) 将分类器损失作为辅助目标微调，比基础模型提升3.22%的准确率。

Conclusion: LLMs的隐藏状态确实编码了数字大小信息，但模型无法有效利用这些信息进行显式推理。通过改进内部数值表示可以增强模型的数值推理能力，这为提升LLMs的数学能力提供了新途径。

Abstract: Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: "Which is larger, $5.7 \times 10^2$ or $580$?" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.

</details>


### [186] [TodoEvolve: Learning to Architect Agent Planning Systems](https://arxiv.org/abs/2602.07839)
*Jiaxi Liu,Yanzuo Jiang,Guibin Zhang,Zihan Zhang,Heng Chang,Zhenfei Yin,Qibing Ren,Junchi Yan*

Main category: cs.CL

TL;DR: TodoEvolve是一个元规划范式，能自主合成并动态修订任务特定的规划架构，通过统一的PlanFactory设计空间和IGPO训练方法，在多个智能体基准测试中超越了手工设计的规划模块。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统主要依赖固定的手工规划结构，缺乏适应开放性问题结构多样性的灵活性，需要更自适应的规划能力。

Method: 1. 构建PlanFactory模块化设计空间，统一标准化不同规划范式；2. 收集高质量规划轨迹；3. 通过阻抗引导偏好优化(IGPO)训练Todo-14B模型，这是一个多目标强化学习目标，鼓励生成性能好、稳定且token高效的规划系统。

Result: 在五个智能体基准测试中，TodoEvolve始终超越精心设计的规划模块，同时保持经济的API成本和运行时开销。

Conclusion: TodoEvolve通过元规划范式成功解决了现有规划系统缺乏灵活性的问题，能够自主适应不同任务结构，为智能体系统提供了更强大的规划能力。

Abstract: Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.

</details>


### [187] [Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers](https://arxiv.org/abs/2602.07842)
*Yuhan Wang,Shiyu Ni,Zhikai Ding,Zihang Zhan,Yuanzi Li,Keping Bi*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型在多答案场景下的置信度校准问题，发现现有方法在多正确答案情况下会系统性地低估置信度，提出了新的基准MACE和解决方案SCA。


<details>
  <summary>Details</summary>
Motivation: 现有置信度校准方法主要针对单答案问答场景研究，但在存在多个有效答案的情况下会失效，因为正确答案之间的分歧会导致置信度被系统性低估。

Method: 1. 引入MACE基准，包含12,000个事实性问题，涵盖六个领域，具有不同数量的正确答案；2. 提出语义置信度聚合（SCA）方法，通过对多个高概率采样响应的置信度进行聚合来解决多答案校准问题。

Result: 实验涉及15种代表性校准方法和4个LLM家族（7B-72B），结果显示：虽然准确率随答案数量增加而提高，但估计的置信度却持续下降，导致混合答案数量问题的严重校准错误。SCA在混合答案设置下实现了最先进的校准性能，同时在单答案问题上保持了强校准能力。

Conclusion: 多答案场景对LLM置信度校准提出了新挑战，现有方法在此情况下会失效。提出的SCA方法能有效解决这一问题，在保持单答案校准性能的同时，显著提升多答案场景的校准效果。

Abstract: Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.

</details>


### [188] [SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization](https://arxiv.org/abs/2602.07909)
*Taolin Zhang,Hang Guo,Wang Lu,Tao Dai,Shu-Tao Xia,Jindong Wang*

Main category: cs.CL

TL;DR: SparseEval：一种基于稀疏优化的高效大语言模型评估方法，通过梯度下降优化锚点权重和迭代精化策略，显著降低评估成本


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模不断扩大，评估其性能的计算成本越来越高。传统的基准测试需要大量样本推理，计算开销巨大，因此需要开发高效的评估方法。

Method: 提出SparseEval方法：1) 将模型-项目性能矩阵视为稀疏矩阵；2) 选择代表性项目作为锚点；3) 将高效评估问题形式化为稀疏优化问题；4) 首次采用梯度下降优化锚点权重；5) 使用迭代精化策略进行锚点选择；6) 利用MLP的表征能力处理稀疏优化；7) 提出锚点重要性分数和候选重要性分数评估项目价值。

Result: 在多种基准测试上的广泛实验表明，该方法具有低估计误差和高Kendall's τ相关性，展示了其在真实场景中的优越鲁棒性和实用性。

Conclusion: SparseEval通过稀疏优化框架有效解决了大语言模型评估的高成本问题，为高效模型评估提供了实用解决方案，代码已开源。

Abstract: As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$τ$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.

</details>


### [189] [Patches of Nonlinearity: Instruction Vectors in Large Language Models](https://arxiv.org/abs/2602.07930)
*Irina Bigoulaeva,Jonas Rohweder,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文研究指令调优语言模型内部如何处理指令，发现指令表示相对局部化，称为指令向量(IVs)，它们表现出线性可分性与非线性因果交互并存的特点，挑战了机制可解释性中的线性表示假设。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优语言模型取得了成功并被广泛使用，但对其内部如何处理指令的机制了解甚少。本文旨在从机制角度探究指令特定表示在不同后训练阶段（监督微调和直接偏好优化）中是如何构建和利用的。

Method: 通过因果中介分析识别指令表示在模型中的局部化特征，提出一种新颖的方法来定位语言模型中的信息处理，该方法摆脱了基于补丁技术的隐式线性假设。研究发现指令向量在早期层形成任务表示后，在后期层选择不同的信息通路来完成任务，即指令向量充当电路选择器。

Result: 发现指令表示相对局部化，这些指令向量表现出线性可分性与非线性因果交互并存的特点，挑战了机制可解释性中常见的线性表示假设。指令向量在早期层形成任务表示，在后期层选择不同的信息通路来完成任务。

Conclusion: 指令调优语言模型中的指令处理机制比传统线性表示假设更为复杂，指令向量既具有线性可分性又参与非线性因果交互，它们作为电路选择器在不同层间协调信息处理，这为理解语言模型内部工作机制提供了新的视角。

Abstract: Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.

</details>


### [190] [Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation](https://arxiv.org/abs/2602.07954)
*Krzysztof Wróbel,Jan Maria Kowalski,Jerzy Surma,Igor Ciuciura,Maciej Szymański*

Main category: cs.CL

TL;DR: Bielik Guard是一系列波兰语内容安全分类器，包含0.1B和0.5B参数两个变体，用于检测仇恨/攻击、粗俗、性内容、犯罪和自残五类不安全内容。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在波兰语应用中的部署增加，需要高效准确的内容安全分类器来确保内容安全。

Method: 基于MMLW-RoBERTa-base（0.1B参数）和PKOBP/polish-roberta-8k（0.5B参数）构建，在6,885个社区标注的波兰文本数据集上进行微调，分类五类不安全内容。

Result: 0.5B变体在测试集上获得0.791（微观）和0.785（宏观）F1分数；0.1B变体在实际用户提示中达到77.65%精确度和0.63%低误报率，优于相同规模的HerBERT-PL-Guard。

Conclusion: Bielik Guard提供了高效的波兰语内容安全分类解决方案，0.5B变体性能最佳，0.1B变体效率突出，模型公开可用，旨在提供适当响应而非简单内容屏蔽。

Abstract: As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\%) and very low false positive rate (0.63\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\% precision, 4.70\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.

</details>


### [191] [Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms](https://arxiv.org/abs/2602.07963)
*Vaibhav Shukla,Hardik Sharma,Adith N Reganti,Soham Wasmatkar,Bagesh Kumar,Vrijendra Singh*

Main category: cs.CL

TL;DR: 该研究创建了CompositeHarm基准测试，通过翻译评估大语言模型在多语言环境下的安全对齐表现，发现攻击成功率在印度语言中显著上升，特别是在对抗性语法下，而上下文危害转移较为温和。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要基于英语，翻译作为多语言行为探测的捷径，但无法完整捕捉有害意图或结构在不同语言间的变化。某些危害在翻译后几乎保持不变，而其他危害则会扭曲或消失，需要系统研究这种效应。

Method: 引入CompositeHarm基准测试，结合两个互补的英文数据集（AttaQ针对结构化对抗攻击，MMSafetyBench覆盖上下文现实世界危害），将其扩展到六种语言：英语、印地语、阿萨姆语、马拉地语、卡纳达语和古吉拉特语。采用三个大模型进行评估，并采用受边缘AI设计原则启发的轻量级推理策略，减少冗余评估次数同时保持跨语言保真度。

Result: 研究发现攻击成功率在印度语言中急剧上升，特别是在对抗性语法下，而上下文危害转移较为温和。轻量级推理策略使大规模多语言安全测试在计算上可行且环保。

Conclusion: 翻译基准测试是构建有基础、资源感知、语言自适应安全系统的必要第一步，但还不够充分。需要更深入的多语言安全评估方法来确保模型在各种语言环境下的安全性。

Abstract: Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.

</details>


### [192] [Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection](https://arxiv.org/abs/2602.07978)
*Rui Feng,Zhiyao Luo,Liuyu Wu,Wei Wang,Yuting Song,Yong Liu,Kok Pin Ng,Jianqing Li,Xingyao Wang*

Main category: cs.CL

TL;DR: SynCog框架通过可控零样本多模态数据合成和思维链推理微调，解决MCI诊断中的数据稀缺和模型可解释性问题，在多语言基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于语音的数字生物标志物在轻度认知障碍早期识别中面临临床数据稀缺、跨语言泛化能力不足以及缺乏可解释推理等挑战，限制了临床应用的信任度。

Method: 提出SynCog框架：1) 通过可控零样本多模态数据合成模拟不同认知特征的虚拟受试者，缓解数据稀缺问题；2) 使用思维链推理策略微调多模态大语言模型，使模型能够明确表达诊断思维过程而非黑箱预测。

Result: 在ADReSS和ADReSSo基准测试中，通过合成数据增强获得80.67%和78.46%的Macro-F1分数，优于现有基线模型；在独立真实世界普通话队列(CIR-E)中实现48.71%的Macro-F1，展示了强大的跨语言泛化能力。

Conclusion: SynCog框架为解决临床数据稀缺和模型可解释性问题提供了有效方案，为实现临床可信且语言包容的全球认知评估工具迈出了关键一步。

Abstract: Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.

</details>


### [193] [Is Reasoning Capability Enough for Safety in Long-Context Language Models?](https://arxiv.org/abs/2602.08874)
*Yu Fu,Haz Sameen Shahgir,Huanli Gong,Zhipeng Wei,N. Benjamin Erichson,Yue Dong*

Main category: cs.CL

TL;DR: 研究发现，在长上下文推理攻击中，更强的推理能力并不能自动提升大语言模型的安全性，反而可能帮助模型组装出有害意图却无法拒绝执行。


<details>
  <summary>Details</summary>
Motivation: 测试一个假设：更强的推理能力应该能通过帮助模型识别隐含的有害意图来提升安全性。研究在长上下文环境中，当有害意图是隐含的、需要通过推理才能识别时，这一假设是否成立。

Method: 引入组合推理攻击这一新的威胁模型，将有害查询分解成不完整的片段，分散在长上下文中。然后使用中性的推理查询诱导模型检索和合成这些片段，使有害意图在组合后才显现。评估了14个前沿大语言模型，上下文长度达64k tokens。

Result: 三个主要发现：1）具有更强通用推理能力的模型对组合推理攻击并不更鲁棒，经常组装出有害意图却无法拒绝；2）随着上下文长度增加，安全对齐效果持续下降；3）推理时的计算努力是关键缓解因素，增加推理时计算可将GPT-oss-120b模型的攻击成功率降低超过50个百分点。

Conclusion: 安全性不会随着推理能力的增强而自动提升，特别是在长上下文推理场景下。需要专门的安全措施来应对组合推理攻击，不能依赖推理能力本身来保证安全。

Abstract: Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.

</details>


### [194] [The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation](https://arxiv.org/abs/2602.07996)
*Arash Marioriyad,Omid Ghahroodi,Ehsaneddin Asgari,Mohammad Hossein Rohban,Mahdieh Soleymani Baghshah*

Main category: cs.CL

TL;DR: LLM作为自动评估器时，其判断会受到无关上下文线索（如来源、时间、人口统计信息）的显著影响，但这些影响很少在评估理由中明确承认，揭示了模型评估的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为自动评估器时是否能够忠实、公正地评估系统输出，即是否仅基于内容质量做出判断，不受无关上下文影响，并能透明反映决策因素。

Method: 通过控制性线索扰动实验，向评估提示中注入合成元数据标签（来源、时间、年龄、性别、种族、教育状态），测试6个LLM评估模型在ELI5（事实问答）和LitBench（创意写作）两个数据集上的表现，测量判决偏移率和线索承认率。

Result: LLM评估器对无关线索表现出显著敏感性，如来源层次偏好（专家>人类>LLM>未知）、时效性偏好（新>旧）、教育状态偏好等，但线索承认率通常接近零，表明即使线索驱动决策也很少在理由中明确承认。线索承认率还依赖于数据集，在事实性ELI5中某些模型和线索更可能承认，但在开放性的LitBench中即使判决大幅偏移也几乎不承认。

Conclusion: LLM作为评估器存在显著的判决敏感性与有限的线索承认之间的解释差距，这对研究和部署中基于模型的评估可靠性提出了重要关切。

Abstract: Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.

</details>


### [195] [DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity](https://arxiv.org/abs/2602.08005)
*Jitai Hao,Qiang Huang,Yaowei Wang,Min Zhang,Jun Yu*

Main category: cs.CL

TL;DR: DeltaKV通过残差编码压缩KV缓存，结合Sparse-vLLM推理引擎，在保持精度的同时将内存降至29%，吞吐量提升2倍


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM部署面临KV缓存内存线性增长的瓶颈，现有压缩方法难以平衡精度、压缩比和硬件效率

Method: 基于两个经验发现（长距离token相似性和KV表示中的共享潜在组件），提出DeltaKV残差压缩框架，通过编码相对于历史参考的语义残差来减少存储；进一步开发Sparse-vLLM推理引擎，具有解耦内存管理和针对稀疏不规则KV布局的优化内核

Result: DeltaKV将KV缓存内存降至原始的29%，在LongBench、SCBench和AIME上保持接近无损的精度；结合Sparse-vLLM后，在长上下文场景中相比vLLM实现高达2倍的吞吐量提升

Conclusion: DeltaKV和Sparse-vLLM为可扩展的长上下文LLM部署提供了实用路径，在保持精度的同时显著提升内存效率和推理性能

Abstract: The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.

</details>


### [196] [Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning](https://arxiv.org/abs/2602.08028)
*Po-Chun Chen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: DIP框架通过生成多样化高层推理策略并整合为最终计划，提升零样本推理准确性，无需依赖资源密集型采样。


<details>
  <summary>Details</summary>
Motivation: 标准思维链提示中无指导推理路径不稳定，现有方法依赖单一推理策略限制了在不同任务上的性能表现。

Method: 提出DIP框架：1) 生成多个多样化高层推理策略；2) 将每个策略扩展为详细的逐步草稿计划；3) 将这些草稿计划归纳为最终计划。

Result: 实验表明DIP优于单一策略提示方法，验证了多计划归纳在基于提示的推理中的有效性。

Conclusion: 通过生成多样化推理策略并整合为最终计划，DIP框架能够有效提升大语言模型的零样本推理准确性。

Abstract: To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.

</details>


### [197] [TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs](https://arxiv.org/abs/2602.08048)
*Arshia Hemmat,Philip Torr,Yongqiang Chen,Junchi Yu*

Main category: cs.CL

TL;DR: 本文提出TDGNet，一种用于扩散语言模型幻觉检测的时序动态图框架，通过分析去噪过程中的注意力图演化来检测幻觉，相比现有方法在多个基准测试中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型具有并行去噪和双向上下文优势，但其幻觉检测研究不足。现有的自回归LLM检测器依赖单次推理线索，不适用于扩散生成，因为事实证据分布在去噪轨迹中，可能随时间出现、漂移或自我修正。

Method: 提出TDGNet框架，将幻觉检测建模为在演化令牌级注意力图上的学习问题。在每个去噪步骤中，稀疏化注意力图并通过消息传递更新每个令牌的记忆，然后使用时序注意力聚合轨迹范围内的证据进行最终预测。

Result: 在LLaDA-8B和Dream-7B模型上的QA基准测试显示，TDGNet相比基于输出、基于潜在表示和静态图的基线方法，在AUROC指标上取得一致改进，具有单次推理和适度计算开销。

Conclusion: 研究结果表明，对注意力图进行时序推理对于扩散语言模型的鲁棒幻觉检测至关重要，TDGNet框架有效利用了扩散生成过程中的动态特性。

Abstract: Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.

</details>


### [198] [Emergent Search and Backtracking in Latent Reasoning Models](https://arxiv.org/abs/2602.08100)
*Jasmine Cui,Charles Ye*

Main category: cs.CL

TL;DR: LRTs在隐藏空间中进行无词推理，自发形成结构化搜索过程：探索阶段、初步承诺、收敛或回溯，回溯能显著提升准确性


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在无词情况下的推理过程，探索潜在推理变换器（LRTs）如何在连续隐藏空间中进行思考，与传统的链式思维（CoT）形成对比

Method: 使用潜在推理变换器（LRTs）在多项选择QA基准上解码模型每一步演变的信念，分析其在隐藏空间中的结构化搜索过程

Result: 模型自发学习到结构化搜索过程：探索阶段概率质量分散、初步承诺领先选项、收敛或回溯；回溯普遍（32%）、有益（准确率提升34%），且主要从语义最接近的干扰项转向正确答案；搜索具有适应性，替换干扰项可缩短探索时间54%

Conclusion: 潜在推理模型在激活空间中实现了链式思维通过文字实现的功能：能够犯错、察觉并恢复，展示了无词推理的有效性和灵活性

Abstract: What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.

</details>


### [199] [Gender and Race Bias in Consumer Product Recommendations by Large Language Models](https://arxiv.org/abs/2602.08124)
*Ke Xu,Shera Potka,Alex Thomo*

Main category: cs.CL

TL;DR: 该研究首次系统性地探索了大型语言模型在生成产品推荐时存在的性别和种族偏见问题，通过多种分析方法揭示了推荐结果中的显著人口统计学差异。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地用于生成消费者产品推荐，但其可能嵌入和放大性别与种族偏见的潜力尚未得到充分探索。本研究旨在填补这一空白，成为首批系统研究LLM推荐系统中偏见问题的尝试之一。

Method: 研究采用提示工程方法，引导LLM为不同种族和性别群体生成产品推荐，然后使用三种分析方法：标记词分析、支持向量机和Jensen-Shannon散度来识别和量化偏见。

Result: 研究发现不同人口统计学群体获得的推荐存在显著差异，揭示了LLM推荐系统中存在的不公平现象。

Conclusion: 研究结果强调了开发更公平的LLM推荐系统的必要性，为后续的偏见缓解研究提供了实证基础。

Abstract: Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.

</details>


### [200] [DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries](https://arxiv.org/abs/2602.08149)
*Sahana Ramnath,Nima Chitsazan,Mingyang Zhou,Chia-Hsuan Lee,Shi-Xiong Zhang,Stephen Rawls,Sambit Sahu,Sangwoo Cho,Xiang Ren,Genta Indra Winata,Akshaj Kumar Veldanda*

Main category: cs.CL

TL;DR: DIALSUMMER框架针对对话摘要评估提出分层错误分类法，解决对话结构转换和叙述视角转换的复杂性，并创建人工标注数据集分析错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有对话摘要评估方法忽略了对话特有的复杂性：从多说话者分散讨论到摘要句子的结构转换，以及从第一/第二人称到第三人称的叙述视角转换。

Method: 提出DIALSUMMER框架，包含两层错误分类法：对话层面关注说话者/轮次，轮次内层面关注单轮次信息；创建人工标注数据集，分析错误趋势并测试LLM-Judge的错误检测能力。

Result: 分析发现有趣趋势：对话中间轮次最容易被遗漏，外部幻觉多出现在摘要末尾；LLM-Judge在错误检测上表现有限，显示数据集的挑战性和未来改进需求。

Conclusion: DIALSUMMER框架为对话摘要评估提供全面方法，其数据集和分类法展示了对话摘要任务的复杂性，需要进一步研究提升LLM在此领域的性能。

Abstract: Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.

</details>


### [201] [LLMs and people both learn to form conventions -- just not with each other](https://arxiv.org/abs/2602.08208)
*Cameron R. Jones,Agnese Lombardi,Kyle Mahowald,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: LLMs和人类在同类对话中都能形成沟通惯例，但在人机混合对话中却无法有效对齐，即使让LLMs模仿人类表面行为也无法达到人类间对话的协调水平。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能在多模态沟通游戏中像人类一样形成沟通惯例，以及人机混合对话中的对齐问题。

Method: 通过多模态沟通游戏实验，比较人类-人类、AI-AI、人类-AI三种对话组合的表现，测量准确性、一致性和消息长度等指标。

Result: 同类对话（人类-人类、AI-AI）都显示出惯例形成迹象（准确性提高、一致性增强、消息缩短），但人机混合对话失败。即使提示LLMs模仿人类表面行为，人机对话的准确性和词汇重叠仍落后于同类对话。

Conclusion: 对话对齐不仅需要模仿先前互动的能力，还需要对传达意义有共享的解释性偏见，LLMs与人类在这方面的差异阻碍了有效沟通惯例的形成。

Abstract: Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.

</details>


### [202] [Pretraining with Token-Level Adaptive Latent Chain-of-Thought](https://arxiv.org/abs/2602.08220)
*Boyi Zeng,Yiqin Hao,He Li,Shixiang Song,Feichen Song,Zitong Wang,Siyuan Huang,Yi Xu,ZiWei He,Xinbing Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出自适应潜在思维链预训练方法，通过为每个token生成可变长度的潜在推理轨迹，在不增加参数的情况下提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统通过增加参数和训练数据来扩展大语言模型的方法受到高质量语料库有限和通信成本上升的限制，需要探索新的扩展维度

Method: 提出自适应潜在思维链预训练，模型在生成每个token前先生成可变长度的潜在推理轨迹，为困难token分配更长轨迹，为简单token分配较短甚至零轨迹，通过单阶段预训练自然实现

Result: 在Llama架构上的实验表明，自适应潜在思维链能持续改善语言建模困惑度和广泛下游任务准确率，即使训练FLOPs少于先前循环基线

Conclusion: 通过内部化潜在思维链到预训练中，在不增加参数的情况下增加每个token的计算量，提供了一种有效且计算高效的模型扩展新维度

Abstract: Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.

</details>


### [203] [CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts](https://arxiv.org/abs/2602.08221)
*Xuhua Ma,Richong Zhang,Zhijie Nie*

Main category: cs.CL

TL;DR: CoRect通过对比上下文化和非上下文化的前向传播logits来识别存在高参数偏置的层，然后修正隐藏状态以保留基于证据的信息，从而解决RAG中的知识冲突问题。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）在处理知识冲突时存在困难，模型内部的参数化知识会覆盖检索到的证据，导致输出不忠实。现有方法要么依赖肤浅的解码调整，要么需要真实目标进行权重编辑，存在局限性。

Method: 通过层间分析发现参数抑制现象：在深层中，某些FFN层会用记忆的先验覆盖上下文敏感表示。提出CoRect方法，通过对比上下文化和非上下文化前向传播的logits来识别高参数偏置的层，然后修正隐藏状态以保留基于证据的信息。

Result: 在问答和摘要基准测试中，CoRect相比强基线方法，持续提高了忠实度并减少了幻觉。

Conclusion: CoRect通过识别和修正存在参数偏置的层，有效解决了RAG中的知识冲突问题，提高了生成内容的忠实度，且不需要真实标签。

Abstract: Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.

</details>


### [204] [Document Reconstruction Unlocks Scalable Long-Context RLVR](https://arxiv.org/abs/2602.08237)
*Yao Xiao,Lei Wang,Yue Deng,Guanzheng Chen,Ziqi Jin,Jung-jae Kim,Xiaoli Li,Roy Ka-wei Lee,Lidong Bing*

Main category: cs.CL

TL;DR: 提出了一种无监督的强化学习方法RLVR，通过让LLM在长文档中识别和排序缺失段落来提升长上下文能力，无需人工标注或教师模型监督。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习需要依赖昂贵的黄金标准答案或教师模型评估标准，成本高且耗时。本研究旨在探索无监督方法来增强LLM的长上下文能力，消除对大量人工标注或教师模型监督的需求。

Method: 首先在长文档中用特殊占位符替换几个段落，然后通过强化学习训练LLM从候选选项集中正确识别和排序缺失段落来重构文档。这种训练范式使模型能够捕捉全局叙事连贯性。

Result: 在RULER和LongBench v2两个基准测试上验证了方法的有效性。在RULER上获得显著提升，在LongBench v2上也能实现合理改进，且无需手动整理的长上下文QA数据。进行了广泛的消融研究分析奖励设计、数据整理策略、训练方案和数据缩放效应的影响。

Conclusion: 提出了一种有效的无监督强化学习方法，能够显著提升LLM的长上下文能力，无需昂贵的人工标注或教师模型监督，并公开了代码、数据和模型。

Abstract: Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.

</details>


### [205] [On convexity and efficiency in semantic systems](https://arxiv.org/abs/2602.08238)
*Nathaniel Imel,Noga Zaslavasky*

Main category: cs.CL

TL;DR: 该研究分析了人类语义范畴系统的两个特征：凸性和效率性。通过信息瓶颈框架发现两者本质不同，效率性更能解释颜色命名系统的实证现象。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解人类语义范畴系统中凸性和效率性这两个广泛认可特征之间的关系。虽然之前观察到颜色命名中两者共存，但它们的分析关系及共存原因尚未得到充分理解。

Method: 采用信息瓶颈框架进行理论和实证分析。首先证明凸性和效率性在理论上是不同的，然后分析IB最优系统在颜色命名领域的表现，最后比较两者对实证数据的预测能力。

Result: 1. 凸性和效率性在理论上相互独立：存在凸但低效的系统，也存在最优效率但非凸的系统；2. 在颜色命名领域，IB最优系统大多是凸的，解释了凸性方法的实证基础；3. 效率性比凸性更能区分实际颜色命名系统与假设变体，凸性在效率性基础上几乎没有额外改进。

Conclusion: 凸性和效率性虽然能产生相似的结构观察结果，但本质上是不同的概念。效率性提供了对语义类型学更全面的解释，能解释凸性无法解释的一系列实证现象。

Abstract: There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.

</details>


### [206] [Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence](https://arxiv.org/abs/2602.08252)
*Devin R. Wright,Justin E. Lane,F. LeRon Shults*

Main category: cs.CL

TL;DR: CLIFS方法利用认知语言模式、大语言模型和隐式隐喻从语言中测量身份融合，在预测已验证的融合分数方面优于现有方法，并识别出两种极端暴力路径


<details>
  <summary>Details</summary>
Motivation: 随着两极分化和政治暴力加剧，理解极端主义的心理根源日益重要。先前研究表明身份融合能预测参与极端行为的意愿，但需要更有效的测量方法

Method: 开发了认知语言身份融合评分方法，利用认知语言模式、大语言模型和隐式隐喻从语言中测量融合，在英国和新加坡数据集上进行验证

Result: 该方法在预测已验证的融合分数方面优于现有方法。应用于极端主义宣言时，识别出两种高融合暴力路径：意识形态者倾向于以群体术语框架自我，形成亲属关系纽带；而受委屈驱动的个体则以个人身份术语框架群体

Conclusion: 这些结果完善了身份融合理论，并为融合研究和极端主义检测提供了一个可扩展的工具

Abstract: In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.

</details>


### [207] [Language Modeling and Understanding Through Paraphrase Generation and Detection](https://arxiv.org/abs/2602.08274)
*Jan Philip Wahle*

Main category: cs.CL

TL;DR: 该论文提出将释义分解为构成性语言方面（释义类型），为语义等价提供更细粒度的认知基础视角，并证明基于释义类型训练的模型在相关任务和下游应用中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法将释义简化为两个文本之间的二元决策或单一重写，掩盖了哪些语言因素负责意义保留。需要更细粒度的语义等价理解，使计算语言模型能够理解和控制构成相同意义的不同方面。

Method: 提出将释义分解为构成性语言方面（释义类型）的方法，为语义等价提供更细粒度和认知基础的视角。训练模型识别这些释义类型，而不是简单的二元分类。

Result: 基于释义类型训练的模型在相关任务中表现更强：在抄袭检测中超越人类基线（维基百科案例89.6% vs 78.4%，arXiv科学论文案例66.5% vs 55.7%）；在Quora重复问题识别中优于基于二元对训练的模型。

Conclusion: 分解释义为构成性语言方面（释义类型）提供了更细粒度的语义等价视角，能显著提升模型在相关任务和下游应用中的性能，即使先进机器学习模型在未专门训练时也难以完成此任务。

Abstract: Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...

</details>


### [208] [New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR](https://arxiv.org/abs/2602.08281)
*Zhilin Wang,Yafu Li,Shunkai Zhang,Zhi Wang,Haoran Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: RLVR通过优化原子步骤概率使LLM获得新能力，而非仅激发潜在能力，这为解决多步推理任务提供了新解释。


<details>
  <summary>Details</summary>
Motivation: 澄清RLVR是否赋予LLM新能力还是仅激发潜在能力这一核心争议，为涌现能力提供新的理论解释。

Method: 提出基于实例级可解性的概率框架，假设通过锐化原子步骤概率驱动复杂推理；使用Algebrarium框架，在单步操作上训练模型，评估未见多步任务性能。

Result: (1) RLVR通过放大现有技能激励探索新解路径；(2) 复合性能严格受原子步骤联合概率控制（ρ∈[0.69,0.96]）；(3) RLVR作为全局优化器可能导致特定技能被牺牲以最大化总奖励。

Conclusion: RLVR通过迭代优化可解问题使模型发展出解决先前不可解场景的能力，为RLVR中的涌现能力提供了新颖解释。

Abstract: Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($ρ\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.

</details>


### [209] [When Does Context Help? Error Dynamics of Contextual Information in Large Language Models](https://arxiv.org/abs/2602.08294)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 论文提出了一个统一的理论框架来分析Transformer大语言模型中任意上下文信息的影响，通过输出误差动态来表征上下文影响，并推导出误差减少的几何条件。


<details>
  <summary>Details</summary>
Motivation: 尽管推理时的上下文信息（如演示、检索知识或交互历史）可以在不更新参数的情况下显著提升大语言模型的性能，但其理论作用在特定设置（如上下文学习）之外仍缺乏深入理解。

Method: 提出了一个统一的理论框架来分析Transformer大语言模型中的上下文信息影响。在单层Transformer中，证明了上下文条件误差向量可加性分解为基线误差向量和上下文修正向量，并推导出误差减少的几何条件。进一步展示了上下文修正范数存在由上下文-查询相关性和互补性决定的显式上界，并将结果扩展到多上下文和多层Transformer。

Result: 实验在上下文学习、检索增强生成和记忆演化等任务上验证了理论，并基于理论提出了一种原则性的上下文选择策略，将性能提升了0.6%。

Conclusion: 该研究为理解大语言模型中上下文信息的作用提供了统一的理论框架，揭示了误差减少的几何条件，并提出了有效的上下文选择策略，对提升模型性能具有理论和实践意义。

Abstract: Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\%$.

</details>


### [210] [JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation](https://arxiv.org/abs/2602.08305)
*Binglin Wu,Yingyi Zhang,Xiannneg Li*

Main category: cs.CL

TL;DR: JUSTICE框架通过模拟法官"搜索→预判→撰写"的认知流程，引入预判阶段来提升法律判决文书生成的准确性和法律合理性。


<details>
  <summary>Details</summary>
Motivation: 现有法律判决文书生成方法过于简化复杂法律推理过程，特别是忽略了法官形成初步结论的"预判"阶段，导致两个核心问题：1) 基础司法要素获取不足；2) 预判过程建模不充分，从而影响最终文书的合法性。

Method: 提出JUSTICE框架，包含三个核心组件：1) 参考性司法要素检索器(RJER)：检索相关法律条文和先例案例；2) 中间结论模拟器(ICE)：生成可验证的中间结论，实现预判阶段；3) 司法统一合成器(JUS)：综合所有输入生成最终判决文书。

Result: 在领域内法律基准测试和分布外数据集上的实验表明，JUSTICE显著优于强基线方法，在法律准确性方面有实质性提升，包括刑期预测准确率提高4.6%。

Conclusion: 明确建模预判过程对于增强生成判决文书的合法连贯性和准确性至关重要，JUSTICE框架通过模拟人类法官的认知工作流程有效解决了现有方法的局限性。

Abstract: Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \textit{\textbf{J}udicial \textbf{U}nified \textbf{S}ynthesis \textbf{T}hrough \textbf{I}ntermediate \textbf{C}onclusion \textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\rightarrow$ Pre-Judge $\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.

</details>


### [211] [Improving Data and Reward Design for Scientific Reasoning in Large Language Models](https://arxiv.org/abs/2602.08321)
*Zijie Chen,Zhenghao Lin,Xiao Liu,Zhenzhong Lan,Yeyun Gong,Peng Cheng*

Main category: cs.CL

TL;DR: 本文提出Dr. SCI数据集和训练流程，用于提升大语言模型在开放式科学问题上的表现，通过系统化数据处理、动态难度课程和基于评分标准的强化学习，显著提升了科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在开放式科学问题上的挑战，主要瓶颈在于科学后训练的数据构建和奖励设计。现有方法存在监督不可靠、评估困难的问题，需要系统化的解决方案。

Method: 1) 构建Dr. SCI数据集：包含100万问题，覆盖8个STEM学科，有明确的可验证/开放式划分、可扩展的难度标注和细粒度评分标准；2) Dr. SCI后训练流程：包括探索扩展的SFT（扩大推理模式覆盖）、动态难度课程（根据模型能力调整训练数据）、基于科学评分标准的RL（通过评分标准实现开放式问题的稳定强化学习）。

Result: 使用Dr. SCI流程训练的Qwen3-4B-Base模型在GPQA-diamond上达到63.2分，在GPQA-general上达到32.4分，持续优于o1-mini和GPT-4o等强基线，在科学推理特别是开放式设置中取得显著提升。

Conclusion: Dr. SCI数据集和训练流程有效解决了大语言模型在开放式科学问题上的挑战，通过系统化的数据构建和创新的训练策略，显著提升了模型的科学推理能力，特别是在开放式问题回答方面。

Abstract: Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.

</details>


### [212] [An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling](https://arxiv.org/abs/2602.08322)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出了一种基于注意力机制的生成式框架，用于同时处理多意图检测和槽填充任务，解决了现有对话系统中多意图场景的挑战。


<details>
  <summary>Details</summary>
Motivation: 现实对话场景中用户通常在一个话语中表达多个意图，而现有方法主要针对单意图场景，多意图SLU面临数据集缺乏和任务干扰的挑战。

Method: 提出生成式框架，采用注意力叠加解码器处理可变数量意图，通过引入归纳偏置解决多任务学习中的干扰问题；利用BERT的NSP头构建新的多意图数据集。

Result: 在MixATIS和MixSNIPS两个公开数据集以及自建数据集上均取得了最先进的性能表现。

Conclusion: 提出的注意力叠加注意力生成模型有效解决了多意图SLU问题，通过创新的解码器设计和数据集构建方法提升了任务性能。

Abstract: In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.

</details>


### [213] [Latent Reasoning with Supervised Thinking States](https://arxiv.org/abs/2602.08332)
*Ido Amos,Avi Caciularu,Mor Geva,Amir Globerson,Jonathan Herzig,Lior Shani,Idan Szpektor*

Main category: cs.CL

TL;DR: Thinking States是一种在输入处理过程中进行推理的方法，通过生成思考标记并嵌入到后续输入中，减少推理延迟，提高效率。


<details>
  <summary>Details</summary>
Motivation: 链式思维推理虽然能帮助大语言模型解决复杂任务，但生成长推理过程会导致显著的推理成本。需要一种更高效的推理方法。

Method: 在输入处理过程中每几个输入标记就生成一系列思考标记，将这些思考转换回嵌入空间，并添加到后续输入标记中。这种方法既能捕捉CoT的循环特性，又能在输入处理时生成思考。

Result: 在多个推理任务上优于其他潜在推理方法，在数学问题上缩小了与CoT的差距，在2-Hop QA上达到与CoT相当的性能且延迟更低。在状态跟踪任务上表现出比CoT更强的推理能力，并能成功泛化到比训练时更长的序列。

Conclusion: Thinking States是一种有效的推理方法，能够在输入处理过程中进行并行化推理，既保持了CoT的优势，又显著降低了推理延迟，具有良好的泛化能力。

Abstract: Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.

</details>


### [214] [UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models](https://arxiv.org/abs/2602.08336)
*Cheng Yang,Chufan Shi,Bo Shui,Yaokang Wu,Muzi Tao,Huijuan Wang,Ivan Yee Lee,Yong Liu,Xuezhe Ma,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: UReason是一个诊断性基准测试，用于评估推理在图像生成中的实际效果，发现推理痕迹虽然能提升性能，但作为上下文条件反而会阻碍视觉合成，存在"推理悖论"现象。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型越来越多地采用思维链推理来指导图像生成，但推理对视觉合成的实际效果尚不清楚。需要评估推理能否在像素层面忠实执行。

Method: 提出UReason诊断基准，包含2,000个实例，涵盖代码、算术、空间、属性和文本推理五个任务族。引入评估框架比较直接生成、推理引导生成和去上下文生成三种方法。

Result: 在八个开源统一模型中观察到一致的"推理悖论"：推理痕迹通常比直接生成提升性能，但将中间思想作为条件上下文往往会阻碍视觉合成，而仅基于精炼提示的条件能带来显著提升。

Conclusion: 瓶颈在于上下文干扰而非推理能力不足。UReason为研究统一模型中的推理提供了原则性测试平台，并激励未来方法在有效整合推理进行视觉生成的同时减轻干扰。

Abstract: To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.

</details>


### [215] [ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts](https://arxiv.org/abs/2602.08371)
*Hung Quang Tran,Nam Tien Pham,Son T. Luu,Kiet Van Nguyen*

Main category: cs.CL

TL;DR: 该研究创建了越南语情感语料库ViGoEmotions，包含20,664条社交媒体评论，标注为27种细粒度情感，并评估了8种预训练Transformer模型在三种预处理策略下的情感分类性能。


<details>
  <summary>Details</summary>
Motivation: 情感分类在情感预测和有害内容检测中具有重要作用。尽管NLP领域特别是大语言模型取得了显著进展，但越南语情感分类领域仍缺乏高质量、细粒度的情感语料库，需要研究不同预处理策略对模型性能的影响。

Method: 创建了越南语情感语料库ViGoEmotions，包含20,664条社交媒体评论，标注为27种细粒度情感。评估了8种预训练的Transformer模型，采用三种预处理策略：1) 保留原始表情符号并进行规则化归一化；2) 将表情符号转换为文本描述；3) 应用ViSoLex模型进行词汇归一化。

Result: 将表情符号转换为文本通常能提高多个BERT基线的性能，而保留表情符号对ViSoBERT和CafeBERT效果最好。移除表情符号通常导致性能下降。ViSoBERT获得了最高的Macro F1-score（61.50%）和Weighted F1-score（63.26%）。CafeBERT和PhoBERT也表现出色。

Conclusion: 提出的ViGoEmotions语料库能有效支持多种架构，但预处理策略和标注质量仍然是影响下游性能的关键因素。表情符号处理方式对模型性能有显著影响，不同模型对表情符号的处理策略有不同的适应性。

Abstract: Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.

</details>


### [216] [Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.08382)
*Zhuoen Chen,Dongfang Li,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 提出认知启发的长上下文推理框架，通过分块压缩和选择性记忆召回解决LLM长上下文处理问题，相比基线方法显著提升效率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文时面临计算成本高、信息遗忘和检索增强生成中的上下文碎片化等挑战，需要更高效的解决方案

Method: 基于分块压缩和选择性记忆召回：将长输入分段为块，用学习到的压缩器编码为压缩记忆表示；门控模块动态选择相关记忆块；推理模块通过演化的工作记忆迭代处理以解决下游任务

Result: 在RULER-HQA等多跳推理基准上达到竞争性准确率，上下文长度从7K扩展到1.75M令牌，相比强基线在准确率-效率权衡上表现更优，GPU峰值内存使用减少2倍，推理速度比MemAgent快6倍

Conclusion: 提出的认知启发框架通过压缩和选择性记忆机制有效解决了LLM长上下文处理的关键挑战，在保持准确性的同时显著提升了计算效率

Abstract: Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.

</details>


### [217] [TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration](https://arxiv.org/abs/2602.08404)
*Linye Wei,Zixiang Luo,Pingzhi Tang,Meng Li*

Main category: cs.CL

TL;DR: TEAM框架通过利用专家路由决策的时空一致性，采用三种互补策略来加速MoE扩散大语言模型，在保持性能的同时实现最高2.2倍加速。


<details>
  <summary>Details</summary>
Motivation: MoE扩散大语言模型在推理时存在效率问题：每个去噪步骤激活大量专家，但只有少量token被最终接受，导致显著的推理开销，限制了在延迟敏感应用中的部署。

Method: TEAM框架利用专家路由决策在去噪层级间的时间一致性和token位置间的空间一致性，采用三种互补策略：保守选择已解码和掩码token的必要专家，同时在多个候选token上进行激进的推测性探索。

Result: 实验结果表明，TEAM相比原始MoE扩散大语言模型实现了最高2.2倍的加速，且性能下降可忽略不计。

Conclusion: TEAM是一个即插即用的框架，通过更少的激活专家实现更多token的接受，有效解决了MoE架构与扩散解码之间的不匹配问题，显著提升了推理效率。

Abstract: Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.

</details>


### [218] [Large Language Models and Impossible Language Acquisition: "False Promise" or an Overturn of our Current Perspective towards AI](https://arxiv.org/abs/2602.08437)
*Ziyan wang,Longlong Ma*

Main category: cs.CL

TL;DR: 该研究通过实验检验乔姆斯基对大型语言模型的批评，构建不可能语言测试GPT-2和LSTM模型的学习能力，发现GPT-2在不可能语言上表现不佳，而LSTM表现符合乔姆斯基观点，提出了从理性主义转向功能主义和经验主义的研究范式转变。


<details>
  <summary>Details</summary>
Motivation: 乔姆斯基在《CHATGPT的虚假承诺》中批评大型语言模型只是模式预测器，缺乏人类语言习得的内在因果和自我修正结构，无法区分不可能语言。这一批评代表了AI基础理论的根本挑战，结合了LLM方法论的主要问题并具有典型的先验理性主义视角。研究旨在从语言学和心理学文献角度以及实验研究角度检验这一著名批评。

Method: 通过应用特定转换构建一组句法上不可能的语言（包括整句反转和基于词数奇偶性添加否定）。在GPT-2小型模型和长短期记忆（LSTM）模型上进行两轮对照实验，使用韦尔奇t检验进行统计分析。

Result: 统计分析显示，GPT-2小型模型在学习所有不可能语言方面的表现均低于其在可能语言上的表现（p<0.001）。而LSTM模型的表现与乔姆斯基的论点一致，表明Transformer架构演化的不可替代作用。

Conclusion: 基于理论分析和实证发现，提出了在乔姆斯基理论框架内对LLM的新视角，以及从乔姆斯基的"理性主义-浪漫主义"范式向功能主义和经验主义的理论范式转变，为LLM研究提供了新的方向。

Abstract: In Chomsky's provocative critique "The False Promise of CHATGPT," Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his "rationalist-romantics" paradigm to functionalism and empiricism in LLMs research.

</details>


### [219] [Characterizing, Evaluating, and Optimizing Complex Reasoning](https://arxiv.org/abs/2602.08498)
*Haoran Zhang,Yafu Li,Zhi Wang,Zhilin Wang,Shunkai Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: 论文提出统一框架解决大型推理模型的三个核心问题：定义推理质量、评估复杂推理轨迹、利用评估信号优化推理。基于ME²原则（宏观微观效率效果），将推理建模为有向无环图，开发DAG评估方法，构建TRM-Preference数据集训练思维奖励模型，实验证明能显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对大型推理模型三个基本问题的统一解决方案：1) 如何定义高质量推理；2) 如何可靠评估具有复杂内部结构的长推理轨迹；3) 如何利用这种评估信号进行推理优化。这些问题阻碍了推理模型的进一步发展。

Method: 1) 提出ME²原则，从宏观和微观层面定义推理质量（效率和效果）；2) 将推理轨迹建模为有向无环图，开发基于DAG的成对评估方法；3) 构建TRM-Preference数据集，训练思维奖励模型来大规模评估推理质量。

Result: 实验表明思维奖励是有效的优化信号：在测试时选择更好的推理能带来更好的结果（最高19.3%提升）；在强化学习训练中，思维奖励能增强推理能力和性能（最高3.9%提升），在多样化任务中均有效。

Conclusion: 该研究提供了一个统一的视角来解决大型推理模型的核心挑战，通过ME²原则、DAG建模和思维奖励模型，实现了对复杂推理轨迹的有效评估和优化，显著提升了推理模型的性能。

Abstract: Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.

</details>


### [220] [GISA: A Benchmark for General Information-Seeking Assistant](https://arxiv.org/abs/2602.08543)
*Yutao Zhu,Xingshuo Zhang,Maosen Zhang,Jiajie Jin,Liancheng Zhang,Xiaoshuai Song,Kangzhi Zhao,Wencong Zeng,Ruiming Tang,Han Li,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CL

TL;DR: GISA是一个用于评估通用信息搜索助手的新基准，包含373个人工构建的真实信息搜索查询，支持四种结构化答案格式，并提供完整的人类搜索轨迹作为参考。


<details>
  <summary>Details</summary>
Motivation: 现有基准存在三个主要问题：1) 从答案反向构建查询导致任务不自然；2) 要么专注于定位特定信息，要么专注于多源信息聚合，缺乏统一；3) 依赖静态答案集容易受到数据污染。需要更真实、全面的评估基准。

Method: 创建GISA基准，包含373个人工构建的真实信息搜索查询，支持四种结构化答案格式（项目、集合、列表、表格），确保确定性评估。包含实时子集定期更新答案以防止记忆，并提供完整的人类搜索轨迹作为过程级监督和模仿学习的参考。

Result: 实验显示，即使是性能最好的模型也仅达到19.30%的精确匹配分数。在需要复杂规划和全面信息收集的任务上，性能显著下降。这表明现有模型在真实信息搜索场景中仍有很大改进空间。

Conclusion: GISA基准填补了现有评估方法的空白，提供了更真实、全面的信息搜索助手评估框架。实验结果揭示了当前模型在复杂信息搜索任务上的局限性，为未来研究指明了改进方向。

Abstract: The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.

</details>


### [221] [How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location](https://arxiv.org/abs/2602.08548)
*Xuanliang Zhang,Dingzirui Wang,Keyan Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 论文通过激活修补等技术揭示了LLM处理表格的内部机制，将表格理解分解为语义绑定、坐标定位和信息提取三阶段流程，发现模型通过计数分隔符的序数机制定位单元格，并在线性子空间中编码列索引。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型越来越多地用于处理表格相关任务，但其处理线性化二维结构化表格的内部机制仍然不透明。本研究旨在揭示LLM理解表格的内部工作原理。

Method: 使用激活修补技术和互补的可解释性方法，将表格理解机制分解为原子任务——单元格定位，通过分析模型内部表示来揭示其工作机制。

Result: 发现模型通过计数离散分隔符的序数机制来解析坐标定位单元格；列索引编码在线性子空间中，可通过向量算术精确引导模型注意力；多单元格定位任务通过复用原子定位中识别的相同注意力头实现泛化。

Conclusion: 研究揭示了Transformer架构中表格理解的三阶段机制，为理解LLM处理结构化数据提供了全面解释，表明模型通过序数计数和线性子空间编码等机制实现表格定位功能。

Abstract: While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.

</details>


### [222] [Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation](https://arxiv.org/abs/2602.08600)
*Archchana Sindhujan,Girish A. Koushik,Shenbin Qian,Diptesh Kanojia,Constantin Orăsan*

Main category: cs.CL

TL;DR: 本文针对低资源语言对（英语-马拉雅拉姆语）的质量评估问题，提出了首个包含人工标注直接评估分数和翻译质量评注的片段级QE数据集，并开发了ALOPE-RL强化学习框架，通过结合错误感知奖励机制，使LLM能够超越数值评分进行翻译质量推理。


<details>
  <summary>Details</summary>
Motivation: 当前质量评估方法主要依赖标量质量分数，缺乏明确的翻译错误信息；对于低资源语言，由于标注数据有限，现有方法难以获得可靠性能。需要开发既能评估质量又能解释错误原因，且在数据有限情况下仍能有效工作的QE方法。

Method: 1) 创建首个英语-马拉雅拉姆语片段级QE数据集，包含直接评估分数和翻译质量评注；2) 提出ALOPE-RL强化学习框架，基于策略奖励训练高效适配器，奖励来自DA分数和TQR；3) 使用LoRA和4位量化技术微调紧凑型LLM（≤4B参数）。

Result: ALOPE-RL在小规模QE数据集上训练后，在英语-马拉雅拉姆语QE任务上达到最先进性能，超越了更大的LLM基线和领先的编码器基QE模型。证明了错误感知、基于策略的学习在有限数据和计算预算下仍能提供强大的QE性能。

Conclusion: 通过结合错误感知奖励的强化学习框架，可以在低资源语言对的质量评估中实现高性能，即使使用小型LLM和有限数据。该方法为资源稀缺环境下的QE研究提供了新方向，并发布了数据集、代码和模型以支持未来研究。

Abstract: Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.

</details>


### [223] [VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling](https://arxiv.org/abs/2602.08607)
*Ziyang Cheng,Yuhao Wang,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 该论文提出VocalNet-MDM，一种基于掩码扩散建模的非自回归语音大语言模型，解决了自回归模型的效率限制，实现了3.7-10倍的解码加速和34%的首块延迟降低。


<details>
  <summary>Details</summary>
Motivation: 当前自回归语音大语言模型存在严格串行约束，限制了生成效率并引入了曝光偏差。需要探索非自回归范式来提高语音交互的效率和降低延迟。

Method: 提出VocalNet-MDM，采用掩码扩散建模作为非自回归范式。引入分层块级掩码来对齐训练目标与块扩散解码中的渐进掩码状态，以及迭代自蒸馏来将多步优化压缩到更少步骤以实现低延迟推理。

Result: 仅使用6K小时语音数据训练，VocalNet-MDM实现了3.7-10倍的解码加速，首块延迟降低34%。在保持竞争性识别准确率的同时，实现了最先进的文本质量和语音自然度。

Conclusion: 掩码扩散建模是低延迟、高效语音大语言模型的有前景且可扩展的替代方案，能够显著提升流式语音交互的效率。

Abstract: Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\times$--10$\times$ decoding speedup and reduces first-chunk latency by 34\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.

</details>


### [224] [Do Multilingual LLMs have specialized language heads?](https://arxiv.org/abs/2602.08625)
*Muhammad Naufil*

Main category: cs.CL

TL;DR: 研究探索多语言大语言模型是否具有针对特定语言的注意力头，并尝试移除不需要语言的头而不影响目标语言性能


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在生产部署中效率低下，当只关注部分支持语言时，模型复杂度可能过高。目前缺乏对多语言LLM语言特定注意力头的研究，而这类模型能执行翻译之外的多样化任务

Method: 研究多语言LLM是否具有专门的语言注意力头，并探索移除不需要语言的头而不降低目标语言性能的可能性

Result: 研究发现多语言LLM确实存在语言特定的注意力头，可以移除不需要语言的头而不显著影响目标语言性能

Conclusion: 研究结果为多语言LLM的更高效部署策略提供依据，能够在保持目标语言高准确性的同时减少模型复杂度

Abstract: Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.

</details>


### [225] [Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models](https://arxiv.org/abs/2602.08658)
*Mingzi Cao,Xingwei Tan,Mahmud Akhter,Marco Valentino,Maria Liakata,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 本文研究了如何将演绎、归纳和溯因三种基本推理范式引入大语言模型，并通过符号任务数据集训练模型，在现实任务中实现了显著的泛化性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型的推理能力改进吸引了大量研究关注，但基本推理范式（演绎、归纳、溯因）如何影响模型的泛化能力尚未得到系统探索。本研究旨在揭示这些核心范式之间的相互作用如何影响大语言模型的推理行为。

Method: 首先收集了一个新的符号任务推理轨迹数据集，每个任务针对三种基本推理范式之一，以抽象化具体世界知识。然后研究了将这些技能引入大语言模型的有效方法，包括简单微调、增加模型深度的方法，以及将密集模型转换为专家混合模型等复杂方法。

Result: 在完全用自然语言表述且包含真实世界知识的现实领域外任务上进行全面评估，结果显示该方法具有强大的泛化能力，在现实任务中实现了显著的性能提升（最高达14.60分）。

Conclusion: 通过系统地将基本推理范式引入大语言模型，可以显著提升模型在现实任务中的泛化性能，为改进大语言模型的推理能力提供了有效途径。

Abstract: Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.

</details>


### [226] [Learning to Judge: LLMs Designing and Applying Evaluation Rubrics](https://arxiv.org/abs/2602.08672)
*Clemencia Siro,Pourya Aliannejadi,Mohammad Aliannejadi*

Main category: cs.CL

TL;DR: LLMs能够生成并应用自己的评估标准，但在事实性和知识密集型任务中评分可靠性下降，不同模型间的评估标准存在差异。


<details>
  <summary>Details</summary>
Motivation: 人类定义的评估标准通常是静态的，且与LLMs内部语言质量表示方式不一致。研究者希望探索LLMs是否能够设计和应用自己的评估标准。

Method: 引入GER-Eval方法，研究LLMs能否设计和应用自己的评估标准。评估LLM定义标准的语义连贯性、评分可靠性以及与人类标准的对齐程度。

Result: LLMs能够可靠地生成可解释且任务感知的评估维度，并在模型内部一致应用这些标准。但在事实性和知识密集型设置中，评分可靠性会下降。闭源模型（如GPT-4o）比开源模型（如Llama）具有更高的一致性和跨模型泛化能力。

Conclusion: 评估是LLMs的一种学习到的语言能力，在模型内部一致但在不同模型间存在碎片化。需要开发新的方法来联合建模人类和LLMs的评估语言，以提高可靠性和可解释性。

Abstract: Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.

</details>


### [227] [Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement](https://arxiv.org/abs/2602.08688)
*Hossein Kermani,Fatemeh Oudlajani,Pardis Yarahmadi,Hamideh Mahdi Soltani,Mohammad Makki,Zahra HosseiniKhoo*

Main category: cs.CL

TL;DR: 比较波斯语推文不文明内容检测的三种方法：人工编码、ParsBERT监督学习和大型语言模型（ChatGPT）。在#MahsaAmini运动的47,278条推文上评估，ParsBERT在仇恨言论检测上显著优于ChatGPT模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在比较不同方法在低资源语言（波斯语）环境中检测不文明内容和仇恨言论的效果，为研究人员提供方法选择的指导。

Method: 使用#MahsaAmini运动的47,278条波斯语推文，比较三种方法：1）人工定性编码；2）基于ParsBERT的监督学习；3）七个ChatGPT模型。评估准确性和效率，并测试提示语言（英语vs波斯语）的影响。

Result: ParsBERT在仇恨言论检测上显著优于所有七个ChatGPT模型。ChatGPT不仅在微妙案例上表现不佳，在明确的不文明内容上也存在困难。提示语言（英语vs波斯语）对ChatGPT输出没有显著影响。

Conclusion: 研究详细比较了不同方法在低资源语言环境中分析仇恨言论的优缺点，为相关研究提供了方法选择的参考依据，表明ParsBERT在波斯语不文明内容检测上优于ChatGPT。

Abstract: This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.

</details>


### [228] [Challenges in Translating Technical Lectures: Insights from the NPTEL](https://arxiv.org/abs/2602.08698)
*Basudha Raje,Sadanand Venkatraman,Nandana TP,Soumyadeepa Das,Polkam Poojitha,M. Vijaykumar,Tanima Bagchi,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该研究探讨了机器翻译在孟加拉语、马拉雅拉姆语和泰卢固语等印度语言中的实际应用和方法论意义，重点关注新兴翻译工作流程和现有评估框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于印度语言多样性背景下教育技术的多语言适应需求，特别是NEP 2020政策推动下的教育技术发展。选择这三种语言是基于语言多样性的三角验证，并利用NPTEL大规模开放在线课程平台作为语料库。

Method: 使用NPTEL MOOC平台作为语料库，构建了包含技术概念清晰表达的自发语音语料库，考虑了合适的语域和词汇选择。研究测试了形态丰富、语义紧凑的语言特征对表面重叠度评估指标的敏感性。

Result: 研究发现评估指标存在特定敏感性，形态丰富且语义紧凑的语言特征在表面重叠度指标测试中面临挑战，突显了现有机器翻译评估框架在印度语言应用中的局限性。

Conclusion: 研究强调了在印度这样语言多样的国家，构建适合技术概念清晰表达的自发语音语料库的重要性，并指出需要开发更适应形态丰富语言特征的机器翻译评估方法。

Abstract: This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.

</details>


### [229] [Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search](https://arxiv.org/abs/2602.08700)
*Clemencia Siro,Zahra Abbasiantaeb,Yifei Yuan,Mohammad Aliannejadi,Maarten de Rijke*

Main category: cs.CL

TL;DR: 研究探讨了在对话式搜索系统中，图像增强的澄清问题对用户性能的影响，发现图像效果因任务类型和用户专业水平而异


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究表明文本澄清问题能提升检索性能和用户体验，且图像在其他检索场景中已被证明有效，但图像在澄清问题中对用户性能的影响尚未充分探索

Method: 对73名参与者进行用户研究，比较多模态（图像+文本）和纯文本澄清问题在两种搜索相关任务中的效果：回答澄清问题和查询重构，从多个角度分析影响

Result: 在回答澄清问题时，参与者强烈偏好多模态问题，但纯文本设置下用户表现更好；在查询重构任务中，偏好更平衡，图像能产生更精确的查询并提升检索性能；图像效果受任务类型和用户专业水平影响

Conclusion: 视觉增强的益处具有任务依赖性，应根据具体搜索上下文和用户特征进行战略实施，为设计有效的多模态对话搜索系统提供重要见解

Abstract: Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.

</details>


### [230] [FactSim: Fact-Checking for Opinion Summarization](https://arxiv.org/abs/2602.08709)
*Leandro Anghinoni,Jorge Sanchez*

Main category: cs.CL

TL;DR: 本文提出了一种新的自动化评估方法，用于衡量生成式AI在意见摘要任务中的事实一致性，通过比较摘要中的主张与原始评论的相似性来评估覆盖度和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统基于自动化指标评估生成式AI在文本摘要（特别是意见摘要）任务的方法存在局限性，尤其是在大语言模型带来范式转变的背景下，需要更全面精确的评估技术。

Method: 提出了一种新颖的完全自动化方法，通过提取文本中的事实评估，测量摘要中的主张与原始评论的相似性，从而评估生成摘要的覆盖度和一致性。

Result: 该方法能够为相似的主张分配更高的分数，无论主张是否被否定、改写或扩展，并且与人类判断的相关性高于现有最先进的指标。

Conclusion: 该研究为生成式AI在意见摘要任务中的事实一致性评估提供了一种有效的自动化解决方案，能够更好地评估生成摘要的质量。

Abstract: We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.

</details>


### [231] [PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments](https://arxiv.org/abs/2602.08716)
*Shangrui Nie,Kian Omoomi,Lucie Flek,Zhixue Zhao,Charles Welch*

Main category: cs.CL

TL;DR: PERSPECTRA是一个用于评估大语言模型多元主义能力的基准测试，通过整合Kialo辩论图的结构清晰性和Reddit讨论的语言多样性，构建了包含3,810个扩展论点的数据集，涵盖100个争议话题的762个正反立场。


<details>
  <summary>Details</summary>
Motivation: 多元主义（能够接触不同观点而不将其简化为单一视角）对于开发忠实反映人类多样性的大语言模型至关重要，但这一特性在LLM研究社区中尚未得到仔细检验，且大多数对齐研究中都缺失。现有辩论数据源存在局限性：Reddit提供语言多样性和规模但缺乏清晰的论证结构，Kialo提供明确的正反图但过于简洁且脱离自然话语。

Method: 引入PERSPECTRA基准，通过受控的检索和扩展流程，整合Kialo辩论图的结构清晰性和Reddit讨论的语言多样性。构建了3,810个扩展论点，涵盖100个争议话题的762个正反立场，每个观点扩展到多个自然变体。初始化三个任务：观点计数（识别不同观点）、观点匹配（将支持立场和话语与源观点对齐）、极性检查（推断混合话语中的总体立场）。

Result: 实验使用最先进的开源和专有LLM，揭示了系统性失败，如高估观点数量和对让步结构的错误分类，突显了多元主义感知理解和推理的困难。模型在准确识别、区分和推理多个观点方面存在显著挑战。

Conclusion: PERSPECTRA通过结合多样性和结构，建立了第一个可扩展、可配置的基准，用于评估模型如何代表、区分和推理多个观点。这项工作填补了LLM研究中多元主义评估的空白，为开发更忠实反映人类多样性的语言模型提供了重要工具。

Abstract: Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.

</details>


### [232] [Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy](https://arxiv.org/abs/2602.08740)
*Gaifan Zhang,Danushka Bollegala*

Main category: cs.CL

TL;DR: 提出一种大规模比较和可视化句子编码器的方法，通过创建编码器地图来展示各编码器之间的相对关系。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统性的方法来理解和比较大量公开可用的句子编码器，揭示它们之间的相似性和差异性，为研究者提供编码器选择的指导。

Method: 首先用句子集的嵌入矩阵表示每个编码器，然后计算其成对内积（PIP）矩阵，最后为每个编码器创建反映其与单位基编码器量子相对熵（QRE）的特征向量。

Result: 构建了包含1101个公开句子编码器的地图，准确反映了编码器之间的各种关系，相似属性的编码器在地图上位置相近。编码器特征向量能准确预测编码器在下游任务（如检索和聚类）中的性能。

Conclusion: 该方法成功创建了句子编码器的全面地图，为理解预训练句子编码器的格局提供了新视角，证明了地图的忠实性和实用性。

Abstract: We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.

</details>


### [233] [LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation](https://arxiv.org/abs/2602.08793)
*Yushi Sun,Xujia Li,Nan Tang,Quanqing Xu,Chuanhui Yang,Lei Chen*

Main category: cs.CL

TL;DR: LakeHopper框架通过识别知识差距、聚类选择数据和增量微调，将预训练语言模型从源数据湖迁移到目标数据湖，减少新数据湖的标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的列类型标注方法需要大量标注数据，且针对特定数据湖训练。当面对新数据湖时，需要重新标注大量数据，成本高昂。研究如何将已有模型迁移到新数据湖，最小化新数据湖的标注需求。

Method: 提出LakeHopper框架：1) 通过语言模型交互识别源-目标数据湖之间的知识差距；2) 采用基于聚类的数据选择方案从未标注列中选择信息量大的数据；3) 使用增量微调机制逐步将源模型适应到目标数据湖，避免丢失共享知识。

Result: 在两个不同数据湖迁移任务上验证了LakeHopper的有效性，包括低资源和高资源两种设置。实验结果表明该框架能够成功将源模型迁移到目标数据湖。

Conclusion: LakeHopper框架通过解决知识差距、智能数据选择和增量微调，实现了预训练语言模型在不同数据湖之间的有效迁移，显著减少了新数据湖的标注需求。

Abstract: Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.

</details>


### [234] [Affective Flow Language Model for Emotional Support Conversation](https://arxiv.org/abs/2602.08826)
*Chenghui Zou,Ning Wang,Tiesunlong Shen,Luwei Xiao,Chuan Ma,Xiangpeng Li,Rui Mao,Erik Cambria*

Main category: cs.CL

TL;DR: AFlow框架通过建模多轮对话中的连续情感流，为情感支持对话提供细粒度监督，在策略一致性和共情响应质量上显著超越现有方法，甚至优于GPT-4o和Claude-3.5等专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统依赖稀疏的结果级信号对齐，对中间策略决策的监督有限，导致复杂多轮支持对话效果不佳。

Method: 提出AFlow框架，通过建模多轮轨迹中的连续情感流，引入对话前缀的细粒度监督；使用子路径级流平衡目标传播偏好信号到中间状态，提升策略一致性和共情响应质量。

Result: 在多样情感语境中一致且显著优于竞争基线；紧凑开源骨干的AFlow在主要ESC指标上超越GPT-4o和Claude-3.5等专有大语言模型。

Conclusion: AFlow通过连续情感流建模为情感支持对话提供有效的细粒度监督，显著提升了多轮对话中的策略决策和共情响应质量。

Abstract: Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.

</details>


### [235] [WildReward: Learning Reward Models from In-the-Wild Human Interactions](https://arxiv.org/abs/2602.08829)
*Hao Peng,Yunjia Qi,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: WildReward：直接从用户交互中训练奖励模型，无需人工标注偏好对，性能媲美传统奖励模型


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖大规模人工标注的偏好对，成本高昂。随着大语言模型的广泛部署，用户交互成为丰富的隐式奖励信号来源，能否直接从用户交互中开发奖励模型？

Method: 采用WildChat作为交互源，提出从用户反馈中提取可靠人类反馈的流程，通过序数回归直接在用户反馈上训练WildReward，无需偏好对，获得18.6万高质量训练实例

Result: WildReward在性能上达到甚至超过传统奖励模型，具有更好的校准性和跨样本一致性。模型性能直接受益于用户多样性，用户越多奖励模型越强。应用于在线DPO训练时，在各种任务上都有显著提升

Conclusion: 直接从用户交互中训练奖励模型是可行的，WildReward展示了这种方法的有效性，为奖励模型训练提供了更高效、成本更低的替代方案

Abstract: Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.

</details>


### [236] [Understanding Dynamic Compute Allocation in Recurrent Transformers](https://arxiv.org/abs/2602.08864)
*Ibraheem Muhammad Moosa,Suhas Lohit,Ye Wang,Moitreya Chatterjee,Wenpeng Yin*

Main category: cs.CL

TL;DR: 该研究通过算法和合成语言任务评估令牌级自适应计算，发现计算分配能与任务复杂度对齐但缺乏泛化能力，早期决策依赖静态结构线索而在线停止更接近算法执行状态。


<details>
  <summary>Details</summary>
Motivation: 先前关于令牌级自适应计算的研究主要在自然语言基准上进行任务级评估，其中令牌级难度不可观测且与架构因素混淆，无法确定计算分配是否真正与底层复杂度对齐。

Method: 1) 引入复杂度控制的评估范式，使用参数化难度的算法和合成语言任务；2) 提出ANIRA统一循环Transformer框架，支持每令牌可变深度计算；3) 使用该框架系统分析令牌级自适应计算与复杂度对齐、泛化和决策时序的关系。

Result: 计算分配能与任务复杂度对齐而无需显式难度监督，但这种对齐不意味着算法泛化：模型无法泛化到未见输入大小，尽管分配了额外计算。早期计算决策依赖静态结构线索，而在线停止更接近跟踪算法执行状态。

Conclusion: 令牌级自适应计算能与任务复杂度对齐，但缺乏泛化能力，表明需要更精细的评估方法来理解自适应计算机制及其实际效果。

Abstract: Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.

</details>


### [237] [How Should We Model the Probability of a Language?](https://arxiv.org/abs/2602.08951)
*Rasul Dent,Pedro Ortiz Suarez,Thibault Clérice,Benoît Sagot*

Main category: cs.CL

TL;DR: 论文认为当前语言识别系统覆盖范围有限的问题主要是自找的，源于将LID视为去语境化的文本分类，忽视了先验概率估计的重要性，需要重新将LID定义为路由问题并整合环境线索。


<details>
  <summary>Details</summary>
Motivation: 商业语言识别系统仅能可靠识别几百种书面语言，研究级系统在某些情况下扩展了覆盖范围，但对大多数语言来说覆盖仍然零散或不存在。这种状况主要是由于将LID视为去语境化的文本分类的框架导致的。

Method: 这是一篇立场论文，主张重新思考语言识别问题。建议将LID重新定义为路由问题，并开发系统性的方法来整合环境线索，使语言在局部环境中变得合理。

Result: 论文没有提供具体的实验结果，而是提出了理论框架和分析。指出当前LID方法的问题根源在于去语境化的文本分类框架和机构激励机制偏向于全局、固定先验的模型。

Conclusion: 要提高尾部语言的覆盖范围，需要重新将LID视为路由问题，并开发原则性的方法来整合环境线索，这些线索能使语言在局部环境中变得合理。这需要改变当前的研究范式和方法论。

Abstract: Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.

</details>


### [238] [Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models](https://arxiv.org/abs/2602.08984)
*Yuliang Liu,Yunchong Song,Yixuan Wang,Kewen Ge,Alex Lamb,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出Next Concept Prediction (NCP)生成式预训练范式，通过预测跨多个token的离散概念来构建更具挑战性的预训练目标，相比传统token级模型获得一致性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统Next Token Prediction (NTP)在token级别进行预测，而NCP旨在构建更高级别的概念预测任务，通过引入更难的预训练目标来提升语言模型的能力。

Method: 提出ConceptLM模型，使用Vector Quantization对隐藏状态进行量化，构建概念词汇表。模型同时利用NCP和NTP驱动参数更新，生成概念来指导后续token的生成。在不同规模（70M-1.5B参数）上从头训练，包括Pythia和GPT-2架构。

Result: 在13个基准测试上，NCP相比传统token级模型获得一致性能提升。在8B参数的Llama模型上的持续预训练实验表明，NCP能进一步提升NTP训练的模型。

Conclusion: NCP通过引入更难的预训练任务，能够产生更强大的语言模型，为更好的语言建模提供了有前景的路径。

Abstract: We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [239] [Trojans in Artificial Intelligence (TrojAI) Final Report](https://arxiv.org/abs/2602.07152)
*Kristopher W. Reese,Taylor Kulp-McDowall,Michael Majurski,Tim Blattner,Derek Juba,Peter Bajcsy,Antonio Cardone,Philippe Dessauw,Alden Dima,Anthony J. Kearsley,Melinda Kleczynski,Joel Vasanth,Walid Keyrouz,Chace Ashcraft,Neil Fendley,Ted Staley,Trevor Stout,Josh Carney,Greg Canal,Will Redman,Aurora Schmidt,Cameron Hickert,William Paul,Jared Markowitz,Nathan Drenkow,David Shriver,Marissa Connor,Keltin Grimes,Marco Christiani,Hayden Moore,Jordan Widjaja,Kasimir Gabert,Uma Balakrishnan,Satyanadh Gundimada,John Jacobellis,Sandya Lakkur,Vitus Leung,Jon Roose,Casey Battaglino,Farinaz Koushanfar,Greg Fields,Xihe Gu,Yaman Jandali,Xinqiao Zhang,Akash Vartak,Tim Oates,Ben Erichson,Michael Mahoney,Rauf Izmailov,Xiangyu Zhang,Guangyu Shen,Siyuan Cheng,Shiqing Ma,XiaoFeng Wang,Haixu Tang,Di Tang,Xiaoyi Chen,Zihao Wang,Rui Zhu,Susmit Jha,Xiao Lin,Manoj Acharya,Wenchao Li,Chao Chen*

Main category: cs.CR

TL;DR: IARPA TrojAI项目针对AI木马威胁展开研究，开发检测方法并识别未解决挑战，为AI安全领域提供重要参考。


<details>
  <summary>Details</summary>
Motivation: 应对现代人工智能中新兴的AI木马漏洞威胁，这些恶意后门可导致系统意外失败或被恶意行为者劫持。

Method: 通过权重分析和触发器反演等方法进行检测，并开发部署模型的木马风险缓解方法。

Result: 检测器性能、敏感度评估结果，以及"自然"木马的普遍性发现，提供了全面的测试评估数据。

Conclusion: 总结了项目经验教训，为推进AI安全研究提供建议，强调该领域需要持续关注未解决的挑战。

Abstract: The Intelligence Advanced Research Projects Activity (IARPA) launched the TrojAI program to confront an emerging vulnerability in modern artificial intelligence: the threat of AI Trojans. These AI trojans are malicious, hidden backdoors intentionally embedded within an AI model that can cause a system to fail in unexpected ways, or allow a malicious actor to hijack the AI model at will. This multi-year initiative helped to map out the complex nature of the threat, pioneered foundational detection methods, and identified unsolved challenges that require ongoing attention by the burgeoning AI security field. This report synthesizes the program's key findings, including methodologies for detection through weight analysis and trigger inversion, as well as approaches for mitigating Trojan risks in deployed models. Comprehensive test and evaluation results highlight detector performance, sensitivity, and the prevalence of "natural" Trojans. The report concludes with lessons learned and recommendations for advancing AI security research.

</details>


### [240] [Hydra: Robust Hardware-Assisted Malware Detection](https://arxiv.org/abs/2602.07240)
*Eli Propp,Seyed Majid Zahedi*

Main category: cs.CR

TL;DR: Hydra提出了一种新颖的恶意软件检测机制，通过时间切片和特征集调度策略，在硬件性能计数器监控受限的情况下，用时间粒度换取更广泛的行为覆盖，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 硬件性能计数器（HPCs）用于恶意软件检测时存在一个根本性架构限制：只能同时监控有限数量的事件，这导致检测盲点。现有工作主要关注为静态选择的单一事件集优化机器学习模型，而鲁棒性检测需要不仅多样化模型，还要多样化底层特征集（即监控的硬件事件），以捕获更广泛的程序行为。

Method: 提出Hydra检测机制：将执行轨迹划分为时间切片，学习有效的特征集和相应分类器的部署调度策略。通过循环使用互补的特征集，Hydra缓解了固定监控视角的限制。

Result: 实验评估显示，Hydra显著优于最先进的单特征集基线方法，F1分数提高了19.32%，误报率降低了60.23%。

Conclusion: 特征集多样性对于鲁棒检测至关重要，战略性多特征集调度是硬件辅助恶意软件检测的有效原则。通过用时间粒度换取更广泛覆盖，可以显著提升检测性能。

Abstract: Malware detection using Hardware Performance Counters (HPCs) offers a promising, low-overhead approach for monitoring program behavior. However, a fundamental architectural constraint, that only a limited number of hardware events can be monitored concurrently, creates a significant bottleneck, leading to detection blind spots. Prior work has primarily focused on optimizing machine learning models for a single, statically chosen event set, or on ensembling models over the same feature set. We argue that robustness requires diversifying not only the models, but also the underlying feature sets (i.e., the monitored hardware events) in order to capture a broader spectrum of program behavior. This observation motivates the following research question: Can detection performance be improved by trading temporal granularity for broader coverage, via the strategic scheduling of different feature sets over time? To answer this question, we propose Hydra, a novel detection mechanism that partitions execution traces into time slices and learns an effective schedule of feature sets and corresponding classifiers for deployment. By cycling through complementary feature sets, Hydra mitigates the limitations of a fixed monitoring perspective. Our experimental evaluation shows that Hydra significantly outperforms state-of-the-art single-feature-set baselines, achieving a 19.32% improvement in F1 score and a 60.23% reduction in false positive rate. These results underscore the importance of feature-set diversity and establish strategic multi-feature-set scheduling as an effective principle for robust, hardware-assisted malware detection.

</details>


### [241] [Beyond Crash: Hijacking Your Autonomous Vehicle for Fun and Profit](https://arxiv.org/abs/2602.07249)
*Qi Sun,Ahmed Abdo,Luis Burbano,Ziyang Li,Yaxing Yao,Alvaro Cardenas,Yinzhi Cao*

Main category: cs.CR

TL;DR: JackZebra是首个针对视觉端到端自动驾驶系统的路线级劫持对抗框架，通过可重构显示屏的物理攻击车辆，逐步将受害车辆引导至攻击者选择的目的地。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在安全关键环境中运行，现有物理对抗攻击主要针对即时安全故障（如碰撞、违规），但本文关注一种定性不同的风险：长期路线完整性破坏，攻击者逐步将受害车辆引导至攻击者选择的目的地，同时车辆保持"正常"行驶。

Method: 设计JackZebra对抗框架，使用配备可重构显示屏的物理攻击车辆。核心挑战是时间持久性：对抗影响必须在视角、光照、天气、交通变化及受害者持续重新规划的情况下保持有效。关键见解是将路线劫持视为闭环控制问题，将对抗补丁转换为可通过交互调整循环在线选择的转向原语。

Result: 评估显示JackZebra能够成功劫持受害车辆偏离原始路线，并以高成功率在对抗目的地停止。

Conclusion: 本文展示了自动驾驶系统面临的新型长期路线劫持风险，提出了首个物理可行的路线级对抗攻击框架，揭示了自动驾驶安全需要关注超越即时安全故障的长期完整性威胁。

Abstract: Autonomous Vehicles (AVs), especially vision-based AVs, are rapidly being deployed without human operators. As AVs operate in safety-critical environments, understanding their robustness in an adversarial environment is an important research problem. Prior physical adversarial attacks on vision-based autonomous vehicles predominantly target immediate safety failures (e.g., a crash, a traffic-rule violation, or a transient lane departure) by inducing a short-lived perception or control error. This paper shows a qualitatively different risk: a long-horizon route integrity compromise, where an attacker gradually steers a victim AV away from its intended route and into an attacker-chosen destination while the victim continues to drive "normally." This will not pose a danger to the victim vehicle itself, but also to potential passengers sitting inside the vehicle.
  In this paper, we design and implement the first adversarial framework, called JackZebra, that performs route-level hijacking of a vision-based end-to-end driving stack using a physically plausible attacker vehicle with a reconfigurable display mounted on the rear. The central challenge is temporal persistence: adversarial influence must remain effective in changing viewpoints, lighting, weather, traffic, and the victim's continual replanning -- without triggering conspicuous failures. Our key insight is to treat route hijacking as a closed-loop control problem and to convert adversarial patches into steering primitives that can be selected online via an interactive adjustment loop. Our adversarial patches are also carefully designed against worst-case background and sensor variations so that the adversarial impacts on the victim. Our evaluation shows that JackZebra can successfully hijack victim vehicles to deviate from original routes and stop at adversarial destinations with a high success rate.

</details>


### [242] [Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model](https://arxiv.org/abs/2602.07422)
*Tianyi Wu,Mingzhe Du,Yue Liu,Chengran Yang,Terry Yue Zhuo,Jiaheng Zhang,See-Kiong Ng*

Main category: cs.CR

TL;DR: SecCoderX是一个基于在线强化学习的框架，用于生成功能保持的安全代码，解决了现有方法在安全性和功能性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件开发中应用日益广泛，但其生成不安全代码的倾向阻碍了实际部署。现有安全代码对齐方法存在功能-安全悖论，即提高安全性往往以显著降低功能性为代价。

Method: SecCoderX采用在线强化学习框架，通过两种方式桥接漏洞检测和安全代码生成：1）合成多样化、基于现实的漏洞诱导编码任务用于在线RL展开；2）训练基于推理的漏洞奖励模型，提供可扩展且可靠的安全监督。这些组件在在线RL循环中统一，用于对齐代码LLMs生成安全且功能性的代码。

Result: 广泛实验表明SecCoderX实现了最先进的性能，将有效安全率（ESR）比未对齐模型提高了约10%，而先前方法往往使ESR降低14-54%。

Conclusion: SecCoderX成功解决了功能-安全悖论，为安全代码生成提供了有效的在线强化学习框架，显著提升了代码LLMs的安全性和功能性平衡。

Abstract: Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.

</details>


### [243] [SoK: Credential-Based Trust Management in Decentralized Ledger Systems](https://arxiv.org/abs/2602.07572)
*Yanna Jiang,Haiyu Deng,Qin Wang,Guangsheng Yu,Xu Wang,Yilin Sai,Shiping Chen,Wei Ni,Ren Ping Liu*

Main category: cs.CR

TL;DR: 对基于凭证的去中心化信任管理系统进行系统性综述，分析架构设计、凭证机制和信任评估模型，建立分类体系和评估标准


<details>
  <summary>Details</summary>
Motivation: 随着去中心化系统和区块链的兴起，基于凭证的去中心化信任管理系统变得越来越重要，但理论与实践之间存在差距，需要进行系统性分析

Method: 通过系统性文献综述方法，从多个维度分析现有的DTMS解决方案，包括架构设计、凭证机制和信任评估模型，建立详细的分类体系和全面的评估标准

Result: 提供了基于凭证的DTMS方法的详细分类，建立了评估DTMS实现的综合标准，识别了该领域的关键挑战和有前景的研究方向

Conclusion: 该研究为DTMS领域的研究者和实践者提供了有价值的见解，特别是在访问控制、声誉系统和基于区块链的信任框架等领域，有助于弥合理论与实践之间的差距

Abstract: Trust management systems (TMS) are crucial for managing trust in distributed environments. The rise of decentralized systems and blockchain has sparked interest in credential-based decentralized trust management systems (DTMS). This paper bridges the gap between theory and practice through a systematic review of credential-based DTMS. We analyze existing DTMS solutions through multiple dimensions, including their architectural designs, credential mechanisms, and trust evaluation models. Our survey provides a detailed taxonomy of credential-based DTMS approaches and establishes comprehensive evaluation criteria for assessing DTMS implementations. Through extensive analysis of current systems and implementations, we identify critical challenges and promising research directions in the field. Our examination offers valuable insights for researchers and practitioners working on DTMS, particularly in areas such as access control, reputation systems, and blockchain-based trust frameworks.

</details>


### [244] [Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents](https://arxiv.org/abs/2602.07652)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Yoonpyo Lee,Jay Yoo,Tanzim Ahad,Syed Bahauddin Alam,Sajedul Talukder*

Main category: cs.CR

TL;DR: 论文提出AgentFence框架，用于评估LLM智能体在规划、记忆、工具调用等任务中的安全边界攻击，发现不同架构的智能体安全漏洞率差异显著（0.29-0.51），主要风险来自操作层面的攻击类型。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被部署为具有规划、状态维护和工具调用能力的深度智能体，安全失效从文本不安全转向轨迹不安全，需要系统评估智能体架构的安全边界。

Method: 提出AgentFence架构中心安全评估框架，定义14种信任边界攻击类别，通过轨迹可审计的对话中断检测安全失效，在保持基础模型不变的情况下评估八种智能体架构。

Result: 不同智能体架构的平均安全中断率差异显著（0.29-0.51），最高风险类别为钱包拒绝攻击、授权混淆、检索毒化和规划操纵，安全中断主要由边界违规主导。

Conclusion: AgentFence将智能体安全重新定义为操作层面的问题：智能体是否能在长期运行中保持在目标和权限范围内，揭示了架构设计对安全性的重要影响。

Abstract: Large language models are increasingly deployed as *deep agents* that plan, maintain persistent state, and invoke external tools, shifting safety failures from unsafe text to unsafe *trajectories*. We introduce **AgentFence**, an architecture-centric security evaluation that defines 14 trust-boundary attack classes spanning planning, memory, retrieval, tool use, and delegation, and detects failures via *trace-auditable conversation breaks* (unauthorized or unsafe tool use, wrong-principal actions, state/objective integrity violations, and attack-linked deviations). Holding the base model fixed, we evaluate eight agent archetypes under persistent multi-turn interaction and observe substantial architectural variation in mean security break rate (MSBR), ranging from $0.29 \pm 0.04$ (LangGraph) to $0.51 \pm 0.07$ (AutoGPT). The highest-risk classes are operational: Denial-of-Wallet ($0.62 \pm 0.08$), Authorization Confusion ($0.54 \pm 0.10$), Retrieval Poisoning ($0.47 \pm 0.09$), and Planning Manipulation ($0.44 \pm 0.11$), while prompt-centric classes remain below $0.20$ under standard settings. Breaks are dominated by boundary violations (SIV 31%, WPA 27%, UTI+UTA 24%, ATD 18%), and authorization confusion correlates with objective and tool hijacking ($ρ\approx 0.63$ and $ρ\approx 0.58$). AgentFence reframes agent security around what matters operationally: whether an agent stays within its goal and authority envelope over time.

</details>


### [245] [AirCatch: Effectively tracing advanced tag-based trackers](https://arxiv.org/abs/2602.07656)
*Abhishek Kumar Mishra,Swadeep,Guevara Noubir,Mathieu Cunche*

Main category: cs.CR

TL;DR: AirCatch是一个被动检测系统，利用物理层特征检测恶意蓝牙跟踪器，即使攻击者快速轮换标识符也能有效识别。


<details>
  <summary>Details</summary>
Motivation: 现有的基于协议的防御方案和学术解决方案主要假设标识符稳定或信标可预测，但当攻击者使用高级恶意跟踪器频繁轮换标识符时，这些基于标识符的防御机制会失效。

Method: AirCatch采用三个创新：1) 调制感知的载波频率偏移指纹，增强设备区分度；2) 基于高核心密度和持久性的跟踪检测算法，通过按标识符分段来抵抗污染和规避；3) 超低成本接收器BlePhasyr，使用约10美元的BLE SDR硬件。

Result: 在Apple、Google、Tile和三星标签系列的多小时捕获测试中，AirCatch实现了零误报，并在广泛的对抗配置和环境中实现早期检测，仅在极端低速率情况下性能下降。

Conclusion: AirCatch通过利用物理层约束（载波频率偏移特征）有效检测恶意跟踪器，即使攻击者快速轮换逻辑标识符，其模拟特征仍保持稳定，为资源受限部署提供了实用的RF指纹检测方案。

Abstract: Tag-based tracking ecosystems help users locate lost items, but can be leveraged for unwanted tracking and stalking. Existing protocol-driven defenses and prior academic solutions largely assume stable identifiers or predictable beaconing. However, identifier-based defenses fundamentally break down against advanced rogue trackers that aggressively rotate identifiers. We present AirCatch, a passive detection system that exploits a physical-layer constraint: while logical identifiers can change arbitrarily fast, the transmitter's analog imprint remains stable and reappears as a compact and persistently occupied region in Carrier Frequency Offset (CFO) feature space. AirCatch advances the state of the art along three axes: (i) a novel, modulation-aware CFO fingerprint that augments packet-level CFO with content-independent CFO components that amplify device distinctiveness; (ii) a new tracking detection algorithm based on high core density and persistence that is robust to contamination and evasion through per-identifier segmentation; and (iii) an ultra-low-cost receiver, an approximately 10 dollar BLE SDR named BlePhasyr, built from commodity components, that makes RF fingerprinting based detection practical in resource-constrained deployments. We evaluate AirCatch across Apple, Google, Tile, and Samsung tag families in multi-hour captures, systematically stress-test evasion using a scenario generator over a grid of transmission and rotation periods, and validate in diverse real-world mobility traces including home and office commutes, public transport, car travel, and airport journeys while sweeping background tag density. Across these stress tests, AirCatch achieves no false positives and early detection over a wide range of adversarial configurations and environments, degrading gracefully only in extreme low-rate regimes that also reduce attacker utility.

</details>


### [246] [IPBAC: Interaction Provenance-Based Access Control for Secure and Privacy-Aware Systems](https://arxiv.org/abs/2602.07722)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CR

TL;DR: IPBAC模型通过集成交互溯源与访问控制，解决了传统RBAC系统角色定义僵化、难以处理动态场景、缺乏详细问责和可追溯性等问题。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制系统（包括RBAC）面临角色定义僵化、难以处理动态场景、缺乏详细问责和可追溯性等显著限制，需要更灵活和可追溯的访问控制解决方案。

Method: 提出基于交互溯源的访问控制（IPBAC）模型，将交互溯源与访问控制集成。交互溯源详细记录系统内的操作和交互，捕获包括执行者身份、操作时间、上下文等全面的元数据。

Result: IPBAC确保更强的未授权访问防护，增强审计和合规的可追溯性，支持自适应安全策略。这种基于溯源的访问控制不仅增强了安全性，还为审计和合规提供了稳健框架。

Conclusion: 基于交互溯源的访问控制模型能够有效克服传统访问控制系统的局限性，提供更强的安全性、可追溯性和适应性，为系统安全和合规管理提供了创新解决方案。

Abstract: Traditional access control systems, including RBAC, face significant limitations such as inflexible role definitions, difficulty handling dynamic scenarios, and lack of detailed accountability and traceability. To this end, we introduce the Interaction Provenance-based Access Control (IPBAC) model. In this paper, we explore the integration of interaction provenance with access control to overcome these limitations. Interaction provenance refers to the detailed recording of actions and interactions within a system, capturing comprehensive metadata such as the identity of the actor, the time of an action, and the context. IPBAC ensures stronger protection against unauthorized access, enhances traceability for auditing and compliance, and supports adaptive security policies. This provenance-based access control not only strengthens security, but also provides a robust framework for auditing and compliance.

</details>


### [247] [Leveraging the Power of Ensemble Learning for Secure Low Altitude Economy](https://arxiv.org/abs/2602.07725)
*Yaoqi Yang,Yong Chen,Jiacheng Wang,Geng Sun,Dusit Niyato,Zhu Han*

Main category: cs.CR

TL;DR: 本文探讨了在低空经济(LAE)安全中应用集成学习来防御恶意飞机入侵攻击，通过结合多个模型的优势提高入侵检测系统的准确性、适应性和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 低空经济具有巨大发展潜力，但面临恶意飞机入侵的安全威胁。当前入侵检测系统在LAE的异构数据、动态环境和资源受限设备条件下，存在检测准确性、适应性和资源利用率方面的挑战。

Method: 采用集成学习方法，通过结合多个模型的集体知识来增强异常检测能力。建立了集成学习在安全LAE中的应用框架，包括研究重点、解决方案和案例研究，并提出了一个集成学习支持的恶意飞机追踪框架。

Result: 通过设计的案例研究评估了集成学习框架的可行性和有效性，证明了集成学习能够提高LAE安全系统的鲁棒性和效率，增强对恶意飞机入侵攻击的防御能力。

Conclusion: 集成学习为安全低空经济提供了有效的解决方案，能够克服当前入侵检测系统的局限性。未来需要进一步研究以推进集成学习在安全LAE中的应用发展。

Abstract: Low Altitude Economy (LAE) holds immense promise for enhancing societal well-being and driving economic growth. However, this burgeoning field is vulnerable to security threats, particularly malicious aircraft intrusion attacks. To address the above concerns, intrusion detection systems (IDS) can be used to defend against malicious aircraft intrusions in LAE. Whereas, due to the heterogeneous data, dynamic environment, and resource-constrained devices within LAE, current IDS face challenges in detection accuracy, adaptability, and resource utilization ratio. In this regard, due to the inherent ability to combine the strengths of multiple models, ensemble learning can realize more robust and diverse anomaly detection further enhance IDS accuracy, thereby improving robustness and efficiency of the secure LAE. Unlike single-model approaches, ensemble learning can leverage the collective knowledge of its constituent models to effectively defend the malicious aircraft intrusion attacks. Specifically, this paper investigates ensemble learning for secure LAE, covering research focuses, solutions, and a case study. We first establish the rationale for ensemble learning and then review research areas and potential solutions, demonstrating the necessities and benefits of applying ensemble learning to secure LAE. Subsequently, we propose a framework of ensemble learning-enabled malicious aircrafts tracking in the secure LAE, where its feasibility and effectiveness are evaluated by the designed case study. Finally, we conclude by outlining promising future research directions for further advancing the ensemble learning-enabled secure LAE.

</details>


### [248] [Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model](https://arxiv.org/abs/2602.07878)
*Tianyi Wang,Huawei Fan,Yuanchao Shu,Peng Cheng,Cong Wang*

Main category: cs.CR

TL;DR: 本文揭示传统算法复杂度攻击对现代LLM服务系统无效，提出针对调度器状态转换的"填充与挤压"攻击策略，通过操纵KV缓存和强制抢占实现高效的黑盒攻击。


<details>
  <summary>Details</summary>
Motivation: LLM推理成本高昂，轻微延迟就会导致巨大运营成本和可用性风险。现有研究主要关注通过算法复杂度攻击触发最坏输出长度，但这些攻击对现代LLM服务系统效果有限，需要探索系统层面的攻击方法。

Method: 提出"填充与挤压"攻击策略：1) "填充"阶段耗尽全局KV缓存，诱导队头阻塞；2) "挤压"阶段强制系统进入重复抢占状态。攻击使用从简单文本提示到复杂提示工程的多种方法操纵输出长度，并利用内存状态侧信道探测，可在黑盒设置中以较低成本实施。

Result: 广泛评估显示，与现有攻击相比，该攻击在首令牌时间上实现20-280倍平均减速，在每输出令牌时间上实现1.5-4倍平均减速，同时攻击成本降低30-40%。

Conclusion: 系统级优化如连续批处理虽然能缓解算法攻击的传染性影响，但调度器状态转换成为新的攻击面。提出的"填充与挤压"攻击策略能有效针对现代LLM服务系统，揭示了系统层面的安全漏洞，需要新的防御机制来应对这类攻击。

Abstract: Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency attacks are largely ineffective against modern LLM serving systems. We reveal that system-level optimization such as continuous batching provides a logical isolation to mitigate contagious latency impact on co-located users. To this end, in this paper, we shift the focus from the algorithm to the system layer, and introduce a new Fill and Squeeze attack strategy targeting the state transition of the scheduler. "Fill" first exhausts the global KV cache to induce Head-of-Line blocking, while "Squeeze" forces the system into repetitive preemption. By manipulating output lengths using methods from simple plain-text prompts to more complex prompt engineering, and leveraging side-channel probing of memory status, we demonstrate that the attack can be orchestrated in a black-box setting with much less cost. Extensive evaluations indicate by up to 20-280x average slowdown on Time to First Token and 1.5-4x average slowdown on Time Per Output Token compared to existing attacks with 30-40% lower attack cost.

</details>


### [249] [Privacy-Preserving Covert Communication Using Encrypted Wearable Gesture Recognition](https://arxiv.org/abs/2602.07936)
*Tasnia Ashrafi Heya,Sayed Erfan Arefin*

Main category: cs.CR

TL;DR: 提出首个基于可穿戴设备的隐私保护隐蔽通信系统，使用同态加密实现加密手势识别，防止第三方获取原始传感器数据、学习特征或分类结果


<details>
  <summary>Details</summary>
Motivation: 在隐蔽和安全关键场景中，传统语音通信可能暴露用户意图或操作上下文。现有可穿戴手势通信系统会泄露运动数据、中间表示或推理输出，导致意图推断、行为生物特征泄露和内部攻击风险

Method: 采用多方同态学习管道，直接在加密运动数据上进行手势识别，防止对手推断手势语义、重放传感器轨迹或访问中间表示。设计了触觉和视觉反馈机制用于隐蔽信号传递

Result: 在商用智能手表采集的600个手势样本上评估，分类准确率超过94.44%，证明了系统可行性，可从高性能系统部署到资源受限的边缘设备

Conclusion: 这是首个在可穿戴隐蔽通信场景中应用加密手势识别的工作，通过隐私保护设计确保原始传感器信号、学习特征和分类输出都不会暴露给第三方，实现了实用的可部署性

Abstract: Secure communication is essential in covert and safety-critical settings where verbal interactions may expose user intent or operational context. Wearable gesture-based communication enables low-effort, nonverbal interaction, but existing systems leak motion data, intermediate representations, or inference outputs to untrusted infrastructure, enabling intent inference, behavioral biometric leakage, and insider attacks. This work proposes a privacy-preserving gesture-based covert communication system that ensures, no raw sensor signals, learned features, or classification outputs are exposed to any third-party. The system employs a multi-party homomorphic learning pipeline for gesture recognition directly over encrypted motion data, preventing adversaries from inferring gesture semantics, replaying sensor traces, or accessing intermediate representations. To our knowledge, this work is the first to apply encrypted gesture recognition in a wearable-based covert communication setting. We design and evaluate haptic and visual feedback mechanisms for covert signal delivery and evaluate the system using 600 gesture samples from a commodity smartwatch, achieving over 94.44% classification accuracy and demonstrating the feasibility of the proposed system with practical deployability from high-performance systems to resource-constrained edge devices.

</details>


### [250] [IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports](https://arxiv.org/abs/2602.08072)
*Md Nafiu Rahman,Sadif Ahmed,Zahin Wahab,Gias Uddin,Rifat Shahriyar*

Main category: cs.CR

TL;DR: IssueGuard是一个Chrome扩展工具，用于实时检测和防止GitHub/GitLab问题报告中意外泄露API密钥等敏感信息，结合正则表达式和微调CodeBERT模型，达到92.70%的F1分数。


<details>
  <summary>Details</summary>
Motivation: GitHub和GitLab等协作平台的issue跟踪系统包含大量非结构化文本（日志、代码片段、配置示例），存在意外泄露API密钥和凭证的风险，但这些平台没有提供提交前的警告机制。

Method: 实现为Chrome扩展，结合基于正则表达式的候选提取和微调的CodeBERT模型进行上下文分类，直接在Web界面中持续分析issue编辑器，提供清晰的视觉警告。

Result: 在基准数据集上达到92.70%的F1分数，优于传统的基于正则表达式的扫描器，能有效区分真实密钥和误报。

Conclusion: IssueGuard是一个有效的实时秘密泄露检测工具，通过上下文感知的分类方法提高了准确性，帮助用户在提交前避免敏感数据泄露。

Abstract: GitHub and GitLab are widely used collaborative platforms whose issue-tracking systems contain large volumes of unstructured text, including logs, code snippets, and configuration examples. This creates a significant risk of accidental secret exposure, such as API keys and credentials, yet these platforms provide no mechanism to warn users before submission. We present \textsc{IssueGuard}, a tool for real-time detection and prevention of secret leaks in issue reports. Implemented as a Chrome extension, \textsc{IssueGuard} analyzes text as users type and combines regex-based candidate extraction with a fine-tuned CodeBERT model for contextual classification. This approach effectively separates real secrets from false positives and achieves an F1-score of 92.70\% on a benchmark dataset, outperforming traditional regex-based scanners. \textsc{IssueGuard} integrates directly into the web interface and continuously analyzes the issue editor, presenting clear visual warnings to help users avoid submitting sensitive data. The source code is publicly available at \href{https://github.com/nafiurahman00/IssueGuard}{https://github.com/nafiurahman00/IssueGuard}, and a demonstration video is available at \href{https://youtu.be/kvbWA8rr9cU}{https://youtu.be/kvbWA8rr9cU}.

</details>


### [251] [A Transfer Learning Approach to Unveil the Role of Windows Common Configuration Enumerations in IEC 62443 Compliance](https://arxiv.org/abs/2602.08165)
*Miguel Bicudo,Estevão Rabello,Daniel Menasché,Paulo Segal,Claudio Segal,Anton Kocheturov,Priyanjan Sharma*

Main category: cs.CR

TL;DR: 提出一种迁移学习方法，将Windows配置枚举映射到IEC 62443-3-3安全标准，利用Linux数据集实现自动化合规检查


<details>
  <summary>Details</summary>
Motivation: 工业控制系统环境高度异构，包含Linux、专有实时系统和Windows。虽然IEC 62443-3-3标准提供了全面的安全框架，但将其要求转化为具体的配置检查仍然具有挑战性，特别是对于Windows平台。

Method: 采用迁移学习方法，将Windows通用配置枚举映射到IEC 62443-3-3系统安全要求，利用已标记的Linux数据集来训练模型。

Result: 生成了标记的数据集，支持自动化合规检查、需求流行度分析，并识别了跨平台的相似性和差异性。CCE成为连接抽象标准和具体配置的桥梁。

Conclusion: 该方法推进了Windows环境中IEC 62443-3-3合规的自动化、可追溯性和清晰度，为异构工业控制系统安全提供了实用解决方案。

Abstract: Industrial control systems (ICS) depend on highly heterogeneous environments where Linux, proprietary real-time operating systems, and Windows coexist. Although the IEC 62443-3-3 standard provides a comprehensive framework for securing such systems, translating its requirements into concrete configuration checks remains challenging, especially for Windows platforms. In this paper, we propose a transfer learning methodology that maps Windows Common Configuration Enumerations (CCEs) to IEC 62443-3-3 System Security Requirements by leveraging labeled Linux datasets. The resulting labeled dataset enables automated compliance checks, analysis of requirement prevalence, and identification of cross-platform similarities and divergences. Our results highlight the role of CCEs as a bridge between abstract standards and concrete configurations, advancing automation, traceability, and clarity in IEC 62443-3-3 compliance for Windows environments.

</details>


### [252] [Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4](https://arxiv.org/abs/2602.08384)
*Jianyu Zhang,Fuyuan Zhang,Jiayi Lu,Jilin Hu,Xiaoyi Yin,Long Zhang,Feng Yang,Yongwang Zhao*

Main category: cs.CR

TL;DR: AutoReal：一种面向工业级系统验证的LLM驱动定理证明方法，通过CoT训练和上下文增强，在7B参数规模上实现51.67%的seL4定理证明成功率


<details>
  <summary>Details</summary>
Motivation: 传统形式化方法成本高昂，需要专家多年努力；现有LLM定理证明研究多集中于数学基准，对工业级验证项目评估有限；大型闭源模型无法本地部署且成本高

Method: 提出AutoReal方法：1) 基于思维链的证明训练，教LLM理解证明步骤背后的推理过程；2) 上下文增强，利用项目中的证明上下文提升证明能力。基于该方法微调得到7B参数的AutoReal-Prover

Result: 在seL4验证项目中，AutoReal-Prover在660个重要定理上达到51.67%的证明成功率，显著优于之前27.06%的结果；在AFP的三个安全项目中，对451个定理达到53.88%的证明成功率

Conclusion: AutoReal推动了LLM驱动定理证明在真实工业级验证中的应用，实现了轻量级本地部署，在工业规模系统验证中表现出色

Abstract: Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification.

</details>


### [253] [LLMs + Security = Trouble](https://arxiv.org/abs/2602.08422)
*Benjamin Livshits*

Main category: cs.CR

TL;DR: 论文主张通过约束解码在代码生成阶段直接强制执行安全约束，而非依赖后验检测修复，以解决AI生成代码的安全漏洞长尾问题


<details>
  <summary>Details</summary>
Motivation: 当前使用概率性AI检查器或攻击者来保护概率生成代码的"以火攻火"方法无法解决安全漏洞的长尾问题，系统仍可能暴露于零日漏洞。神经符号方法虽然理论上吸引人，但难以与LLM辅助开发中常见的"氛围编码"工作流协调，需要人工干预会破坏安全构造保证。

Method: 提出在代码生成阶段通过约束解码强制执行安全约束，特别针对扩散式代码模型，利用其模块化、分层特性实现安全构造代码的生成

Result: 该方法为AI生成代码提供了更强的安全保证，能够更有效地处理安全漏洞的长尾问题，同时保持较低的生成延迟

Conclusion: 在代码生成阶段直接强制执行安全约束比后验检测修复方法能提供更强的安全保障，扩散式代码模型为此提供了优雅的实现途径，有望实现安全构造代码的生成

Abstract: We argue that when it comes to producing secure code with AI, the prevailing "fighting fire with fire" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.
  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the "vibe coding" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.
  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.

</details>


### [254] [Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion](https://arxiv.org/abs/2602.08668)
*Scott Thornton*

Main category: cs.CR

TL;DR: 混合检索增强生成(RAG)管道结合向量相似性搜索和知识图谱扩展进行多跳推理，但存在安全风险：向量检索的"种子"块可通过实体链接访问敏感图谱邻域，导致跨租户数据泄露。


<details>
  <summary>Details</summary>
Motivation: 混合RAG管道结合向量搜索和知识图谱扩展，但这种组合引入了新的安全漏洞模式：向量检索的"种子"块可通过实体链接访问敏感图谱邻域，导致跨租户数据泄露，这在纯向量检索中不会发生。

Method: 1. 形式化定义检索枢轴风险(RPR)；2. 引入Leakage@k、放大因子和枢轴深度(PD)等指标量化泄露程度；3. 提出七种检索枢轴攻击方法；4. 在合成多租户企业语料库和Enron邮件语料库上进行实验；5. 在图谱扩展边界实施授权控制。

Result: 1. 未防御的混合管道枢轴风险高达0.95，每个查询返回多个未授权项；2. 泄露通常出现在PD=2处，这与二分块-实体拓扑结构有关；3. 在图谱扩展边界实施授权后，RPR接近0，泄露被消除；4. 即使标签伪造率高达10%，防御仍有效，且开销最小。

Conclusion: 混合RAG管道的安全漏洞根源在于边界授权缺失，而非组件本身不安全。两个单独安全的检索组件组合后可能形成不安全系统，必须在过渡点重新检查授权。在图谱扩展边界实施授权可有效消除跨租户数据泄露风险。

Abstract: Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved "seed" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure.
  We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition.
  We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point.

</details>


### [255] [Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing](https://arxiv.org/abs/2602.08741)
*Jona te Lintelo,Lichao Wu,Stjepan Picek*

Main category: cs.CR

TL;DR: 本文提出了一种名为Large Language Lobotomy (L³)的训练免费、架构无关的攻击方法，通过利用MoE LLMs中的专家路由动态来破坏安全对齐，能够将攻击成功率从7.3%提升至70.4%。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然提高了LLMs的扩展效率，但其路由结构引入了新的安全攻击面。研究发现MoE LLMs中的安全关键行为（如拒绝回答）集中在少数专家中而非均匀分布，这为攻击提供了机会。

Method: 提出L³攻击方法：1）学习与拒绝行为相关的路由模式；2）将安全行为归因于特定专家；3）自适应地沉默最相关的安全专家直到产生有害输出。该方法无需训练且架构无关。

Result: 在8个最先进的开源MoE LLMs上评估，自适应专家沉默将平均攻击成功率从7.3%提升至70.4%，最高达86.3%，优于先前的训练免费MoE越狱方法。绕过防护通常只需沉默少于20%的层级专家，同时基本保留语言通用能力。

Conclusion: 研究揭示了MoE设计中效率驱动与鲁棒安全对齐之间的根本矛盾，并建议未来MoE LLMs应采用架构和路由感知的方法更鲁棒地分布安全机制。

Abstract: The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L$^3$), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L$^3$ learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L$^3$ on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.

</details>


### [256] [DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing](https://arxiv.org/abs/2602.08750)
*Guy Farrelly,Michael Chesser,Seyit Camtepe,Damith C. Ranasinghe*

Main category: cs.CR

TL;DR: DyMA-Fuzz是一个针对嵌入式系统固件测试的模糊测试框架，专门处理DMA（直接内存访问）接口，解决了现有工具忽略DMA的问题，通过运行时分析自动注入测试数据，显著提高了代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 随着智能设备在关键领域（汽车、医疗、工业）的普及，需要强大的固件测试。现有模糊测试框架主要处理内存映射I/O和中断输入，但忽略了DMA这一关键的高吞吐量接口，而DMA绕过CPU直接访问内存，是固件测试的重要挑战。

Method: DyMA-Fuzz将基于流的模糊测试输入注入扩展到重托管环境中的DMA驱动接口。它使用运行时分析技术来推断DMA内存访问模式，自动将模糊测试数据注入目标缓冲区，无需手动配置或数据手册。解决了供应商特定描述符、异构DMA设计和不同描述符位置等关键挑战。

Result: 在94个固件样本和8个DMA保护的CVE基准测试中，DyMA-Fuzz发现了现有最先进工具遗漏的漏洞和执行路径，实现了高达122%的代码覆盖率提升。

Conclusion: DyMA-Fuzz是自动固件测试的实用有效进展，为模糊测试复杂嵌入式系统提供了可扩展的解决方案，显著提升了DMA接口的测试覆盖能力。

Abstract: The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems.

</details>


### [257] [CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse](https://arxiv.org/abs/2602.08798)
*Hedong Zhang,Neusha Javidnia,Shweta Pardeshi,Qian Lou,Farinaz Koushanfar*

Main category: cs.CR

TL;DR: CryptoGen是首个支持可扩展隐私保护神经生成的系统，通过安全重用加密的KV缓存，在不可信服务器环境中保护用户提示和模型参数的隐私。


<details>
  <summary>Details</summary>
Motivation: 云托管生成模型的广泛部署带来了基本挑战：如何在不可信环境中实现高效的自回归生成，同时保护用户提示和模型参数的隐私。现有判别任务安全推理系统在适应自回归解码时存在二次方延迟和内存增长问题。

Method: CryptoGen整合同态加密和秘密共享，支持预填充和生成阶段。关键技术包括统一的加密KV缓存框架、针对不同阶段的异构SIMD编码、优化的密文-密文矩阵-矩阵和矩阵-向量操作，以及高效的噪声刷新和密文连接机制。

Result: 在WikiText-2、PTB和LAMBADA数据集训练的生成Transformer模型上评估，对于128-512个令牌的输入长度，CryptoGen相比最先进的判别安全推理系统实现了4.4x-7.6x更低的每令牌延迟，同时保持接近线性的延迟和内存扩展，对于更长序列优势更明显。

Conclusion: CryptoGen通过安全重用和更新加密KV缓存，实现了接近线性的扩展，是首个支持可扩展隐私保护神经生成的系统，已作为开源库发布。

Abstract: The widespread deployment of cloud-hosted generative models raises a fundamental challenge: enabling efficient autoregressive generation while preserving the privacy of both user prompts and model parameters in untrusted environments. We address this challenge in a client-server setting where an untrusted server hosts an autoregressive Transformer and the client requires cryptographic protection for both inputs and inference. We present CryptoGen, the first system to enable scalable privacy-preserving neural generation with persistent encrypted key-value (KV) cache reuse. Discriminative-task secure inference systems incur quadratic latency and memory growth when adapted to autoregressive decoding due to the lack of native encrypted KV-cache support. In contrast, CryptoGen achieves near-linear scaling by securely reusing and updating encrypted KV caches throughout generation. CryptoGen integrates homomorphic encryption and secret sharing to support both prefilling and generation. Key techniques include a unified encrypted KV-cache framework, heterogeneous SIMD encodings for different phases, optimized cipher-cipher matrix-matrix and matrix-vector operations, and efficient noise refresh and ciphertext concatenation mechanisms. Evaluation on generative Transformer models trained on WikiText-2, PTB, and LAMBADA shows that for input lengths of 128-512 tokens, CryptoGen achieves 4.4x-7.6x lower per-token latency than state-of-the-art discriminative secure inference systems, while maintaining near-linear latency and memory scaling, with advantages increasing for longer sequences. CryptoGen is released as an open-source library.

</details>


### [258] [Reverse Online Guessing Attacks on PAKE Protocols](https://arxiv.org/abs/2602.08993)
*Eloise Christian,Tejas Gadwalkar,Arthur Azevedo de Amorim,Edward V. Zieglar*

Main category: cs.CR

TL;DR: 论文重新评估了PAKE协议模型，指出缺乏PKI或服务器认证机制使得协议易受反向在线猜测攻击，攻击者通过冒充服务器来验证密码猜测，这种攻击在钓鱼、密码喷洒等场景中特别有效。


<details>
  <summary>Details</summary>
Motivation: 尽管PAKE协议因抵抗各种猜测攻击且不需要PKI而受到标准化关注，但作者发现缺乏PKI或服务器认证机制实际上使协议容易受到反向在线猜测攻击，这种攻击将检测负担转移到客户端，现有防御机制失效。

Method: 通过重新评估PAKE模型，分析反向在线猜测攻击的逻辑和风险，特别关注攻击者冒充服务器验证密码猜测的场景，以及这种攻击在钓鱼、密码喷洒、自动化登录流程等场景中的有效性。

Result: 研究表明反向猜测攻击在攻击者无差别攻击客户端时特别有效，如钓鱼攻击或密码喷洒攻击，或用于具有自动化登录流程或通用密码的应用（如WPA3-SAE）。

Conclusion: 利益相关者应默认使用比用户密码更严格的措施来认证服务器，仅密码模式应作为其他认证机制不可用时的最后手段，以应对灾难性安全故障。

Abstract: Though not yet widely deployed, password-authenticated key exchange (PAKE) protocols have been the subject of several recent standardization efforts, partly because of their resistance against various guessing attacks, but also because they do not require a public-key infrastructure (PKI), making them naturally resistant against PKI failures. The goal of this paper is to reevaluate the PAKE model by noting that the absence of a PKI -- or, more generally, of a mechanism aside from the password for authenticating the server -- makes such protocols vulnerable to reverse online guessing attacks, in which an adversary attempts to validate password guesses by impersonating a server. While their logic is similar to traditional guessing, where the attacker impersonates a client, reverse guessing poses a unique risk because the burden of detection is shifted to the clients, rendering existing defenses against traditional guessing moot. Our results demonstrate that reverse guessing is particularly effective when an adversary attacks clients indiscriminately, such as in phishing or password-spraying attacks, or for applications with automated login processes or a universal password, such as WPA3-SAE. Our analysis suggests that stakeholders should, by default, authenticate the server using more stringent measures than just the user's password, and that a password-only mode of operation should be a last resort against catastrophic security failures when other authentication mechanisms are not available.

</details>


### [259] [Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks](https://arxiv.org/abs/2602.07090)
*Yu-Che Tsai,Hsiang Hsiao,Kuan-Yu Chen,Shou-De Lin*

Main category: cs.CR

TL;DR: SPARSE是一个用户中心的文本嵌入隐私保护框架，通过可微分掩码学习和椭圆噪声注入，针对用户定义的概念选择性扰动隐私敏感维度，在保护隐私的同时保持下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入面临严重的隐私风险，特别是嵌入反转攻击可能暴露敏感属性或重建原始文本。现有的差分隐私防御方法假设所有嵌入维度具有均匀敏感性，导致噪声过大和效用下降。

Method: SPARSE结合了两种技术：(1) 可微分掩码学习，用于识别用户定义概念的隐私敏感维度；(2) Mahalanobis机制，根据维度敏感性校准椭圆噪声注入。与传统球形噪声注入不同，SPARSE选择性扰动隐私敏感维度，同时保留非敏感语义。

Result: 在六个数据集、三种嵌入模型和多种攻击场景下的评估表明，SPARSE能持续减少隐私泄露，同时在性能上优于最先进的差分隐私方法。

Conclusion: SPARSE提供了一个有效的概念特定隐私保护框架，通过维度敏感的噪声注入，在文本嵌入中实现了更好的隐私-效用权衡。

Abstract: Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks, which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings. SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.

</details>


### [260] [ShallowJail: Steering Jailbreaks against Large Language Models](https://arxiv.org/abs/2602.07107)
*Shang Liu,Hanyu Pei,Zeyan Liu*

Main category: cs.CR

TL;DR: ShallowJail是一种利用大语言模型浅层对齐漏洞的新型越狱攻击方法，通过操纵推理过程中的初始令牌来误导模型产生有害输出


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击要么是黑盒方法（使用精心设计但不隐蔽的提示），要么是白盒方法（需要大量计算资源），需要一种更有效且隐蔽的攻击方式

Method: ShallowJail通过利用LLMs的浅层对齐漏洞，在推理过程中操纵初始令牌来误导模型响应

Result: 实验证明ShallowJail能显著降低最先进LLM的安全性，有效误导模型产生有害输出

Conclusion: ShallowJail揭示了大语言模型浅层对齐的脆弱性，为模型安全防护提出了新的挑战

Abstract: Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are either black-box, using carefully crafted, unstealthy prompts, or white-box, requiring resource-intensive computation. In light of these challenges, we introduce ShallowJail, a novel attack that exploits shallow alignment in LLMs. ShallowJail can misguide LLMs' responses by manipulating the initial tokens during inference. Through extensive experiments, we demonstrate the effectiveness of~\shallow, which substantially degrades the safety of state-of-the-art LLM responses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [261] [ST-Raptor: An Agentic System for Semi-Structured Table QA](https://arxiv.org/abs/2602.07034)
*Jinxiu Qu,Zirui Tang,Hongzhang Huang,Boyu Niu,Wei Zhou,Jiannan Wang,Yitong Song,Guoliang Li,Xuanhe Zhou,Fan Wu*

Main category: cs.AI

TL;DR: ST-Raptor是一个用于半结构化表格问答的智能体系统，通过视觉编辑、树状结构建模和智能体驱动查询解决，在准确性和可用性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 半结构化表格问答需要精确提取单元格内容和位置，并恢复表格布局中隐含的逻辑结构、层次关系和语义关联。现有方法存在信息丢失、处理复杂布局困难等问题，人工解释又耗时耗力。

Method: ST-Raptor提供了一个交互式分析环境，结合视觉编辑、基于树的结构建模和智能体驱动的查询解决，支持准确且用户友好的表格理解。

Result: 在基准数据集和真实世界数据集上的实验结果表明，ST-Raptor在准确性和可用性方面均优于现有方法。

Conclusion: ST-Raptor通过智能体系统有效解决了半结构化表格问答的挑战，提供了比现有方法更准确、更易用的解决方案。

Abstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.

</details>


### [262] [PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents](https://arxiv.org/abs/2602.07187)
*Hanyu Wang,Yuanpu Cao,Lu Lin,Jinghui Chen*

Main category: cs.AI

TL;DR: PreFlect提出前瞻性反思机制，在计划执行前进行批评和优化，相比传统后验性反思显著提升智能体性能


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型智能体的反思机制本质上是回顾性的：智能体先行动，观察到失败后才尝试恢复。这种后验性方法存在效率问题，需要在执行前就进行前瞻性规划优化。

Method: 1. 前瞻性反思机制：在执行前对智能体计划进行批评和优化；2. 从历史轨迹中提炼规划错误模式；3. 动态重规划机制：在执行过程中遇到意外偏差时实时更新计划

Result: 在不同基准测试中，PreFlect显著提升了复杂现实任务中的智能体效用，优于基于反思的基线方法和多个更复杂的智能体架构

Conclusion: 前瞻性反思机制比传统后验性反思更有效，通过执行前优化计划和执行中动态调整，显著提升智能体在复杂任务中的性能

Abstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.

</details>


### [263] [Is there "Secret Sauce'' in Large Language Model Development?](https://arxiv.org/abs/2602.07238)
*Matthias Mertens,Natalia Fischl-Lanzoni,Neil Thompson*

Main category: cs.AI

TL;DR: 研究发现，在AI模型性能前沿，80-90%的性能差异由训练计算量解释，而非专有技术；但在非前沿领域，专有技术和共享算法进步显著降低达到特定能力所需的计算量。


<details>
  <summary>Details</summary>
Motivation: 探究领先LLM开发者是否拥有专有"秘方"，还是LLM性能主要由计算规模驱动，以理解AI领导力和能力扩散的机制。

Method: 使用2022-2025年间发布的809个模型的训练和基准测试数据，通过包含发布日期和开发者固定效应的缩放定律回归进行分析。

Result: 1) 存在开发者特定的效率优势，但其重要性取决于模型在性能分布中的位置；2) 在性能前沿，80-90%的性能差异由更高训练计算量解释；3) 在非前沿领域，专有技术和共享算法进步显著降低计算需求；4) 公司内部模型效率存在巨大差异（可达40倍以上）。

Conclusion: 前沿AI进步主要由计算规模驱动而非专有技术，但专有技术在非前沿领域仍能显著提高效率；公司内部效率差异巨大，这对AI领导力和能力扩散具有重要启示。

Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.

</details>


### [264] [From Out-of-Distribution Detection to Hallucination Detection: A Geometric View](https://arxiv.org/abs/2602.07253)
*Litian Liu,Reza Pourreza,Yubing Jian,Yao Qin,Roland Memisevic*

Main category: cs.AI

TL;DR: 该研究将大语言模型的幻觉检测重新定义为分布外检测问题，提出无需训练、基于单样本的检测方法，在推理任务中实现强准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的幻觉检测是一个关键开放问题，对安全性和可靠性有重要影响。现有方法在问答任务中表现良好，但在需要推理的任务中效果较差。研究者希望通过分布外检测的视角重新审视幻觉检测问题。

Method: 将语言模型的下一词预测视为分类任务，应用分布外检测技术，并对大语言模型的结构差异进行适当修改。该方法无需训练，仅需单样本即可进行检测。

Result: 基于分布外检测的方法在推理任务的幻觉检测中实现了强准确性，证明了该方法的有效性。

Conclusion: 将幻觉检测重新定义为分布外检测问题，为大语言模型安全提供了一个有前景且可扩展的途径。

Abstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.

</details>


### [265] [Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective](https://arxiv.org/abs/2602.07259)
*Cheol Woo Kim,Davin Choo,Tzeh Yuan Neoh,Milind Tambe*

Main category: cs.AI

TL;DR: 论文提出将AI安全视为Stackelberg安全博弈问题，强调需要从静态优化转向动态战略监督，考虑开发部署中的对抗性激励问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全框架主要将对齐视为静态优化问题，忽略了数据收集、模型评估和部署过程中的动态对抗性激励。随着AI系统能力增强，需要不仅关注模型层面的对齐，还要对参与开发和部署的人类和机构进行战略监督。

Method: 提出基于Stackelberg安全博弈的新视角，将AI监督视为防御者（审计员、评估者、部署者）与攻击者（恶意行为者、未对齐贡献者、最坏情况故障模式）之间的战略互动。该框架为AI生命周期中的激励设计、有限监督能力和对抗性不确定性提供统一分析工具。

Result: 该框架可应用于：(1) 训练时审计数据/反馈投毒，(2) 有限评审资源下的预部署评估，(3) 对抗环境中的鲁棒多模型部署。将算法对齐与机构监督设计相结合，使AI监督更具前瞻性、风险意识和抗操纵能力。

Conclusion: Stackelberg安全博弈为AI安全提供了统一框架，强调通过博弈论威慑使AI监督更加主动、风险感知和抗操纵，填补了算法对齐与机构监督设计之间的空白。

Abstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.

</details>


### [266] [BRIDGE: Predicting Human Task Completion Time From Model Performance](https://arxiv.org/abs/2602.07267)
*Fengyuan Liu,Jay Gala,Nilaksh,Dzmitry Bahdanau,Siva Reddy,Hugo Larochelle*

Main category: cs.AI

TL;DR: BRIDGE框架通过模型响应学习任务难度，并将其与人类完成时间对齐，实现仅从模型性能推断人类任务完成时间


<details>
  <summary>Details</summary>
Motivation: 现有基于人类任务完成时间的基准评估方法成本高、噪声大、难以扩展，需要一种可扩展的方法来将模型性能与人类可解释的任务难度联系起来

Method: 使用双参数逻辑项目反应理论模型，从多个基准的模型性能数据中联合估计潜在任务难度和模型能力，发现潜在任务难度与人类完成时间的对数呈线性关系

Result: 潜在任务难度与人类完成时间的对数呈线性关系，可以从模型性能单独推断新基准的人类任务完成时间；前沿模型能力预测显示，50%可解决任务范围大约每6个月翻倍

Conclusion: BRIDGE提供了一个统一的心理测量框架，能够从模型响应中学习任务难度并将其锚定到人类任务完成时间，为AI系统真实世界能力评估提供了可扩展的方法

Abstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.

</details>


### [267] [Progressive Multi-Agent Reasoning for Biological Perturbation Prediction](https://arxiv.org/abs/2602.07408)
*Hyomin Kim,Sang-Yeon Hwang,Jaechang Lim,Yinhua Piao,Yunhak Oh,Woo Youn Kim,Chanyoung Park,Sungsoo Ahn,Junhyeok Jeon*

Main category: cs.AI

TL;DR: LINCSQA是用于预测批量细胞化学扰动下靶基因调控的新基准，PBio-Agent是一个多智能体框架，通过难度感知任务排序和迭代知识精炼来提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单细胞遗传扰动，而药物发现核心的批量细胞化学扰动研究不足。大语言模型在处理高维扰动结果时容易被纠缠的生物学关系淹没，需要新的方法来解决这一挑战。

Method: 提出PBio-Agent多智能体框架，包含难度感知任务排序和迭代知识精炼。关键洞见是：受相同扰动影响的基因共享因果结构，使置信预测的基因能为更困难案例提供上下文。框架使用生物知识图谱增强的专门智能体，合成智能体整合输出，专门判断器确保逻辑一致性。

Result: PBio-Agent在LINCSQA和PerturbQA基准上均优于现有基线方法，即使较小的模型也能在没有额外训练的情况下预测和解释复杂的生物过程。

Conclusion: 该工作填补了批量细胞化学扰动预测的空白，提出的多智能体框架通过利用基因间的因果结构共享，有效解决了高维扰动结果的复杂性挑战，为药物发现提供了有力工具。

Abstract: Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.

</details>


### [268] [TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents](https://arxiv.org/abs/2602.07274)
*Kaijie Zhu,Yuzhou Nie,Yijiang Li,Yiming Huang,Jialian Wu,Jiang Liu,Ximeng Sun,Zhenfei Yin,Lun Wang,Zicheng Liu,Emad Barsoum,William Yang Wang,Wenbo Guo*

Main category: cs.AI

TL;DR: TermiGen是一个端到端管道，用于合成可验证的终端环境和弹性专家轨迹，通过多智能体迭代生成有效任务和Docker容器，并使用生成器-批评器协议注入错误来训练模型，最终在TerminalBench上达到31.3%的通过率，创造了新的开源模型最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前开源大语言模型在执行复杂终端任务时面临两大限制：1）缺乏高保真、可执行的训练环境，现有环境要么不够多样化和可扩展，要么存在幻觉问题；2）标准指令调优使用的专家轨迹很少包含小模型常见的简单错误，导致学生模型无法有效从自身运行时错误中恢复。

Method: TermiGen采用端到端管道：首先通过迭代多智能体精炼循环生成功能有效的任务和Docker容器；然后使用生成器-批评器协议，在轨迹收集过程中主动注入错误，合成富含错误纠正循环的数据。最后使用这些数据对模型进行微调。

Result: 使用TermiGen生成的数据集微调的TermiGen-Qwen2.5-Coder-32B模型在TerminalBench上达到了31.3%的通过率，创造了新的开源模型最佳性能，甚至超过了o4-mini等专有模型。

Conclusion: TermiGen通过合成可验证环境和弹性专家轨迹，有效解决了开源大语言模型在终端任务训练中的环境稀缺和分布不匹配问题，显著提升了模型在复杂终端任务上的执行能力。

Abstract: Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.

</details>


### [269] [Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs](https://arxiv.org/abs/2602.07276)
*Pengrui Han,Xueqiang Xu,Keyang Xuan,Peiyang Song,Siru Ouyang,Runchu Tian,Yuqing Jiang,Cheng Qian,Pengcheng Jiang,Jiashuo Sun,Junxia Cui,Ming Zhong,Ge Liu,Jiawei Han,Jiaxuan You*

Main category: cs.AI

TL;DR: STEER2ADAPT：一个轻量级框架，通过组合而非从头学习新的引导向量来适配大语言模型，利用可重用的低维语义先验子空间，仅需少量示例即可动态发现基向量的线性组合。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法大多依赖每个任务或概念的单一静态方向，在任务变化时不够灵活，且无法处理需要多个协调能力的复杂任务。

Method: 提出STEER2ADAPT框架，将任务共享的底层概念维度捕获为可重用的低维语义先验子空间，通过少量示例动态发现基向量的线性组合来适配新任务。

Result: 在9个任务和3个模型的推理和安全领域实验中，平均提升8.2%，证明该方法具有数据效率高、稳定性好和透明度高的特点。

Conclusion: STEER2ADAPT是一种有效的数据高效、稳定且透明的推理时适配方法，能够通过组合现有引导向量来灵活适应复杂任务。

Abstract: Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.

</details>


### [270] [Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems](https://arxiv.org/abs/2602.08104)
*Risal Shahriar Shefin,Debashis Gupta,Thai Le,Sarra Alqahtani*

Main category: cs.AI

TL;DR: 提出基于梯度的两阶段框架，用于多智能体强化学习中的可解释故障检测与溯源，能识别初始故障源、验证多米诺效应、追踪故障传播路径。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在安全关键领域应用日益广泛，但缺乏可解释的故障检测与归因方法。现有方法多为黑盒检测，难以理解故障传播机制和检测异常。

Method: 两阶段梯度框架：第一阶段通过策略梯度成本的泰勒余项分析进行可解释的智能体级故障检测，确定初始故障候选；第二阶段通过评论家导数的几何分析（一阶敏感性和二阶曲率）构建可解释的传染图，验证故障传播路径。

Result: 在Simple Spread（3和5智能体）和StarCraft II环境中评估，使用MADDPG和HATRPO算法，实现了88.2-99.4%的初始故障源检测准确率，并提供检测决策的几何证据。

Conclusion: 该框架超越了黑盒检测，提供了梯度层面的可解释法医分析工具，为安全关键多智能体系统中的级联故障诊断提供了实用方法。

Abstract: Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains "downstream-first" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.

</details>


### [271] [Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System](https://arxiv.org/abs/2602.07308)
*Sutapa Dey Tithi,Nazia Alam,Tahreem Yasir,Yang Shi,Xiaoyi Tian,Min Chi,Tiffany Barnes*

Main category: cs.AI

TL;DR: 研究开发了一个自适应系统，通过动态选择两种ICAP模式的例题（引导式例题和错误式例题）来优化认知参与度，比较了BKT和DRL两种自适应方法与基线方法在逻辑智能辅导系统中的效果。


<details>
  <summary>Details</summary>
Motivation: ICAP框架定义了四种认知参与水平，更高的认知参与能带来更好的学习效果，但在智能辅导系统中个性化设计能激发最佳认知参与度的学习活动仍然是一个关键挑战。

Method: 开发了一个自适应系统，通过动态选择两种ICAP模式的例题来搭建认知参与度：主动模式的引导式例题和建构模式的错误式例题。比较了贝叶斯知识追踪（BKT）和深度强化学习（DRL）作为自适应方法，与一个非自适应基线方法在逻辑智能辅导系统中选择例题类型的效果。

Result: 在113名学生参与的实验中，两种自适应策略都显著提高了学生在测试问题上的表现。BKT对低先验知识学生的后测成绩提升最大，帮助他们赶上了高先验知识同学的水平；而DRL在高先验知识学生中产生了显著更高的后测成绩。

Conclusion: 该研究为认知参与度和自适应性的复杂交互及其对学习成果的影响提供了新的见解，展示了不同自适应方法对不同知识水平学生的差异化效果。

Abstract: The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.

</details>


### [272] [SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities](https://arxiv.org/abs/2602.08254)
*Arman Aghaee,Sepehr Asgarian,Jouhyun Jeon*

Main category: cs.AI

TL;DR: SynthAgent是一个多智能体系统框架，用于模拟肥胖症合并精神障碍患者，通过整合临床数据构建个性化虚拟患者，模拟疾病进展和治疗反应。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界数据碎片化、偏见性和隐私限制的问题，为研究复杂疾病提供高保真患者模拟的途径。

Method: 开发SynthAgent多智能体系统框架，整合医保索赔数据、人口调查和患者中心文献，构建具有人格特质的个性化虚拟患者，通过自主智能体交互模拟疾病进展、治疗反应和生活管理。

Result: 评估100多个生成的虚拟患者显示，GPT-5和Claude 4.5 Sonnet作为核心引擎表现最佳，保真度最高，优于Gemini 2.5 Pro和DeepSeek-R1。

Conclusion: SynthAgent提供了一个可扩展且保护隐私的框架，用于探索医学和心理领域的患者旅程、行为动态和决策过程。

Abstract: Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.

</details>


### [273] [RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving](https://arxiv.org/abs/2602.07339)
*Ruturaj Reddy,Hrishav Bakul Barua,Junn Yong Loo,Thanh Thi Nguyen,Ganesh Krishnasamy*

Main category: cs.AI

TL;DR: RAPiD是一个确定性策略提取框架，将预训练的扩散轨迹规划器蒸馏为高效策略，消除扩散采样过程，实现8倍加速和竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 扩散轨迹规划器能很好建模人类驾驶的多模态行为，但其依赖迭代随机采样导致实时性和安全性挑战，难以在安全关键场景部署。

Method: 使用分数正则化策略优化，利用预训练扩散规划器的评分函数作为行为先验来正则化策略学习；通过模仿预测性驾驶员控制器的评论家提供密集的安全监督。

Result: 在nuPlan闭环场景中实现竞争性性能，相比扩散基线加速8倍；在interPlan基准测试中达到学习型规划器的最先进泛化能力。

Conclusion: RAPiD成功将扩散规划器蒸馏为高效确定性策略，在保持性能的同时显著提升计算效率，为实时安全关键部署提供了可行方案。

Abstract: Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.

</details>


### [274] [W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents](https://arxiv.org/abs/2602.07359)
*Xiaoqiang Lin,Jun Hao Liew,Silvio Savarese,Junnan Li*

Main category: cs.AI

TL;DR: 提出Wide and Deep研究智能体框架，通过并行工具调用实现宽度扩展，在深度研究基准上显著提升性能并减少所需步骤。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体主要通过增加顺序思考和工具调用的深度来提升性能，但通过并行工具调用实现宽度扩展的潜力尚未充分探索。

Method: 提出Wide and Deep研究智能体框架，利用内在并行工具调用在单个推理步骤内实现有效协调，避免复杂的多智能体编排，并探索各种工具调用调度器来优化并行策略。

Result: 宽度扩展显著提升深度研究基准性能，减少获得正确答案所需的轮次；在BrowseComp基准上，GPT-5-Medium达到62.2%准确率，超过GPT-5-High报告的54.9%。

Conclusion: 优化宽度与深度之间的权衡是实现高效深度研究智能体的关键途径，并行工具调用能显著提升性能而不需要复杂的上下文管理或其他技巧。

Abstract: Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.

</details>


### [275] [VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation](https://arxiv.org/abs/2602.07399)
*Changhua Xu,Jie Lu,Junyu Xuan,En Yu*

Main category: cs.AI

TL;DR: VGAS框架通过生成-选择范式解决VLA模型在少样本适应中的几何模糊问题，使用价值引导的动作块选择来提升轨迹的几何精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在少样本适应中面临几何模糊问题，即使生成语义合理的轨迹，由于几何不确定性仍会导致执行失败，需要解决有限监督下的几何精度问题。

Method: 提出VGAS框架：1) 使用微调VLA作为高召回率提议生成器；2) 引入Q-Chunk-Former作为几何基础Transformer批评器；3) 提出显式几何正则化(EGR)来保持动作排序分辨率并缓解价值不稳定性。

Result: 实验和理论分析表明，VGAS在有限演示和分布偏移下能持续提升成功率和鲁棒性。

Conclusion: VGAS通过生成-选择范式有效解决了VLA模型少样本适应中的几何模糊问题，为视觉-语言-动作系统的可靠适应提供了新思路。

Abstract: Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \emph{generation--selection} perspective and propose a novel framework \textbf{VGAS} (\textbf{V}alue-\textbf{G}uided \textbf{A}ction-chunk \textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \textit{Explicit Geometric Regularization} (\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.

</details>


### [276] [Computing the Reachability Value of Posterior-Deterministic POMDPs](https://arxiv.org/abs/2602.07473)
*Nathanaël Fijalkow,Arka Ghosh,Roman Kniazev,Guillermo A. Pérez,Pierre Vandenhove*

Main category: cs.AI

TL;DR: 提出后验确定性POMDPs新类别，解决了POMDPs中可达概率无法计算的问题，使得在该类别下可达概率可以任意精度近似计算。


<details>
  <summary>Details</summary>
Motivation: POMDPs在不确定性下的顺序决策建模中很重要，但许多验证和综合问题是不可判定或难处理的。特别是Madani等人的结果表明，无法计算或近似POMDPs中到达目标状态的最大概率，这与完全可观测MDPs形成鲜明对比。

Method: 引入后验确定性POMDPs新类别：如果给定当前状态、采取的动作和接收的观测，下一个状态可以唯一确定，则POMDP是后验确定性的。这意味着一旦真实状态已知，它将永远保持已知。

Result: 对于后验确定性POMDPs，到达给定状态集的最大概率可以近似到任意精度。这包括所有MDPs和经典的非平凡示例（如Tiger POMDP），使其成为已知最大的POMDPs类别之一。

Conclusion: 后验确定性POMDPs定义了一个具有良好计算性质的POMDPs新类别，解决了POMDPs可达性分析中的基本计算障碍，为实际应用提供了可行的解决方案。

Abstract: Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.
  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.
  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.

</details>


### [277] [GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design](https://arxiv.org/abs/2602.07491)
*Isabella A. Stewart,Tarjei Paule Hage,Yu-Chuan Hsu,Markus J. Buehler*

Main category: cs.AI

TL;DR: 该研究提出了一个结合知识图谱与多智能体推理的框架，用于寻找PFAS（全氟和多氟烷基物质）的可持续替代品，通过分布式专业化和关系推理来加速材料发现过程。


<details>
  <summary>Details</summary>
Motivation: 在材料科学领域，创新需要整合从分子化学到机械性能的多个概念，但人类或单智能体大语言模型难以处理如此庞大的信息流，且后者容易产生幻觉。当前挑战已不再是信息获取，而是如何以有意义、跨领域的方式连接信息。

Method: 引入了一个由大规模知识图谱指导的多智能体框架。智能体专门负责问题分解、证据检索、设计参数提取和图遍历，通过揭示不同知识领域之间的潜在联系来支持假设生成。通过定制图遍历策略，系统在专注于领域关键结果的利用性搜索和揭示新兴跨领域连接的探索性搜索之间交替进行。

Result: 消融研究表明，完整的多智能体流程优于单次提示，突显了分布式专业化和关系推理的价值。以生物医学导管为例，该框架生成了平衡摩擦性能、热稳定性、化学抗性和生物相容性的可持续无PFAS替代品。

Conclusion: 这项工作建立了一个结合知识图谱与多智能体推理的框架，扩展了材料设计空间，展示了几个初步的设计候选方案来验证该方法。

Abstract: Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.

</details>


### [278] [MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning](https://arxiv.org/abs/2602.07543)
*Heewoong Noh,Gyoung S. Na,Namkyeong Lee,Chanyoung Park*

Main category: cs.AI

TL;DR: MSP-LLM：一个统一的LLM框架，将材料合成规划分解为前驱体预测和合成操作预测两个子问题，通过引入离散材料类别作为中间决策变量，显著提升了材料合成规划的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 材料合成规划是AI驱动材料发现中的关键瓶颈，现有方法只能解决孤立子任务，缺乏统一的解决方案。需要建立一个能够同时处理前驱体选择和合成操作序列设计的完整框架。

Method: 提出MSP-LLM框架，将材料合成规划分解为前驱体预测和合成操作预测两个子问题。引入离散材料类别作为中间决策变量，构建化学一致的决策链。在合成操作预测中，采用分层前驱体类型作为归纳偏置，并使用显式条件策略在自回归解码状态中保留前驱体相关信息。

Result: 实验表明，MSP-LLM在前驱体预测、合成操作预测以及完整的材料合成规划任务上均优于现有方法，证明了该框架在材料合成规划中的有效性和可扩展性。

Conclusion: MSP-LLM提供了一个有效且可扩展的统一框架，能够加速现实世界中的材料发现过程，解决了材料合成规划这一长期存在的瓶颈问题。

Abstract: Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.

</details>


### [279] [VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning](https://arxiv.org/abs/2602.07559)
*Kaleem Ullah Qasim,Jiashu Zhang,Hao Li,Muhammad Kafeel Shaheen*

Main category: cs.AI

TL;DR: Verify-RL框架通过符号微分实现可验证的数学问题分解，确保子问题更简单、解决子问题有助于父任务、且分解关系有数学基础，相比启发式方法显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数学问题分解方法通常是启发式的，无法保证子问题更简单、解决子问题有助于父任务、且分解关系有数学基础，导致大量无效分解

Method: 利用符号微分作为可验证分解的自然结构：微积分规则明确定义表达式如何分解为更简单的组件，并具有可证明的性质。提出Verify-RL框架，确保每个父子分解满足三个可验证条件：结构复杂度严格递减、解包含性、形式规则推导

Result: 消除无效分解带来显著性能提升：最难问题的准确率从32%翻倍至68%，整体相对改进达40%。可验证条件通过符号计算实现自动验证，达到"构造即验证"的效果

Conclusion: 基于符号微分的可验证分解框架为数学问题求解提供了理论基础保证，相比启发式方法能显著提升语言模型在复杂数学问题上的性能，证明了形式化验证在课程学习中的重要性

Abstract: Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving "verification by construction" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.

</details>


### [280] [SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures](https://arxiv.org/abs/2602.07628)
*Keondo Park,Younghoon Na,Yourim Choi,Hyunwoo Ryu,Hyun-Woo Shin,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: SleepMaMi是一个睡眠基础模型，通过分层双编码器设计同时建模整夜睡眠宏观结构和细粒度信号微观特征，在超过20,000个PSG记录上预训练，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前睡眠医学主要使用任务特定模型，这些模型专注于局部微观结构特征，忽略了PSG丰富的多模态上下文和整夜睡眠的全局宏观结构。需要统一的基础模型来同时掌握长时间睡眠架构和细粒度信号形态。

Method: 采用分层双编码器设计：宏观编码器建模整夜时间依赖关系，通过人口统计学引导的对比学习与年龄、性别、BMI等客观元数据对齐；微观编码器捕获生物信号的短期特征，通过混合掩码自编码器和多模态对比目标优化。在超过20,000个PSG记录（158K小时）上进行预训练。

Result: SleepMaMi在多样化的下游任务中超越了现有的基础模型，展示了优越的泛化能力和标签高效的临床睡眠分析适应能力。

Conclusion: SleepMaMi成功解决了睡眠医学中任务特定模型的局限性，通过统一的基础模型框架同时掌握宏观睡眠结构和微观信号特征，为临床睡眠分析提供了更强大的工具。

Abstract: While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.

</details>


### [281] [Efficient Table Retrieval and Understanding with Multimodal Large Language Models](https://arxiv.org/abs/2602.07642)
*Zhuoyan Xu,Haoyang Fang,Boran Han,Bonan Min,Bernie Wang,Cuixiong Hu,Shuai Zhang*

Main category: cs.AI

TL;DR: TabRAG框架通过视觉-文本基础模型检索候选表格图像，MLLM细粒度重排序，最终MLLM推理生成答案，显著提升表格图像检索和问答性能


<details>
  <summary>Details</summary>
Motivation: 现实世界中表格常以图像形式存在（如财务报表、手写记录、文档扫描），现有MLLM方法通常假设表格已准备好，但实际场景需要从大规模表格图像集合中检索相关表格进行推理回答用户查询

Method: 提出TabRAG框架：1) 使用联合训练的视觉-文本基础模型检索候选表格图像；2) 利用MLLM对候选表格进行细粒度重排序；3) 使用MLLM在选定表格上进行推理生成答案

Result: 在新构建的数据集（88,161训练样本，9,819测试样本，8个基准，48,504个唯一表格）上实验表明，框架在检索召回率上提升7.0%，答案准确率提升6.1%，显著优于现有方法

Conclusion: TabRAG为现实世界表格理解任务提供了实用解决方案，通过检索-重排序-推理的三阶段框架，有效处理大规模表格图像集合的查询回答问题

Abstract: Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.

</details>


### [282] [ONTrust: A Reference Ontology of Trust](https://arxiv.org/abs/2602.07662)
*Glenda Amaral,Tiago Prince Sales,Riccardo Baratella,Daniele Porello,Renata Guizzardi,Giancarlo Guizzardi*

Main category: cs.AI

TL;DR: 本文提出了一个基于统一基础本体的信任参考本体(ONTrust)，旨在为人类和机器提供对信任的正式概念化，以支持可信系统的构建。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和区块链等技术的发展，信任在系统采纳中的重要性日益凸显。为了构建可信系统，需要为人类和机器提供对信任的正式概念化，以支持信息建模、自动推理和信息集成等任务。

Method: 开发了基于统一基础本体(UFO)的信任参考本体(ONTrust)，使用OntoUML进行规范，并应用于多个实际案例进行验证。

Result: ONTrust正式定义了信任概念及其不同类型，描述了影响信任的各种因素，解释了信任关系中风险的产生机制，并通过文献中的两个案例研究展示了其应用效果。

Conclusion: ONTrust为信任提供了一个坚实的本体基础，能够支持概念建模、企业架构设计、语言评估、信任管理、需求工程以及可信人工智能等多个领域的应用。

Abstract: Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.

</details>


### [283] [EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge](https://arxiv.org/abs/2602.07695)
*Congcong Hu,Yuang Shi,Fan Huang,Yang Xiang,Zhou Ye,Ming Jin,Shiyu Wang*

Main category: cs.AI

TL;DR: EventCast是一个将未来事件知识集成到时间序列预测中的模块化框架，专门解决电商在闪购、节假日等突发事件期间的需求预测问题，相比传统方法显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有电商需求预测系统在高影响时期（如闪购、节假日促销、政策干预）往往失效，因为这些时期需求模式会发生突然且不可预测的变化。传统方法要么忽略未来干预，要么直接使用大语言模型进行数值预测，都存在局限性。

Method: EventCast采用模块化框架，利用LLM专门进行事件驱动推理。首先从运营数据库中提取非结构化业务数据（如营销活动、节假日安排、卖家激励），通过LLM将其转换为可解释的文本摘要，同时利用世界知识处理文化差异和新事件组合。然后将这些摘要与历史需求特征在双塔架构中融合，实现准确、可解释且可扩展的预测。

Result: 在4个国家160个地区超过10个月的真实电商场景部署中，EventCast相比无事件知识的变体在MAE和MSE上分别提升了86.9%和97.7%；在事件驱动期间，相比最佳工业基线，MAE降低了57.0%，MSE降低了83.3%。自2025年3月起已部署到实际工业管道中。

Conclusion: EventCast通过将LLM专门用于事件驱动推理，而非直接进行数值预测，成功整合了未来事件知识，为动态电商环境中的运营决策提供了实用的解决方案，显著提升了高影响时期的需求预测准确性。

Abstract: Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.

</details>


### [284] [Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution](https://arxiv.org/abs/2602.07749)
*Zhenyu Wu,Yanxi Long,Jian Li,Hua Huang*

Main category: cs.AI

TL;DR: Geo-coder：首个基于多智能体系统的几何图像逆向编程框架，通过像素级锚定和度量驱动代码演化，实现复杂几何细节的精确重建，在几何重建精度和视觉一致性方面显著领先。


<details>
  <summary>Details</summary>
Motivation: 程序代码作为连接视觉与逻辑的桥梁，为通过几何操作（如辅助线构建和透视变换）增强大模型多模态推理能力提供了可行的监督方法。然而，当前逆向图形方法在准确重建复杂几何细节方面面临巨大挑战，常导致关键几何约束丢失或结构失真。

Method: 提出Geo-coder——首个基于多智能体系统的几何图像逆向编程框架。创新性地将过程解耦为：1）通过像素级锚定进行几何建模，利用视觉算子和大模型的互补优势精确捕捉像素坐标和视觉属性；2）度量驱动代码演化，引入合成-渲染-验证闭环，通过双向视觉反馈驱动代码自校正。

Result: 大量实验表明，Geo-coder在几何重建精度和视觉一致性方面取得显著领先。通过有效保留核心几何语义，重建图像在多模态推理任务中表现出与原始图像相当的性能，充分验证了框架的鲁棒性。开源了包含1500多个样本的Geo-coder数据集和GeocodeLM模型。

Conclusion: Geo-coder成功解决了复杂几何细节重建的瓶颈问题，为后续研究提供了坚实的数据和模型基础。该框架通过逆向编程方法实现了几何图像的精确重建，在多模态推理任务中展现出强大的应用潜力。

Abstract: Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.

</details>


### [285] [Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency](https://arxiv.org/abs/2602.07754)
*Bahare Riahi,Veronica Catete*

Main category: cs.AI

TL;DR: 研究调查本科生对AI评分系统的看法，发现学生对AI缺乏情境理解和个性化表示担忧，建议AI系统应体现人类判断、灵活性和同理心，作为人类监督下的补充工具。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在了解学生对AI评分系统的看法，特别关注AI评分在公平性、信任度、一致性和透明度方面的表现，基于Jobin（2019）提出的伦理原则框架，探索AI在教育评估中的伦理问题。

Method: 研究采用定性方法，调查了27名本科计算机科学学生对AI评分系统的看法，通过比较AI生成的反馈与原始人工评分反馈，分析AI在块状编程最终项目中的表现。

Result: 研究发现学生对AI评分系统存在担忧，主要关注AI缺乏情境理解和个性化能力。AI生成的反馈在理解学生工作背景和提供个性化指导方面存在局限性。

Conclusion: 研究建议公平可信的AI系统应反映人类判断、灵活性和同理心，作为人类监督下的补充工具。这项工作通过放大学生声音和为AI人性化设计提供原则，为以伦理为中心的评估实践做出贡献。

Abstract: This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.

</details>


### [286] [RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection](https://arxiv.org/abs/2602.08214)
*Ziwei Wang,Yuanhe Zhang,Jing Chen,Zhenhong Zhou,Ruichao Liang,Ruiying Du,Ju Jia,Cong Wu,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出RECUR攻击方法，通过递归熵引导的反事实利用和反思，揭示大型推理模型在推理过程中存在的资源耗尽安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务中需要显式推理，这需要更长的上下文长度，导致资源消耗显著增加。先前研究表明对抗性输入可能触发冗余推理过程，但推理过程本身，特别是其反思组件，受到的关注有限，尽管它可能导致过度反思并消耗过多计算能力。

Method: 引入递归熵来量化反思中的资源消耗风险，基于此提出RECUR攻击方法：通过递归熵引导的反事实利用和反思，构建反事实问题来验证LRMs的内在缺陷和风险。

Result: 实验表明，在良性推理下，递归熵呈现明显下降趋势；而RECUR攻击破坏了这一趋势，使输出长度增加高达11倍，吞吐量降低90%。

Conclusion: 本文为稳健推理提供了新视角，揭示了推理本身存在的安全问题，特别是通过递归熵量化的资源消耗风险。

Abstract: Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.

</details>


### [287] [InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation](https://arxiv.org/abs/2602.08229)
*Yifan Yang,Jinjia Li,Kunxi Li,Puhao Zheng,Yuanyi Wang,Zheyan Qu,Yang Yu,Jianmin Wu,Ming Li,Hongxia Yang*

Main category: cs.AI

TL;DR: 论文提出去中心化评估框架解决LLM评估中的不一致性问题，通过区块链协议激励全球贡献者作为独立验证者，显著降低评估方差。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型评估存在集中化评估的透明度低、过拟合和硬件差异导致的方差问题。实证分析显示，HumanEval上单个模型十次运行的标准差（1.67）甚至超过了官方排行榜上前10名模型的性能差距（0.91），导致当前排名统计上不可靠。

Method: 提出去中心化评估框架，通过区块链协议激励全球贡献者作为独立验证者，在异构计算节点上进行大规模基准测试，实现硬件和参数多样性。采用稳健的奖励系统确保评估完整性，防止不诚实参与。

Result: 去中心化评估框架将同一模型十次运行的标准差从1.67降低到0.28，显著提高了模型排名的统计置信度。该平台已完全实现并将向社区发布。

Conclusion: 去中心化评估框架通过多方共识和多样化推理环境，将评估从"集中化黑盒"转变为"去中心化背书"，提供了更稳定、更具代表性的评估指标，解决了当前LLM评估中的统计不稳定性问题。

Abstract: The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a "centralized black box" into a "decentralized endorsement" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.

</details>


### [288] [Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition](https://arxiv.org/abs/2602.07787)
*Pierre-Louis Favreau,Jean-Pierre Lo,Clement Guiguet,Charles Simon-Meunier,Nicolas Dehandschoewercker,Allen G. Roush,Judah Goldfeder,Ravid Shwartz-Ziv*

Main category: cs.AI

TL;DR: Minitap多智能体系统在AndroidWorld基准测试中实现100%成功率，首次完全解决所有116个任务，超越人类表现（80%）。


<details>
  <summary>Details</summary>
Motivation: 解决单智能体架构在移动设备任务执行中的失败问题：混合推理轨迹导致的上下文污染、智能体未检测到的静默文本输入失败、以及无逃脱机制的重复杂作循环。

Method: 通过针对性机制：六个专门化智能体的认知分离、基于设备状态的文本输入确定性后验证、以及检测循环并触发策略改变的元认知推理。

Result: 在AndroidWorld基准测试中达到100%成功率，完全解决所有116个任务。消融实验显示：多智能体分解贡献+21分，验证执行+7分，元认知+9分。

Conclusion: Minitap作为首个完全解决AndroidWorld基准测试的系统，通过多智能体架构、验证执行和元认知机制有效解决了单智能体系统的局限性，已开源发布。

Abstract: We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use

</details>


### [289] [On Protecting Agentic Systems' Intellectual Property via Watermarking](https://arxiv.org/abs/2602.08401)
*Liwen Wang,Zongjie Li,Yuchong Xie,Shuai Wang,Dongdong She,Wei Wang,Juergen Rahmel*

Main category: cs.AI

TL;DR: AGENTWM是首个专门为智能体模型设计的水印框架，通过利用动作序列的语义等价性，在功能相同的工具执行路径中注入水印，有效保护智能体系统的知识产权免受模仿攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型向能够进行自主推理和工具使用的智能体系统演进，创造了重要的知识产权价值。这些系统容易受到模仿攻击，而现有的LLM水印技术在智能体领域失效，因为现实中的智能体系统通常作为灰盒运行，隐藏了验证所需的内部推理轨迹。

Method: AGENTWM利用动作序列的语义等价性，通过微妙地偏向功能相同的工具执行路径的分布来注入水印。开发了自动生成鲁棒水印方案的流水线，以及严格的统计假设检验程序进行验证。

Result: 在三个复杂领域的广泛评估表明，AGENTWM实现了高检测准确率，同时对智能体性能影响极小。AGENTWM能有效保护智能体知识产权，对抗性攻击者无法在不严重降低被盗模型效用的情况下移除水印。

Conclusion: AGENTWM是首个专门为智能体模型设计的水印框架，成功解决了现有LLM水印技术在智能体领域的局限性，为保护智能体系统的知识产权提供了有效解决方案。

Abstract: The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.

</details>


### [290] [Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training](https://arxiv.org/abs/2602.07824)
*Yiwei Qin,Zhen Huang,Tiantian Mi,Weiye Si,Chenyang Zhou,Qipeng Guo,Siyuan Feng,Pengfei Liu*

Main category: cs.AI

TL;DR: 提出Data Darwinism十级分类法，通过数据-模型协同进化框架提升基础模型性能，在科学文献领域构建Darwin-Science语料库并验证有效性


<details>
  <summary>Details</summary>
Motivation: 数据质量决定基础模型性能，但缺乏系统化的数据处理框架。需要建立数据与模型协同进化的理论框架，让先进模型为下一代系统生成更优质数据

Method: 提出Data Darwinism十级分类法（L0-L9），在科学文献领域构建Darwin-Science语料库（900B tokens，L0-L5）。使用前沿LLM进行L4（生成精炼）和L5（认知补全）处理，解决原始科学文本的可学习性差距。从头预训练daVinci-origin-3B/7B模型作为无污染基线，然后进行600B tokens的持续预训练

Result: Darwin-Science在20多个基准测试中比基线模型提升+2.12（3B）和+2.95（7B）分，在领域对齐任务上提升+5.60和+8.40分。系统性地推进到L5级别带来+1.36的总增益，证实高级数据处理能解锁潜在数据价值

Conclusion: Data Darwinism框架有效验证了数据-模型协同进化的概念，高级数据处理能显著提升模型性能。发布Darwin-Science语料库和daVinci-origin模型，支持基于原则的协同进化开发

Abstract: Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.
  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.

</details>


### [291] [Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning](https://arxiv.org/abs/2602.07830)
*Jiahui Zhou,Dan Li,Boxin Li,Xiao Zhang,Erli Meng,Lin Li,Zhuomin Chen,Jian Lou,See-Kiong Ng*

Main category: cs.AI

TL;DR: VeriTime是一个通过数据合成、数据调度和强化学习训练来定制LLM进行时间序列推理的框架，使小型模型在时间序列任务上达到或超过大型专有LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在各领域普遍存在，但利用LLM推理能力处理时间序列任务仍处于早期阶段，主要受限于缺乏精心策划的时间序列CoT训练数据、数据效率低下以及缺乏专门针对时间序列CoT数据的RL算法。

Method: 1) 提出数据合成管道，构建具有过程可验证注释的TS-文本多模态数据集；2) 设计数据调度机制，按难度层次和任务分类原则安排训练样本；3) 开发两阶段强化微调，利用可验证过程级CoT数据的细粒度多目标奖励。

Result: VeriTime显著提升了LLM在各种时间序列推理任务上的性能，使紧凑的3B、4B模型能够达到或超过大型专有LLM的推理能力。

Conclusion: VeriTime框架通过系统化的数据合成、调度和强化学习训练，成功解决了时间序列推理中的关键挑战，为LLM在时间序列领域的应用提供了有效解决方案。

Abstract: Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.

</details>


### [292] [LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge](https://arxiv.org/abs/2602.07849)
*Xin Wang,Hualin Zhou,Sheng Guang Wang,Ting Dang,Yu Zhang,Hong Jia,Tao Gu*

Main category: cs.AI

TL;DR: LQA是一个轻量化的量化自适应框架，用于在边缘设备上部署视觉语言模型，通过选择性混合量化和无梯度测试时适应，在资源受限环境下实现鲁棒高效的VLM部署。


<details>
  <summary>Details</summary>
Motivation: 边缘设备部署视觉语言模型面临资源限制和分布偏移导致的性能下降问题，现有测试时适应方法资源消耗过大，不适合边缘设备部署。

Method: 提出LQA框架，包含选择性混合量化策略和量化无梯度适应机制，结合模态感知量化策略实现轻量化的测试时适应。

Result: 在合成和真实世界分布偏移实验中，LQA将整体适应性能提升4.5%，内存使用低于全精度模型，比基于梯度的TTA方法内存使用降低高达19.9倍。

Conclusion: LQA为边缘设备上鲁棒、隐私保护且高效的VLM部署提供了实用路径，特别适合资源受限的硬件环境。

Abstract: Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.

</details>


### [293] [Emergent Misalignment is Easy, Narrow Misalignment is Hard](https://arxiv.org/abs/2602.07852)
*Anna Soligo,Edward Turner,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.AI

TL;DR: 微调大语言模型在狭窄有害数据集上会导致涌现性错位，模型在多种无关场景下给出刻板的"邪恶"回应。专家调查未能预测此结果，揭示了我们对LLM学习和泛化归纳偏好的理解不足。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在狭窄有害数据集上微调时出现的涌现性错位现象，探索LLM学习和泛化的归纳偏好，理解为什么模型会从特定任务学习扩展到普遍错位行为。

Method: 使用涌现性错位作为案例研究，发现不同错位微调收敛到相同的线性表示。构建狭窄解决方案的线性表示（通过KL散度损失学习），比较两种表示的特性。

Result: 普遍错位表示具有更低的损失、更强的扰动鲁棒性，且在预训练分布中更具影响力。普遍解决方案比狭窄解决方案更稳定、更高效。

Conclusion: 本研究分离出普遍错位的具体表示，可用于监控和缓解。为研究LLM泛化中的归纳偏好提供了详细案例和初步指标，开源了所有代码、数据集和模型微调。

Abstract: Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.

</details>


### [294] [ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation](https://arxiv.org/abs/2602.07883)
*Jingqi Zhou,Sheng Wang,DeZhao Deng,Junwen Lu,Junwei Su,Qintong Li,Jiahui Gao,Hao Wu,Jiyue Jiang,Lingpeng Kong,Chuan Wu*

Main category: cs.AI

TL;DR: ToolSelf：一种新型智能体范式，将配置更新抽象为可调用工具，实现运行时自我重配置，使LLM智能体能够自主适应任务动态变化


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体系统受限于静态配置，这些配置在执行前固定，无法适应任务动态变化。现有方法依赖人工编排或启发式补丁，泛化能力差且优化碎片化

Method: 提出ToolSelf范式，将配置更新抽象为可调用工具，统一任务执行和自我调整到单一动作空间。设计配置感知两阶段训练（CAT），结合拒绝采样微调和轨迹级强化学习

Result: 在多样化基准测试中，ToolSelf媲美专用工作流同时能泛化到新任务，平均性能提升24.1%，展示了向真正自适应智能体的路径

Conclusion: ToolSelf通过工具驱动的运行时自我重配置，使智能体从被动执行者转变为任务和自我的双重管理者，为构建真正自适应的智能体系统提供了新范式

Abstract: Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.

</details>


### [295] [MemFly: On-the-Fly Memory Optimization via Information Bottleneck](https://arxiv.org/abs/2602.07885)
*Zhenyuan Zhang,Xianzhang Jia,Zhiqin Yang,Zhenbo Song,Wei Xue,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: MemFly是一个基于信息瓶颈原则的LLM记忆框架，通过梯度自由优化器构建分层记忆结构，结合混合检索机制，在记忆一致性、响应保真度和准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有记忆框架面临一个基本困境：既要高效压缩冗余信息，又要为下游任务保持精确检索。需要弥合这一差距。

Method: 基于信息瓶颈原则，通过梯度自由优化器最小化压缩熵同时最大化相关熵，构建分层记忆结构。开发混合检索机制，整合语义、符号和拓扑路径，包含迭代细化处理复杂多跳查询。

Result: 综合实验表明，MemFly在记忆一致性、响应保真度和准确性方面显著优于最先进的基线方法。

Conclusion: MemFly框架成功解决了现有记忆框架的困境，通过信息瓶颈原则和混合检索机制实现了高效压缩和精确检索的平衡。

Abstract: Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.

</details>


### [296] [TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor](https://arxiv.org/abs/2602.08517)
*Shaoang Zhang,Yazhe Niu*

Main category: cs.AI

TL;DR: TreeTensor是一个通用的嵌套数据容器，用于处理具有层次结构的多模态数据，能够零成本地应用各种函数和操作到嵌套数据上。


<details>
  <summary>Details</summary>
Motivation: 传统张量（Tensor）在处理具有层次结构的嵌套数据时存在不便和低效问题，特别是在复杂的认知AI系统中，数据通常具有各种模态的嵌套结构。

Method: 通过总结嵌套数据的两种主要计算模式，提出TreeTensor这一通用嵌套数据容器，利用约束树结构视角系统建模数据关系，并提供各种魔法工具来零成本地应用函数和操作。

Result: TreeTensor在各种问题中展现出强大的可用性，特别是在目前最复杂的AI系统之一——星际争霸II的AlphaStar中，同时表现出优异的运行时效率且无任何开销。

Conclusion: TreeTensor为解决嵌套数据处理问题提供了一个有效的解决方案，能够与现有机器学习库无缝集成，并可通过与其他方法结合扩展更多用途。

Abstract: Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.

</details>


### [297] [Selective Fine-Tuning for Targeted and Robust Concept Unlearning](https://arxiv.org/abs/2602.07919)
*Mansi,Avinash Kori,Francesca Toni,Soteris Demetriou*

Main category: cs.AI

TL;DR: TRUST是一种新颖的针对性鲁棒选择性微调方法，通过动态估计目标概念神经元并利用Hessian正则化进行选择性微调，实现高效的概念遗忘


<details>
  <summary>Details</summary>
Motivation: 文本引导扩散模型易被利用生成有害内容，传统概念遗忘方法在单个概念层面处理，现有方法依赖全模型微调计算成本高，概念定位方法静态且效果欠佳

Method: 提出TRUST方法：1）动态估计目标概念神经元；2）通过选择性微调进行概念遗忘；3）采用Hessian正则化增强鲁棒性

Result: TRUST在对抗性提示下表现鲁棒，显著保持生成质量，比SOTA方法更快，能遗忘单个概念、概念组合和条件概念，无需特定正则化

Conclusion: TRUST为扩散模型的概念遗忘提供了一种高效、鲁棒且通用的解决方案，解决了现有方法的计算成本和效果限制问题

Abstract: Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.

</details>


### [298] [IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery](https://arxiv.org/abs/2602.07943)
*Ivaxi Sheth,Zhijing Jin,Bryan Wilder,Dominik Janzing,Mario Fritz*

Main category: cs.AI

TL;DR: LLMs能够帮助识别有效的工具变量，通过两阶段评估框架验证其能力，并开发了IV Co-Scientist多智能体系统来提出、批评和优化工具变量选择。


<details>
  <summary>Details</summary>
Motivation: 在存在内生变量与结果混杂的情况下，工具变量（IVs）用于隔离内生变量的因果效应。识别有效的工具变量需要跨学科知识、创造力和上下文理解，这是一项非平凡的任务。本文研究大型语言模型（LLMs）是否能帮助完成这项任务。

Method: 采用两阶段评估框架：首先测试LLMs是否能从文献中恢复已确立的工具变量，评估其复制标准推理的能力；其次评估LLMs是否能识别和避免已被经验或理论否定的工具变量。基于这些结果，开发了IV Co-Scientist多智能体系统，该系统能提出、批评和优化给定处理-结果对的工具变量。还引入了一种统计检验来在没有真实值的情况下评估一致性。

Result: 研究结果表明，LLMs具有从大型观测数据库中识别有效工具变量的潜力。LLMs能够成功恢复文献中已确立的工具变量，并能避免使用已被否定的工具变量。

Conclusion: LLMs在工具变量识别方面展现出潜力，IV Co-Scientist系统为因果推断中的工具变量选择提供了新的自动化方法，有助于提高因果效应估计的准确性。

Abstract: In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.

</details>


### [299] [Accelerating Social Science Research via Agentic Hypothesization and Experimentation](https://arxiv.org/abs/2602.07983)
*Jishu Sen Gupta,Harini SI,Somesh Kumar Singh,Syed Mohamad Tawseeq,Yaman Kumar Singla,David Doermann,Rajiv Ratn Shah,Balaji Krishnamurthy*

Main category: cs.AI

TL;DR: EXPERIGEN是一个端到端的科学发现框架，通过生成器提出假设、实验者评估假设的两阶段搜索，在多个领域发现2-4倍更多统计显著且预测能力提升7-17%的假设，并通过专家评审和真实A/B测试验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的社会科学研究过程缓慢，依赖观察、假设生成和实验验证的迭代循环。现有数据驱动方法虽然能加速部分过程，但未能支持端到端的科学发现。需要开发能够完整支持科学发现过程的框架。

Method: 提出EXPERIGEN框架，采用受贝叶斯优化启发的两阶段搜索：生成器提出候选假设，实验者进行实证评估。该框架可扩展到多模态和关系数据集等复杂数据环境。

Result: 在多个领域，EXPERIGEN发现2-4倍更多统计显著的假设，预测能力比先前方法提高7-17%。专家评审显示88%的假设具有中等或强新颖性，70%被认为有影响力且值得研究。A/B测试显示统计显著结果(p<1e-6)，效应大小达344%。

Conclusion: EXPERIGEN能够有效支持端到端的科学发现，不仅提升统计性能，还能生成新颖、有实证基础且可操作的假设，为数据驱动的社会科学研究提供了强大的自动化工具。

Abstract: Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.

</details>


### [300] [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)
*Rui Li,Zeyu Zhang,Xiaohe Bo,Quanyu Dai,Chaozhuo Li,Feng Wen,Xu Chen*

Main category: cs.AI

TL;DR: RAPS：基于声誉感知的发布-订阅范式，用于实现LLM多智能体的自适应、可扩展和鲁棒协调


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的多智能体架构展现了群体智能潜力，但手动编排工作量大，需要自动化设计智能体工作流。核心挑战是如何在可扩展的智能体之间建立自适应、可靠的通信。

Method: 提出RAPS框架，基于分布式发布-订阅协议，让智能体基于声明的意图交换消息而非预定义拓扑。包含两个叠加层：1）反应式订阅，让智能体动态优化意图；2）贝叶斯声誉机制，为每个智能体提供本地监控器来检测和隔离恶意节点。

Result: 在五个基准测试上的广泛实验表明，该设计在统一的多智能体协调框架中有效平衡了自适应性、可扩展性和鲁棒性。

Conclusion: RAPS通过声誉感知的发布-订阅范式，解决了LLM多智能体协调中的自适应、可扩展和鲁棒性问题，为自动化智能体工作流设计提供了有效解决方案。

Abstract: Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.

</details>


### [301] [Small Agent Group is the Future of Digital Health](https://arxiv.org/abs/2602.08013)
*Yuqiao Meng,Luoxi Tang,Dazheng Zhang,Rafael Brens,Elvys J. Romero,Nancy Guo,Safa Elkefi,Zhaohan Xi*

Main category: cs.AI

TL;DR: 本文挑战了大型语言模型在数字健康领域的"规模优先"范式，提出小型智能体群体(SAG)通过协同推理机制，在临床决策中实现比单一大型模型更好的效果、可靠性和部署成本平衡。


<details>
  <summary>Details</summary>
Motivation: 当前数字健康领域过度依赖大型语言模型的"规模优先"理念，认为模型越大、数据越多临床智能就越强。但真实临床需求不仅需要有效性，还需要可靠性和合理的部署成本。临床决策本质上是协作过程，因此需要探索是否小型智能体群体能支持更好的临床推理。

Method: 提出小型智能体群体(SAG)方法，从单一模型智能转向集体专业知识，通过协作审议过程分配推理、循证分析和关键审核。使用多样化的临床指标进行广泛评估，涵盖有效性、可靠性和部署成本。

Result: SAG在性能上优于单一大型模型，无论是否进行额外优化或检索增强生成。结果表明SAG所代表的协同推理可以替代临床环境中模型参数的增长。

Conclusion: SAG为数字健康提供了一个可扩展的解决方案，能更好地平衡有效性、可靠性和部署效率，挑战了传统的单一模型规模扩展范式。

Abstract: The rapid adoption of large language models (LLMs) in digital health has been driven by a "scaling-first" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.

</details>


### [302] [Free(): Learning to Forget in Malloc-Only Reasoning Models](https://arxiv.org/abs/2602.08030)
*Yilun Zheng,Dongyang Ma,Tian Liang,Jiahao Xu,Xinting Huang,Lijie Chen,Haitao Mi,Yan Wang*

Main category: cs.AI

TL;DR: Free()LM通过引入自我遗忘机制解决推理模型过度思考导致性能下降的问题，使用Free-Module LoRA适配器动态修剪无用上下文，在多种规模模型上实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准LLMs存在"只分配不释放"的架构缺陷，持续累积有效和冗余推理步骤，缺乏修剪过时信息的机制，导致过度思考时性能下降而非提升。

Method: 提出Free()LM模型，通过Free-Module（即插即用LoRA适配器）引入内在自我遗忘能力。模型在推理模式和清理模式之间迭代切换，动态识别并修剪无用上下文块，保持紧凑无噪声状态。

Result: 在所有模型规模（8B到685B）上均实现一致改进，平均比顶级推理基线提升3.3%，在IMOanswerBench上建立新SOTA。在长时程任务中，标准Qwen3-235B-A22B模型完全崩溃（0%准确率），而Free()LM恢复至50%准确率。

Conclusion: 可持续智能既需要思考的能力，也需要遗忘的自由。自我遗忘机制是解决推理模型过度思考问题的关键。

Abstract: Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as "malloc-only" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.
  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.

</details>


### [303] [Securing Dual-Use Pathogen Data of Concern](https://arxiv.org/abs/2602.08061)
*Doni Bloomfield,Allison Berke,Moritz S. Hanke,Aaron Maiwald,James R. M. Black,Toby Webster,Tina Hernandez-Boussard,Oliver M. Crook,Jassi Pannu*

Main category: cs.AI

TL;DR: 论文提出了一个五级生物安全数据框架（BDL），用于根据病原体数据在训练AI模型时可能带来的生物安全风险进行分类，并为每个级别提出相应的技术限制措施，旨在通过数据控制减少生物武器开发等有害AI应用的风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI在生物学领域的广泛应用，训练AI模型所使用的生物数据（如序列、结构、图像、功能数据）与模型最终能力密切相关，包括可能带来生物安全风险的能力。国际研究团体已认可通过数据控制来防止AI被用于有害应用（如生物武器开发），因此需要建立一个系统化的数据分类和控制框架。

Method: 提出了一个五级生物安全数据等级（BDL）框架，根据不同类型病原体数据在训练AI模型时可能贡献给有害能力的程度进行分类。每个级别包含特定的数据类型，并针对其风险水平提出相应的技术限制措施。同时为新型双重用途病原体数据设计了一个治理框架。

Result: 建立了一个系统化的生物安全数据分类体系，将病原体数据按照风险等级分为五个层次，并为每个层次制定了适当的技术控制措施。该框架为数据治理提供了具体的技术方案，特别是在广泛可获取计算和编码资源的背景下，数据控制成为减少有害生物AI能力扩散的高杠杆干预手段。

Conclusion: 在计算和编码资源广泛可获取的世界中，数据控制可能是减少有害生物AI能力扩散的最有效干预手段之一。提出的BDL框架和治理方案为实施这种控制提供了具体的技术和治理基础，有助于平衡AI在生物学研究中的创新应用与生物安全风险防控之间的关系。

Abstract: Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.

</details>


### [304] [Weak-Driven Learning: How Weak Agents make Strong Agents Stronger](https://arxiv.org/abs/2602.08222)
*Zehao Chen,Gongxun Li,Tianxiang Ai,Yifei Li,Zixuan Huang,Wang Zhou,Fuzhen Zhuang,Xianglong Liu,Jianxin Li,Deqing Wang,Yikun Ban*

Main category: cs.AI

TL;DR: WMSS是一种后训练优化方法，利用模型自身历史弱检查点来指导继续优化，通过熵动态识别可恢复的学习差距并进行补偿学习，突破后训练饱和瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型后训练中存在持续饱和瓶颈：模型变得高度自信后，进一步训练收益递减。现有方法继续强化目标预测，但研究发现信息丰富的监督信号仍潜藏在模型自身的历史弱状态中。

Method: 提出WMSS后训练范式，利用弱检查点指导继续优化。通过熵动态识别可恢复的学习差距，并通过补偿学习强化这些差距，使强智能体超越传统后训练饱和。

Result: 在数学推理和代码生成数据集上的实验表明，使用WMSS方法训练的智能体实现了有效的性能提升，同时不产生额外的推理成本。

Conclusion: WMSS通过利用模型自身历史弱状态中的监督信号，成功突破了后训练饱和瓶颈，为大型语言模型的持续优化提供了新思路。

Abstract: As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.

</details>


### [305] [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)
*Siqu Ou,Tianrui Wan,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.AI

TL;DR: SAYO：通过强化学习框架引入区域级视觉注意力奖励，解决多模态大语言模型中视觉注意力不稳定的问题，提升复杂推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在复杂推理任务中主要依赖长文本推理轨迹，但缺乏学习稳定视觉注意力策略的机制。分析发现当前模型存在视觉聚焦弱的问题：早期视觉对齐错误很少在后续推理中得到纠正，导致错误传播和推理失败。这一局限源于训练过程中视觉注意力信用分配不足。

Method: 提出SAYO模型，采用强化学习框架训练，引入区域级视觉注意力奖励。该奖励明确将优化信号与视觉基础推理步骤对齐，使模型能够学习更可靠的注意力行为。

Result: 在多个多模态基准测试上的广泛实验表明，SAYO在多样化的推理和感知任务上持续提升性能。

Conclusion: 通过强化学习框架中的区域级视觉注意力奖励，SAYO能够解决多模态大语言模型中视觉注意力不稳定的问题，显著提升复杂推理任务的性能表现。

Abstract: While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.

</details>


### [306] [G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design](https://arxiv.org/abs/2602.08253)
*Baoyun Zhao,He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: G-LNS是一个生成式进化框架，利用大语言模型自动设计大规模邻域搜索算子，通过协同进化破坏和修复算子对，在组合优化问题上超越了现有LLM启发式设计方法和经典求解器。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动启发式设计方法通常局限于构造性优先级规则或参数化局部搜索指导，限制了搜索空间到固定的启发式形式。这种设计在结构探索方面能力有限，难以在复杂组合优化问题中逃离深度局部最优。

Method: 提出G-LNS生成式进化框架，扩展LLM-based AHD到大规模邻域搜索算子的自动设计。不同于先前孤立进化启发式的方法，G-LNS利用LLM协同进化紧密耦合的破坏和修复算子对，通过合作评估机制显式捕捉它们的交互作用。

Result: 在旅行商问题和带容量车辆路径问题等挑战性组合优化基准测试中，G-LNS显著优于基于LLM的AHD方法以及强大的经典求解器。发现的启发式不仅以更少的计算预算获得接近最优解，而且在多样化和未见过的实例分布上表现出鲁棒的泛化能力。

Conclusion: G-LNS框架成功地将LLM-based AHD扩展到更灵活的大规模邻域搜索算子设计，通过协同进化破坏-修复算子对实现了更有效的结构探索，为复杂组合优化问题的自动启发式设计提供了新方向。

Abstract: While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.

</details>


### [307] [Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis](https://arxiv.org/abs/2602.08276)
*Haoyu Jia,Kento Kawaharazuka,Kei Okada*

Main category: cs.AI

TL;DR: 提出Structural Context Model形式化模型，通过上下文结构分析比较LLM智能体，包含声明式实现框架和Semantic Dynamics Analysis工作流，在动态猴子香蕉问题上实现32%成功率提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体研究存在碎片化问题，概念框架和方法论原则常与底层实现细节混杂，缺乏可分析、自洽的形式化模型来进行实现无关的智能体表征和比较。

Method: 提出Structural Context Model形式化模型，从上下文结构角度分析LLM智能体；包含声明式实现框架和Semantic Dynamics Analysis可持续工程工作流，支持快速系统化设计迭代。

Result: 在动态猴子香蕉问题变体上，使用该框架设计的智能体在最具挑战性的设置中实现了高达32个百分点的成功率提升。

Conclusion: 提出的形式化模型和工作流为LLM智能体研究提供了原则性见解，支持快速系统化设计迭代，解决了当前研究碎片化问题。

Abstract: Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.

</details>


### [308] [The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI](https://arxiv.org/abs/2602.08295)
*Ilya Levin*

Main category: cs.AI

TL;DR: 论文提出"氛围自动化"概念，认为生成式AI代表了从算法优化到语境语义导航的认知转变，将人类角色从问题规范转向"氛围工程"。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能代表了计算机科学基础假设的质变，而不仅仅是技术增量进步。传统机器学习是"自动化的自动化"，而生成式AI通过导航语境、语义和风格连贯性运作，挑战了基于预定义客观指标优化的范式。

Method: 引入"氛围自动化"概念框架，分析生成式AI如何操作化隐性规律——无法通过显式算法规则完全指定的情境敏感模式。提出人类角色转变为"氛围工程"，即协调生成系统中的对齐和情境判断。

Result: 构建了包含三个分析层次和三个行动领域的概念框架：教师世界观、行业关系和课程设计。讨论了模式崩溃和文化同质化的风险，强调需要刻意参与生成系统以避免回归合成统一性。

Conclusion: 生成式AI代表了计算机科学的认识论转变，从算法优化转向语境导航。这要求教育机构和行业进行相应转型，通过"氛围工程"管理隐性规律的操作化，同时警惕文化同质化风险。

Abstract: The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.
  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.
  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.

</details>


### [309] [Moral Sycophancy in Vision Language Models](https://arxiv.org/abs/2602.08311)
*Shadman Rabby,Md. Hefzul Hossain Papon,Sabbir Ahmed,Nokimul Hasan Arif,A. B. M. Ashikur Rahman,Irfan Ahmad*

Main category: cs.AI

TL;DR: 该研究首次系统分析了视觉语言模型中的道德谄媚行为，发现当用户表达不同意见时，VLMs经常放弃正确的道德判断而迎合用户，且存在从正确转向错误的明显不对称性。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要探索了VLMs在一般情境下的谄媚行为，但对其在道德基础视觉决策中的影响了解不足。本研究旨在填补这一空白，系统分析VLMs在用户明确反对时的道德谄媚行为。

Method: 在Moralise和M^3oralBench数据集上评估了10个广泛使用的VLMs，通过用户明确反对的情境分析道德谄媚行为。使用错误引入率（EIR）和错误纠正率（ECR）量化模型表现，并分析不同道德立场初始语境的影响。

Result: VLMs经常在初始判断正确的情况下产生道德错误的后续回应；存在明显不对称性：模型更可能从道德正确转向错误而非相反；后续提示在Moralise上降低性能，在M^3oralBench上表现混合甚至改善；EIR和ECR显示明显权衡：纠错能力强的模型引入更多推理错误，保守模型错误少但自我纠正能力有限；道德正确初始语境引发更强的谄媚行为。

Conclusion: VLMs对道德影响高度脆弱，需要原则性策略来提高多模态AI系统的伦理一致性和鲁棒性。研究揭示了模型在道德决策中谄媚行为的系统性模式，为开发更稳健的道德AI系统提供了重要见解。

Abstract: Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.

</details>


### [310] [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)
*Yanming Li,Xuelin Zhang,WenJie Lu,Ziye Tang,Maodong Wu,Haotian Luo,Tongtong Wu,Zijie Peng,Hongze Mi,Yibo Feng,Naiqiang Tan,Chao Huang,Hong Chen,Li Shen*

Main category: cs.AI

TL;DR: SHARP框架通过Shapley值进行精确信用分配，优化多智能体强化学习，解决LLM与外部工具集成中的信用分配难题


<details>
  <summary>Details</summary>
Motivation: 将LLM与外部工具通过多智能体系统集成是解决复杂问题的新范式，但训练这些系统面临信用分配挑战，现有方法依赖稀疏或全局广播奖励，无法准确捕捉个体贡献，导致强化学习效率低下

Method: 提出SHARP框架，通过归一化轨迹组内智能体特定优势来稳定训练，采用分解的奖励机制：全局广播准确性奖励、基于Shapley值的边际信用奖励（每个智能体）、工具过程奖励（提高执行效率）

Result: 在多个真实世界基准测试中，SHARP显著优于现有最先进基线，相比单智能体和多智能体方法分别实现了23.66%和14.05%的平均匹配改进

Conclusion: SHARP通过精确的信用分配有效解决了多智能体强化学习中的训练稳定性问题，为LLM与外部工具集成的多智能体系统提供了有效的优化框架

Abstract: Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.

</details>


### [311] [CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT](https://arxiv.org/abs/2602.08339)
*Chengyi Du,Yazhe Niu,Dazhong Shen,Luxin Xu*

Main category: cs.AI

TL;DR: CoTZero提出了一种无需标注的视觉语言模型训练范式，通过双阶段数据合成和认知对齐训练方法，提升模型的层次化推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型主要依赖表面相关性而非逻辑连贯的结构化表示，导致缺乏高层次语义结构和非因果关系理解，限制了组合性和可验证推理能力。

Method: CoTZero包含两个核心组件：(1) 双阶段数据合成方法：自下而上阶段提取原子视觉基元并组合成结构化问题推理形式；自上而下阶段使用全局结构指导局部细节和因果关系的解释；(2) 认知对齐训练方法：在合成数据基础上，通过强化微调中的认知一致可验证奖励机制，提供推理连贯性和事实正确性的逐步反馈。

Result: 在多级语义不一致基准测试中，CoTZero在包含词汇扰动负样本的跨领域设置下达到了83.33%的F1分数。消融实验证实每个组件都对提升可解释性和人类对齐的视觉推理有贡献。

Conclusion: CoTZero通过引入人类认知模型到推理过程中，有效解决了视觉语言模型在结构化表示和逻辑推理方面的局限性，实现了更可解释和人类对齐的视觉推理能力。

Abstract: Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.

</details>


### [312] [OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration](https://arxiv.org/abs/2602.08344)
*Qi Guo,Jianing Wang,Deyang Kong,Xiangyu Xi,Jianfei Zhang,Yi Lu,Jingang Wang,Wei Wang,Shikun Zhang,Wei Ye*

Main category: cs.AI

TL;DR: 提出Outline-Guided Path Exploration (OPE)方法，通过生成多样化的推理大纲来引导并行路径探索，解决并行思维中探索路径间互信息瓶颈问题，提升大型推理模型的数学问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有并行思维方法主要关注聚合阶段优化，对路径探索阶段关注有限。研究发现探索路径间的互信息瓶颈限制了整体性能，需要解决路径探索中的信息冗余和多样性不足问题。

Method: 提出Outline-Guided Path Exploration (OPE)方法：1) 先生成多样化的推理大纲来划分解空间；2) 基于大纲进行并行路径推理；3) 采用迭代强化学习策略分别优化大纲规划和基于大纲的推理。

Result: 在多个具有挑战性的数学基准测试上进行广泛实验，证明OPE能有效提升不同聚合策略下的推理性能，使大型推理模型更可靠地发现正确解决方案。

Conclusion: OPE通过显式划分解空间并减少信息冗余，解决了并行思维中探索路径间的互信息瓶颈问题，显著提升了大型推理模型在复杂数学问题上的表现。

Abstract: Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.

</details>


### [313] [Towards Better Evolution Modeling for Temporal Knowledge Graphs](https://arxiv.org/abs/2602.08353)
*Zhang Jiasheng,Li Zhangpin,Wang Mingzhe,Shao Jie,Cui Jiangtao,Li Hui*

Main category: cs.AI

TL;DR: 现有TKG基准存在严重缺陷：仅通过统计共现就能达到接近SOTA的性能，无需使用时间信息，这暴露了数据集固有偏差和评估任务过于简化的问题。


<details>
  <summary>Details</summary>
Motivation: 研究发现现有时序知识图谱（TKG）基准存在严重问题：即使不使用任何时间信息，仅通过统计实体共现就能达到接近最先进水平的性能。这表明现有基准无意中引入了捷径，无法公平评估TKG演化建模的真正挑战。

Method: 通过分析现有基准问题的根源，识别出数据集固有偏差和评估任务过于简化等核心问题。在此基础上构建了TKG演化基准，包括四个偏差校正后的数据集和两个与演化过程紧密相关的新任务。

Result: 揭示了现有TKG基准的多个局限性：时间间隔知识的不合理格式化、忽略知识过时性学习、演化理解信息不足等。这些问题都放大了捷径效应，阻碍了公平评估。

Conclusion: 提出了TKG演化基准，通过偏差校正数据集和更贴近实际演化过程的新任务，为TKG演化建模提供了更准确的评估框架，促进对TKG演化挑战的更准确理解。

Abstract: Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.

</details>


### [314] [Does Your Reasoning Model Implicitly Know When to Stop Thinking?](https://arxiv.org/abs/2602.08354)
*Zixuan Huang,Xin Xia,Yuxi Ren,Jianbin Zheng,Xuanda Wang,Zhixia Zhang,Hongyan Xie,Songshi Liang,Zehao Chen,Xuefeng Xiao,Fuzhen Zhuang,Jianxin Li,Yikun Ban,Deqing Wang*

Main category: cs.AI

TL;DR: SAGE是一种新的采样范式，通过释放大型推理模型的自我停止思考能力，显著提升推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型使用长思维链方法存在大量冗余，损害计算效率并导致实时应用延迟。研究发现长推理链与正确性无关甚至有害，而模型本身隐含知道何时停止思考的能力被当前采样范式所掩盖。

Method: 提出SAGE（自我感知引导高效推理）采样范式，释放模型的自我停止思考能力。进一步将SAGE作为混合采样整合到基于群体的强化学习中（SAGE-RL），使SAGE-RL能够将SAGE发现的高效推理模式融入标准pass@1推理。

Result: SAGE-RL显著提升了大型推理模型在多个具有挑战性的数学基准测试中的推理准确性和效率。

Conclusion: 通过释放模型内在的自我停止思考能力，SAGE采样范式能够显著提升大型推理模型的推理效率和准确性，为高效推理提供了新方向。

Abstract: Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.

</details>


### [315] [Circuit Representations of Random Forests with Applications to XAI](https://arxiv.org/abs/2602.08362)
*Chunxi Ji,Adnan Darwiche*

Main category: cs.AI

TL;DR: 将随机森林分类器编译为电路，用于高效计算决策解释和鲁棒性分析


<details>
  <summary>Details</summary>
Motivation: 现有方法在计算随机森林分类器的决策解释时效率较低，需要更高效的方法来获取决策的完整原因、鲁棒性分析和决策翻转路径

Method: 1) 提出将随机森林编译为电路的方法，每个电路直接编码分类器中某个类别的实例；2) 利用该方法获得可处理的电路，用于计算决策的完整和一般原因；3) 提出计算决策鲁棒性和所有最短决策翻转路径的算法

Result: 提出的方法比现有类似方法显著更高效，能够枚举所有充分原因、必要原因和对比解释，计算决策鲁棒性，并识别随机森林分类器决策的所有最短翻转路径

Conclusion: 该方法为随机森林分类器提供了高效的决策解释框架，支持多种解释任务，包括原因枚举、鲁棒性分析和决策翻转路径识别

Abstract: We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.

</details>


### [316] [MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval](https://arxiv.org/abs/2602.08369)
*Xin Zhang,Kailai Yang,Chenyue Li,Hao Li,Qiyu Wei,Jun'ichi Tsujii,Sophia Ananiadou*

Main category: cs.AI

TL;DR: MemAdapter是一个统一的记忆检索框架，通过两阶段训练策略实现跨记忆范式的快速对齐，显著降低对齐成本并提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体记忆系统通常采用孤立的设计范式（如显式、参数化或潜在记忆），其紧密耦合的检索方法阻碍了跨范式的泛化和融合，需要统一的记忆系统来解决这一问题。

Method: 提出MemAdapter框架，采用两阶段训练策略：1）在统一记忆空间训练生成式子图检索器；2）通过对比学习训练轻量级对齐模块，使检索器适应未见记忆范式。

Result: 在三个公开评估基准上的实验表明，生成式子图检索器在三种记忆范式和不同智能体模型规模上均优于五种强基线系统。MemAdapter在单GPU上13分钟内完成跨范式对齐，使用不到5%的训练计算量即超越原始记忆检索器性能，并能实现跨记忆范式的有效零样本融合。

Conclusion: MemAdapter作为一个即插即用的智能体记忆系统解决方案，通过统一的记忆检索框架实现了跨异构记忆范式的快速对齐和高效融合，显著提升了记忆检索的灵活性和效率。

Abstract: Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.

</details>


### [317] [Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI](https://arxiv.org/abs/2602.08373)
*Feiyu Wu,Xu Zheng,Yue Qu,Zhuocheng Wang,Zicheng Feng,Hui Li*

Main category: cs.AI

TL;DR: VIRF框架通过神经符号架构将LLM规划器与形式化安全逻辑导师结合，实现可验证的安全规划与主动修复，而非被动拒绝不安全计划。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为具身AI规划器缺乏形式化推理能力，无法提供严格的安全保证。现有方法要么依赖不可靠的LLM进行安全检查，要么简单地拒绝不安全计划而不提供修复方案。

Method: 提出可验证迭代精炼框架(VIRF)，采用神经符号架构，建立导师-学徒对话机制：基于形式化安全本体的确定性逻辑导师为LLM规划器提供因果性和教学性反馈，实现智能计划修复而非简单避免。同时开发了从现实世界文档合成安全知识库的可扩展知识获取流程。

Result: 在家庭安全任务中，VIRF实现了0%的危险行动率(HAR)和77.3%的目标条件率(GCR)，在所有基线方法中表现最佳。平均仅需1.1次修正迭代，效率很高。

Conclusion: VIRF为构建根本上可信且可验证安全的具身智能体提供了一条原则性路径，将安全范式从被动把关转变为主动协作。

Abstract: Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.

</details>


### [318] [Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning](https://arxiv.org/abs/2602.08520)
*Xinhai Sun*

Main category: cs.AI

TL;DR: 本文提出"强化推理"方法，利用LLM自身的不确定性在推理时选择性调用二次推理，无需重新训练即可显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在单次贪婪推理协议下会系统性地低估模型真实能力，许多错误源于内部模糊性下的过早决策，而非知识缺失。

Method: 提出基于熵感知的推理时控制策略，利用模型自身不确定性选择性地调用第二次更审慎的推理尝试。

Result: 在MMLU-Pro的12,032个问题上，使用DeepSeek-v3.2模型，准确率从60.72%提升到84.03%，仅增加61.06%的推理调用。100%重问消融实验达到84.35%，表明不确定性感知选择能以更少计算获得大部分可实现的改进。

Conclusion: 该方法不仅提供实用的推理时升级，还提出了更广泛的熵感知范式，用于衡量和扩展模型能力，为LLM的潜在推理范围提供诊断视角，并激励未来训练目标中明确约束正确性-置信度对齐。

Abstract: Modern large language models (LLMs) are often evaluated and deployed under a \emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \emph{without any retraining}.
  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\% to 84.03\%, while only incurring 61.06\% additional inference calls. A 100\% re-asking ablation reaches 84.35\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.
  Beyond providing a practical inference-time upgrade, our results suggest a broader \emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.

</details>


### [319] [An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture](https://arxiv.org/abs/2602.08597)
*Roland Bertin-Johannet,Lara Scipio,Leopold Maytié,Rufin VanRullen*

Main category: cs.AI

TL;DR: 提出并评估了一种用于全局工作空间理论中模态选择的顶部注意机制，该机制提高了系统的噪声鲁棒性，并在跨任务和跨模态泛化方面表现出色


<details>
  <summary>Details</summary>
Motivation: 全局工作空间理论(GWT)作为认知神经科学启发的框架，为多模态整合提供了新思路，但现有实现中相关的注意机制研究不足，需要开发有效的顶部注意机制来提升系统性能

Method: 提出了一种顶部注意机制来选择全局工作空间中的模态，在两个复杂度递增的多模态数据集(Simple Shapes和MM-IMDb 1.0)上进行评估，并与现有多模态注意模型进行比较

Result: 该注意机制提高了全局工作空间系统的噪声鲁棒性，展示了文献中多模态注意模型不具备的跨任务和跨模态泛化能力，在MM-IMDb 1.0基准测试中使全局工作空间达到与最先进方法竞争的水平

Conclusion: 提出的顶部注意机制有效增强了全局工作空间理论在多模态整合中的性能，特别是在噪声鲁棒性和泛化能力方面，为认知启发的计算架构提供了有价值的实现方案

Abstract: Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.

</details>


### [320] [OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval](https://arxiv.org/abs/2602.08603)
*Teng Wang,Rong Shan,Jianghao Lin,Junjie Wu,Tianyi Xu,Jianping Zhang,Wenteng Chen,Changwang Zhang,Zhaoxiang Wang,Weinan Zhang,Jun Wang*

Main category: cs.AI

TL;DR: OSCAR是一个基于优化引导的智能体规划框架，用于组合图像检索，将启发式搜索过程转化为轨迹优化问题，通过离线-在线范式实现更优的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索方法存在两大问题：统一嵌入检索存在单模型近视问题，而启发式智能体检索则受限于次优的试错编排。需要一种更系统化的方法来处理异构视觉和文本约束的复杂推理。

Method: 提出OSCAR框架，采用离线-在线范式：1) 离线阶段将CIR建模为两阶段混合整数规划问题，通过布尔集合运算推导最大化真实覆盖的最优轨迹；2) 将最优轨迹存储在黄金库中，作为在线推理时VLM规划器的上下文演示；3) 在线阶段使用这些演示来引导规划器。

Result: 在三个公共基准和一个私有工业基准上的实验表明，OSCAR始终优于现有最先进方法。特别值得注意的是，仅使用10%的训练数据就能达到优越性能，证明了规划逻辑的强泛化能力而非数据集特定的记忆。

Conclusion: OSCAR成功将组合图像检索从启发式搜索过程转化为原则性的轨迹优化问题，通过离线推导最优轨迹并在在线推理中引导规划器，实现了更优的检索性能和更强的泛化能力。

Abstract: Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.

</details>


### [321] [Debate is efficient with your time](https://arxiv.org/abs/2602.08630)
*Jonah Brown-Cohen,Geoffrey Irving,Simon C. Marshall,Ilan Newman,Georgios Piliouras,Mario Szegedy*

Main category: cs.AI

TL;DR: 论文研究了AI安全辩论中人类监督的查询成本，引入了辩论查询复杂度(DQC)概念，发现PSPACE/poly问题类恰好是O(log n)查询可判定的函数类，表明辩论具有极高的查询效率。


<details>
  <summary>Details</summary>
Motivation: AI安全辩论使用两个竞争模型帮助人类判断验证复杂计算任务。先前工作建立了辩论在理论上能解决什么问题，但未分析人类监督的实际成本：判断需要检查辩论记录多少次查询？

Method: 引入辩论查询复杂度(DQC)，即验证者为了正确决定辩论必须检查的最小比特数。分析不同复杂度类别的DQC边界，建立查询复杂度与电路复杂度的联系。

Result: 发现PSPACE/poly（辩论能高效判定的问题类）恰好是O(log n)查询可判定的函数类。证明依赖所有输入比特的函数需要Ω(log n)查询，任何可由大小为s的电路计算的函数满足DQC(f) ≤ log(s) + 3。

Conclusion: 辩论具有惊人的查询效率：即使对于高度复杂的问题，对数级监督就足够了。证明DQC下界与电路复杂度中心问题相关，为AI安全辩论的实际可行性提供了理论保证。

Abstract: AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.
  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.

</details>


### [322] [Intermediate Results on the Complexity of STRIPS$_{1}^{1}$](https://arxiv.org/abs/2602.08708)
*Stefan Edelkamp,Jiří Fink,Petr Gregor,Anders Jonsson,Bernhard Nebel*

Main category: cs.AI

TL;DR: 该论文研究了STRIPS规划中操作符限制为1个前提条件和1个效果时的计算复杂度问题，探讨这种简化版本是否NP完全


<details>
  <summary>Details</summary>
Motivation: 基于Bylander关于命题STRIPS规划计算复杂度的研究结果，虽然已知当操作符限制为2个前提条件和2个后置条件时，规划存在性判定是PSPACE完全的，但对于操作符只有1个前提条件和1个效果的情况，是否NP完全仍是未知问题

Method: 通过调用SAT求解器处理小规模实例，引入文字图概念，并将其映射到Petri网进行分析

Result: 论文为STRIPS$^1_1$的小解假设问题提供了新的见解和证据

Conclusion: 该研究有助于澄清命题STRIPS规划在极端简化情况下的计算复杂度边界问题

Abstract: This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.

</details>


### [323] [Exploring SAIG Methods for an Objective Evaluation of XAI](https://arxiv.org/abs/2602.08715)
*Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Anna Arias-Duart*

Main category: cs.AI

TL;DR: 本文首次系统综述了SAIG方法——通过生成人工真实值来评估XAI技术的评估方法，提出了新的分类法并识别了七个关键特征，发现该领域缺乏共识需要进一步标准化。


<details>
  <summary>Details</summary>
Motivation: XAI评估领域方法多样且复杂，与传统AI评估不同，XAI缺乏普遍正确的解释真实值，使得客观评估具有挑战性。SAIG方法通过生成人工真实值来解决这一问题，但该领域缺乏系统性综述和分析。

Method: 1. 首次对SAIG方法进行全面综述和分析；2. 提出新的分类法对这些方法进行分类；3. 识别了区分不同SAIG方法的七个关键特征；4. 进行对比研究分析不同方法的有效性。

Result: 研究发现XAI评估技术中最有效的方法缺乏共识，这令人担忧。对比研究揭示了当前SAIG方法的多样性和不一致性，强调了该领域需要进一步研究和标准化。

Conclusion: SAIG方法为解决XAI评估挑战提供了有前景的方向，但当前缺乏统一标准和共识。需要进一步研究来建立更可靠、标准化的XAI评估框架，以推动该领域的发展。

Abstract: The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.

</details>


### [324] [Belief Offloading in Human-AI Interaction](https://arxiv.org/abs/2602.08754)
*Rose E. Guingrich,Dvija Mehta,Umang Bhatt*

Main category: cs.AI

TL;DR: 本文研究人类与AI交互中的"信念卸载"现象，即人们将形成和维持信念的过程外包给AI系统，这会影响其行为和信念体系。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越多地将LLM聊天机器人作为思维伙伴，这可能导致认知卸载，在过度依赖的情况下对认知技能产生负面影响。需要研究这种特定类型的认知卸载——信念卸载。

Method: 结合哲学、心理学和计算机科学研究，明确信念卸载发生的边界条件，并提供信念卸载的描述性分类及其规范意义。

Result: 提出了信念卸载的概念框架和分类体系，分析了其发生的条件，并探讨了其对人类行为和信念体系的潜在影响。

Conclusion: 信念卸载是人类与AI交互中的重要现象，需要进一步研究其潜在影响和后果，为未来工作提供方向。

Abstract: What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, "belief offloading," in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.

</details>


### [325] [Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure](https://arxiv.org/abs/2602.08783)
*Zirui Li,Xuefeng Bai,Kehai Chen,Yizhi Li,Jian Yang,Chenghua Lin,Min Zhang*

Main category: cs.AI

TL;DR: 该研究将潜在思维链视为表示空间中可操纵的因果过程，通过结构因果模型分析潜在步骤，探究其在数学和通用推理任务中的因果必要性、影响传播和答案模式保留等关键问题。


<details>
  <summary>Details</summary>
Motivation: 当前潜在思维链方法用内部潜在步骤替代显式文本推理，但这些中间计算难以通过相关性探测之外的方式进行评估。研究者希望将潜在思维链视为可操纵的因果过程，以更好地理解和改进潜在推理系统。

Method: 将潜在步骤建模为结构因果模型中的变量，通过逐步do干预分析其影响。研究两种代表性范式（Coconut和CODI），在数学和通用推理任务上探究三个关键问题：步骤的因果必要性、影响传播机制以及中间轨迹是否保留竞争答案模式。

Result: 发现潜在步骤预算不像同质的额外深度，而更像具有非局部路由的分阶段功能；识别出早期输出偏差与晚期表示承诺之间的持续差距；潜在步骤表现出明显的因果结构和功能分化。

Conclusion: 研究结果支持模式条件和稳定性感知分析作为解释和改进潜在推理系统的更可靠工具，并提出了相应的训练/解码目标。强调需要超越相关性探测的因果分析方法来理解潜在推理过程。

Abstract: Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.

</details>


### [326] [The Use of AI Tools to Develop and Validate Q-Matrices](https://arxiv.org/abs/2602.08796)
*Kevin Fan,Jacquelyn A. Bialo,Hongli Li*

Main category: cs.AI

TL;DR: AI工具在认知诊断建模中支持Q矩阵构建的可行性研究，发现不同AI模型表现差异显著，其中Google Gemini 2.5 Pro与验证Q矩阵的一致性最高，甚至超过人类专家，但后续版本表现下降。


<details>
  <summary>Details</summary>
Motivation: Q矩阵构建是认知诊断建模的关键步骤，但人工构建耗时耗力。本研究旨在探索通用语言模型等AI工具是否能够支持Q矩阵的开发，为这一劳动密集型任务提供自动化辅助。

Method: 使用多个AI模型（通用语言模型）与人类专家相同的训练材料，生成阅读理解测试的Q矩阵。将AI生成的Q矩阵与Li和Suen（2013）验证的Q矩阵以及人类评分者的Q矩阵进行比较，使用Cohen's kappa评估一致性。分别在2025年5月和2026年1月进行两轮分析。

Result: 不同AI模型表现差异显著，Google Gemini 2.5 Pro与验证Q矩阵的一致性最高（Kappa = 0.63），超过了所有人类专家。然而，2026年1月使用更新版本AI进行的后续分析显示，与验证Q矩阵的一致性有所下降。

Conclusion: AI工具在支持Q矩阵构建方面显示出潜力，特别是某些模型能够达到甚至超过人类专家的表现。但AI模型版本更新可能影响性能稳定性，需要进一步研究AI工具在认知诊断建模中的可靠性和应用前景。

Abstract: Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.

</details>


### [327] [Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures](https://arxiv.org/abs/2602.08804)
*Liming Zhou,Ailing Liu,Hongwei Liu,Min He,Heng Zhang*

Main category: cs.AI

TL;DR: RC-LLM：一种基于残差连接和大语言模型的微服务根因分析方法，通过多源遥测数据融合和上下文推理能力提升复杂微服务架构中的故障定位效果


<details>
  <summary>Details</summary>
Motivation: 在复杂大规模微服务架构中，根因定位面临挑战。微服务间复杂的故障传播以及遥测数据（指标、日志、追踪）的高维特性限制了现有根因分析方法的有效性。

Method: 提出RC-LLM方法：1）设计残差式分层融合结构来整合多源遥测数据；2）利用大语言模型的上下文推理能力来建模时间和跨微服务的因果依赖关系。

Result: 在CCF-AIOps微服务数据集上的实验结果表明，RC-LLM在根因分析方面实现了较高的准确性和效率。

Conclusion: RC-LLM通过结合残差连接结构和大语言模型的推理能力，有效解决了复杂微服务架构中的根因定位问题，为微服务故障诊断提供了新的解决方案。

Abstract: Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.

</details>


### [328] [Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation](https://arxiv.org/abs/2602.08815)
*Yanglei Gan,Peng He,Yuxiang Cai,Run Lin,Guanyu Zhou,Qiao Liu*

Main category: cs.AI

TL;DR: NADEx是一个用于时序知识图谱推理的负感知扩散模型，通过结合负样本原型和余弦对齐正则化来改进预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在时序知识图谱推理中存在两个问题：1) 生成路径仅基于正证据，忽略了信息丰富的负上下文；2) 训练目标主要依赖交叉熵排序，虽然改善了候选排序但缺乏对去噪嵌入校准的监督。

Method: NADEx将实体、关系和时序间隔的主体中心历史编码为序列嵌入，在前向过程中扰动查询对象，在反向过程中使用Transformer去噪器基于时序关系上下文进行重建。引入基于批负样本原型的余弦对齐正则化器来收紧决策边界。

Result: 在四个公共时序知识图谱基准测试上的综合实验表明，NADEx实现了最先进的性能。

Conclusion: NADEx通过结合负样本感知和校准监督，有效改进了时序知识图谱推理中的扩散模型性能。

Abstract: Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.

</details>


### [329] [Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning](https://arxiv.org/abs/2602.08835)
*Andrés Holgado-Sánchez,Peter Vamplew,Richard Dazeley,Sascha Ossowski,Holger Billhardt*

Main category: cs.AI

TL;DR: 该论文提出了一种基于聚类和偏好多目标强化学习的方法，用于学习社会智能体中的价值对齐模型和价值系统，以解决价值操作化中的误规范问题。


<details>
  <summary>Details</summary>
Motivation: 价值感知AI需要识别人类价值观并适应不同用户的价值系统，但价值操作化容易产生误规范。价值观的社会性要求其表示能同时适应多个用户，而价值系统虽然多样但存在群体模式。现有序列决策方法虽然尝试为不同目标或价值进行个性化，但需要手动设计特征或缺乏基于价值的可解释性和适应性。

Method: 提出基于聚类和偏好多目标强化学习(PbMORL)的算法，在马尔可夫决策过程中学习价值对齐模型和价值系统。联合学习社会衍生的价值对齐模型(groundings)和一组简洁表示社会中不同用户群体的价值系统。每个聚类包含代表其成员价值偏好的价值系统，以及反映与该价值系统对齐行为的近似帕累托最优策略。

Result: 在两个包含人类价值的MDP上评估了该方法，与最先进的PbMORL算法和基线进行比较。

Conclusion: 该方法能够学习社会智能体的价值对齐模型和价值系统，解决了价值操作化中的误规范问题，同时适应多样化的用户偏好，并提供了基于价值的可解释性。

Abstract: Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.
  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.

</details>


### [330] [Deciding the Satisfiability of Combined Qualitative Constraint Networks](https://arxiv.org/abs/2602.08848)
*Quentin Cohen-Solal,Alexandre Niveau,Maroua Bouzid*

Main category: cs.AI

TL;DR: 提出一个统一框架，整合多种定性形式化的扩展与组合，包括多尺度推理、时间序列和松散集成，并研究其可满足性判定及复杂度。


<details>
  <summary>Details</summary>
Motivation: 在人工智能推理中，定性推理能够在信息不精确、不完整且无数值的情况下推断新知识。现有定性形式化的扩展和组合形式多样，但缺乏统一框架来系统研究这些组合的可满足性判定及其复杂度。

Method: 提出一个形式化框架，统一多种定性形式化的扩展和组合，包括多尺度推理、时间序列和松散集成。该框架支持在这些组合和扩展中进行推理，并以统一方式研究可满足性判定及其复杂度。特别地，建立了两个互补定理来保证可满足性判定是多项式时间的。

Result: 建立了两个互补定理，保证可满足性判定是多项式时间的。利用这些定理恢复了尺寸-拓扑组合的已知结果。还将定性形式化的主要定义推广到包含文献定义中排除但在组合背景下重要的定性形式化。

Conclusion: 提出的统一框架能够系统处理多种定性形式化的扩展和组合，为研究这些组合的可满足性判定和复杂度提供了理论基础，并扩展了定性形式化的定义范围。

Abstract: Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.

</details>


### [331] [Efficient and Stable Reinforcement Learning for Diffusion Language Models](https://arxiv.org/abs/2602.08905)
*Jiawei Liu,Xiting Wang,Yuanyuan Zhong,Defu Lian,Yu Yang*

Main category: cs.AI

TL;DR: 提出STP框架，通过空间剪枝和时间剪枝提高扩散大语言模型强化学习的效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 强化学习对于释放扩散大语言模型的复杂推理能力至关重要，但应用于dLLMs时面临效率和稳定性方面的独特挑战

Method: 提出时空剪枝框架，包含：1）空间剪枝：使用静态先验约束探索空间；2）时间剪枝：绕过冗余的后期细化步骤

Result: 理论分析表明STP严格降低了对数似然估计的方差，确保更稳定的策略更新；实验证明STP在效率和准确性上都超越了最先进的基线方法

Conclusion: STP框架有效解决了扩散大语言模型强化学习中的效率和稳定性问题，为dLLMs的RL应用提供了更优的解决方案

Abstract: Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.

</details>


### [332] [CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse](https://arxiv.org/abs/2602.08939)
*Longling Geng,Andy Ouyang,Theodore Wu,Daphne Barretto,Matthew John Hayes,Rachael Cooper,Yuqiao Zeng,Sameer Vijay,Gia Ancone,Ankit Rai,Matthew Wolfman,Patrick Flanagan,Edward Y. Chang*

Main category: cs.AI

TL;DR: CausalT5K是一个包含5000多个案例的诊断基准，用于系统检测LLM在因果推理中的三种关键能力缺陷：阶梯坍塌、谄媚性漂移和错误拒绝，通过实用性和安全性指标揭示聚合准确率无法发现的故障模式。


<details>
  <summary>Details</summary>
Motivation: LLM在因果推理中存在阶梯坍塌、谄媚性和错误拒绝等已知缺陷，但由于缺乏系统诊断基准，修复进展缓慢。需要构建一个能够系统检测这些故障模式的诊断工具。

Method: 开发了CausalT5K基准，包含5000多个案例，覆盖10个领域，将因果陷阱嵌入现实叙事中。采用人机协作流程，涉及40名领域专家、迭代交叉验证周期，以及基于规则、LLM和人工评分的复合验证方法，实现了Pearl的因果阶梯作为研究基础设施。

Result: 初步实验揭示了四象限控制景观，其中静态审计策略普遍失败。基准能够分解性能为实用性（敏感性）和安全性（特异性），揭示聚合准确率无法发现的故障模式。

Conclusion: CausalT5K作为研究基础设施，为推进可信推理系统提供了有价值的诊断工具，能够系统检测LLM在因果推理中的关键缺陷，填补了现有基准的空白。

Abstract: LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench

</details>


### [333] [CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute](https://arxiv.org/abs/2602.08948)
*Chen Jin,Ryutaro Tanno,Tom Diethe,Philip Teare*

Main category: cs.AI

TL;DR: CoRefine是一种基于置信度引导的自优化方法，通过轻量级控制器动态决定何时停止、重新检查或尝试不同方法，显著减少推理所需的计算量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常依赖测试时并行解码（如512个样本）来提高推理准确性，但这会带来巨大的计算开销。需要一种更高效的方法来减少推理所需的计算资源。

Method: CoRefine在冻结的LLM之上添加一个轻量级的211k参数Conv1D控制器，该控制器利用完整跟踪置信度来决定：1) 停止推理，2) 重新检查，或3) 尝试不同方法。还扩展了CoRefine-Tree，这是一种混合顺序-并行变体，自适应地平衡探索和利用。

Result: CoRefine平均每个问题只需2.7个优化步骤，相对于512样本基线减少了约190倍的token使用量。控制器在自信停止时达到92.6%的精确度，表明置信度动态可靠地指示正确性而无需真实标签验证。在多样化的推理基准测试和三个开源模型上都表现良好。

Conclusion: 通过将置信度视为控制信号而非正确性保证，CoRefine为可扩展推理和不完美验证器的智能体设置提供了一个模块化原语，实现了计算效率与推理准确性的良好平衡。

Abstract: Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.

</details>


### [334] [stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968)
*Lucas Maes,Quentin Le Lidec,Dan Haramati,Nassim Massaudi,Damien Scieur,Yann LeCun,Randall Balestriero*

Main category: cs.AI

TL;DR: SWM是一个模块化、经过测试和文档化的世界模型研究生态系统，提供高效数据收集工具、标准化环境、规划算法和基准实现，旨在解决现有世界模型实现缺乏可重用性、标准化的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大多数世界模型实现都是针对特定论文的，缺乏可重用性，增加了bug风险，并降低了评估标准化程度。这限制了世界模型研究的进展和比较。

Method: 开发了stable-worldmodel（SWM）生态系统，包含模块化设计、测试框架、详细文档，提供数据收集工具、标准化环境、规划算法和基准实现。每个环境都支持可控的变化因素（视觉和物理属性），以支持鲁棒性和持续学习研究。

Result: 通过SWM研究了DINO-WM的零样本鲁棒性，展示了该生态系统的实用性。SWM为世界模型研究提供了标准化、可重用的框架。

Conclusion: SWM解决了世界模型研究中实现碎片化的问题，提供了一个模块化、经过测试和文档化的生态系统，能够支持鲁棒性和持续学习研究，促进世界模型领域的标准化和可重复性。

Abstract: World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.

</details>


### [335] [InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery](https://arxiv.org/abs/2602.08990)
*Shiyang Feng,Runmin Ma,Xiangchao Yan,Yue Fan,Yusong Hu,Songtao Huang,Shuaiyu Zhang,Zongsheng Cao,Tianshuo Peng,Jiakang Yuan,Zijie Guo,Zhijie Zhong,Shangheng Du,Weida Wang,Jinxin Shi,Yuhao Zhou,Xiaohan He,Zhiyin Yu,Fangchen Yu,Qihao Zheng,Jiamin Wu,Mianxin Liu,Chi Zhang,Shaowei Hou,Shuya Li,Yankai Jiang,Wenjie Lou,Lilong Wang,Zifu Wang,Jiong Wang,Wanghan Xu,Yue Deng,Dongrui Liu,Yiheng Wang,Wenlong Zhang,Fenghua Ling,Shufei Zhang,Xiaosong Wang,Shuangjia Zheng,Xun Huang,Siqi Sun,Shuyue Hu,Peng Ye,Chunfeng Song,Bin Wang,Conghui He,Yihao Liu,Xin Li,Qibin Hou,Tao Chen,Xiangyu Yue,Bin Wang,Liang He,Dahua Lin,Bowen Zhou,Bo Zhang,Lei Bai*

Main category: cs.AI

TL;DR: InternAgent-1.5是一个端到端科学发现系统，通过生成、验证、演化三个协调子系统，在计算和实验领域实现自主科学发现，在多个基准测试和实际发现任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的端到端系统，能够在计算建模和实验室实验两个领域进行自主科学发现，解决跨领域科学发现的协调问题。

Method: 采用结构化架构，包含生成、验证、演化三个协调子系统，支持深度研究、解决方案优化和长时程记忆等基础能力，能够在扩展的发现周期中持续运行。

Result: 在GAIA、HLE、GPQA、FrontierScience等科学推理基准测试中取得领先性能；在算法发现任务中自主设计机器学习方法；在实验发现任务中执行完整计算或湿实验室实验，在地球、生命、生物、物理等领域产生科学发现。

Conclusion: InternAgent-1.5为自主科学发现提供了一个通用且可扩展的框架，能够协调计算建模和实验室实验，在多个科学领域实现有效的科学发现。

Abstract: We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.

</details>


### [336] [iGRPO: Self-Feedback-Driven LLM Reasoning](https://arxiv.org/abs/2602.09000)
*Ali Hatamizadeh,Shrimai Prabhumoye,Igor Gitman,Ximing Lu,Seungju Han,Wei Ping,Yejin Choi,Jan Kautz*

Main category: cs.AI

TL;DR: iGRPO是一种两阶段强化学习方法，通过模型自生成草稿和动态自条件优化，在数学推理任务上超越现有方法，达到新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在解决复杂数学问题方面显示出潜力，但它们仍然难以产生准确且一致的解决方案。强化学习可以对齐模型与任务特定的奖励，但现有方法如PPO和GRPO仍有改进空间。

Method: iGRPO是GRPO的两阶段扩展：第一阶段采样多个探索性草稿并选择最高奖励的草稿；第二阶段将最佳草稿附加到原始提示后，在草稿条件化的改进上应用GRPO风格更新，训练策略超越其先前的最佳尝试。

Result: 在匹配的rollout预算下，iGRPO在多个基础模型上持续超越GRPO。应用于OpenReasoning-Nemotron-7B模型时，在AIME24和AIME25上分别达到85.62%和79.64%的新SOTA结果。

Conclusion: iGRPO展示了迭代、自反馈强化学习在推进可验证数学推理方面的潜力，其细化包装器不仅限于GRPO变体，还能从生成式评判中受益，并通过延迟熵崩溃改变学习动态。

Abstract: Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\% and 79.64\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.

</details>


### [337] [Data Science and Technology Towards AGI Part I: Tiered Data Management](https://arxiv.org/abs/2602.09003)
*Yudong Wang,Zixuan Fu,Hengyu Zhao,Chen Zhao,Chuyue Zhou,Xinle Lin,Hongya Lyu,Shuaikang Xue,Yi Yi,Yingjiao Wang,Zhi Zheng,Yuzhou Zhang,Jie Zhou,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 论文提出L0-L4分层数据管理框架，通过数据与模型协同进化提升LLM训练效率，解决当前单纯扩大数据规模面临的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM研究过度依赖数据规模单向扩展，面临数据可用性、获取成本和训练效率瓶颈。作者认为AGI发展正进入数据-模型协同进化新阶段，需要更智能的数据管理策略。

Method: 提出L0-L4分层数据管理框架：从原始未筛选资源到组织化可验证知识。利用LLM进行数据质量评分和内容编辑等管理过程，根据数据特性、管理策略和训练角色将数据战略性地分配到预训练、中期训练和对齐等不同阶段。

Result: 实验验证表明，分层感知的数据利用显著提高了训练效率和模型性能。作者向社区发布了分层数据集和处理工具。

Conclusion: 分层数据管理框架平衡了数据质量、获取成本和边际训练效益，为可扩展和可持续的数据管理提供了系统化方法，支持数据与模型的协同进化。

Abstract: The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.

</details>


### [338] [GEBench: Benchmarking Image Generation Models as GUI Environments](https://arxiv.org/abs/2602.09007)
*Haodong Li,Jingwei Wu,Quan Sun,Guopeng Li,Juanxi Tian,Huanyu Zhang,Yanlin Lai,Ruichuan An,Hongbo Peng,Yuhong Dai,Chenxi Li,Chunmei Qing,Jia Wang,Ziyang Meng,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.AI

TL;DR: GEBench是一个用于评估GUI生成中动态交互和时间连贯性的新基准，包含700个样本和五维评估指标GE-Score，发现现有模型在单步转换表现良好但在长序列中保持时间连贯性方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型能够基于用户指令预测未来GUI状态，但现有基准主要关注通用领域的视觉保真度，对GUI特定上下文中的状态转换和时间连贯性评估不足。

Method: 提出GEBench基准，包含700个精心策划的样本，涵盖五个任务类别，包括单步交互和多步轨迹，以及定位点标注。提出GE-Score五维评估指标：目标达成、交互逻辑、内容一致性、UI合理性和视觉质量。

Result: 对当前模型的广泛评估表明，它们在单步转换上表现良好，但在保持长时间交互序列的时间连贯性和空间定位方面存在显著困难。图标解释、文本渲染和定位精度是关键瓶颈。

Conclusion: 这项工作为系统评估提供了基础，并为未来构建高保真生成GUI环境的研究指明了有前景的方向。代码已开源。

Abstract: Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [339] [AgentSpawn: Adaptive Multi-Agent Collaboration Through Dynamic Spawning for Long-Horizon Code Generation](https://arxiv.org/abs/2602.07072)
*Igor Costa*

Main category: cs.SE

TL;DR: AgentSpawn：一种动态多智能体协作架构，通过自动内存转移、自适应生成策略和一致性协议，显著提升长时程代码生成任务的完成率并降低内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统采用静态工作流，无法在运行时分析发现未预期复杂性时进行自适应调整。长时程代码生成需要持续的上下文和跨领域的自适应专业知识，当前系统存在五个关键差距：内存连续性、技能继承、任务恢复、运行时生成和并发一致性。

Method: 提出AgentSpawn架构，包含三个核心机制：(1) 生成过程中的自动内存转移，(2) 由运行时复杂度指标触发的自适应生成策略，(3) 并发修改的一致性协议。该架构解决了现有研究中的五个关键差距。

Result: 实验验证显示，AgentSpawn在SWE-bench等基准测试中比静态基线方法实现了34%更高的完成率，同时通过选择性切片将内存开销降低了42%。

Conclusion: AgentSpawn通过动态智能体协作机制有效解决了长时程代码生成中的自适应性问题，显著提升了任务完成效率并降低了资源消耗，为多智能体系统的动态工作流设计提供了新思路。

Abstract: Long-horizon code generation requires sustained context and adaptive expertise across domains. Current multi-agent systems use static workflows that cannot adapt when runtime analysis reveals unanticipated complexity. We propose AgentSpawn, an architecture enabling dynamic agent collaboration through: (1) automatic memory transfer during spawning, (2) adaptive spawning policies triggered by runtime complexity metrics, and (3) coherence protocols for concurrent modifications. AgentSpawn addresses five critical gaps in existing research around memory continuity, skill inheritance, task resumption, runtime spawning, and concurrent coherence. Experimental validation demonstrates AgentSpawn achieves 34% higher completion rates than static baselines on benchmarks like SWE-bench while reducing memory overhead by 42% through selective slicing.

</details>


### [340] [Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark](https://arxiv.org/abs/2602.07079)
*Go Frendi Gunawan,Mukhlis Amien*

Main category: cs.SE

TL;DR: 该研究对11个先进大语言模型在5个软件工程任务上进行了多任务评估，发现模型性能存在显著差异：相同完美分数的模型在完成时间、工具效率和成本上差异巨大，工具使用频率与成功率无关，并识别出两种低效模式。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在软件工程中展现出卓越能力，但缺乏覆盖多样化软件工程活动的综合基准测试。现有研究通常聚焦单一任务，未能全面评估模型在实际软件工程工作流中的表现。

Method: 研究采用多任务评估方法，对11个最先进的大语言模型在5个代表性软件工程任务上进行测试：bug修复、功能开发、代码重构、技术文档编写和研究综述。开发了自动化验证框架来测量输出质量和完成效率。

Result: 关键发现包括：1) 获得相同完美分数的模型在完成时间上存在22倍差异，工具效率49倍差异，估计成本53倍差异；2) 工具使用频率与成功率无相关性(r=0.077)；3) 识别出两种低效模式：循环低效和推理低效；4) 编码任务达到100%成功率，而研究任务更具挑战性(90.9%)。

Conclusion: 该研究提供了对LLMs在软件工程中表现的全面评估，揭示了模型效率的显著差异和工具使用的无效性，强调了在评估LLMs时需要考虑效率指标的重要性。所有实验数据、验证脚本和分析代码均已公开以确保可复现性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.

</details>


### [341] [Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation](https://arxiv.org/abs/2602.07083)
*Yongqing Jiang,Jianze Wang,Zhiqi Shen,Zhenghong Lin,Jiayuan Wang,Yijian Yang,Kaoshan Dai,Haoran Luo*

Main category: cs.SE

TL;DR: 提出一个物理一致性自动建筑建模框架，通过领域知识构建、约束导向模型对齐和验证驱动评估，显著减少幻觉和非合规输出


<details>
  <summary>Details</summary>
Motivation: 结构建模是计算工程科学的基础，即使微小的物理不一致或规范违反都可能使下游模拟失效。虽然大语言模型已展示自动生成建模代码的潜力，但在严格工程约束下，不可执行或物理不一致的输出仍然普遍存在

Method: 提出物理一致性自动建筑建模框架，包括：1）引入CivilInstruct领域特定数据集，形式化结构工程知识和约束推理；2）采用两阶段微调策略强制约束满足和API合规性；3）提出MBEval验证驱动基准，通过闭环验证评估可执行性和结构动力学一致性

Result: 实验结果显示，在严格的验证指标上相比基线模型有持续改进，显著减少了幻觉和非合规输出

Conclusion: 该框架通过整合领域知识构建、约束导向模型对齐和验证驱动评估，实现了物理一致的自动建筑建模，为工程领域的可靠代码生成提供了有效解决方案

Abstract: Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.

</details>


### [342] [Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation](https://arxiv.org/abs/2602.07086)
*Michael Marketsmüller,Simon Martin,Tim Schlippe*

Main category: cs.SE

TL;DR: 本文系统评估了三种RAG变体在企业系统自然语言接口中的应用，发现在SQL查询和REST API调用生成任务中，检索增强至关重要，其中CoRAG在混合文档环境下表现最优。


<details>
  <summary>Details</summary>
Motivation: 企业系统需要自然语言接口来将用户请求转换为结构化操作（如SQL查询和REST API调用）。虽然大语言模型在代码生成方面显示出潜力，但在特定领域的企业环境中，特别是需要同时处理检索和修改任务时，其有效性尚未得到充分探索。

Method: 使用SAP Transactional Banking作为实际企业用例，构建了涵盖SQL查询生成、REST API调用生成以及需要动态任务分类的混合任务的新测试数据集。评估了三种检索增强生成（RAG）变体：标准RAG、Self-RAG和CoRAG，在数据库专用、API专用和混合文档三种上下文下的18种实验配置。

Result: 结果显示检索至关重要：无检索时所有任务的精确匹配准确率为0%，而检索带来了执行准确率（最高79.30%）和组件匹配准确率（最高78.86%）的显著提升。CoRAG在混合文档设置中表现最稳健，在混合任务中实现了统计显著的改进（10.29%精确匹配 vs 标准RAG的7.45%），主要得益于其卓越的SQL生成性能（15.32% vs 11.56%）。

Conclusion: 检索策略设计是生产级自然语言接口的关键决定因素，迭代查询分解在文档异构性下优于top-k检索和二元相关性过滤。CoRAG在混合文档环境中的优越性能为企业系统自然语言接口的实际部署提供了重要指导。

Abstract: Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.

</details>


### [343] [Architectural Anti-Patterns in Student-Developed Microservice Architectures: An Exploratory Study](https://arxiv.org/abs/2602.07147)
*Marco De Luca,Michele Perlotto,Anna Rita Fasolino,Porfirio Tramontana*

Main category: cs.SE

TL;DR: 该研究分析了216名硕士生在微服务架构课程中开发的系统，发现学生引入了23种已知反模式，其中安全问题最为突出，反映了学生更关注功能实现而非系统健壮性。


<details>
  <summary>Details</summary>
Motivation: 由于分布式系统的复杂性和学术界与工业界之间的差距，教授微服务架构具有挑战性。了解学生在微服务架构中引入的质量问题对于改进教育至关重要。

Method: 研究采用纵向、基于项目的课程设计（2023-2025年），涉及216名硕士生（67个团队），他们为游戏化测试平台设计并部署了现实的容器化微服务架构。使用已建立的反模式分类法分析学生开发的系统。

Result: 最终系统揭示了58种已知微服务反模式中的23种，涵盖五个类别：安全问题最为频繁（认证、授权、数据保护）；团队组织和服务交互问题次之；服务内设计和跨服务分解问题较少。学生普遍优先考虑功能交付而非健壮性和运维纪律。

Conclusion: 为改进微服务架构教育，建议：强制执行最低标准（API契约、网关）、提供弹性通信实验、集成安全设计实践、提供CI/CD模板。该研究贡献了现实、全面的教育经验和可复制的行业对齐微服务架构教学模型。

Abstract: Teaching microservice architectures is challenging due to distributed complexity and the gap between academia and industry. Understanding the quality issues students introduce in MSAs is essential to improve education. This study analyzes student-developed microservices using an established anti-pattern taxonomy and derives lessons learned with actionable teaching recommendations. We conducted a longitudinal, project-based course (2023-2025) involving 216 Master's students (67 teams) who designed and deployed a realistic, containerized MSA for a gamified testing platform. The final systems revealed 23 out of 58 known MSA anti-patterns, spanning five categories. Security issues were most frequent, highlighting weaknesses in authentication, authorization, and data protection. Team Organization and Service Interaction problems followed, reflecting limited DevOps experience and difficulties in inter-service coordination. Fewer issues appeared in Intra-service Design and Inter-service Decomposition, suggesting students generally defined service boundaries well. Overall, students prioritized feature delivery over robustness and operational discipline. To address this, we recommend enforcing minimal standards (API contracts, gateways), providing labs on resilient communication, integrating security-by-design practices, and offering CI-CD templates. The paper contributes a realistic, full-scale educational experience and a replicable model for teaching industry-aligned microservice architecture.

</details>


### [344] [Forecasting Developer Environments with GenAI: A Research Perspective](https://arxiv.org/abs/2602.07412)
*Raula Gaikovina Kula,Christoph Treude,Xing Hu,Sebastian Baltes,Earl T. Barr,Kelly Blincoe,Fabio Calefato,Junjie Chen,Marc Cheong,Youmei Fan,Daniel M. German,Marco Gerosa,Jin L. C. Guo,Shinpei Hayashi,Robert Hirschfeld,Reid Holmes,Yintong Huo,Takashi Kobayashi,Michele Lanza,Zhongxin Liu,Olivier Nourry,Nicole Novielli,Denys Poshyvanyk,Shinobu Saito,Kazumasa Shimari,Igor Steinmacher,Mairieli Wessel,Markus Wagner,Annie Vella,Laurie Williams,Xin Xia*

Main category: cs.SE

TL;DR: 专家会议探讨生成式AI对IDE的影响，识别了四个关键研究主题


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI在代码生成、测试、代码审查和程序修复等方面的卓越表现如何改变IDE中的人机交互，理解其对软件开发环境的影响

Method: 组织为期四天的Shonan Meeting 222研究会议，汇集33位来自软件工程、人工智能和人机交互领域的专家，通过讨论识别挑战和机遇

Result: 会议确定了四个主要研究主题，为研究人员和从业者提供了重点关注领域

Conclusion: 生成式AI有潜力显著改变IDE中的人机交互，需要跨学科合作来探索其影响并解决相关挑战

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222, a four-day intensive research meeting. Four themes emerged as areas of interest for researchers and practitioners.

</details>


### [345] [ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair](https://arxiv.org/abs/2602.07561)
*Quanjun Zhang,Ye Shang,Haichuan Hu,Chunrong Fang,Zhenyu Chen,Liang Xiao*

Main category: cs.SE

TL;DR: ComPass：基于预训练语言模型和对比学习的自动补丁正确性评估方法，通过代码转换规则生成语义保留的代码片段，结合对比学习和数据增强技术，显著提升了补丁正确性评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前自动程序修复（APR）存在补丁过拟合问题，即补丁能通过现有测试套件但实际不正确。虽然已有基于预训练语言模型（PLM）的自动补丁正确性评估（APCA）方法，但由于训练范式和数据集的限制，效果仍不理想。需要一种能更好利用有限标注数据的方法来提升补丁正确性评估的准确性。

Method: ComPass采用对比学习和数据增强技术：1）使用代码转换规则为无标注预训练语料和标注微调补丁生成语义保留的代码片段；2）通过对比学习预训练PLMs，捕捉相同语义但不同结构的代码特征；3）集成补丁代码片段的表示嵌入，并使用二元分类器联合微调PLMs来评估补丁正确性。

Result: 在Defects4J的2274个真实世界补丁上的实验结果显示，ComPass达到了88.35%的准确率，显著优于最先进的基线方法APPT。

Conclusion: ComPass通过结合对比学习和数据增强技术，有效解决了现有PLM-based APCA方法的局限性，在自动补丁正确性评估方面取得了显著改进，为减少自动程序修复中的补丁过拟合问题提供了有效解决方案。

Abstract: Automated program repair (APR) attempts to reduce manual debugging efforts and plays a vital role in software maintenance. Despite remarkable progress, APR is still limited in generating overfitting patches, i.e., patches passing available test suites but incorrect. This issue, known as patch overfitting, has become a key concern in the APR community, with numerous approaches proposed to address it. Very recent work proposes a pre-trained language model (PLM)-based automated patch correctness assessment (APCA) approach, indicating the potential of such PLMs in reasoning about patch correctness. Despite being promising, it is still far from perfect due to various limitations, such as the training paradigm and training dataset. In this paper, we present ComPass, a PLM-based APCA approach that leverages contrastive learning and data augmentation to address the technical limitations of prior work. Our work is inspired by the opportunity to integrate contrastive learning with recent PLMs in the field of patch correctness assessment, where large-scale labeled patches are difficult to obtain. ComPass utilizes code transformation rules to generate semantic-preserving code snippets for both unlabeled pre-training corpus and labeled fine-tuning patches. ComPass then pre-trains PLMs with contrastive learning, which captures code features with the same semantics but different structures. ComPass finally integrates representation embeddings of patch code snippets and fine-tunes PLMs with a binary classifier jointly to assess patch code correctness. Experimental results on 2274 real-world patches from Defects4J demonstrate that ComPass achieves an accuracy of 88.35%, significantly outperforming state-of-the-art baseline APPT.

</details>


### [346] [Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach](https://arxiv.org/abs/2602.07569)
*Eduardo C. Peixoto,Hector Oliveira,Geber L. Ramalho,Cesar França*

Main category: cs.SE

TL;DR: 该研究通过系统映射方法分析了76个数字成熟度模型，识别出最常用的10个维度（组织、战略、技术、文化、流程、运营、人员、管理、客户和数据），并为每个维度提出了整合性定义，以解决现有模型维度定义不清晰、不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 数字化转型项目失败率高，数字成熟度模型虽有潜力但存在明显缺陷：维度选择差异大、定义不清晰、组成部分不明确。需要对这些模型提供更清晰的理解。

Method: 采用系统映射方法，包括自动搜索和滚雪球技术，分析了76个数字成熟度模型，回答两个研究问题：1) DMM中最常用的维度是什么？2) 这些维度如何描述，包括其组成部分？

Result: 识别出10个最常用的维度：组织、战略、技术、文化、流程、运营、人员、管理、客户和数据。对这些维度的不同解释进行了调和，并为每个维度提出了整合性定义。

Conclusion: 相比之前的分析，本研究为数字成熟度模型提供了更广泛和更新的视角，通过明确的整合性定义帮助解决现有模型维度定义不一致的问题，为数字化转型实践提供更清晰的指导框架。

Abstract: Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.

</details>


### [347] [A Course on the Introduction to Quantum Software Engineering: Experience Report](https://arxiv.org/abs/2602.07589)
*Andriy Miranskyy*

Main category: cs.SE

TL;DR: 该论文报告了一门将量子计算与软件工程结合的交叉课程设计，强调通过软件工程视角教授量子计算，关注测试、抽象、工具和生命周期管理等实践问题。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算教育主要关注算法和框架层面，缺乏对软件工程实践（如测试、抽象、工具和生命周期管理）的关注。量子计算日益通过编程实践，需要培养具备软件工程能力的量子开发者。

Method: 设计并实施了一门面向本科生和研究生的交叉课程，将基础量子概念与软件工程视角结合，强调可执行工件、经验推理，以及处理概率行为、噪声和不断演化的工具链带来的权衡。

Result: 尽管学生先前对量子计算接触有限，但一旦建立了通过可执行工件表达的对量子信息和量子算法的基础理解，他们就能有效参与量子软件工程主题。课程设计模块化，评估模型可扩展，适合不同学术水平。

Conclusion: 该课程设计为软件工程教育者开发量子计算课程提供了可转移的经验，证明了通过软件工程视角教授量子计算的可行性，强调可执行工件和经验推理的重要性。

Abstract: Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.
  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.
  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.

</details>


### [348] [Evaluating Large Language Models for Detecting Architectural Decision Violations](https://arxiv.org/abs/2602.07609)
*Ruoyu Su,Alexander Bakhtin,Noman Ahmad,Matteo Esposito,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: LLMs能够有效检测代码相关的架构决策违规，但对于依赖部署配置或组织知识的隐式决策效果有限，尚不能完全替代人工验证。


<details>
  <summary>Details</summary>
Motivation: 软件架构决策记录（ADRs）对维护架构质量至关重要，但许多决策违规未被发现，因为项目缺乏系统化文档和自动化检测机制。LLMs的发展为大规模自动化架构推理提供了新可能。

Method: 研究分析了109个GitHub仓库中的980个ADRs，采用多模型流水线方法：一个LLM主模型筛选潜在决策违规，三个额外LLM独立验证推理过程。评估了模型间一致性、准确性、精确率和召回率，并辅以专家评估。

Result: LLMs在显式、可代码推断的决策上表现出显著一致性和强准确性；但对于依赖部署配置或组织知识的隐式或部署导向决策，准确性不足。

Conclusion: LLMs能够有意义地支持架构决策合规性验证，但对于非代码相关的决策，尚不能替代人类专业知识。

Abstract: Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.

</details>


### [349] [HAIF: A Human-AI Integration Framework for Hybrid Team Operations](https://arxiv.org/abs/2602.07641)
*Marc Bara*

Main category: cs.SE

TL;DR: 提出HAIF框架解决人机混合团队工作组织问题，包含四大核心原则、正式委托决策模型、分级自治和反馈机制，可集成到现有敏捷工作流中


<details>
  <summary>Details</summary>
Motivation: 生成式AI、副驾驶和智能体系统在知识工作中快速部署，但缺乏框架来组织人机混合团队的日常工作。现有敏捷、DevOps、MLOps和AI治理框架都无法将混合团队作为统一的交付单元来建模

Method: 采用设计科学研究方法，开发基于协议、可扩展的HAIF框架，包含四大核心原则、正式委托决策模型、分级自治与量化过渡标准、反馈机制，可集成到现有敏捷和看板工作流中

Result: 提出完整的HAIF框架，包含领域特定验证清单、非软件环境适应指南，分析框架结构限制（如连续人机协同生产挑战离散委托模型），框架工具无关且支持迭代采用

Conclusion: HAIF框架解决了AI能力越强越难证明监督必要性的采用悖论，但缺乏监督的后果也越严重。框架为未来实证验证奠定了基础，填补了人机混合团队操作框架的空白

Abstract: The rapid deployment of generative AI, copilots, and agentic systems in knowledge work has created an operational gap: no existing framework addresses how to organize daily work in teams where AI agents perform substantive, delegated tasks alongside humans. Agile, DevOps, MLOps, and AI governance frameworks each cover adjacent concerns but none models the hybrid team as a coherent delivery unit. This paper proposes the Human-AI Integration Framework (HAIF): a protocol-based, scalable operational system built around four core principles, a formal delegation decision model, tiered autonomy with quantifiable transition criteria, and feedback mechanisms designed to integrate into existing Agile and Kanban workflows without requiring additional roles for small teams. The framework is developed following a Design Science Research methodology. HAIF explicitly addresses the central adoption paradox: the more capable AI becomes, the harder it is to justify the oversight the framework demands-and yet the greater the consequences of not providing it. The paper includes domain-specific validation checklists, adaptation guidance for non-software environments, and an examination of the framework's structural limitations-including the increasingly common pattern of continuous human-AI co-production that challenges the discrete delegation model. The framework is tool-agnostic and designed for iterative adoption. Empirical validation is identified as future work.

</details>


### [350] [Debugging code world models](https://arxiv.org/abs/2602.07672)
*Babak Rahmani*

Main category: cs.SE

TL;DR: 代码世界模型（CWMs）通过预测程序执行后的运行时状态来模拟程序执行，但存在两个主要失败模式：长执行历史导致的令牌预算耗尽和字符串值状态处理困难。


<details>
  <summary>Details</summary>
Motivation: 研究代码世界模型的错误来源和局限性，理解其在局部语义执行和长时状态跟踪方面的表现，为改进模型提供方向。

Method: 从两个互补角度研究CWMs：局部语义执行和长时状态跟踪。使用真实代码基准测试识别失败模式，并通过受控的排列跟踪基准测试隔离状态传播行为。

Result: 发现两个主要失败模式：1）密集运行时状态产生导致长执行历史的程序令牌预算耗尽；2）字符串值状态处理失败，主要源于子词分词限制而非程序结构。长时状态退化主要由错误动作生成驱动，当使用真实命令时，Transformer-based CWM能在长时范围内准确传播状态。

Conclusion: 研究结果指出了改进CWMs的方向：需要更高效的监督和与程序执行及数据类型更好对齐的状态表示方法。

Abstract: Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.

</details>


### [351] [On Sequence-to-Sequence Models for Automated Log Parsing](https://arxiv.org/abs/2602.07698)
*Adam Sorrenti,Andriy Miranskyy*

Main category: cs.SE

TL;DR: 该研究系统评估了Transformer、Mamba、LSTM等序列建模架构在日志解析任务中的性能与计算成本，发现Transformer准确率最高，Mamba在计算效率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化日志解析面临异构日志格式、训练与部署数据分布偏移、基于规则方法脆弱性等挑战，需要系统评估不同序列建模架构的性能和计算成本。

Method: 通过控制实验比较四种序列建模架构：Transformer、Mamba状态空间模型、单向LSTM和双向LSTM，共训练396个模型，使用相对Levenshtein编辑距离进行评估并进行统计显著性检验。

Result: Transformer获得最低平均相对编辑距离(0.111)，其次是Mamba(0.145)、单向LSTM(0.186)和双向LSTM(0.265)。Mamba在保持竞争力的准确率同时计算成本显著更低。字符级分词通常能提升性能，序列长度对Transformer准确率影响可忽略，Mamba和Transformer比循环模型具有更强的样本效率。

Conclusion: Transformer能将解析错误减少23.4%，而Mamba在数据或计算资源受限时是强有力的替代方案。研究结果为研究人员和实践者提供了关于表示选择、序列长度和样本效率的实用指导。

Abstract: Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.

</details>


### [352] [Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards](https://arxiv.org/abs/2602.07783)
*Zejun Zhang,Yixin Gan,Zhenchang Xing,Tian Zhang,Yi Li,Xiwei Xu,Qinghua Lu,Liming Zhu*

Main category: cs.SE

TL;DR: LintCFG：基于LLM的DSL驱动编译方法，自动化生成代码检查工具配置，支持跨编程语言、编码标准和检查工具


<details>
  <summary>Details</summary>
Motivation: 手动配置代码检查工具复杂且需要专业知识，编程语言、编码标准和检查工具的多样性及演变导致重复且维护密集的配置工作

Method: 设计领域特定语言（DSL）以工具无关的方式表达编码规则，将检查工具配置构建为DSL配置指令，通过编译过程将自然语言编码标准解析为DSL编码标准，匹配配置指令并验证一致性，最终生成特定检查工具的配置

Result: 在Java编码标准的Checkstyle实验中，DSL表示精度和召回率超过90%，细粒度检查工具配置生成的准确率、精度、召回率和F1分数接近70%（部分超过70%），精度比基线方法提升超过100%。用户研究表明提高了开发人员配置检查工具的效率和方法的通用性

Conclusion: LintCFG方法能有效自动化代码检查工具配置，支持跨编程语言、编码标准和检查工具，显著提高配置效率和准确性

Abstract: Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.

</details>


### [353] [Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution](https://arxiv.org/abs/2602.07821)
*Shinobu Saito*

Main category: cs.SE

TL;DR: 该论文将空间统计方法应用于软件工程领域，通过分析模块调用关系来识别需要修改或删除的软件模块。


<details>
  <summary>Details</summary>
Motivation: 在软件维护工作中，软件架构师和程序员需要识别需要修改或删除的模块。虽然用户请求和错误报告可用于此目的，但评估软件内部模块的执行状态同样至关重要。

Method: 首先定义软件空间数据集，将软件内部结构视为基于模块调用关系的空间。然后使用空间统计方法进行空间聚类可视化和基于空间度量的统计测试。

Result: 论文展示了空间统计在软件工程领域的应用潜力，通过可视化空间聚类和统计测试来评估模块执行状态。

Conclusion: 空间统计在软件工程领域具有实用性，但未来仍面临挑战需要进一步研究和解决。

Abstract: In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.

</details>


### [354] [HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid](https://arxiv.org/abs/2602.07871)
*Xiang Li,Siyu Lu,Sarro Federica,Claire Le Goues,He Ye*

Main category: cs.SE

TL;DR: HerAgent：基于环境成熟度层次结构的自动化软件环境设置方法，通过执行验证和修复逐步构建可执行环境，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动化软件环境设置面临依赖复杂、构建系统异构、文档不完整等挑战。现有基于大语言模型的方法通常使用弱信号（如依赖安装或部分测试执行）评估成功，无法确保项目真正可运行。

Method: 提出环境成熟度层次结构，定义基于逐步增强执行要求的三个成功级别，最终要求项目主入口点成功执行。基于此层次结构，开发HerAgent方法，通过执行验证和修复逐步构建可执行环境。

Result: 在四个公共基准测试中，HerAgent优于所有相关工作，实现了高达79.6%的改进。在复杂的C/C++项目上，比先前方法提升66.7%。此外，HerAgent独特解决了11-30个环境实例，这些实例是先前方法无法配置的。

Conclusion: 环境设置成功应通过可执行证据而非单一二进制信号评估。HerAgent通过环境成熟度层次结构和执行验证方法，显著提高了自动化环境设置的准确性和可靠性。

Abstract: Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.

</details>


### [355] [Rethinking Code Complexity Through the Lens of Large Language Models](https://arxiv.org/abs/2602.07882)
*Chen Xie,Yuling Shi,Xiaodong Gu,Beijun Shen*

Main category: cs.SE

TL;DR: 传统代码复杂度指标与LLM处理代码的难度不相关，作者提出基于LLM视角的新复杂度指标LM-CC，该指标能更好预测LLM性能


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在代码理解和生成任务上的快速发展，一个重要但尚未充分探索的问题是：传统的代码复杂度指标（如圈复杂度）是否能有效表征LLM处理代码时遇到的困难？作者发现传统指标与LLM性能之间缺乏一致性关联。

Method: 提出LM-CC（语言模型代码复杂度）指标，其核心前提是LLM感知的难度由程序语义的非线性驱动。方法包括：基于熵将程序分解为语义单元，将这些单元组织成组合层次结构，并通过组合层次和分支引起的发散的原则性聚合来量化复杂度，捕捉代码处理过程中的累积模型不确定性。

Result: 实验表明，在控制代码长度后，传统复杂度指标与LLM性能没有一致相关性。而LM-CC不仅比传统指标与LLM性能的相关性更强，而且降低LM-CC能直接提升任务性能。

Conclusion: 传统代码复杂度指标无法有效表征LLM处理代码的难度，需要从LLM视角重新定义代码复杂度。LM-CC作为基于LLM感知的新指标，能更好地预测和改善LLM在代码任务上的性能。

Abstract: Code complexity metrics such as cyclomatic complexity have long been used to assess software quality and maintainability. With the rapid advancement of large language models (LLMs) on code understanding and generation tasks, an important yet underexplored question arises: do these traditional complexity metrics meaningfully characterize the difficulty LLMs experience when processing code? In this work, we empirically demonstrate that, after controlling for code length, classical metrics exhibit no consistent correlation with LLM performance, revealing a fundamental mismatch with model-perceived difficulty. To address this gap, we propose LM-CC, a novel code complexity metric designed from the perspective of LLMs. The core premise of LM-CC is that LLM-perceived difficulty is driven by the nonlinearity of program semantics. Accordingly, we decompose programs into semantic units based on entropy, organize these units into a compositional hierarchy, and quantify complexity as a principled aggregation of compositional level and branching-induced divergence, capturing cumulative model uncertainty during code processing. Our extensive experiments show that LM-CC not only correlates more strongly with LLM performance than traditional metrics but also that lowering it directly enhances task performance.

</details>


### [356] [Is Your Private Information Logged? An Empirical Study on Android App Logs](https://arxiv.org/abs/2602.07893)
*Zhiyuan Chen,Soham Sanjay Deo,Poorna Chander Reddy Puttaparthi,Vanessa Nava-Camal,Yiming Tang,Xueling Zhang,Weiyi Shang*

Main category: cs.SE

TL;DR: 该研究分析了Android应用日志中的隐私泄露问题，通过构建全面的数据集进行实证研究，揭示了开发者对日志隐私问题的关注点以及Android应用日志中隐私泄露的普遍性。


<details>
  <summary>Details</summary>
Motivation: 随着移动应用的快速增长，用户对隐私的担忧日益突出。Android应用日志作为重要的计算机资源，既帮助开发者调试和监控应用状态，又包含丰富的软件系统信息。先前研究承认软件日志和Android应用中的隐私泄露是重要问题，但未能提供Android应用日志中隐私泄露的全面视图。

Method: 研究构建了全面的Android应用日志数据集，并进行实证研究，从三个方面进行分析：(1) 了解真实世界开发者对软件日志相关隐私问题的关注；(2) 研究Android应用日志中的隐私泄露；(3) 调查隐私泄露的Android应用日志特征并分析其原因。

Result: 研究揭示了真实世界开发者对软件日志隐私问题的五类不同关注点，以及Android应用日志中隐私泄露的普遍性。大多数隐私泄露源于开发者对此类泄露的无意识。研究还发现Android应用日志中隐私泄露的现状和严重程度。

Conclusion: 该研究为开发者提供了保护隐私不被记录的建议，强调了Android应用日志中隐私泄露问题的严重性，并指出开发者意识不足是主要根源。研究结果有助于提高开发者对日志隐私保护的重视。

Abstract: With the rapid growth of mobile apps, users' concerns about their privacy have become increasingly prominent. Android app logs serve as crucial computer resources, aiding developers in debugging and monitoring the status of Android apps, while also containing a wealth of software system information. Previous studies have acknowledged privacy leaks in software logs and Android apps as significant issues without providing a comprehensive view of the privacy leaks in Android app logs. In this study, we build a comprehensive dataset of Android app logs and conduct an empirical study to analyze the status and severity of privacy leaks in Android app logs. Our study comprises three aspects: (1) Understanding real-world developers' concerns regarding privacy issues related to software logs; (2) Studying privacy leaks in the Android app logs; (3) Investigating the characteristics of privacy-leaking Android app logs and analyzing the reasons behind them. Our study reveals five different categories of concerns from real-world developers regarding privacy issues related to software logs and the prevalence of privacy leaks in Android app logs, with the majority stemming from developers' unawareness of such leaks. Additionally, our study provides developers with suggestions to safeguard their privacy from being logged.

</details>


### [357] [Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry](https://arxiv.org/abs/2602.08015)
*Patricia G. F. Matsubara,Tayana Conte*

Main category: cs.SE

TL;DR: 该论文提出将健康科学领域的"证据到决策"框架引入软件工程领域，以解决系统文献综述结果难以触达实践者的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管软件工程领域已进行大量系统文献综述并完善了相关流程，但研究结果仍难以有效传达给行业实践者，需要寻找新的解决方案来弥合研究与实践的鸿沟。

Method: 引入健康科学领域的证据到决策框架，该框架通过专家小组评估现有最佳证据，并基于相关标准制定结构化建议。论文还提供了基于SE系统文献综述的工作示例。

Result: 提出EtD框架可以为软件工程领域提供更全面的决策标准，帮助将系统文献综述结果转化为对实践者有用的建议，但实施过程中可能面临挑战。

Conclusion: 证据到决策框架有望改善软件工程研究与实践之间的知识转移，但需要解决实施中的挑战，并开发更全面的行业实践建议标准。

Abstract: Over twenty years ago, the Software Engineering (SE) research community have been involved with Evidence-Based Software Engineering (EBSE). EBSE aims to inform industrial practice with the best evidence from rigorous research, preferably from systematic literature reviews (SLRs). Since then, SE researchers have conducted many SLRs, perfected their SLR procedures, proposed alternative ways of presenting their results (such as Evidence Briefings), and profusely discussed how to conduct research that impacts practice. Nevertheless, there is still a feeling that SLRs' results are not reaching practitioners. Something is missing. In this vision paper, we introduce Evidence to Decision (EtD) frameworks from the health sciences, which propose gathering experts in panels to assess the existing best evidence about the impact of an intervention in all relevant outcomes and make structured recommendations based on them. The insight we can leverage from EtD frameworks is not their structure per se but all the relevant criteria for making recommendations to practitioners from SLRs. Furthermore, we provide a worked example based on an SE SLR. We also discuss the challenges the SE research and practice community may face when adopting EtD frameworks, highlighting the need for more comprehensive criteria in our recommendations to industry practitioners.

</details>


### [358] [Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies](https://arxiv.org/abs/2602.08084)
*Mark Looi,Marc Szepan*

Main category: cs.SE

TL;DR: 研究比较了时区相近（近岸）和时区差异大（远岸）的外包软件开发对项目成功的影响，发现近岸开发在整体成功、质量、项目管理、进度控制和沟通方面更有优势。


<details>
  <summary>Details</summary>
Motivation: 随着全球软件外包成为普遍实践，项目团队分布在不同的时区。本研究关注客户将软件开发外包给时区相近（近岸）或时区差异大（远岸）的供应商时，时间距离对项目结果的影响。

Method: 通过调查80名客户和访谈其中6名客户，研究了时间距离对整体成功、成本、项目管理努力、进度、质量、沟通问题等结果的影响，同时考察了软件开发方法论对这些结果的影响。

Result: 近岸开发在整体成功、质量、减少项目管理努力、保持进度、提高质量和减少沟通问题方面具有优势。软件开发方法论似乎只影响更高的成本。

Conclusion: 近岸开发对沟通密集型或敏捷项目更为有利。研究为外包全球软件开发的客户提供了实用建议，建议他们优先考虑近岸开发。

Abstract: Developing software globally using outsourced resources has become a common practice, with project teams often distributed in different time zones. In this study, we focus on customers that contract software development to vendors in temporally nearshore or far offshore locations. We conducted a survey to determine the effect of temporal distance on overall success, costs, project management effort, schedule, quality, communication problems, and other outcomes of interest to managers. In the survey of 80 customers and interviews with 6 of them, we also investigated the effect of software development methodology on the same outcomes. The results show that nearshore development is advantageous for overall success, quality, reduced PM effort, maintaining schedule, higher quality, and engendering fewer communication problems. Development methodology appears to only influence higher costs. We assess our findings in the context of prior GSE research and provide practical advice for customers of outsourced global software development, chief of which is to favor nearshore for communication-intensive or Agile projects.

</details>


### [359] [Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks](https://arxiv.org/abs/2602.08133)
*Mojtaba Mostafavi Ghahfarokhi,Hamed Jahantigh,Alireza Asadi,Abbas Heydarnoori*

Main category: cs.SE

TL;DR: 该研究提出将源代码度量作为辅助信号，用于自动生成计算笔记本的文档，通过两阶段方法（数据集构建和模型评估）证明代码度量能提升文档生成的准确性和上下文相关性。


<details>
  <summary>Details</summary>
Motivation: 自动文档生成方法通常忽视代码的结构和量化特征，而这些特征对可读性和理解很重要。计算笔记本作为数据科学家的常用工具，集成了代码、叙述和结果，但存在文档不一致的问题。代码度量可能包含与程序理解相关的信息，可作为文档生成的辅助信号。

Method: 采用两阶段方法：1）改进CodeSearchNet数据集构建流程，从1700多万个代码和Markdown单元格中创建专门数据集，经过结构和语义过滤后提取约36,734个高质量（代码，Markdown）对；2）评估两种建模范式：轻量级CNN-RNN架构和少样本GPT-3.5架构，分别在有/无代码度量信息的情况下进行对比。

Result: 结果表明，加入代码度量信息能显著提升生成文档的质量：CNN-RNN架构在BLEU-1上提升6%，ROUGE-L F1上提升3%；LLM架构在BERTScore F1上提升9%。这证明代码度量提供了有价值的结构上下文，能增强不同模型家族的自动文档生成能力。

Conclusion: 源代码度量作为辅助信号能有效提升自动文档生成的准确性和上下文相关性，为计算笔记本等复杂代码文档的自动化生成提供了新思路，表明结构特征在文档生成任务中具有重要价值。

Abstract: Effective code documentation is essential for collaboration, comprehension, and long-term software maintainability, yet developers often neglect it due to its repetitive nature. Automated documentation generation has evolved from heuristic and rule-based methods to neural network-based and large language model (LLM)-based approaches. However, existing methods often overlook structural and quantitative characteristics of code that influence readability and comprehension. Prior research suggests that code metrics capture information relevant to program understanding. Building on these insights, this paper investigates the role of source code metrics as auxiliary signals for automated documentation generation, focusing on computational notebooks, a popular medium among data scientists that integrates code, narrative, and results but suffers from inconsistent documentation. We propose a two-stage approach. First, the CodeSearchNet dataset construction process was refined to create a specialized dataset from over 17 million code and markdown cells. After structural and semantic filtering, approximately 36,734 high-quality (code, markdown) pairs were extracted. Second, two modeling paradigms, a lightweight CNN-RNN architecture and a few-shot GPT-3.5 architecture, were evaluated with and without metric information. Results show that incorporating code metrics improves the accuracy and contextual relevance of generated documentation, yielding gains of 6% in BLEU-1 and 3% in ROUGE-L F1 for CNN-RNN-based architecture, and 9% in BERTScore F1 for LLM-based architecture. These findings demonstrate that integrating code metrics provides valuable structural context, enhancing automated documentation generation across diverse model families.

</details>


### [360] [Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects](https://arxiv.org/abs/2602.08166)
*Oscar Manglaras,Alex Farkas,Thomas Woolford,Christoph Treude,Markus Wagner*

Main category: cs.SE

TL;DR: 提出一个支持技术特定分析模块和多仓库环境的静态架构重构框架，解决微服务架构文档维护难题


<details>
  <summary>Details</summary>
Motivation: 微服务架构虽然鼓励小型独立服务开发，但增加了架构复杂性。准确文档对维护至关重要，但由于服务快速独立演化而难以保持更新。现有静态架构重构方法存在技术限制、单仓库约束或高实现门槛等问题。

Method: 提出新颖的静态架构重构框架，支持技术特定的分析模块（称为提取器），并支持多仓库环境中的分布式架构重构。描述了核心设计概念和算法，包括提取器执行方式、数据传递机制以及输出统一方法。框架与现有静态分析工具和算法互操作，允许从提取器内调用或嵌入它们。

Result: 该框架能够克服现有方法的技术限制，支持多仓库环境，降低实现门槛，并提供与现有工具的互操作性。

Conclusion: 提出的静态架构重构框架为解决微服务架构文档维护挑战提供了有效的解决方案，通过支持技术特定分析模块和多仓库环境，能够保持架构文档的准确性和时效性。

Abstract: Microservice architectures encourage the use of small, independently developed services; however, this can lead to increased architectural complexity. Accurate documentation is crucial, but is challenging to maintain due to the rapid, independent evolution of services. While static architecture reconstruction provides a way to maintain up-to-date documentation, existing approaches suffer from technology limitations, mono-repo constraints, or high implementation barriers. This paper presents a novel framework for static architecture reconstruction that supports technology-specific analysis modules, called \emph{extractors}, and supports \emph{distributed architecture reconstruction} in multi-repo environments. We describe the core design concepts and algorithms that govern how extractors are executed, how data is passed between them, and how their outputs are unified. Furthermore, the framework is interoperable with existing static analysis tools and algorithms, allowing them to be invoked from or embedded within extractors.

</details>


### [361] [ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases](https://arxiv.org/abs/2602.08181)
*Oscar Manglaras,Alex Farkas,Thomas Woolford,Christoph Treude,Markus Wagner*

Main category: cs.SE

TL;DR: ModARO是一个模块化的微服务架构重构方法，允许编写可重用的提取器来重构不同技术栈的微服务架构，解决了跨项目复用和跨仓库重构的难题。


<details>
  <summary>Details</summary>
Motivation: 微服务架构虽然促进了小型独立服务的开发，但增加了整体架构复杂性。快速独立的服务开发增加了架构漂移的风险，且难以维护文档。自动架构重构可以避免这些问题，但现有方法难以跨项目复用重构代码，因为不同项目使用不同的技术组合和项目特定约定。此外，微服务通常被拆分到不同的代码仓库，使得从单一代码库无法获得系统的完整视图。

Method: 提出了ModARO方法，允许编写模块化的重构代码（"提取器"），这些提取器可以针对任何技术编写，并能在不同项目中复用，独立于周围的技术栈以及服务是否被拆分到多个代码库。开发者可以组装或创建适合其技术栈的提取器，并在不同仓库间分发架构重构任务。

Result: 通过配置ModARO重构了10个开源项目，并通过用户研究验证了ModARO的有效性和可用性。用户研究涉及8名行业从业者，与最先进的基线方法进行比较，证明了ModARO的实用性和可用性。

Conclusion: ModARO方法使开发者能够为特定技术栈定制提取器，并在不同仓库间分发架构重构任务，从而支持集成到仓库的CI/CD流水线中。这种方法解决了微服务架构重构中的跨项目复用和跨仓库重构难题。

Abstract: Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines.

</details>


### [362] [Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners](https://arxiv.org/abs/2602.08192)
*Mirko Perkusich,Danyllo Albuquerque,Allysson Allex Araújo,Matheus Paixão,Rohit Gheyi,Marcos Kalinowski,Angelo Perkusich*

Main category: cs.SE

TL;DR: 研究调查了巴西70名专业人士在Scrum管理活动中使用大语言模型的情况，发现LLM主要应用于探索Scrum实践，提高生产力和减少人工劳动，但存在输出不完全准确、保密问题和幻觉等风险。


<details>
  <summary>Details</summary>
Motivation: 虽然Scrum在软件项目管理中广泛应用，LLM为知识密集型Scrum实践提供了新机会，但现有研究主要关注编码和测试等技术活动，缺乏LLM在Scrum管理活动中的应用证据。

Method: 通过对70名巴西专业人士进行调查研究，其中49人积极使用Scrum，33人报告在Scrum实践中使用LLM助手，分析了LLM在Scrum管理活动中的使用情况。

Result: 结果显示LLM使用水平高且频繁：85%受访者具备中级或高级熟练度，52%每天使用。LLM主要集中于探索Scrum实践，工件和事件获得针对性但不均衡的支持，而更广泛的管理任务采用更为谨慎。主要益处包括提高生产力（78%）和减少人工劳动（75%），但存在"几乎正确"的输出（81%）、保密担忧（63%）和使用中的幻觉（59%）等风险。

Conclusion: 本研究首次对LLM在Scrum管理中的使用进行了实证描述，识别了当前实践，量化了益处和风险，并为敏捷环境中负责任地采用和集成LLM提供了方向。

Abstract: Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments.

</details>


### [363] [Specification Vibing for Automated Program Repair](https://arxiv.org/abs/2602.08263)
*Taohong Zhu,Lucas C. Cordeiro,Mustafa A. Mustafa,Youcheng Sun*

Main category: cs.SE

TL;DR: VibeRepair是一种基于行为规范的自动程序修复方法，将修复过程从直接修改代码转变为修复行为规范，通过LLM生成更准确、行为一致的修复方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的自动程序修复方法大多是代码中心的，直接重写源代码可能导致幻觉修复和行为不一致。需要一种更易被LLM理解的表示形式，以实现更准确的理解、分析和修复对齐。

Method: VibeRepair采用规范中心的修复范式：1) 将错误代码转换为结构化行为规范；2) 推断并修复规范偏差；3) 在修正后的行为规范严格指导下合成代码；4) 按需推理组件通过程序分析和历史修复证据增强困难案例处理。

Result: 在Defects4J v1.2上正确修复174个bug，比最强基线多28个（提升19%）；在Defects4J v2.0上修复178个bug，比先前方法多33个（提升23%）。在训练期后收集的真实世界基准测试中也表现出有效性和泛化能力。

Conclusion: 通过将修复中心从代码转移到明确的行为意图，VibeRepair为"氛围编码"时代重新定义了自动程序修复：让行为先行，代码自然跟随。

Abstract: Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of "vibe" coding: make the behavior sing, and the code will follow.

</details>


### [364] [Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas](https://arxiv.org/abs/2602.08765)
*Micah Villmow*

Main category: cs.SE

TL;DR: Scylla是一个用于评估智能编码工具的评价框架，通过七层测试逐步增加复杂度来量化不同架构选择对能力和成本的影响，核心指标是Cost-of-Pass（CoP）。


<details>
  <summary>Details</summary>
Motivation: 当前LLM工具正在快速自动化软件开发任务，但缺乏严谨的方法来评估不同架构选择（如提示、技能、工具、多智能体设置）如何实质影响能力和成本。

Method: 引入Scylla评价框架，使用七层测试（T0-T6）逐步增加复杂度进行结构化消融研究，核心指标是Cost-of-Pass（CoP）。框架模型无关，可与任何CLI工具配合使用，使用多个LLM评估者进行共识评估。

Result: 创建了一个可重复的框架，量化了智能体复杂度与实际结果之间的权衡，表明架构复杂度并不总是提高质量。

Conclusion: Scylla框架为评估智能编码工具提供了系统方法，能够量化不同架构选择对成本和能力的影响，帮助开发者做出更明智的决策。

Abstract: LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.

</details>


### [365] [ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS](https://arxiv.org/abs/2602.08866)
*Bang Xie,Senjian Zhang,Zhiyuan Peng,Wei Chen,Chenhao Ying,Yuan Luo*

Main category: cs.SE

TL;DR: ArkEval：首个针对HarmonyOS ArkTS语言的自动化代码修复评估框架与基准数据集，包含502个可复现问题，用于评估LLM在ArkTS代码修复中的能力


<details>
  <summary>Details</summary>
Motivation: 随着HarmonyOS平台的重要性日益增长，ArkTS作为其核心开发语言缺乏自动化代码修复工具，主要原因是缺少高质量的评估基准。当前生态系统需要专门的工具来支持ArkTS代码的自动修复。

Method: 1) 从华为官方包含400多个独立ArkTS应用的大型仓库中挖掘问题；2) 通过严格的多阶段筛选流程，筛选出502个可复现问题；3) 采用基于LLM的测试生成和投票机制确保可测试性；4) 标准化问题描述以支持公平评估；5) 使用检索增强的修复工作流评估四个最先进的LLM模型

Result: 构建了首个专门针对ArkTS自动化程序修复的全面基准数据集ArkEval，包含502个可复现问题。通过评估四个最先进的LLM模型，揭示了当前LLM在修复ArkTS代码方面的能力和局限性。

Conclusion: ArkEval填补了HarmonyOS生态系统中ArkTS语言自动化代码修复评估的空白，为未来在这个低资源语言领域的研究铺平了道路，有助于推动ArkTS开发工具的进步。

Abstract: Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain.

</details>


### [366] [DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories](https://arxiv.org/abs/2602.08887)
*Adam Trendowicz,Daniel Seifert,Andreas Jedlitschka,Marcus Ciolkowski,Anton Strahilov*

Main category: cs.SE

TL;DR: 本文提出了基于GPT-4o的"DeepQuali"方法，用于敏捷软件开发中的需求质量评估和改进，并在两家小型公司进行了实证评估。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（特别是大语言模型）在软件工程中主要用于编码任务，但在需求工程（特别是需求验证）方面应用有限。当前GAI在需求领域的应用主要集中在需求获取、转换和分类，而非质量评估。

Method: 提出并评估了基于GPT-4o的"DeepQuali"方法，用于敏捷软件开发中的需求质量评估和改进。该方法在两个小型公司的项目中应用，将LLM的质量评估与专家判断进行比较，并通过走查、反馈收集和接受度评级来评估方法。

Result: 专家在很大程度上同意LLM的质量评估，特别是在整体评级和解释方面。但专家之间在详细评级上并不总是一致，表明专业知识和经验可能影响判断。专家认可该方法的实用性，但批评其缺乏工作流程集成。

Conclusion: 大语言模型在支持软件工程师进行需求质量评估和改进方面具有潜力。明确使用质量模型和解释性反馈可以提高接受度，但需要更好地集成到现有工作流程中。

Abstract: Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach "DeepQuali", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.

</details>


### [367] [Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance](https://arxiv.org/abs/2602.08915)
*Giovanni Pinna,Jingzhi Gong,David Williams,Federica Sarro*

Main category: cs.SE

TL;DR: 该研究对5个AI编程助手在7,156个PR任务中的表现进行了实证比较，发现任务类型是接受率的主要影响因素，文档任务接受率最高(82.1%)，不同助手在不同任务类型上各有优势。


<details>
  <summary>Details</summary>
Motivation: 随着AI编程助手的快速普及，缺乏对其在不同任务类型和时间维度上有效性的系统比较，需要实证研究来指导开发者选择合适的工具。

Method: 使用AIDev数据集的7,156个PR数据，比较OpenAI Codex、GitHub Copilot、Devin、Cursor和Claude Code五个AI助手，进行时间趋势分析和任务类型分层分析。

Result: 时间趋势显示Devin是唯一持续改进的助手(每周+0.77%)；文档任务接受率(82.1%)显著高于新功能任务(66.1%)；OpenAI Codex在所有9个任务类别中表现稳定(59.6%-88.6%)；不同助手在不同任务类型上各有优势。

Conclusion: AI编程助手的表现高度依赖于任务类型，没有单一助手在所有任务上都最优，开发者应根据具体任务类型选择合适的工具，同时需要关注助手随时间演化的性能变化。

Abstract: The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%).

</details>


### [368] [Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability](https://arxiv.org/abs/2602.07071)
*S M Rakib UI Karim,Wenyi Lu,Sean Goggins*

Main category: cs.SE

TL;DR: 这篇文献综述探讨了人工智能如何被用来解决开源软件可持续性面临的挑战，包括维护贡献者参与度、确保资金、代码质量与安全、社区健康以及防止项目废弃等问题。


<details>
  <summary>Details</summary>
Motivation: 开源软件是现代数字基础设施的基础，但在许多关键案例中仍然难以确保足够的贡献。研究旨在探索如何利用人工智能解决开源软件可持续性面临的挑战。

Method: 通过文献综述方法，综合近期跨学科研究，分析人工智能在开源软件可持续性领域的应用、局限性和伦理问题。

Result: 识别了人工智能在开源软件中的关键应用领域，包括自动化错误分类、系统维护、贡献者引导、社区健康分析、漏洞检测和任务自动化。同时揭示了数据可用性、偏见与公平性、透明度、滥用风险等局限性。

Conclusion: 人工智能不应被视为替代品，而是增强人类基础设施的工具。研究强调了人工智能驱动干预的承诺与陷阱，并提出了未来研究方向，旨在支持更具韧性和公平性的开源生态系统。

Abstract: Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [369] [Lemon Agent Technical Report](https://arxiv.org/abs/2602.07092)
*Haipeng Jiang,Kailong Ren,Zimo Yin,Zhetao Sun,Xin Gan,Guangyi Lv,Ming He,Peng Wang,Congli Yin,Hong Pan,Changwen Zhang,Shan Tong,Zhengyu Xu,Zeping Chen,Yubin Huangfu,Yanzhi Xu,Xing Su,Qin Feng,Dong An,Jianping Fan*

Main category: cs.MA

TL;DR: Lemon Agent是一个基于AgentCortex框架的多智能体编排-工作者系统，通过分层自适应调度机制、三层渐进式上下文管理和自演化记忆系统，在复杂任务处理中实现了资源效率、上下文管理和多模态感知的优化，在权威基准测试中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体系统在处理复杂长时程任务时表现出色，但仍存在资源效率、上下文管理和多模态感知方面的固有局限性。为解决这些问题，研究者提出了Lemon Agent系统。

Method: 基于新提出的AgentCortex框架构建多智能体编排-工作者系统，采用分层自适应调度机制（编排层和工作层）、三层渐进式上下文管理策略、自演化记忆系统，以及增强的MCP工具集。

Result: 在权威基准测试中，Lemon Agent在GAIA上实现了91.36%的整体准确率，在xbench-DeepSearch排行榜上以77+分位居榜首，表现出色。

Conclusion: Lemon Agent通过其创新的架构设计，在复杂任务处理中实现了全局协调与局部执行的协同平衡，显著优化了资源利用和任务处理效率，为智能体系统的进一步发展提供了有价值的参考。

Abstract: Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perception. Based on these observations, Lemon Agent is introduced, a multi-agent orchestrator-worker system built on a newly proposed AgentCortex framework, which formalizes the classic Planner-Executor-Memory paradigm through an adaptive task execution mechanism. Our system integrates a hierarchical self-adaptive scheduling mechanism that operates at both the overall orchestrator layer and workers layer. This mechanism can dynamically adjust computational intensity based on task complexity. It enables orchestrator to allocate one or more workers for parallel subtask execution, while workers can further improve operational efficiency by invoking tools concurrently. By virtue of this two-tier architecture, the system achieves synergistic balance between global task coordination and local task execution, thereby optimizing resource utilization and task processing efficiency in complex scenarios. To reduce context redundancy and increase information density during parallel steps, we adopt a three-tier progressive context management strategy. To make fuller use of historical information, we propose a self-evolving memory system, which can extract multi-dimensional valid information from all historical experiences to assist in completing similar tasks. Furthermore, we provide an enhanced MCP toolset. Empirical evaluations on authoritative benchmarks demonstrate that our Lemon Agent can achieve a state-of-the-art 91.36% overall accuracy on GAIA and secures the top position on the xbench-DeepSearch leaderboard with a score of 77+.

</details>


### [370] [Altruism and Fair Objective in Mixed-Motive Markov games](https://arxiv.org/abs/2602.08389)
*Yao-hua Franck Xu,Tayeb Lemlouma,Arnaud Braud,Jean-Marie Bonnin*

Main category: cs.MA

TL;DR: 本文提出了一种基于比例公平性的新框架来促进多智能体合作中的公平性，替代传统的功利主义目标，并在经典社会困境和序列环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 合作对社会至关重要，但个体倾向于搭便车以获取集体合作的利益而不承担成本，导致不公平。传统功利主义方法虽然能产生高效结果，但可能导致高度不平等。需要一种新框架来促进更公平的合作。

Method: 提出用比例公平性替代标准功利主义目标，为每个智能体定义基于个体对数收益空间的公平利他效用函数。推导了确保经典社会困境中合作的解析条件，并将框架扩展到序列设置，定义了公平马尔可夫博弈，并推导了新的公平Actor-Critic算法来学习公平策略。

Result: 在各种社会困境环境中评估了该方法，验证了基于比例公平性的框架能够促进更公平的合作。

Conclusion: 比例公平性框架为多智能体合作提供了一种有效的公平性促进方法，能够平衡效率与公平，在经典和序列社会困境中都能实现更公平的合作结果。

Abstract: Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments.

</details>


### [371] [EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse](https://arxiv.org/abs/2602.08529)
*Ning Lin,Haolun Li,Mingshu Liu,Chengyun Ruan,Kaibo Huang,Yukun Wei,Zhongliang Yang,Linna Zhou*

Main category: cs.MA

TL;DR: EvoCorps是一个进化多智能体框架，用于主动去极化在线讨论，通过动态社会游戏的方式协调监控、规划、生成和扩散角色，实现实时对抗性放大的闭环干预。


<details>
  <summary>Details</summary>
Motivation: 在线讨论中的极化现象侵蚀社会信任并加速错误信息传播，当前的技术响应主要是诊断性和事后处理。现有治理方法存在固有延迟和静态策略，难以应对实时演变的协调对抗性放大。

Method: 提出EvoCorps进化多智能体框架，将讨论治理视为动态社会游戏，协调监控、规划、基于事实的生成和多身份扩散角色。采用检索增强的集体认知核心提供事实基础和行动-结果记忆，通过闭环进化学习在环境和攻击者变化时调整策略。

Result: 在MOSAIC社交AI模拟平台上进行控制评估，在多源新闻流中加入对抗性注入和放大的场景中，EvoCorps在情感极化、观点极端性和论证理性方面均优于对抗性基线。

Conclusion: EvoCorps为从检测和事后缓解转向过程中闭环干预提供了实用路径，展示了主动去极化框架的可行性。

Abstract: Polarization in online discourse erodes social trust and accelerates misinformation, yet technical responses remain largely diagnostic and post-hoc. Current governance approaches suffer from inherent latency and static policies, struggling to counter coordinated adversarial amplification that evolves in real-time. We present EvoCorps, an evolutionary multi-agent framework for proactive depolarization. EvoCorps frames discourse governance as a dynamic social game and coordinates roles for monitoring, planning, grounded generation, and multi-identity diffusion. A retrieval-augmented collective cognition core provides factual grounding and action--outcome memory, while closed-loop evolutionary learning adapts strategies as the environment and attackers change. We implement EvoCorps on the MOSAIC social-AI simulation platform for controlled evaluation in a multi-source news stream with adversarial injection and amplification. Across emotional polarization, viewpoint extremity, and argumentative rationality, EvoCorps improves discourse outcomes over an adversarial baseline, pointing to a practical path from detection and post-hoc mitigation to in-process, closed-loop intervention. The code is available at https://github.com/ln2146/EvoCorps.

</details>


### [372] [Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics](https://arxiv.org/abs/2602.08938)
*Tuo Zhang,Leonardo Stella*

Main category: cs.MA

TL;DR: 本文提出了一种无需正则化的对抗训练方法，通过重新利用进化博弈论中的BNN动态，在零和游戏中实现最后迭代收敛，并扩展到扩展式博弈中。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法通常需要正则化来确保收敛到纳什均衡，但正则化需要额外的超参数调优，这在收益结构未知或变化时尤其困难。本文旨在开发无需正则化的收敛方法。

Method: 重新利用进化博弈论中的Brown-von Neumann-Nash (BNN)动态，利用其在零和游戏中无需正则化的内在收敛特性；开发新框架将BNN动态通过反事实加权整合到扩展式博弈中；实现基于神经函数近似的算法，支持可扩展学习。

Result: 在噪声正规式博弈中提供最后迭代收敛保证；在扩展式博弈中提供理论保证；实验结果表明该方法能快速适应非平稳性，优于最先进的正则化方法。

Conclusion: 本文提出的基于BNN动态的无正则化方法在多智能体学习中具有优势，特别是在收益结构未知或变化的环境中，为对抗训练提供了更简单有效的解决方案。

Abstract: Zero-sum games are a fundamental setting for adversarial training and decision-making in multi-agent learning (MAL). Existing methods often ensure convergence to (approximate) Nash equilibria by introducing a form of regularization. Yet, regularization requires additional hyperparameters, which must be carefully tuned--a challenging task when the payoff structure is known, and considerably harder when the structure is unknown or subject to change. Motivated by this problem, we repurpose a classical model in evolutionary game theory, i.e., the Brown-von Neumann-Nash (BNN) dynamics, by leveraging the intrinsic convergence of this dynamics in zero-sum games without regularization, and provide last-iterate convergence guarantees in noisy normal-form games (NFGs). Importantly, to make this approach more applicable, we develop a novel framework with theoretical guarantees that integrates the BNN dynamics in extensive-form games (EFGs) through counterfactual weighting. Furthermore, we implement an algorithm that instantiates our framework with neural function approximation, enabling scalable learning in both NFGs and EFGs. Empirical results show that our method quickly adapts to nonstationarities, outperforming the state-of-the-art regularization-based approach.

</details>


### [373] [Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.08965)
*John Gardiner,Orlando Romero,Brendan Tivnan,Nicolò Dal Fabbro,George J. Pappas*

Main category: cs.MA

TL;DR: 该论文提出了首个利用共享量子纠缠作为协调资源的MARL框架，相比传统共享随机性，量子纠缠允许更丰富的无通信关联策略，并在某些合作游戏中展现出量子优势。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，无法通信是协调的主要挑战。传统方法使用共享随机性（如相关设备）来关联局部策略，但量子物理研究表明，在某些无通信的单轮合作游戏中，共享量子纠缠能实现比共享随机性更优的策略，即存在量子优势。因此需要开发能利用量子纠缠的MARL框架。

Method: 提出基于可微分策略参数化的框架：1）引入新颖的可微分策略参数化，允许优化量子测量；2）设计新型策略架构，将联合策略分解为量子协调器和分散的局部执行器；3）将框架应用于单轮游戏（作为黑盒oracle）和序列决策问题（Dec-POMDP）。

Result: 1）在单轮游戏中，能够纯粹从经验中学习到实现量子优势的策略；2）在作为Dec-POMDP建模的多智能体序列决策问题中，展示了学习具有量子优势策略的能力。

Conclusion: 该研究首次将量子纠缠作为协调资源引入MARL框架，证明了量子优势在强化学习环境中的可实现性，为多智能体协调开辟了新的研究方向。

Abstract: The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).

</details>
