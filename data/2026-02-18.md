<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 32]
- [cs.CL](#cs.CL) [Total: 30]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出一种解耦的零样本人-物交互检测框架，将物体检测与交互识别分离，利用多模态大语言模型进行零样本交互识别，无需训练即可工作，也可通过微调提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将交互识别与特定检测器紧密耦合，依赖粗粒度的视觉语言模型特征，限制了未见交互的泛化能力。需要一种更灵活、泛化性更强的零样本人-物交互检测方法。

Method: 1) 解耦框架：分离物体检测与交互识别；2) 确定性生成方法：将交互识别转化为视觉问答任务，强制确定性输出，实现无需训练的零样本交互识别；3) 空间感知池化模块：整合外观和成对空间线索；4) 一次性确定性匹配方法：单次前向传播预测所有候选交互。

Result: 在HICO-DET和V-COCO数据集上表现出优越的零样本性能，具有强大的跨数据集泛化能力，并能灵活集成任何物体检测器而无需重新训练。

Conclusion: 提出的解耦框架通过分离物体检测与交互识别，利用多模态大语言模型实现零样本交互识别，在保持灵活性的同时显著提升了泛化性能，为开放词汇人-物交互检测提供了有效解决方案。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at https://github.com/SY-Xuan/DA-HOI.

</details>


### [2] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出基于累积样本损失(CSL)的视频标注错误检测方法，通过分析帧级损失轨迹识别错误标注和时序错乱问题


<details>
  <summary>Details</summary>
Motivation: 现实世界视频数据集常存在标注错误（错误标签和时序错乱），这些错误在需要时间一致性的任务中特别有害，需要一种模型无关的方法来检测这些错误

Method: 提出累积样本损失(CSL)方法：训练视频分割模型并保存每个epoch的权重，用这些检查点评估测试视频中每帧的损失，错误标注或时序错乱的帧会表现出持续高损失或不规则模式

Result: 在EgoPER和Cholec80数据集上的实验展示了强大的检测性能，能有效识别错误标签和帧错乱等细微不一致问题

Conclusion: 该方法为数据集审计和视频机器学习训练可靠性提升提供了强大工具，无需标注错误的ground truth，且具有跨数据集通用性

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [3] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 该论文提出了一种分布深度学习框架，用于解决医学影像超分辨率中的域偏移问题，特别是在4D Flow MRI增强应用中，通过结合计算流体动力学模拟和小规模真实数据微调来提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统超分辨率方法依赖配对数据集（下采样和原始高分辨率图像），但在真实临床环境中，低分辨率数据通常来自与简单下采样不同的采集机制，导致输入数据超出训练域，模型泛化能力差。

Method: 提出分布深度学习框架，首先在计算流体动力学（CFD）模拟的高分辨率数据及其下采样版本上训练模型，然后在少量配对的4D Flow MRI和CFD样本上进行微调，使用经过协调的数据集。

Result: 该框架显著优于传统深度学习方法，通过实际数据应用证明了分布学习在解决域偏移和提升临床现实场景中超分辨率性能方面的有效性。

Conclusion: 分布深度学习框架能够有效解决医学影像超分辨率中的域偏移问题，提高模型在临床现实场景中的鲁棒性和泛化能力，特别适用于4D Flow MRI等新型成像模态的分辨率增强。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [4] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经体积渲染的相机虚拟化方法，用于动态场景的新视角合成，特别针对体育广播等需要时间归档功能的应用场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的方法在处理快速、非刚性、多主体动态场景时存在局限性，无法满足体育广播等应用对时间归档和回顾渲染的需求。

Method: 采用神经体积渲染框架，将动态场景建模为多视角同步相机在特定时间的刚性变换，通过神经表示学习来提升渲染质量。

Result: 该方法能够实现高质量的新视角合成，并支持时间归档功能，用户可以回顾动态场景的任何历史时刻并进行渲染，适用于回放、分析和存档等应用。

Conclusion: 神经体积渲染方法为相机虚拟化提供了有效的解决方案，特别在支持时间归档功能方面填补了现有方法的空白，适用于体育广播和现场表演等应用。

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [5] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 该研究首次对长上下文视觉语言模型（最长344K上下文）进行大规模训练研究，专注于长文档视觉问答，并测量到长上下文文本的迁移效果。通过系统研究持续预训练、监督微调和偏好优化，在24B和32B参数模型上实现了MMLongBenchDoc的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 虽然已有一些强大的开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V），但它们的训练方法和数据流程不可复现。本研究旨在填补这一空白，系统研究长上下文视觉语言模型的训练方法。

Method: 对24B和32B参数模型进行系统研究，包括：1）持续预训练；2）监督微调；3）偏好优化。使用合成数据管道支持自我改进，并在训练和评估中使用页面索引来提升长文档性能。通过大量长上下文评估和消融实验验证方法。

Result: 在MMLongBenchDoc基准测试中，两个参数规模（24B和32B）都达到了最先进的性能。关键发现包括：1）训练上下文长度与评估长度匹配时效果最佳；2）使用页面索引能显著提升长文档性能；3）合成数据管道支持通过持续预训练和监督微调实现自我改进；4）视觉长上下文训练能迁移到长上下文文本性能。

Conclusion: 该研究提供了首个全面、可复现的长上下文视觉语言模型训练框架，填补了现有开源模型训练方法不可复现的空白。同时发布了MMLBD-C，一个经过手动校正的MMLongBenchDoc版本，以减少基准测试中的错误和低质量示例。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [6] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan,Xu*

Main category: cs.CV

TL;DR: 提出E^2D方法，通过探索-利用两阶段优化策略，在保持高精度的同时大幅提升大规模数据集蒸馏效率


<details>
  <summary>Details</summary>
Motivation: 现有解耦式数据集蒸馏方法面临效率与精度的权衡：优化型方法精度高但计算量大，无优化型方法高效但精度低。需要克服这一权衡，实现高效且高精度的大规模数据集蒸馏。

Method: 提出探索-利用蒸馏(E^2D)：1) 使用全图像初始化保持语义完整性和特征多样性；2) 探索阶段进行均匀更新并识别高损失区域；3) 利用阶段聚焦于高损失区域进行更新以加速收敛；4) 通过减少冗余计算实现高效优化。

Result: 在ImageNet-1K上超越SOTA方法且快18倍；在ImageNet-21K上显著提升精度且快4.3倍。证明针对性更新而非暴力优化能有效平衡精度与效率。

Conclusion: E^2D通过探索-利用策略和减少冗余计算，成功解决了大规模数据集蒸馏中精度与效率的权衡问题，为资源受限环境下的部署提供了实用解决方案。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.

</details>


### [7] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出一种联合采样框架，用于流匹配视频生成器，在提高批次多样性的同时保持时间一致性，避免昂贵的视频解码和反向传播。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，通常每个提示只能生成少量样本。在这种低样本情况下，最大化每批次价值需要高跨视频多样性。现有方法虽然能提高图像生成的多样性，但对视频生成往往损害时间一致性且需要昂贵的解码器反向传播。

Method: 提出联合采样框架，应用多样性驱动更新，然后移除会降低时间一致性目标的分量。为避免图像空间梯度，使用轻量级潜在空间模型计算两个目标，避免视频解码和解码器反向传播。

Result: 在最先进的文本到视频流匹配模型上的实验表明，该方法在保持与强联合采样基线相当的多样性的同时，显著提高了时间一致性和色彩自然度。

Conclusion: 该方法在提高批次多样性的同时有效保持了视频的时间一致性，避免了昂贵的计算成本，为文本到视频生成提供了高效的解决方案。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [8] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 该论文提出了一种无需训练、基于批量的零样本异常检测框架，可将2D基础模型扩展到3D脑部MRI，通过聚合多轴切片构建局部体积标记，恢复立方空间上下文。


<details>
  <summary>Details</summary>
Motivation: 零样本异常检测在医学成像中受到关注，但现有方法主要局限于2D数据集。扩展到3D医学图像具有挑战性，现有方法依赖切片特征和视觉语言模型，无法捕捉体积结构。

Method: 提出完全无需训练的框架，通过聚合2D基础模型处理的多轴切片构建局部体积标记，恢复立方空间上下文，直接与基于距离的批量级异常检测流程集成。

Result: 框架提供了紧凑的3D表示，可在标准GPU上计算，无需微调、提示或监督。结果表明，无需训练的批量零样本异常检测可以从2D编码器有效扩展到完整的3D MRI体积。

Conclusion: 该方法为体积异常检测提供了一种简单而稳健的方法，成功将零样本异常检测从2D扩展到3D脑部MRI，无需任务特定监督。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [9] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Sparrow框架通过视觉感知文本锚定窗口注意力、中间层视觉状态桥接和多token预测策略，解决了视频大语言模型中推测解码的性能崩溃问题，实现了2.82倍的平均加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码在视觉语言模型中广泛使用，但在视频大语言模型中面临严重的性能崩溃问题。草案模型通常会陷入注意力稀释和负面视觉增益的陷阱，这是由于键值缓存爆炸和上下文窗口不匹配导致的。研究者观察到Vid-LLMs中存在视觉语义内化现象，表明关键视觉语义在深层交互中被隐式编码到文本隐藏状态中，这使得原始视觉输入在深层推理中结构冗余。

Method: Sparrow框架采用三种关键技术：1) 通过隐藏状态重用的视觉感知文本锚定窗口注意力，将视觉计算完全卸载到目标模型；2) 利用中间层视觉状态桥接，用语义丰富的中间状态训练草案模型，过滤低级视觉噪声；3) 引入多token预测策略，桥接训练-推理分布偏移。

Result: 实验表明，即使在处理25k个视觉token的情况下，Sparrow也能实现平均2.82倍的加速，有效解决了长序列中的性能下降问题，为实时长视频任务提供了实用解决方案。

Conclusion: Sparrow框架通过创新的视觉感知文本锚定窗口注意力、中间层状态桥接和多token预测策略，成功解决了视频大语言模型中推测解码的性能崩溃问题，实现了显著的推理加速，为长视频实时处理提供了有效解决方案。

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [10] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: CREMD数据集研究不同呈现模式和标注者特征对狗情绪识别的影响，发现视觉上下文显著提高标注一致性，音频增加标注者信心但效果不明确，非主人和男性标注者一致性更高。


<details>
  <summary>Details</summary>
Motivation: 狗情绪识别对改善人-动物互动、兽医护理和自动化监测系统至关重要，但由于情绪评估的主观性和缺乏标准化方法，准确识别狗情绪具有挑战性。需要研究不同呈现方式和标注者特征如何影响狗情绪的感知和标注。

Method: 创建CREMD数据集，包含923个视频片段以三种模式呈现：无上下文无音频、有上下文无音频、有上下文有音频。收集来自不同背景参与者（狗主人、专业人士、不同人口统计特征）的标注，分析影响可靠狗情绪识别的因素。

Result: 1) 添加视觉上下文显著提高标注一致性，但音频线索效果不明确（因设计限制）；2) 非主人和男性标注者比狗主人和女性标注者一致性更高，专业人士一致性较高符合预期；3) 音频显著增加标注者识别特定情绪（特别是愤怒和恐惧）的信心。

Conclusion: 狗情绪识别受呈现模式和标注者特征显著影响，视觉上下文是关键因素，音频虽增加信心但需进一步研究，标注者背景差异影响识别一致性，为改进狗情绪识别系统提供了重要见解。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [11] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT框架使用扩散先验和主动视角采样，从少量输入观测中合成高质量的高斯泼溅Wang Tiles，显著减少数据需求同时保持视觉质量和交互性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅和Wang Tiles方法虽然能实现逼真渲染和大规模环境生成，但通常依赖于密集采样的示例重建，数据需求量大。需要一种数据高效的方法来从最小化输入中合成高质量的大规模虚拟环境。

Method: 结合扩散先验和主动视角采样，通过分层不确定性量化机制与生成扩散模型集成，自主识别最具信息量的视角，同时幻觉化缺失的结构细节以确保瓦片间的无缝过渡。

Result: 实验结果表明，该系统显著减少了所需数据量，同时保持了大规模虚拟环境所需的视觉完整性和交互性能。

Conclusion: DAV-GSWT为大规模虚拟环境的高质量合成提供了一种数据高效的方法，通过扩散先验和主动采样机制解决了现有方法对密集数据依赖的限制。

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [12] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: GMAIL框架将生成图像视为与真实图像不同的模态，通过跨模态对齐和多模态学习，在潜在空间中桥接两种模态，从而有效利用生成图像提升视觉语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型能合成高度逼真的图像，为训练机器学习模型提供丰富数据源。但直接将生成图像当作真实图像使用会导致模态差异问题，甚至引发模式崩溃。需要一种能区分对待两种模态的方法来有效利用生成图像。

Method: 提出GMAIL框架：1) 将生成图像视为与真实图像不同的独立模态；2) 在潜在空间而非像素空间桥接两种模态；3) 先用跨模态对齐损失在生成图像上微调模型；4) 然后用对齐后的模型结合生成图像进一步训练各种视觉语言模型。

Result: 在多个视觉语言任务上显著提升性能：图像描述、零样本图像检索、零样本图像分类、长描述检索。展示了生成数据的正缩放趋势，并在大型多模态模型LLaVA的描述性能上取得显著提升。

Conclusion: GMAIL框架通过明确区分生成图像与真实图像作为不同模态，并在潜在空间中进行跨模态对齐，能够有效利用生成模型的进展，提升视觉语言任务的性能，且易于与各种视觉语言模型集成。

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [13] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 本文提出了一种用于日间到夜间无配对图像翻译的新框架，通过检测和抑制目标类别特征的幻觉来提升翻译质量，显著改善下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 日间到夜间无配对图像翻译面临两大挑战：1）外观变化巨大且缺乏像素级监督；2）现有方法常产生语义幻觉，错误合成交通标志、车辆等目标类别物体以及人造光效，这些幻觉严重降低了下游任务性能。

Method: 1）设计双头判别器，同时进行语义分割以识别背景区域的幻觉内容；2）引入类别特定原型，通过聚合标注的目标域对象特征构建，作为每个类别的语义锚点；3）基于薛定谔桥翻译模型，在特征空间中迭代细化，将检测到的幻觉特征明确推离类别原型，从而在翻译轨迹中保持对象语义。

Result: 在BDD100K数据集上，该方法在日间到夜间域适应任务中mAP提升15.5%，对于容易产生幻觉的类别（如交通灯）增益高达31.7%，在定性和定量评估上均优于现有方法。

Conclusion: 提出的框架通过检测和抑制目标类别特征的幻觉，有效解决了无配对图像翻译中的语义保持问题，显著提升了翻译质量和下游任务性能，特别是在容易产生幻觉的类别上表现突出。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation trajectory.Experiments show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [14] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: ASBM是一种新的生成建模框架，通过两阶段方法恢复高维最优轨迹：首先将SB前向动态视为耦合构建问题，通过数据到能量采样的视角学习；然后用简单匹配损失学习后向生成动态，实现更直、更高效的采样路径。


<details>
  <summary>Details</summary>
Motivation: 扩散模型由于无信息、无记忆的前向过程导致高度弯曲的轨迹和噪声评分目标，ASBM旨在通过非无记忆机制恢复高维最优轨迹，提高采样效率和稳定性。

Method: 1. 将Schrödinger Bridge前向动态视为耦合构建问题，通过数据到能量采样的视角学习，将数据传输到能量定义的先验分布；2. 使用简单匹配损失学习后向生成动态，由诱导的最优耦合监督。

Result: ASBM在图像生成实验中表现出更高的保真度和更少的采样步骤，能够扩展到高维数据并显著提高稳定性和效率，还可通过蒸馏实现一步生成器。

Conclusion: ASBM通过非无记忆机制产生更直、更高效的采样路径，相比先前工作在高维数据上具有更好的可扩展性、稳定性和效率，为生成建模提供了新的优化轨迹框架。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [15] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 首次系统评估开源多模态大语言模型在零样本条件下的单图像人脸融合攻击检测能力，发现LLaVA1.6-Mistral-7B在无需微调的情况下超越了传统任务特定方法，显示出多模态预训练能隐式编码面部不一致性特征。


<details>
  <summary>Details</summary>
Motivation: 人脸融合攻击威胁生物特征验证，现有检测系统需要任务特定训练且对新攻击类型泛化能力差。开源多模态大语言模型展现出强大的视觉-语言推理能力，但在生物特征取证领域的潜力尚未充分探索。

Method: 首次对开源MLLMs进行系统性的零样本单图像人脸融合攻击检测评估，使用公开可用的模型权重和标准化、可复现的评估协议，涵盖多种融合技术。

Result: 许多MLLMs在无需微调或领域适应的情况下展现出非平凡的判别能力，LLaVA1.6-Mistral-7B达到最先进性能，在等错误率上比高度竞争的任务特定基线至少高出23%。

Conclusion: 多模态预训练能隐式编码指示融合伪影的细粒度面部不一致性，实现零样本取证敏感性。开源MLLMs可作为生物特征安全和取证图像分析的可复现、可解释且具有竞争力的基础，为开发最先进MAD系统提供新机会。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [16] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: RPT-SR：一种针对固定视角红外图像超分辨率的区域先验注意力Transformer，通过融合可学习的区域先验token和局部token，利用场景布局先验提升重建效率


<details>
  <summary>Details</summary>
Motivation: 通用超分辨率模型（特别是Vision Transformers）在固定或准静态视角的红外成像场景（如监控、自动驾驶）中存在效率问题，未能充分利用这些场景中固有的强空间先验，导致冗余学习和次优性能

Method: 提出RPT-SR架构，采用双token框架：1）可学习的区域先验token，作为场景全局结构的持久记忆；2）局部token，捕捉当前输入的帧特定内容。将这些token融入注意力机制，使先验能够动态调制局部重建过程

Result: 在涵盖长波红外（LWIR）和短波红外（SWIR）光谱的多样化数据集上建立了新的最先进性能，展示了RPT-SR的广泛适用性和多功能性

Conclusion: RPT-SR通过显式编码场景布局信息到注意力机制中，有效解决了固定视角红外图像超分辨率中通用模型效率低下的问题，实现了更优的性能

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [17] [LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction](https://arxiv.org/abs/2602.15493)
*Raffaele Cappelli,Matteo Ferrara*

Main category: cs.CV

TL;DR: LEADER是一种轻量级端到端注意力门控双自编码器，直接从原始指纹图像提取细节点描述符（位置、方向、类型），无需单独预处理和后处理，参数量仅0.9M，在NIST SD27数据集上F1分数比专业潜在指纹提取器高34%。


<details>
  <summary>Details</summary>
Motivation: 指纹识别中的细节点提取正转向深度学习，但真正消除单独预处理和后处理的端到端方法仍然稀缺。现有方法通常需要分离的处理步骤，限制了效率和性能。

Method: 提出LEADER架构：1）集成非极大值抑制和角度解码实现完全端到端推理；2）采用新颖的"城堡-护城河-城墙"真值编码；3）双自编码器结构通过注意力门控机制互连；4）仅使用0.9M参数。

Result: 在普通指纹上达到最先进精度，在潜在指纹上具有强大跨域泛化能力：NIST SD27数据集F1分数比专业潜在细节点提取器高34%；样本级分析平均排名2.07，47%样本排名第一；推理速度GPU 15ms，CPU 322ms，计算效率优于领先商业软件。

Conclusion: LEADER展示了端到端细节点提取的可行性，通过轻量级架构实现高性能和高效推理，学习到的内部表示与指纹领域特征一致，公开源代码和预训练权重促进可复现性。

Abstract: Minutiae extraction, a fundamental stage in fingerprint recognition, is increasingly shifting toward deep learning. However, truly end-to-end methods that eliminate separate preprocessing and postprocessing steps remain scarce. This paper introduces LEADER (Lightweight End-to-end Attention-gated Dual autoencodER), a neural network that maps raw fingerprint images to minutiae descriptors, including location, direction, and type. The proposed architecture integrates non-maximum suppression and angular decoding to enable complete end-to-end inference using only 0.9M parameters. It employs a novel "Castle-Moat-Rampart" ground-truth encoding and a dual-autoencoder structure, interconnected through an attention-gating mechanism. Experimental evaluations demonstrate state-of-the-art accuracy on plain fingerprints and robust cross-domain generalization to latent impressions. Specifically, LEADER attains a 34% higher F1-score on the NIST SD27 dataset compared to specialized latent minutiae extractors. Sample-level analysis on this challenging benchmark reveals an average rank of 2.07 among all compared methods, with LEADER securing the first-place position in 47% of the samples-more than doubling the frequency of the second-best extractor. The internal representations learned by the model align with established fingerprint domain features, such as segmentation masks, orientation fields, frequency maps, and skeletons. Inference requires 15ms on GPU and 322ms on CPU, outperforming leading commercial software in computational efficiency. The source code and pre-trained weights are publicly released to facilitate reproducibility.

</details>


### [18] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出基于语义过滤的框架，利用视觉语言模型实现类别感知的瞬态物体去除，解决3D高斯泼溅重建中的鬼影问题


<details>
  <summary>Details</summary>
Motivation: 多视角捕捉中的瞬态物体（如行人、车辆）会在3D高斯泼溅重建中产生鬼影伪影。现有方法要么依赖场景分解导致内存成本高，要么基于运动启发式方法易受视差模糊影响

Method: 提出语义过滤框架：1) 使用CLIP计算渲染视图与干扰物文本提示之间的相似度得分；2) 在训练迭代中为每个高斯累积得分；3) 对超过校准阈值的高斯进行透明度正则化和周期性剪枝

Result: 在RobustNeRF基准测试中，相比原始3DGS在四个序列上重建质量持续提升，同时保持最小内存开销和实时渲染性能。阈值校准和基线比较验证了语义引导在可预测干扰物类别场景中的实用性

Conclusion: 语义分类通过独立于运动模式识别物体类别，解决了视差模糊问题。该方法为具有可预测干扰物类别的场景中的瞬态去除提供了实用策略，优于基于运动的方法

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [19] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 该论文提出了一套全面的评估指标来衡量手势生物特征识别中得分质量，现有方法主要依赖错误率但无法评估得分好坏，作者通过整合排名偏差、相关性奖励、趋势对应和解缠折扣等因素，提出了先进的接受得分作为整体评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有生物特征容量估计文献主要依赖错误率，但这些错误率无法评估得分的质量好坏。在手势生物特征识别中，从手势和身份感知特征空间推导出的适应度得分，其质量评估仍然是一个开放性问题。

Method: 首先确定输出得分的排名顺序和相关性作为评估基础，考虑排名偏差以及对高排名手势得高分和低排名手势得低分的奖励，补偿输出得分与真实得分趋势之间的对应关系，并将手势身份特征解缠作为折扣因子，通过适当加权整合这些元素，提出先进的接受得分作为整体评估指标。

Result: 在三个数据集上使用五个最先进模型进行了深入实验，结果显示使用该指标选择的最优得分比其他现有指标更合适，且提出的指标与现有指标存在相关性，进一步验证了其可靠性。

Conclusion: 该研究提出了一套全面的评估指标来量化手势生物特征识别中的得分质量，通过整合多个评估维度，提出的先进接受得分能够更全面地评估得分质量，实验验证了其有效性和可靠性。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.

</details>


### [20] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出了一种无需训练的动态LoRA融合框架，通过特征层面的KL散度选择和基于CLIP/DINO分数的梯度校正，在生成过程中动态实现主题与风格的协调合成。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法大多使用静态统计启发式方法，偏离了LoRA学习自适应特征调整的初衷，且忽略了采样输入的随机性，导致主题与风格合成效果不佳。

Method: 提出动态训练免费融合框架：1）前向传播时，在每个LoRA应用层动态计算基础模型特征与主题/风格LoRA特征的KL散度，自适应选择最佳融合权重；2）反向去噪阶段，基于CLIP和DINO等客观指标的梯度校正，提供连续语义和风格指导。

Result: 在多种主题-风格组合上的广泛实验表明，该方法在定性和定量评估中均优于最先进的LoRA融合方法，无需重新训练即可实现协调的主题-风格合成。

Conclusion: 通过特征层面选择和度量引导的潜在调整两种互补机制，在整个扩散时间线上动态集成，实现了无需训练的主题与风格协调合成，为多LoRA融合提供了有效的动态解决方案。

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [21] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出PADE方法，通过增强LVLMs内部正注意力动态来减少幻觉，无需额外训练，提升视觉基础能力


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在幻觉问题，现有免训练方法计算开销大且易受注意力下沉现象干扰，需要更有效的解决方案

Method: 基于正注意力动态构建PAD图识别语义核心视觉区域，采用每头中位数绝对偏差缩放自适应控制干预强度，利用系统标记补偿保持对复杂指令的关注

Result: 在多个LVLMs和基准测试中，PADE改善了视觉基础并减少了幻觉，验证了利用内部注意力动态进行可靠多模态推理的有效性

Conclusion: PADE是一种有效的免训练注意力干预方法，通过增强内部正注意力动态来提升LVLMs的可靠性和减少幻觉

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [22] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 提出全自动OCT图像血管分割与分类方法，结合预处理、导丝伪影去除、坐标变换、聚类和特征提取，使用机器学习分类器实现高精度血管边界检测


<details>
  <summary>Details</summary>
Motivation: 冠状动脉光学相干断层扫描（OCT）虽然能高分辨率可视化血管解剖结构，但面临噪声、成像伪影和复杂组织结构的挑战，需要自动化分析解决方案

Method: 集成图像预处理、导丝伪影去除、极坐标到笛卡尔坐标变换、无监督K-means聚类和局部特征提取的全自动流程，使用逻辑回归和支持向量机进行像素级血管分类

Result: 实验结果显示优异性能，精确度、召回率和F1分数最高达1.00，总体分类准确率达99.68%，计算复杂度低且需要最少人工标注

Conclusion: 该方法为自动化OCT图像分析提供了可靠高效的解决方案，在临床决策支持和实时医学图像处理方面具有应用潜力

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [23] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: IRIS-v2数据集为工业设施数字孪生对齐提供多模态数据，通过分割与图匹配方法减少对齐时间


<details>
  <summary>Details</summary>
Motivation: 老旧工业设施缺乏原生数字模型，现有手动对齐方法（图像+LiDAR）难以规模化，且示意图与现实存在不一致，公开工业数据集稀缺

Method: 提出IRIS-v2综合数据集（图像、点云、2D标注框、分割掩码、CAD模型、3D管道路由信息、P&ID），并通过分割与图匹配相结合的方法进行对齐实验

Result: 在实践案例研究中展示了对齐方法，旨在显著减少对齐任务所需时间

Conclusion: IRIS-v2数据集填补了工业数字孪生对齐研究的数据空白，分割与图匹配结合的方法为工业设施对齐提供了有效解决方案

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [24] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: CEMRAG框架通过将视觉表征分解为可解释的临床概念，并与多模态检索增强生成结合，统一提升放射学报告生成的解释性和事实准确性，挑战了传统认为解释性与性能之间存在权衡的观点。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的放射学报告生成在临床应用中受到限制，主要原因是缺乏可解释性和容易产生与影像证据不符的幻觉。现有研究通常将可解释性和准确性视为独立目标，概念解释技术主要关注透明度，而检索增强生成方法则通过外部检索来提升事实基础。

Method: 提出概念增强多模态检索增强生成（CEMRAG）框架，将视觉表征分解为可解释的临床概念，并与多模态检索增强生成相结合。该框架利用丰富的上下文提示来改进放射学报告生成，采用模块化设计将可解释性分解为视觉透明度和结构化语言模型条件。

Result: 在MIMIC-CXR和IU X-Ray数据集上，针对多种视觉语言模型架构、训练机制和检索配置的实验表明，CEMRAG在临床准确性指标和标准自然语言处理指标上，相比传统检索增强生成和仅概念基线均取得了一致的改进。

Conclusion: 研究结果表明，透明的视觉概念可以增强而非损害医学视觉语言模型的诊断准确性，挑战了可解释性与性能之间存在权衡的假设。模块化设计为临床可信赖的AI辅助放射学提供了原则性路径。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [25] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 本文提出了一个新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在土耳其两个不同温室的不同光照和环境条件下采集。使用YOLOv8、YOLOv9和YOLO11模型进行测试，YOLOv8s在mAP@50指标上表现最佳（86.09%），为智能农业应用提供了基础参考。


<details>
  <summary>Details</summary>
Motivation: 草莓作为经济价值和营养价值丰富的水果，传统视觉评估成熟度的方法主观性强且误差大。现有研究中缺乏全面公开的数据集，导致该领域研究难以比较，因此需要开发计算机辅助系统和公开数据集。

Method: 创建了一个新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在土耳其两个不同温室的不同光照和环境条件下采集。使用YOLOv8、YOLOv9和YOLO11系列模型进行对比测试，评估不同模型在草莓成熟度检测上的性能。

Result: YOLOv9c模型获得最高精确率（90.94%），YOLO11s模型获得最高召回率（83.74%）。在综合性能指标mAP@50上，YOLOv8s表现最佳（86.09%）。结果表明中小型模型在此类数据集上表现更平衡高效。

Conclusion: 该研究提供了一个公开可用的草莓成熟度数据集，填补了该领域数据集的空白。实验结果表明中小型YOLO模型在草莓成熟度检测任务上表现良好，为智能农业应用提供了重要的基础参考，有助于推动自动化草莓收获系统的发展。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [26] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 3D数据优化分析管道：通过两阶段贝叶斯优化自动选择分割和分类模型及参数，减少人工调参负担


<details>
  <summary>Details</summary>
Motivation: 生物医学3D图像分析中，手动选择合适的分割和分类模型及调参是实践中的主要瓶颈，需要自动化解决方案来简化这一过程

Method: 提出3D数据优化分析管道，包含两个贝叶斯优化阶段：第一阶段优化分割模型和后期处理参数，使用领域适应的合成基准数据集；第二阶段优化分类器设计选择，包括编码器、分类头架构、先验知识整合和预训练策略，并包含辅助类别标注工作流

Result: 在四个案例研究中，该管道能够高效地为各个数据集识别出有效的模型和参数配置

Conclusion: 3D数据优化分析管道通过自动化模型选择和参数优化，显著减少了生物医学3D图像分析中的人工干预，提高了分析效率

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [27] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 提出从"语义优先"转向"标准优先"的图像分析范式，将结构发现与语义映射分离，为跨领域图像科学提供可重复分析框架


<details>
  <summary>Details</summary>
Motivation: 当前图像分析主要采用语义优先范式，但在开放科学发现、跨传感器/跨站点可比性、长期监测等场景下，这种范式会因领域本体和标签集的漂移而失效

Method: 引入标准优先的结构发现统一框架：首先基于明确最优标准进行语义无关的结构提取，然后将发现的结构产物映射到领域本体或词汇表中

Result: 该框架为跨领域图像科学提供可重复分析支架，支持多种解释和明确交叉引用，无需重写上游提取过程

Conclusion: 标准优先范式基于控制论、观察即区分和信息论的信息与意义分离原则，当标签无法扩展时具有必要性，对超越类别准确性的验证和将结构产物作为FAIR、AI就绪的数字对象具有重要意义

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [28] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 提出检索增强框架提升基于LLM的视觉语言导航效率，通过指令级轨迹检索和候选方向剪枝，无需微调LLM即可改善导航性能


<details>
  <summary>Details</summary>
Motivation: 基于提示的LLM导航存在决策效率低下的问题，模型需要在每个步骤从头解释指令并对嘈杂冗长的候选方向进行推理，这影响了导航的效率和稳定性

Method: 提出两级检索增强框架：1) 指令级嵌入检索器选择语义相似的成功导航轨迹作为上下文示例；2) 模仿学习的候选检索器在LLM推理前剪枝无关导航方向。两个检索模块都是轻量级、模块化的，且独立于LLM训练

Result: 在Room-to-Room基准测试中，在已见和未见环境上均一致提升了成功率、Oracle成功率和SPL指标。消融研究表明指令级示例检索和候选剪枝对全局指导和逐步决策效率有互补性贡献

Conclusion: 检索增强的决策支持是增强基于LLM的视觉语言导航的有效且可扩展策略，能够在不修改或微调底层语言模型的情况下提高导航效率和稳定性

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [29] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 提出了一种基于语言和几何约束的稀疏体素表示方法，在统一框架中协同建模3D场景的外观、语义和几何信息，实现了优于现有方法的整体场景理解和重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D开放词汇场景理解方法主要关注从2D基础模型蒸馏语言特征到3D特征场，但忽视了场景外观、语义和几何之间的协同作用，导致场景理解与底层几何结构脱节，与重建过程分离。

Method: 使用3D稀疏体素作为基本单元，构建包含外观场、密度场、特征场和置信度场的统一表示框架。通过特征调制模块促进各场之间的协同，从2D基础模型蒸馏语言特征，并集成几何蒸馏通过深度相关正则化和模式一致性正则化从几何基础模型转移几何知识。

Result: 在全面实验中，该方法在整体场景理解和重建方面相比最先进方法实现了优越的整体性能。

Conclusion: 通过语言和几何约束的稀疏体素表示，在统一框架中协同建模外观、语义和几何信息，能够实现更准确、一致的3D场景理解和重建。

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [30] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: 提出R3框架解决多模态模型中生成与理解能力之间的权衡问题，通过"生成-理解-再生成"多步过程，利用理解能力提升生成效果，同时改善与生成相关的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型面临一个关键挑战：提升生成能力往往以牺牲理解为代价，反之亦然。研究发现这种权衡的主要原因是生成与理解之间的潜在冲突，在模型内部形成了竞争动态。

Method: 提出Reason-Reflect-Refine (R3)框架，将单步生成任务重构为"生成-理解-再生成"的多步过程。该算法在生成过程中显式地利用模型的理解能力，缓解优化困境。

Result: 成功缓解了优化困境，实现了更强的生成结果，并改善了与生成过程相关的理解能力。

Conclusion: R3框架为设计下一代统一多模态模型提供了有价值的见解，通过协调生成与理解能力，实现了两者的共同提升。

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.

</details>


### [31] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy是一种用于内窥镜视频的自监督3D重建和新视角合成方法，通过神经渲染技术解决组织变形、单目相机、光照变化等挑战。


<details>
  <summary>Details</summary>
Motivation: 内窥镜在医学成像中至关重要，但现有方法面临组织变形、单目相机、光照变化、遮挡和未知相机轨迹等挑战。开发鲁棒的动态3D重建管道可以增强可视化、提高诊断准确性、辅助治疗规划和指导手术。

Method: 提出NeRFscopy自监督管道，包含具有规范辐射场和时间依赖变形场的可变形模型，变形场通过SE(3)变换参数化。引入复杂项有效利用彩色图像，无需任何模板或预训练模型，仅从数据中学习3D隐式模型。

Result: NeRFscopy在新视角合成方面取得准确结果，在各种具有挑战性的内窥镜场景中优于竞争方法。

Conclusion: NeRFscopy为可变形内窥镜组织的3D重建和新视角合成提供了一种有效的自监督方法，能够应对内窥镜成像中的多种挑战。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [32] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 提出了一种数据高效的序列草图生成方法，通过将预训练文本到视频扩散模型适配于草图绘制过程，利用LLM提供语义规划和笔画顺序，视频扩散模型作为高质量渲染器


<details>
  <summary>Details</summary>
Motivation: 大多数生成模型将草图视为静态图像，忽略了创意绘制过程中的时间结构。草图本质上是顺序过程，笔画以有意义的顺序绘制以探索和完善想法

Method: 将草图表示为短视频，笔画在空白画布上逐步绘制，由文本指定的顺序指令引导。采用两阶段微调策略：1)使用具有受控时间结构的合成形状组合学习笔画顺序；2)从最少7个人工绘制的草图过程中提取视觉外观

Result: 尽管人类绘制的草图数据极其有限，但该方法生成了高质量的序列草图，紧密遵循文本指定的顺序，同时展现出丰富的视觉细节。还展示了通过笔刷风格条件和自回归草图生成等扩展的灵活性

Conclusion: 该方法成功地将预训练文本到视频扩散模型适配于序列草图生成，利用LLM和视频扩散模型的互补优势，实现了数据高效的高质量草图生成，具有额外的可控性和交互式协作绘制能力

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [33] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench是首个专注于教育学术写作的评估平台，通过分层原子任务分解框架将研究流程分解为6个模块24个原子任务，提供细粒度诊断评估，并采用课程学习策略训练出EduWrite模型，在30B参数下超越72B通用模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在社会科学AI应用中的学术写作能力评估存在不足，现有基准测试主要关注单次、整体性生成，缺乏反映复杂学术研究流程的细粒度评估，无法识别具体能力瓶颈。

Method: 提出分层原子任务分解(HATD)框架，将端到端研究流程分解为6个专业研究模块(定量分析、定性研究、政策研究等)和24个细粒度原子任务；采用课程学习策略从基础技能逐步过渡到复杂方法论推理和论证；基于55K原始学术样本构建11K高质量指令对训练EduWrite模型。

Result: EduWrite(30B参数)在多个核心指标上显著超越更大的通用模型(72B)，证明在垂直领域中，数据质量密度和分层分阶段训练课程比参数规模更具决定性。

Conclusion: EduResearchBench填补了教育学术写作评估的空白，通过细粒度任务分解和诊断评估解决了整体评分的局限性，课程学习策略有效降低了学术写作的认知负荷，证明了在专业领域中数据质量和训练策略的重要性。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [34] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: Indic-TunedLens：针对印度语言的多语言大语言模型可解释性框架，通过学习共享仿射变换来调整隐藏状态，实现对模型表示更忠实的解码


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在印度等语言多样化地区部署日益增多，但大多数可解释性工具仍针对英语设计。研究发现LLM通常在英语中心表示空间中运行，跨语言可解释性成为迫切需求

Method: 提出Indic-TunedLens框架，专门针对印度语言学习共享仿射变换。与直接解码中间激活的标准Logit Lens不同，该方法为每种目标语言调整隐藏状态，使其与目标输出分布对齐

Result: 在10种印度语言上使用MMLU基准进行评估，结果显示该方法显著优于现有最先进的可解释性方法，特别是在形态丰富、资源匮乏的语言上表现突出

Conclusion: Indic-TunedLens为多语言transformer的层级语义编码提供了重要见解，解决了印度语言在LLM可解释性方面的特殊挑战

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [35] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出CGRA DeBERTa框架，通过概念引导的残差域增强提升伊斯兰圣训文本的问答准确性，在特定数据集上达到97.85的EM分数，优于BERT和DeBERTa。


<details>
  <summary>Details</summary>
Motivation: 传统伊斯兰文本问答面临领域特定语义、长上下文依赖和概念敏感推理的挑战，需要专门的方法来提升神学问答的准确性。

Method: 基于定制化DeBERTa骨干，结合轻量级LoRA适配和残差概念感知门控机制，引入伊斯兰概念词典的12个核心术语作为神学先验知识，通过重要性加权注意力选择性增强关键语义标记。

Result: 在42591个QA对的数据集上，CGRA DeBERTa获得97.85的EM分数，显著优于BERT（75.87）和DeBERTa（89.77），仅增加约8%的推理开销。

Conclusion: CGRA DeBERTa框架为伊斯兰圣训文本提供了高效、可解释且准确的问答系统，能够为教育材料提供必要的神学细微差别。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [36] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文介绍了在AVerImaTeC共享任务中获得第三名的系统，该系统将去年的检索增强生成（RAG）管道与反向图像搜索（RIS）模块相结合，以低成本实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个简单、低成本但性能有竞争力的多模态事实核查系统，为后续实验提供一个易于复现和调整的起点。

Method: 系统由三个解耦模块组成：1）基于相似性搜索的文本检索模块；2）基于API访问的反向图像搜索（RIS）的图像检索模块；3）使用GPT5.1的生成模块。每个事实核查仅需一次多模态LLM调用。

Result: 系统在AVerImaTeC共享任务中获得第三名，平均每次事实核查成本仅0.013美元（使用GPT5.1 via OpenAI Batch API），性能具有竞争力。

Conclusion: 该系统提供了一个简单、低成本、易于复现的多模态事实核查解决方案，适合作为进一步实验的起点，作者已公开代码、提示、向量存储和成本分析。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [37] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个新型记忆框架，结合了相似性检索和全局选择两种机制，在长期记忆基准测试中取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（RAG和Graph-RAG）主要依赖相似性检索机制，这种系统1风格的检索在处理需要全局推理或全面覆盖相关信息的场景时存在局限。

Method: Mnemis将记忆组织为基础图用于相似性检索，同时构建分层图支持自上而下的语义层次遍历。它整合了系统1相似性搜索和系统2全局选择两种互补机制。

Result: 在长期记忆基准测试中，Mnemis在所有对比方法中取得了最先进性能，在LoCoMo上得分93.9，在LongMemEval-S上得分91.6（使用GPT-4.1-mini）。

Conclusion: 通过结合相似性检索和全局选择两种互补的检索路径，Mnemis能够检索出既语义相关又结构相关的记忆项，有效解决了现有方法的局限性。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [38] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个结合神经符号推理与主动探索的框架，用于知识图谱问答，在保持高准确率的同时减少昂贵的图查询和模型调用。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时仍面临挑战。知识图谱提供了事实基础，但将图结构与神经模型结合存在困难：简单地将图事实嵌入提示会导致效率低下和脆弱性，而纯符号或搜索密集型方法则在检索成本高且缺乏基于梯度的优化。

Method: NeuroSymActive是一个模块化框架，结合了可微分的神经符号推理层与主动、价值引导的探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先考虑高价值的路径扩展。

Result: 在标准KGQA基准测试上的实证结果表明，NeuroSymActive在保持强答案准确率的同时，相比常见的检索增强基线方法，减少了昂贵的图查询和模型调用次数。

Conclusion: NeuroSymActive框架成功地将神经符号推理与主动探索相结合，为知识图谱问答提供了一种高效且准确的解决方案，在减少计算成本的同时保持了良好的性能。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [39] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 研究探索大型语言模型能否通过结构化提示在训练数据中几乎不存在的语言（以图鲁语为例）进行基本对话，通过语法文档、负约束、罗马化标准化和质量控制的合成数据生成等方法，显著减少了词汇污染并提高了语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能在训练数据中几乎不存在的语言（如图鲁语，有200多万使用者但数字存在感极低）中进行基本对话，而不需要微调模型。

Method: 采用结构化提示方法：结合明确的语法文档、负约束（抑制相关语言的高概率标记）、罗马化标准化以及通过自我游戏生成质量控制的合成数据。

Result: 在三个LLM（Gemini 2.0 Flash、GPT-4o、Llama 3.1 70B）上评估，词汇污染从80%降至5%，语法准确率达到85%。负约束带来12-18个百分点的稳定改进，语法文档效果因模型架构而异（8-22个百分点）。

Conclusion: 结构化提示方法可以有效引导LLM在训练数据稀缺的语言中进行基本对话，负约束是关键改进因素，语法文档的效果取决于模型架构。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [40] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT提出了一种基于测试驱动和能力自适应的课程强化微调方法，通过构建四层测试套件并解耦课程进度与原始奖励分数，根据模型能力自适应调整课程设计，显著提升代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法忽视了测试用例的异质难度和粒度，导致奖励信号分布不均衡和训练中的梯度更新偏差，需要一种能够适应模型能力并系统化设计课程的方法来提升LLM在代码生成中的算法复杂性和鲁棒性。

Method: TAROT为每个问题构建四层测试套件（基础、中级、复杂、边缘），提供可控的难度环境。关键创新在于将课程进度与原始奖励分数解耦，实现基于能力的评估，并从课程策略组合中进行原则性选择，而非依赖偶然的测试用例难度组合。

Result: 实验结果表明，代码生成中RFT的最佳课程与模型固有能力密切相关：能力较弱的模型在从易到难的课程中获益更大，而能力更强的模型在从难到易的课程中表现更优。TAROT能自适应地根据模型能力定制课程设计。

Conclusion: TAROT提供了一种可复现的方法，通过自适应地根据模型能力定制课程设计，持续提升生成代码的功能正确性和鲁棒性，为社区研究提供了开源代码和数据。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [41] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole框架利用视觉语言模型的视觉接口实现模型无关的无文本通信，通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，显著减少多智能体系统通信开销。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统依赖离散文本通信，存在运行时开销大和信息量化损失问题。现有潜在状态传输方法要么假设同构发送-接收架构，要么依赖特定配对的学习翻译器，限制了在具有不相交流形的异构模型家族间的可扩展性和模块化。

Method: 提出Vision Wormhole框架，通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，并直接注入接收器的视觉通路。采用中心辐射拓扑将成对对齐复杂度从O(N²)降至O(N)，利用无标签的师生蒸馏目标将高速视觉通道与文本通路的稳健推理模式对齐。

Result: 在异构模型家族（如Qwen-VL、Gemma）上的广泛实验表明，Vision Wormhole在受控比较中减少了端到端运行时间，同时保持与标准基于文本的多智能体系统相当的推理保真度。

Conclusion: Vision Wormhole通过将视觉语言模型的视觉接口重新定位为通用通信端口，实现了模型无关的无文本通信，显著提高了异构多智能体系统的效率和可扩展性。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [42] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 利用大语言模型对芬兰二战卡累利阿难民访谈中的35万个休闲活动和组织成员实体进行自动分类，构建结构化资源用于社会融合研究


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案虽能大规模研究日常生活，但直接从文本提取的信息往往无法直接回答历史学家和社会学家的定量研究问题。芬兰二战卡累利阿难民访谈中提取了35万个活动和组织提及，产生了7.1万个独特名称，数量过多难以直接分析。

Method: 开发了捕捉参与关键方面的分类框架（活动/组织类型、社交程度、规律性、体力需求），标注黄金标准集用于可靠评估，测试大语言模型能否大规模应用相同模式。采用多轮模型运行的简单投票方法。

Result: 研究发现开源权重的大语言模型能够密切匹配专家判断。最终应用该方法标注了35万个实体，为下游社会融合及相关结果研究产生了结构化资源。

Conclusion: 大语言模型能够有效处理大规模历史档案中的复杂分类任务，为历史和社会学研究提供了可扩展的定量分析工具，促进了社会融合等主题的深入研究。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [43] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在筛选和呈现信息时存在系统性源偏好，会优先选择某些来源的信息，这种偏好会影响信息推荐结果。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的智能体越来越多地作为在线平台的信息接口，它们通过筛选、排序和整合信息来影响用户接收的信息。虽然已有研究关注LLM自身生成信息的偏见，但较少关注LLM选择和呈现信息时的偏好因素。研究者假设当信息被归因于特定来源时，当前LLM会表现出系统性的潜在源偏好。

Method: 通过对来自6个模型提供商的12个LLM进行控制实验，涵盖合成和真实世界任务，研究模型是否表现出可预测的源偏好。实验考察了这些偏好对上下文框架的敏感性、与内容影响力的比较，以及是否可以通过明确提示来避免。

Result: 研究发现多个模型表现出强烈且可预测的源偏好。这些偏好对上下文框架敏感，有时甚至超过内容本身的影响力，即使通过明确提示也难以避免。这些偏好有助于解释先前研究中观察到的新闻推荐左倾偏斜现象。

Conclusion: 研究结果呼吁深入调查这些偏好的起源，并开发机制为用户提供透明度和控制权，以管理LLM驱动智能体的偏见。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [44] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 本文介绍了期望检测任务，创建了RedHOTExpect语料库（4.5K条Reddit帖子），使用LLM进行银标注，分析了医疗领域中患者在线讨论的期望类型和表达模式。


<details>
  <summary>Details</summary>
Motivation: 患者的治疗期望对治疗效果有重要影响。虽然主要在临床环境中研究，但像医疗子版块这样的在线患者平台可能包含补充性见解：患者在其他地方觉得不必要或不方便分享的治疗期望。然而，目前没有研究探讨用户在线讨论的期望类型及其表达方式，主要是因为期望尚未在自然语言处理领域得到研究。

Method: 1. 引入期望检测任务；2. 创建RedHOTExpect语料库（4.5K条Reddit帖子）；3. 使用大型语言模型进行银标注；4. 手动验证标注质量（准确率约78%）；5. 分析期望的语言模式，探索患者期望内容和原因。

Result: 1. 乐观和积极主动的框架在身体或治疗相关疾病的帖子中比心理健康背景中更明显；2. 在数据集中，患者主要讨论益处而非负面结果；3. 银标注的标签准确率约为78%；4. 识别了患者在线讨论期望的特定语言模式。

Conclusion: 期望检测是一个重要的NLP任务，特别是在医疗领域。RedHOTExpect语料库为研究在线患者期望提供了有价值的资源。研究发现不同疾病类型的期望表达存在差异，患者倾向于讨论积极期望。这项工作为未来在意见挖掘和产品设计等应用中的期望分析奠定了基础。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [45] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT是基于Gemma 3 27B构建的卢森堡语到法语和英语的机器翻译系统，使用卢森堡语新闻和议会记录等平行语料训练，通过LuxEmbedder过滤低质量数据，在多个语言对上都表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对卢森堡语（LB）到法语（FR）和英语（EN）的机器翻译系统，因为卢森堡语作为小语种缺乏专门的翻译资源，需要构建适合的基准和训练数据。

Method: 基于Gemma 3 27B模型进行微调，使用LuxAlign平行语料库（卢森堡语多语言新闻文章）和议会记录数据，通过Google Translate进行数据增强，使用LuxEmbedder（卢森堡语句子嵌入）过滤低等价性片段对。

Result: LuxMT相比Gemma 3基线有显著改进，即使在训练数据中不包含德语（DE）的情况下，LB到DE的翻译也表现良好。LuxEmbedder作为质量评估指标与其他基于参考的指标有强相关性。

Conclusion: LuxMT系统在卢森堡语翻译任务上表现优异，LuxEmbedder有潜力作为质量评估指标，但需要进一步研究来充分评估其效用，建议谨慎使用。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [46] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine是一个细粒度精炼框架，通过将LLM响应分解为原子单元、验证每个单元的事实性、评估流畅度，并迭代修正细粒度错误，显著提升对话系统的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在对话系统中存在幻觉问题，产生事实错误的回答会误导用户并破坏系统信任。现有的精炼方法通常在响应层面操作，忽略了单个响应可能包含多个可验证或不可验证的事实。

Method: 提出Fine-Refine框架：1) 将响应分解为原子单元；2) 使用外部知识验证每个单元的事实性；3) 通过困惑度评估流畅度；4) 迭代修正细粒度错误。

Result: 在HybriDialogue和OpendialKG数据集上的实验表明，Fine-Refine显著提升了事实性，对话事实分数最高提升7.63分，仅在对话质量上有小幅权衡。

Conclusion: Fine-Refine通过细粒度的响应分解和验证机制，有效解决了对话系统中LLM的幻觉问题，在保持对话质量的同时显著提升了事实准确性。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [47] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出ExpertWeaver，一种基于GLU激活模式的训练免费框架，将预训练稠密模型转换为稀疏MoE架构，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有稠密到MoE的转换方法（动态结构剪枝和降循环）会破坏稠密模型的内在激活模式，导致专家构建不理想。作者发现GLU机制为稠密到MoE转换提供了天然蓝图。

Method: 提出ExpertWeaver框架：利用GLU的细粒度神经激活模式揭示粗粒度结构，识别出持续激活的通用神经元和动态激活的专用神经元，据此划分神经元并构建共享专家和专用路由专家，采用层自适应配置。

Result: 实验表明，ExpertWeaver作为训练免费的动态结构剪枝技术和降循环策略，在MoE初始化方面显著优于现有方法。

Conclusion: GLU激活模式揭示了稠密模型中固有的MoE架构，ExpertWeaver利用这一发现实现了高效的稠密到MoE转换，为构建高质量稀疏模型提供了新途径。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [48] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl是一种无需训练的简单方法，直接从冻结的WavLM模型中提取音节边界和嵌入，用于纯语音语言模型，在多个基准测试中优于现有音节分词器。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型直接从原始音频学习语言，但自监督语音编码器的离散标记会产生过长的序列，现有音节提取方法需要复杂的多阶段训练流程。

Method: 使用WavLM中间层特征的L2范数来检测音节边界，对得到的片段进行平均池化，使用K-means离散化，然后训练语言模型。

Result: ZeroSyl在词汇、句法和叙事基准测试中优于先前的音节分词器，缩放实验显示更细粒度的单元对词汇任务有益，而发现的音节单元在句法建模中表现出更好的缩放行为。

Conclusion: ZeroSyl提供了一种简单有效的训练免费方法，直接从预训练语音模型中提取音节单元，为纯语音语言模型提供了更好的分词方案。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [49] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式文档分析工具，通过灵活的分面聚类和人在回路优化，帮助数字人文学者探索大规模非结构化文档集


<details>
  <summary>Details</summary>
Motivation: 数字人文学者需要处理大规模非结构化文档集合，但现有工具缺乏交互性和灵活性，难以有效探索和组织这些数据

Method: 开发了Perspectives交互式扩展，实现灵活的分面聚焦文档聚类流程，支持通过文档重写提示和基于指令的嵌入定义分析视角，并提供集群优化工具和嵌入模型微调机制

Result: 展示了典型工作流程，数字人文学者可以利用交互式文档地图发现主题、情感或其他相关类别，获得洞察并为后续深入分析准备数据

Conclusion: Perspectives通过人在回路的交互式聚类方法，为数字人文学者提供了探索大规模文档集合的有效工具，支持从不同分析视角发现模式并组织数据

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [50] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 该论文提出了一种结合模型蒸馏和任务特定对比损失的新训练方法，用于训练紧凑高性能的文本嵌入模型，在小型模型上表现优于纯对比或蒸馏训练方法。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型广泛应用于语义相似性任务，但通用模型通常使用对比损失进行单阶段或多阶段训练。现有方法在训练小型模型时效果有限，需要更有效的训练策略来获得高性能的紧凑嵌入模型。

Method: 提出了一种新颖的训练方案，将模型蒸馏技术与任务特定的对比损失相结合。这种方法不是单独使用对比损失或蒸馏训练，而是将两者融合，以产生紧凑且高性能的嵌入模型。

Result: 开发了jina-embeddings-v5-text-small和jina-embeddings-v5-text-nano模型，在相似尺寸的模型中达到或超过了最先进水平。这些模型支持长达32k令牌的长文本、多语言处理，并且嵌入在截断和二进制量化下保持鲁棒性。

Conclusion: 结合模型蒸馏和任务特定对比损失的训练方法比单独的对比或蒸馏训练更有效地训练小型嵌入模型。该方法产生的紧凑模型性能优异，支持长文本和多语言，且公开了模型权重以促进嵌入模型开发的进一步进展。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [51] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: SquRL：基于强化学习的自适应工作流构建框架，用于提升Text-to-SQL任务性能，特别是在复杂和分布外查询上表现优异


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法依赖单一静态工作流，难以适应真实场景中的分布外和长尾情况，需要系统能够自适应地在推理时构建工作流

Method: 提出SquRL强化学习框架，增强LLM在自适应工作流构建中的推理能力，设计了基于规则的奖励函数，并引入动态演员掩码和伪奖励两种训练机制

Result: 在广泛使用的Text-to-SQL基准测试中，动态工作流构建始终优于最佳静态工作流方法，在复杂和分布外查询上增益尤为显著

Conclusion: 动态策略通过利用候选工作流的异质性，能够持续超越最佳静态工作流，SquRL框架有效提升了Text-to-SQL系统在真实场景中的适应性和性能

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [52] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 该论文提出了一种基于症状引导和情感感知的语音抑郁严重程度估计框架，通过症状特定的交叉注意力机制将PHQ-8问卷项目与语音表征对齐，并引入可学习的症状特定参数来适应症状随时间表达方式的差异。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁预测研究大多将抑郁视为二元标签或整体严重程度评分，没有显式建模症状特定信息，限制了提供临床筛查相关症状级别分析的能力。抑郁通过睡眠障碍、兴趣丧失、注意力困难等多种症状表现，需要更精细的症状导向方法。

Method: 提出症状特定且临床启发的语音抑郁严重程度估计框架：1）使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表征对齐，识别语音片段对每个症状的重要性；2）引入可学习的症状特定参数，自适应控制注意力分布的锐度，以适应症状随时间表达方式的差异。

Result: 在标准临床风格数据集EDAIC上的实验结果表明，该方法性能优于先前工作。注意力分布分析显示，较高注意力被分配给包含多个抑郁症状线索的话语，突出了方法的可解释性。

Conclusion: 研究结果强调了症状引导和情感感知建模在基于语音的抑郁筛查中的重要性，为临床筛查提供了更精细的症状级别分析能力。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [53] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: STAPO通过识别和屏蔽RL微调中的"虚假令牌"来解决大语言模型推理训练中的性能崩溃问题，在数学推理基准上平均提升7.13%


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖启发式技术（如熵正则化和重加权）来维持稳定性，但在实践中经常出现后期性能崩溃，导致推理质量下降和训练不稳定。研究发现训练不稳定性由极少数（约0.01%）的"虚假令牌"驱动，这些令牌出现在正确响应中但对推理结果贡献很小，却继承了完整的序列级奖励，导致梯度更新异常放大。

Method: 提出Spurious-Token-Aware Policy Optimization (STAPO)方法，基于发现令牌级策略梯度大小与令牌概率和局部策略熵负相关这一理论结果，选择性屏蔽虚假令牌的更新，并在有效令牌上重新归一化损失。

Result: 在六个数学推理基准上使用Qwen 1.7B、8B和14B基础模型进行测试，STAPO始终表现出优越的熵稳定性，相比GRPO、20-Entropy和JustRL方法平均性能提升7.13%。

Conclusion: 通过理论分析和实验验证，STAPO方法有效解决了RL微调中的训练不稳定问题，通过识别和屏蔽虚假令牌的异常梯度更新，显著提升了大型语言模型推理任务的性能和训练稳定性。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [54] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 研究者创建了首个公开的埃及阿拉伯语TTS数据集NileTTS，包含38小时转录语音，并通过合成数据生成流程和微调XTTS v2模型，填补了埃及阿拉伯语语音合成的资源空白。


<details>
  <summary>Details</summary>
Motivation: 尽管神经文本到语音技术有所进步，但大多数阿拉伯语资源集中在现代标准阿拉伯语和海湾方言上，而埃及阿拉伯语作为最广泛理解的阿拉伯语方言，资源严重不足。本研究旨在填补这一空白。

Method: 1. 使用大型语言模型生成埃及阿拉伯语内容；2. 通过音频合成工具转换为自然语音；3. 自动转录和说话人分割；4. 人工质量验证；5. 在数据集上微调最先进的多语言TTS模型XTTS v2。

Result: 创建了包含38小时转录语音的NileTTS数据集，涵盖医疗、销售和一般对话等多个领域。微调后的模型在埃及阿拉伯语语音合成方面表现优于基于其他阿拉伯语方言训练的基线模型。

Conclusion: 本研究提供了首个公开的埃及阿拉伯语TTS数据集、可复现的方言TTS合成数据生成流程以及开源微调模型，推动了埃及阿拉伯语语音合成研究的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [55] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本文提出基于诺斯罗普·弗莱四类叙事体裁（喜剧、浪漫、悲剧、讽刺）的新角色功能框架，结合荣格原型理论定义了四种通用角色功能，并通过六种大语言模型在40部叙事作品上验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有计算叙事学方法主要关注叙事模式而非角色功能，无法充分捕捉弗莱理论中不同体裁下角色功能的差异。需要建立一个系统化的角色功能框架来补充模式分析，为计算叙事学和叙事生成提供理论基础。

Method: 1. 基于荣格原型理论推导四种通用角色功能（主角、导师、对手、同伴），映射到荣格心理结构组件；2. 根据弗莱的四类体裁（喜剧、浪漫、悲剧、讽刺）将通用功能特化为16种体裁特定角色；3. 使用六种先进大语言模型在40部叙事作品上进行验证，包含160个正样本和30个负样本，评估模型识别有效对应关系和拒绝无效对应关系的能力。

Result: 大语言模型在角色-体裁对应关系识别上表现良好：平均平衡准确率达82.5%，模型间一致性较高（Fleiss' κ = 0.600）。不同体裁表现存在差异（72.7%-89.9%），不同角色识别准确率差异较大（52.5%-99.2%）。定性分析表明这些差异反映了真实的叙事特性，如浪漫体裁中的功能分布和讽刺体裁中对原型的刻意颠覆。

Conclusion: 该角色功能框架有效捕捉了叙事结构中的系统性模式，证明了基于大语言模型的计算叙事学方法的潜力，为未来叙事生成方法和交互式叙事应用开发奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [56] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 本文提出了两种新的词汇语义变化检测指标AMD和SAMD，相比传统APD和PRT指标，在多种语言和编码器下表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测主要依赖APD和余弦距离等少数指标，需要探索更有效的语义变化度量方法。

Method: 提出平均最小距离（AMD）和对称平均最小距离（SAMD），通过跨时间段的词汇使用局部对应关系来量化语义变化。

Result: 在多种语言、编码模型和表示空间中，AMD在降维和非专用编码器下表现更稳健，SAMD在专用编码器中表现优异。

Conclusion: 词汇语义变化检测应考虑APD和PRT之外的替代指标，AMD为基于上下文嵌入的分析提供了稳健选择。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [57] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出一个端到端流程，用于生成和因果估计潜在文本干预，解决文本作为处理变量时的估计偏差问题。


<details>
  <summary>Details</summary>
Motivation: 在文本对下游结果的因果效应研究中，需要系统性地改变文本特征进行受控实验。虽然大语言模型可以生成文本，但产生和评估受控变化需要更仔细的注意。当前方法在估计文本因果效应时存在显著偏差，因为文本固有地混淆了处理和协变量信息。

Method: 提出端到端流程：1）通过稀疏自编码器进行假设生成和引导；2）基于协变量残差化的鲁棒因果估计。该方法解决了文本作为处理变量实验中的计算和统计挑战。

Result: 实证结果表明，该流程能有效诱导目标特征的变化，并减轻估计误差。与朴素估计方法相比，显著减少了由文本混淆处理信息和协变量信息引起的偏差。

Conclusion: 该研究为文本作为处理变量设置中的因果效应估计提供了稳健的基础，通过稀疏自编码器和协变量残差化方法，有效解决了文本因果效应估计中的偏差问题。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [58] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: LLMs在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）的词形还原和词性标注任务表现出竞争力，可作为缺乏数据时的有效标注辅助工具。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）中持续面临挑战，需要探索大语言模型在这些任务中的能力。

Method: 使用包含对齐训练数据和领域外测试数据的新基准，评估GPT-4变体和Mistral等大语言模型在少样本和零样本设置下的表现，并与特定任务RNN基线PIE进行比较。

Result: 即使不进行微调，LLMs在大多数语言的少样本设置中，词性标注和词形还原任务上达到竞争性或更优性能。对于形态复杂和非拉丁文字的语言仍存在挑战。

Conclusion: LLMs是在缺乏数据时启动语言标注任务的可行选择，可作为有效的标注辅助工具，特别是在低资源语言处理中。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [59] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 该论文提出了FineMuSe数据集，这是一个包含二元和细粒度标注的西班牙语多模态性别歧视检测数据集，并评估了LLMs在性别歧视检测任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视以多种形式出现，使得检测具有挑战性。现有的自动化工具通常仅限于二元分类，导致更微妙的性别歧视表现形式可能因缺乏细粒度、上下文敏感的标签而未被检测到。

Method: 1) 提出了FineMuSe数据集，包含二元和细粒度标注的西班牙语多模态性别歧视数据；2) 引入了全面的分层分类法，涵盖性别歧视形式、非性别歧视以及讽刺和幽默等修辞手法；3) 评估了多种LLMs在二元和细粒度性别歧视检测任务上的表现。

Result: 研究发现多模态LLMs在识别细微形式的性别歧视方面与人类标注者表现相当；然而，当这些性别歧视类型通过视觉线索传达时，模型难以捕捉同时出现的多种性别歧视类型。

Conclusion: 该研究通过创建细粒度标注的多模态数据集和评估LLMs性能，为更准确地检测在线性别歧视提供了重要工具和见解，特别是在处理视觉传达的复杂性别歧视类型方面仍有改进空间。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [60] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: ChartEditBench：首个评估多模态大语言模型在多轮图表编辑中持续交互能力的基准，包含5000条难度控制的修改链，通过执行保真度、像素级视觉相似性和逻辑代码验证进行综合评估。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在单轮图表生成上表现良好，但在真实世界探索性数据分析中需要多轮交互迭代优化，这要求模型能够维持共同基础、跟踪先前编辑并适应演化偏好，而当前缺乏评估这种持续交互能力的基准。

Method: 提出ChartEditBench基准，包含5000条难度控制的修改链和人工验证子集；开发鲁棒评估框架，整合执行保真度检查、像素级视觉相似性和逻辑代码验证，克服LLM-as-a-Judge指标的局限性。

Result: 实验显示最先进MLLMs在多轮设置下性能显著下降，主要由于错误累积和共享上下文崩溃；在样式编辑上表现良好，但在数据为中心转换上经常出现执行失败。

Conclusion: ChartEditBench为基于代码的增量、视觉基础图表编辑建立了具有挑战性的测试平台，揭示了MLLMs在多轮交互中的局限性，为意图感知多模态编程研究提供了重要基准。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [61] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 论文提出了*-PLUIE方法，这是ParaPLUIE的任务特定提示变体，用于评估自动生成文本质量，相比传统LLM-as-a-judge方法更高效且与人类判断更一致。


<details>
  <summary>Details</summary>
Motivation: 当前评估自动生成文本质量主要依赖LLM-as-a-judge方法，虽然有效但计算成本高且需要后处理。为了解决这些限制，作者在ParaPLUIE（基于困惑度的LLM评判指标）基础上进行改进。

Method: 提出了*-PLUIE方法，这是ParaPLUIE的任务特定提示变体。该方法基于困惑度估计"是/否"答案的置信度，无需生成文本，降低了计算成本。

Result: 实验表明，个性化的*-PLUIE在保持低计算成本的同时，与人类评分实现了更强的相关性。

Conclusion: *-PLUIE方法提供了一种更高效、与人类判断更一致的自动文本质量评估方案，解决了传统LLM-as-a-judge方法的计算成本问题。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [62] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文提出了一种基于Avey架构的编码器改进方案，通过解耦静态动态参数化、稳定性导向归一化和神经压缩等技术，在保持紧凑性的同时超越了传统Transformer编码器的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存预算紧张的工业NLP应用中，紧凑的预训练双向编码器仍然是核心。虽然自注意力机制通过序列级并行化提供了高质量的双向上下文建模能力，但最近出现的Avey作为一种自回归、无注意力的替代方案，自然适合编码器范式。本文旨在将Avey重新构建为编码器专用架构，并提升其性能。

Method: 将Avey重新构建为编码器专用架构，并引入多项创新：1）解耦静态和动态参数化；2）稳定性导向的归一化方法；3）神经压缩技术。这些改进旨在提升模型效率和性能。

Result: 改进后的架构在标准标记分类和信息检索基准测试中，持续优于四种广泛使用的基于Transformer的编码器，同时在处理长上下文时展现出更好的扩展效率。

Conclusion: 重新构建的Avey编码器架构通过引入解耦参数化、稳定性归一化和神经压缩等创新，在紧凑性、效率和性能方面都超越了传统Transformer编码器，特别适合工业NLP应用中对计算和内存有严格限制的场景。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [63] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI智能体端到端研究能力的基准测试和执行环境，包含5个ICML/ICLR/ACL会议论文重构的任务环境，共39个子任务。GPT-5智能体仅能完成26.5%的子任务，在15次评估中仅1次超越基线（提升11.5%），显示出能力-可靠性差距。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI智能体端到端研究能力的基准环境，需要创建能够测试智能体提出假设、运行实验、超越人类基线等完整研究流程的评估框架。

Method: 从ICML、ICLR、ACL会议中选取5篇口头报告和焦点论文，保留其数据集、评估框架和基线实现，但隐藏论文提出的方法，构建5个容器化的任务环境（共39个子任务）。智能体需要在环境中提出新假设、运行实验并尝试超越论文指标上的人类基线。

Result: GPT-5智能体平均仅完成26.5%的子任务，在15次评估中仅1次（6.7%）超越仓库提供的基线（提升11.5%）。智能体表现出重复的长时程失败模式：缺乏耐心、时间和资源管理差、对弱假设过度自信、并行实验协调困难、上下文长度限制等。但在单次运行中，智能体成功超越了ICML 2025焦点任务的解决方案，表明前沿智能体偶尔能达到最先进水平，但不可靠。Claude Code和Codex也显示出类似差距。

Conclusion: ResearchGym为自主智能体在闭环研究中的系统评估和分析提供了基础设施，揭示了当前AI智能体在端到端研究任务中存在显著的能力-可靠性差距，虽然偶尔能达到最先进水平，但表现不可靠。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [64] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文研究如何通过修改教师模型生成的推理轨迹来防止未经授权的知识蒸馏，实现反蒸馏和API水印两个目标，同时保持答案正确性和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 未经授权的知识蒸馏不公平地利用了前沿模型开发的巨大努力和成本，需要有效的方法来防止这种未经授权的使用。

Method: 提出了多种动态重写教师模型推理输出的方法：两种基于LLM的重写能力，其他使用基于梯度的技术。其中简单的基于指令的重写方法效果显著。

Result: 基于指令的重写方法实现了强大的反蒸馏效果，同时保持甚至提高了教师模型的性能。此外，该方法还能实现高度可靠的水印检测，几乎没有误报。

Conclusion: 通过重写教师模型的推理输出可以有效防止未经授权的知识蒸馏，实现反蒸馏和API水印的双重保护，为模型知识产权提供有效保障。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [65] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出了一种基于da Costian-Tarskianism的本体异质性新方法，使用扩展后果系统和扩展开发图来关联本体。


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，为不同本体系统之间的关联和整合提供理论基础。

Method: 基于Carnapian-Goguenism，采用da Costian-Tarskianism方法，构建扩展后果系统（添加本体公理）和扩展开发图（通过扩展后果系统的态射连接本体）。

Result: 建立了包含本体公理的扩展后果系统理论框架，定义了允许通过态射、纤维化和分裂等操作关联本体的扩展开发图结构。

Conclusion: 该方法为应用本体学领域提供了新的理论工具，并指出了未来研究方向。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [66] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源大语言模型在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在决策支持和智能体工作流中应用广泛，但对其在不确定性下的决策机制理解有限。研究者希望通过比较不同LLM的风险选择行为，填补这一知识空白。

Method: 研究从两个维度比较LLM的风险决策：(1)前景表示方式（显式vs经验基础）和(2)决策理由（解释）。研究涉及20个前沿和开源LLM，并辅以匹配的人类被试实验作为参考点，同时使用期望收益最大化的理性智能体模型作为另一个参考。

Result: 研究发现LLM可分为两类：推理模型（RMs）和对话模型（CMs）。RMs倾向于理性行为，对前景顺序、得失框架和解释不敏感，在显式前景和经验历史呈现下表现相似。CMs理性程度显著较低，更接近人类，对前景顺序、框架和解释敏感，且表现出较大的描述-历史差距。开源LLM的配对比较表明，区分RMs和CMs的关键因素是数学推理训练。

Conclusion: LLM在风险决策中存在明显的分类差异，数学推理训练是影响其决策理性的关键因素。这一发现有助于理解LLM的决策机制，并为开发更可靠的决策支持系统提供指导。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [67] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文提出AI机器学习框架补充确定性算法，预测供应链金融中的发票稀释风险，使用实时动态信用限额替代传统不可撤销付款承诺。


<details>
  <summary>Details</summary>
Motivation: 发票或付款稀释（批准发票金额与实际收款之间的差距）是供应链金融中非信用风险和利润损失的重要来源。传统方法依赖买方的不可撤销付款承诺（IPU），但这可能阻碍供应链金融的采用，特别是对于次级投资级买家。需要更灵活的数据驱动方法来管理这种风险。

Method: 引入AI机器学习框架，补充确定性算法来预测发票稀释。使用实时动态信用限额方法，为每个买方-供应商对实时预测稀释风险。基于包含九个关键交易字段的广泛生产数据集进行评估。

Result: 论文评估了AI机器学习框架如何补充确定性算法来预测发票稀释，但摘要中未提供具体的性能指标或比较结果。

Conclusion: 数据驱动的实时动态信用限额方法可以替代传统的不可撤销付款承诺，更灵活地管理供应链金融中的发票稀释风险，特别是对于次级投资级买家，有助于提高供应链金融的采用率。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [68] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究探索不同记忆类型和用途如何帮助智能体在变化的不确定环境中进行空间导航，发现结合多种策略的架构在处理不同性质子任务时更有效


<details>
  <summary>Details</summary>
Motivation: 研究在动态变化、感知受限的不确定环境中，如何利用记忆来提升空间导航效率，特别是当环境非平稳（障碍物和食物位置每日变化）且智能体感知信息有限时

Method: 研究从简单到复杂的多种策略，包括使用非平稳概率学习技术更新情景记忆，利用这些记忆构建即时地图（不完美、有噪声、限于经验范围）并进行路径规划

Result: 当任务难度（如目标距离）增加时，使用记忆更新的智能体比简单（最小记忆）智能体效率显著提升，前提是定位和环境变化带来的不确定性不太大

Conclusion: 需要能够整合多种策略的架构来处理不同性质的子任务（特别是探索搜索和路径规划），利用非平稳概率学习更新记忆并基于记忆构建即时地图的智能体在适度不确定性条件下表现更优

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [69] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 本文提出了一种自适应弃权系统，通过动态调整安全阈值和五维并行检测器的级联架构，在保持高性能的同时有效平衡LLM的安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM部署面临安全性与实用性的根本权衡：严格过滤机制会阻止良性查询，而宽松控制则可能生成不安全内容。传统基于静态规则或固定置信度阈值的护栏通常缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。采用五维并行检测器组成的多维度检测架构，通过分层级联机制优化速度和精度。级联设计通过逐步过滤查询减少不必要的计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，假阳性显著减少，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率。与非级联模型和外部护栏系统相比，实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性和实用性，同时保持了性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [70] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师的教学解释能力，包含854个解释对应139个科学问题，标注了教学风险维度。


<details>
  <summary>Details</summary>
Motivation: 为了支持自动教学评估器和AI导师的评估与训练，需要创建专门的教学解释数据集，该数据集应基于真实的教师角色和教学实践，并包含系统化的教学风险评估框架。

Method: 基于ScienceQA基准的精选子集构建数据集，包含854个解释对应139个K-12科学问题。通过提示工程实例化6种LLM模拟的教师角色，提出包含5个维度的教学风险评估框架，采用半自动专家评审进行标注。

Result: 创建了EduEVAL-DB数据集，包含人类教师和LLM模拟教师的解释，并标注了教学风险。初步验证实验表明，该数据集适用于评估教学风险检测模型，包括比较先进教育模型与轻量级本地模型的性能。

Conclusion: EduEVAL-DB为评估和训练自动教学评估器提供了有价值的资源，支持教学风险检测模型的开发，特别是可在消费级硬件上部署的轻量级模型。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [71] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"玻璃盒"架构，用于人类参与的记忆管理，通过个人知识图谱替代传统向量检索，实现可检查、可精确删除的AI记忆系统。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI系统主要基于"黑盒"检索增强生成，存在缺乏可解释性、无法精确删除敏感数据、隐私保护不足等问题，需要更透明可控的架构。

Method: Ruva采用个人知识图谱作为基础，从向量匹配转向图推理，支持用户检查和精确删除特定事实，实现人类参与的记忆管理。

Result: Ruva实现了可检查的AI记忆系统，确保"被遗忘权"，用户可以像编辑自己生活一样管理AI的知识库，解决了传统向量数据库的隐私和可解释性问题。

Conclusion: Ruva通过图推理架构为个人AI提供了透明、可控的记忆管理系统，将AI从黑盒转向玻璃盒，赋予用户对其数字记忆的完全控制权。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [72] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 本文提出PID Flow框架，通过信息分解分析多模态Transformer中视觉和语言信息的处理模式，发现在LLaVA模型中存在"模态转导"模式：视觉信息早期达到峰值后衰减，语言信息在深层占主导（约82%），跨模态协同作用低于2%。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测是由视觉证据、语言推理还是真正的跨模态计算驱动，以及这种结构如何在不同层间演化。旨在理解视觉如何转化为语言信息。

Method: 提出基于部分信息分解（PID）的层间分析框架，引入PID Flow流程：结合降维、归一化流高斯化和闭式高斯PID估计，使高维神经表示的PID计算可行。应用于LLaVA-1.5-7B和LLaVA-1.6-7B模型，在六个GQA推理任务上进行实验。

Result: 发现一致的"模态转导"模式：视觉独特信息早期达到峰值后衰减，语言独特信息在深层激增（占最终预测约82%），跨模态协同作用低于2%。该模式在不同模型变体间高度稳定（层间相关性>0.96），但强烈依赖任务。通过注意力敲除实验建立了因果关系。

Conclusion: 研究提供了多模态Transformer中视觉如何转化为语言的信息论和因果解释，为识别模态特定信息丢失的架构瓶颈提供了定量指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [73] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过发现任务覆盖集、提升覆盖不等式并注入约束，来推断额外的累积约束，以捕捉多资源交互，提升调度问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统约束编程中累积约束的传播通常单独进行，忽略了多资源之间的交互作用，导致在某些基准测试上性能严重下降。需要一种方法来捕捉这些交互而不增加搜索时间开销。

Method: 将累积约束解释为占用向量上的线性不等式，通过三个步骤生成有效不等式：(1) 发现覆盖集（不能并行运行的任务集合），(2) 通过提升技术加强覆盖不等式，(3) 将生成的约束注入调度问题实例中。

Result: 在标准RCPSP和RCPSP/max测试套件上的实验表明，推断的约束在有利实例上提高了搜索性能并收紧目标界限，在不利实例上仅有轻微性能下降。此外，发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束。

Conclusion: 提出的预处理方法能够有效推断捕捉多资源交互的累积约束，显著提升调度问题的求解性能，同时为基准测试提供了新的下界和最优解。

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [74] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive是一个模型无关的框架，用于评估自动驾驶中视觉语言模型的理性响应性，通过比较基线模型和理性增强模型在受控上下文变化下的决策，验证人类理性是否真正影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶评估方法主要关注结果性能（如安全性和轨迹精度），但无法确定模型决策是否真正基于人类相关的理性考虑。这导致无法区分模型解释是真正的理性响应决策还是事后合理化，这在安全关键领域可能产生虚假信心。

Method: 提出CARE Drive框架，采用两阶段评估过程：1) 提示校准确保稳定输出；2) 系统性上下文扰动测量决策对人类理性的敏感性，如安全边际、社会压力和效率约束。在自行车超车场景中演示，涉及竞争性规范考虑。

Result: 明确的人类理性显著影响模型决策，改善与专家推荐行为的一致性。然而，响应性在不同上下文因素间存在差异，表明对不同类型理性的敏感性不均匀。

Conclusion: 该研究提供了经验证据，表明基础模型的理性响应性可以在不修改模型参数的情况下进行系统性评估，为自动驾驶中更可靠的模型评估提供了新方法。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [75] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA框架通过激活空间中的向量操作实现LLM人格控制，无需训练即可达到微调级别的性能，揭示了人格特质在表示空间中具有可提取、近似正交的数学结构。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态性和组合性，需要一种更高效、可解释的人格控制框架。

Method: 提出PERSONA框架，包含三个阶段：1) Persona-Base通过对比激活分析提取正交特质向量；2) Persona-Algebra通过向量算术实现精确控制（标量乘法调节强度，加法组合，减法抑制）；3) Persona-Flow在推理时动态组合向量实现上下文感知适应。

Result: 在PersonalityBench上获得9.60的平均分，接近监督微调上限9.61；在Persona-Evolve动态人格适应基准上，在不同模型家族中达到最高91%的胜率。

Conclusion: LLM的人格特质在数学上是可处理的，表现为可提取、近似正交的表示空间方向，支持代数操作，为可解释和高效的行为控制开辟了新方向。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [76] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型能在推理时动态修改内部表示几何，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩展token级搜索来改进推理，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能在推理时修改内部表示几何来构建新抽象。

Method: 提出递归概念演化(RCE)框架：检测到表示不足时生成动态低秩概念子空间；通过最小描述长度准则选择子空间；协同时合并子空间；通过约束优化进行整合以保持稳定性。

Result: 在Mistral-7B上集成RCE，在组合推理基准测试中取得显著提升：ARC-AGI-2提高12-18点，GPQA和BBH提高8-14点，MATH和HLE中深度诱导错误持续减少。

Conclusion: RCE框架使预训练语言模型能在推理时动态修改内部表示几何，通过生成概念子空间来构建新抽象而非重新组合现有抽象，显著提升了组合推理能力。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [77] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: GlobeDiff是一种基于扩散模型的多智能体全局状态推断算法，通过将状态推断过程建模为多模态扩散过程，解决了部分可观测环境下的全局状态估计问题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性严重阻碍了有效的协调和决策。现有的信念状态估计和智能体间通信方法存在局限：信念方法过度依赖历史经验而未能充分利用全局信息，通信方法则缺乏有效利用辅助信息的鲁棒模型。

Method: 提出Global State Diffusion Algorithm (GlobeDiff)，基于局部观测推断全局状态。将状态推断过程建模为多模态扩散过程，克服状态估计中的模糊性，同时实现高保真度的全局状态推断。

Result: 证明了GlobeDiff在单模态和多模态分布下的估计误差有界。大量实验结果表明，GlobeDiff实现了优越的性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过创新的扩散建模方法，有效解决了多智能体系统中的部分可观测性问题，为全局状态推断提供了新的解决方案。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [78] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 论文探讨了在社会科学实验中使用大语言模型作为合成参与者的有效性，对比了两种策略：启发式方法和统计校准方法，并分析了它们在不同研究阶段（探索性vs验证性）的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在社会科学实验中作为合成参与者的应用日益增多，但缺乏关于何时这种模拟能够有效推断人类行为的指导。需要明确不同方法在什么条件下能够支持有效的因果效应估计。

Method: 论文对比了两种策略：1）启发式方法：通过提示工程、模型微调等修复策略来减少LLM引起的误差，使模拟行为与观察到的行为可互换；2）统计校准：结合辅助人类数据和统计调整来考虑观察响应与模拟响应之间的差异。

Result: 启发式方法适用于许多探索性任务，但缺乏验证性研究通常需要的正式统计保证。统计校准在明确假设下保持有效性，并能以比仅依赖人类参与者的实验更低的成本提供更精确的因果效应估计。

Conclusion: 两种方法的潜力都取决于LLM对相关人群的近似程度。研究人员不应仅仅关注用LLM替代研究中的参与者，而应考虑可能被忽视的机会。需要明确每种方法在不同研究类型中的适用假设。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [79] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出使用大语言模型嵌入作为编码方式，以保留建筑语义中更精细的区分，相比传统one-hot编码能更好地捕捉相关子类型之间的细微关系。


<details>
  <summary>Details</summary>
Motivation: 在AECO行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对于有效的AI模型训练至关重要。传统的编码方法（如one-hot）通常无法传达密切相关子类型之间的细微关系，限制了AI的语义理解能力。

Method: 提出一种新颖的训练方法，使用大语言模型嵌入（如OpenAI GPT和Meta LLaMA）作为编码来保留建筑语义中更精细的区分。通过训练GraphSAGE模型对5个高层住宅建筑信息模型中的42个建筑对象子类型进行分类。测试了各种嵌入维度，包括原始高维LLM嵌入和通过Matryoshka表示模型生成的1024维压缩嵌入。

Result: 实验结果表明，LLM编码优于传统的one-hot基线。llama-3（压缩）嵌入的加权平均F1分数达到0.8766，而one-hot编码为0.8475。LLM编码在捕捉建筑语义的细微差别方面表现出更好的性能。

Conclusion: 研究结果强调了利用基于LLM的编码来增强AI解释复杂、领域特定建筑语义能力的潜力。随着LLM和降维技术的不断发展，这种方法在AECO行业的语义细化任务中具有广泛应用的潜力。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [80] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍了基于仿真的合成数据生成技术，用于解决AI训练中数据不足和质量问题，并提出了数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI发展中，数据量不足和数据质量差是采用现代亚符号AI的主要障碍，因此对合成数据生成技术的需求很高。

Method: 采用仿真方法作为系统化的合成数据生成途径，提出了数字孪生AI仿真解决方案的参考框架，用于描述、设计和分析相关方案。

Result: 介绍了基于仿真的合成数据生成的关键概念、优势、挑战，以及数字孪生AI仿真解决方案的参考框架。

Conclusion: 仿真为AI训练提供了有效的合成数据生成方法，数字孪生框架为设计和分析相关解决方案提供了系统化的参考。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [81] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: CircuChain是一个诊断基准，用于区分LLM在电路分析中的指令遵循能力与物理推理能力，发现模型能力增强并不保证约束对齐的改进。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在工程领域接近专家水平，在用户指定约束下的可靠推理变得至关重要。当前不清楚前沿模型是真正应用基本原理推理，还是依赖与明确指令冲突的训练先验。

Method: CircuChain基准包含五种典型电路拓扑的Control/Trap问题对，系统变化符号约定、电流方向和极性定义。采用多阶段验证流程，结合符号求解器、SPICE仿真和基于LLM的错误分类法。

Result: 观察到一致的合规-能力分歧：最强模型物理推理近乎完美，但在Trap条件下违反约定的比例很高；较弱模型物理保真度较低，但对明确指令的遵循度更高。

Conclusion: 模型能力增强并不保证约束对齐的改进，需要新的评估框架来强调数学严格领域下的指令遵循。CircuChain提供了这样的框架，并为工程教育和AI对齐研究提供了可操作的见解。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [82] [An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation](https://arxiv.org/abs/2602.15228)
*Zaiyu Cheng,Antonio Mastropaolo*

Main category: cs.SE

TL;DR: 系统提示对代码生成模型的影响研究：研究发现系统提示的约束特异性并不总是提升正确性，few-shot示例可能损害大型代码模型性能，不同编程语言对提示的敏感性差异显著。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优语言模型在代码生成方面取得了显著进展，但系统提示对通用ILMs和专用CLMs的影响尚未得到充分探索。研究者希望系统评估系统提示的详细程度、模型规模、提示策略和编程语言等因素如何影响代码助手性能。

Method: 采用系统化实验设计，涵盖360种配置：4个模型、5个系统提示、3种提示策略、2种编程语言（Python和Java）、2种温度设置。通过控制变量方法评估不同因素对代码生成正确性的影响。

Result: 1) 增加系统提示约束特异性并不单调提升正确性，提示效果取决于配置与任务需求的匹配度；2) 对于大型代码专用模型，few-shot示例可能比zero-shot生成表现更差；3) 编程语言影响显著，Java对系统提示变化的敏感性远高于Python。

Conclusion: 系统提示对代码生成模型的影响是复杂且配置依赖的，需要针对特定模型、任务和编程语言进行定制化提示工程。传统few-shot策略可能不适用于大型代码模型，而语言特定的提示策略可能是必要的。

Abstract: Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.

</details>


### [83] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 该论文从跨栈视角分析生成式AI在计算系统设计中的应用，识别出五个重复出现的挑战和五个有效的设计原则，并提出了一个挑战-原则映射框架来指导系统设计。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑计算系统的设计、优化和构建方式，但相关研究在软件、架构和芯片设计社区中仍然分散。需要从跨栈视角理解生成模型如何应用于从代码生成到硬件设计的各个层面，并识别跨层次的共同模式和挑战。

Method: 采用跨栈分析方法，涵盖超过275篇论文，跨越计算栈的三个层次（软件、架构、芯片设计）和十一个应用领域。通过分析不同层次中的共同结构困难和有效响应，识别出重复出现的挑战和设计原则，并构建挑战-原则映射框架。

Result: 发现了五个重复出现的挑战：反馈循环危机、隐性知识问题、信任与验证、跨边界协同设计、从确定性到动态性的转变；以及五个独立出现的有效设计原则：采用混合方法、设计持续反馈机制、按角色分离关注点、方法与问题结构匹配、基于数十年系统知识构建。这些被组织成一个挑战-原则映射框架。

Conclusion: 该领域需要共享的工程方法论，包括共同词汇表、跨层基准测试和系统化设计实践，以便进展能够在不同社区之间积累而不是在每个社区中重新发现。从跨层视角可以识别出仅从单一层次无法看到的研究问题。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


### [84] [SACS: A Code Smell Dataset using Semi-automatic Generation Approach](https://arxiv.org/abs/2602.15342)
*Hanyu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 本研究提出了一种半自动方法生成高质量代码异味数据集SACS，包含三种常见代码异味（长方法、大类、特性依恋），每种超过10,000个标注样本，解决了机器学习技术应用中缺乏高质量数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 代码异味是软件重构中的重大挑战，会影响软件可维护性和演进。机器学习技术在代码异味研究中应用广泛，但缺乏高质量数据集是主要瓶颈。手动构建数据集劳动密集，自动生成的数据集标签可靠性低、数据质量差。

Method: 采用半自动方法：1) 应用自动生成规则产生候选异味样本；2) 使用多种指标将样本分为自动接受组和人工审核组，让审核者专注于模糊样本；3) 建立结构化审核指南并开发标注工具支持人工验证过程。

Result: 创建了开源代码异味数据集SACS，涵盖三种广泛研究的代码异味：长方法、大类、特性依恋。每个代码异味类别包含超过10,000个标注样本，提供了大规模、公开可用的基准数据集。

Conclusion: 提出的半自动方法能够生成高质量代码异味数据集，解决了机器学习技术应用中的数据瓶颈问题。SACS数据集可为代码异味检测和自动化重构的未来研究提供支持。

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.

</details>


### [85] [Latent Regularization in Generative Test Input Generation](https://arxiv.org/abs/2602.15552)
*Giorgi Merabishvili,Oliver Weißl,Andrea Stocco*

Main category: cs.SE

TL;DR: 研究探索了通过截断对潜在空间进行正则化对深度学习分类器生成测试输入质量的影响，使用基于风格的GANs评估了三种质量维度：有效性、多样性和故障检测率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索潜在空间正则化（特别是截断操作）如何影响为深度学习分类器生成的测试输入的质量，这对于提高测试覆盖率和故障检测能力具有重要意义。

Method: 使用基于风格的GANs作为生成方法，在MNIST、Fashion MNIST和CIFAR-10三个数据集上评估边界测试。比较两种截断策略：1）潜在代码混合与二分搜索优化，2）随机潜在截断用于生成探索。

Result: 实验表明，潜在代码混合方法比随机截断具有更高的故障检测率，同时还能提高多样性和有效性。

Conclusion: 通过潜在代码混合进行潜在空间正则化可以显著提高生成测试输入的质量，特别是在故障检测、多样性和有效性方面，这为深度学习系统的测试提供了更有效的方法。

Abstract: This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.

</details>


### [86] [Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution](https://arxiv.org/abs/2602.15591)
*Denesa Zyberaj,Lukasz Mazur,Pascal Hirmer,Nenad Petrovic,Marco Aiello,Alois Knoll*

Main category: cs.SE

TL;DR: 使用大型语言模型和视觉语言模型从自然语言需求中自动生成可执行的Gherkin测试场景，通过VSS标准化信号引用，在SDV子系统中实现端到端需求到测试的转换管道


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆的功能测试面临挑战：需求使用自然语言编写，规范包含文本、表格和图表，测试资产分散在异构工具链中，需要自动化解决方案来提高测试效率

Method: 使用LLM和VLM提取信号和行为逻辑，自动生成Gherkin场景，通过检索增强生成预选VSS信号，将Gherkin转换为可执行测试脚本，集成VSS标准化信号引用

Result: 在36个需求中，32个（89%）可以转换为可执行场景；在儿童存在检测系统的虚拟环境和实际车辆中成功执行测试；需要人工审查和针对性替换

Conclusion: 该研究展示了软件定义车辆子系统端到端需求到测试管道的可行性和架构，在CPDS案例的仿真和车辆在环设置中进行了评估，证明了自动化测试生成的潜力

Abstract: Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.

</details>


### [87] [A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings](https://arxiv.org/abs/2602.15761)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 使用差分模糊测试评估LLM生成代码重构的功能等价性，发现19-35%的重构存在语义改变，现有测试套件漏检21%的非等价重构


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在自动化代码重构中的广泛应用，评估和确保LLM生成重构与原始实现之间的功能等价性变得至关重要。现有方法通常依赖预定义测试用例评估正确性，但这种方法存在局限性。

Method: 采用差分模糊测试来检查LLM生成代码重构的功能等价性。该方法不需要预定义测试用例，通过执行和比较数千个自动生成的测试输入来探索更大的输入空间。在三个数据集和两种重构类型上对六个LLM（CodeLlama、Codestral、StarChat2、Qwen-2.5、Olmo-3和GPT-4o）进行了大规模评估。

Result: LLM显示出显著改变程序语义的倾向，产生了19-35%的功能非等价重构。实验进一步表明，这些非等价重构中约有21%未被三个评估数据集的现有测试套件检测到。

Conclusion: 依赖现有测试可能会高估LLM生成代码重构的功能等价性，这些重构仍然容易出现语义偏差。差分模糊测试提供了一种更全面的评估方法，能够发现传统测试方法遗漏的问题。

Abstract: With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.

</details>


### [88] [Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications](https://arxiv.org/abs/2602.15362)
*Devendra Tata,Mona Rajhans*

Main category: cs.SE

TL;DR: 提出自动化多源调试和自然语言错误解释系统，通过收集浏览器、API、服务器等多源错误数据并实时验证API合约，利用大语言模型生成自然语言解释，将模糊错误信息转化为可操作见解。


<details>
  <summary>Details</summary>
Motivation: 现代微服务架构虽然提供了可扩展性，但带来了调试和可观测性挑战。故障发生时通常只显示"Something went wrong"等模糊错误信息，掩盖了浏览器端异常、API合约违规或服务器端逻辑故障等根本原因。现有监控工具孤立地捕获这些事件，无法有效关联或为非技术用户提供可理解的解释。

Method: 提出自动化多源调试和自然语言错误解释框架，自动收集和关联来自浏览器、API、服务器日志等多源错误数据，实时验证API合约，并利用大语言模型生成自然语言解释。

Result: 该方法显著减少了支持工程师的平均解决时间，并通过将神秘错误代码转化为可操作的见解来改善用户体验。

Conclusion: 提出的系统解决了微服务架构中调试和可观测性的关键挑战，通过自动化多源数据收集、关联分析和自然语言解释，为技术支持和最终用户提供了更有效的故障诊断和解决方案。

Abstract: Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [89] [Unforgeable Watermarks for Language Models via Robust Signatures](https://arxiv.org/abs/2602.15323)
*Huijia Lin,Kameron Shahabi,Min Jae Song*

Main category: cs.CR

TL;DR: 该论文提出了一种新型水印方案，通过引入不可伪造性和可恢复性两个新保证来加强内容溯源，构建了首个在替换扰动下具有鲁棒性、不可伪造性和可恢复性的不可检测水印方案。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型生成文本越来越难以与人类写作区分，需要强大的工具来验证内容来源。现有水印方案主要关注模型质量保持和鲁棒检测，但对虚假归因的保护有限，因此需要加强水印的可靠性。

Method: 引入不可伪造性和可恢复性两个新保证，构建基于鲁棒（可恢复）数字签名的新水印方案。关键技术是使用属性保持哈希函数将标准数字签名方案提升为鲁棒数字签名，允许验证接近已签名消息的消息，同时防止伪造远离所有已签名消息的消息。

Result: 提出了首个在替换扰动（即汉明度量中的扰动）下具有不可检测性、鲁棒性、不可伪造性和可恢复性的水印方案。该方案通过鲁棒数字签名技术将内容与其生成模型唯一链接，实现安全归因和细粒度可追溯性。

Conclusion: 通过引入不可伪造性和可恢复性两个新保证，显著加强了水印方案的内容所有权保护能力。基于鲁棒数字签名的技术方案能够将内容与其生成模型唯一链接，为内容溯源提供了更安全的解决方案。

Abstract: Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).

</details>


### [90] [A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection](https://arxiv.org/abs/2602.15376)
*Udbhav Prasad,Aniesh Chawla*

Main category: cs.CR

TL;DR: 本文系统比较了基于学习的分类和相似性方法在安全应用中的表现，发现没有单一方法在所有维度都表现优异，需要结合互补技术。


<details>
  <summary>Details</summary>
Motivation: 传统加密摘要（如MD5、SHA-256）虽然能提供精确身份验证，但在威胁狩猎、恶意软件分析和数字取证等实际安全任务中存在局限性，因为攻击者经常进行微小变换。相似性技术可以解决这一问题，但现有方法缺乏系统性比较。

Method: 使用大型公开数据集，在统一的实验框架下系统比较基于学习的分类和相似性方法，包括相似性摘要、局部敏感哈希（如ssdeep、sdhash、TLSH）以及基于机器学习的嵌入方法，采用行业公认的评估指标。

Result: 研究结果显示，没有单一方法在所有维度上都表现优异；每种方法都展现出不同的权衡取舍，表明有效的恶意软件分析和威胁狩猎平台需要结合互补的分类和相似性技术，而不是依赖单一方法。

Conclusion: 基于学习的相似性技术在安全应用中各有优劣，实际部署时需要结合多种互补技术来构建更有效的恶意软件分析和威胁检测平台。

Abstract: Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.

</details>


### [91] [MEV in Binance Builder](https://arxiv.org/abs/2602.15395)
*Qin Wang,Ruiqiang Li,Guangsheng Yu,Vincent Gramoli,Shiping Chen*

Main category: cs.CR

TL;DR: BNB智能链的MEV套利高度集中，两大建设者控制超96%区块和92%利润，短区块间隔和白名单机制加剧中心化问题


<details>
  <summary>Details</summary>
Motivation: 研究BNB智能链上建设者驱动的MEV套利，分析其独特的提议者-建设者分离设计（白名单建设者、短区块间隔、私有订单流绕过公共内存池）对中心化的影响

Method: 实证追踪2025年5月至11月期间两大主导建设者（48Club和Blockrazor）的套利活动，分析区块生产、利润分布和竞争动态

Result: 两大建设者生产超96%区块并捕获约92%MEV利润；利润集中在短跳数、低复杂度的包装代币和稳定币套利路径；区块构建迅速向垄断收敛

Conclusion: BSC的短区块间隔和白名单PBS设计压缩了MEV竞争的可竞争窗口，放大了延迟优势，导致比以太坊更中心化的MEV提取，结构上更易受审查且公平性更弱

Abstract: We study the builder-driven MEV arbitrage on BNB Smart Chain (BSC). BSC's Proposer--Builder Separation (PBS) adopts a leaner design: only whitelisted builders can participate, blocks are produced at shorter intervals, and private order flow bypasses the public mempool. These features have long raised community concerns over centralization, which we empirically confirm by tracing arbitrage activity of the two dominant builders from May to November 2025. Within months, 48Club and Blockrazor produced over 96\% of blocks and captured about 92\% of MEV profits.
  We find that profits concentrate in short, low-hop arbitrage routes over wrapped tokens and stablecoins, and that block construction rapidly converges toward monopoly. Beyond concentration alone, our analysis reveals a structural source of inequality: BSC's short block interval and whitelisted PBS collapse the contestable window for MEV competition, amplifying latency advantages and excluding slower builders and searchers. MEV extraction on BSC is not only more centralized than on Ethereum, but also structurally more vulnerable to censorship and weakened fairness.

</details>


### [92] [SecCodeBench-V2 Technical Report](https://arxiv.org/abs/2602.15485)
*Longfei Chen,Ji Zhao,Lanxiao Cui,Tong Su,Xingbo Pan,Ziyang Li,Yongxing Wu,Qijiang Cao,Qiyao Cai,Jing Zhang,Yuandong Ni,Junyao He,Zeyu Zhang,Chao Ge,Xuhuai Lu,Zeyu Gao,Yuxin Cui,Weisen Chen,Yuxuan Peng,Shengping Wang,Qi Li,Yukai Huang,Yukun Liu,Tuo Zhou,Terry Yue Zhuo,Junyang Lin,Chao Zhang*

Main category: cs.CR

TL;DR: SecCodeBench-V2是一个用于评估大语言模型生成安全代码能力的公开基准测试，包含98个基于阿里工业场景的代码生成和修复任务，涵盖5种编程语言和22个CWE安全漏洞类别。


<details>
  <summary>Details</summary>
Motivation: 随着AI编程助手在软件开发中的广泛应用，评估这些模型生成安全代码的能力变得至关重要。现有基准测试在工业场景覆盖、安全漏洞多样性和评估可靠性方面存在不足，需要建立一个更全面、可靠的评估框架。

Method: 采用函数级任务设计，每个场景提供完整项目脚手架，要求模型在固定接口和依赖下实现或修复目标函数。通过可执行的PoC测试用例进行功能验证和安全验证，所有测试用例由安全专家编写和双重审查。评估主要基于动态执行，在隔离环境中编译运行模型生成的代码并执行测试用例，对于无法用确定性测试判断的场景，采用LLM-as-a-judge方法。

Result: 建立了包含98个场景的基准测试，涵盖Java、C、Python、Go和Node.js五种编程语言，覆盖22个常见CWE安全漏洞类别。提供了统一的评估流程和基于Pass@K的评分协议，支持跨模型的可比性评估。

Conclusion: SecCodeBench-V2为评估AI编程助手的安全能力提供了一个严谨、可复现的基础框架，填补了工业场景下安全代码生成评估的空白，有助于推动更安全的AI编程助手发展。

Abstract: We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.

</details>


### [93] [Onto-DP: Constructing Neighborhoods for Differential Privacy on Ontological Databases](https://arxiv.org/abs/2602.15614)
*Yasmine Hayder,Adrien Boiret,Cédric Eichler,Benjamin Nguyen*

Main category: cs.CR

TL;DR: 论文提出Onto-DP（本体感知差分隐私），通过增强语义意识来保护数据库免受基于推理规则的攻击


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私模型在保护数据库免受基于推理规则的攻击方面存在不足，攻击者可以利用推理规则发现敏感信息

Method: 提出Onto-DP（本体感知差分隐私），在经典DP模型基础上增加语义意识，使其能够识别和保护推理规则可能暴露的信息

Result: 证明Onto-DP是充分条件，能够有效保护数据库免受了解推理规则的攻击者的攻击

Conclusion: Onto-DP通过增强语义意识扩展了差分隐私范式，为数据库提供了更全面的保护，特别是针对基于推理规则的攻击

Abstract: In this paper, we investigate how attackers can discover sensitive information embedded within databases by exploiting inference rules. We demonstrate the inadequacy of naively applied existing state of the art differential privacy (DP) models in safeguarding against such attacks. We introduce ontology aware differential privacy (Onto-DP), a novel extension of differential privacy paradigms built on top of any classical DP model by enriching it with semantic awareness. We show that this extension is a sufficient condition to adequately protect against attackers aware of inference rules.

</details>


### [94] [Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections](https://arxiv.org/abs/2602.15654)
*Xianglin Yang,Yufei He,Shuo Ji,Bryan Hooi,Jin Song Dong*

Main category: cs.CR

TL;DR: 论文研究自进化LLM智能体在跨会话更新长期记忆时面临的安全风险，提出"僵尸智能体"攻击框架，通过间接内容注入实现持久性控制。


<details>
  <summary>Details</summary>
Motivation: 自进化LLM智能体通过跨会话更新长期记忆来提升长期任务性能，但这种设计带来了安全风险：良性会话中观察到的不可信外部内容可能被存储为记忆，并在后续被当作指令执行。

Method: 提出黑盒攻击框架，包含感染和触发两个阶段。感染阶段：智能体在执行良性任务时读取中毒内容，通过正常更新过程将有效载荷写入长期记忆。触发阶段：有效载荷被检索或传递，导致未经授权的工具行为。针对滑动窗口和检索增强等常见内存实现设计了特定的持久化策略。

Result: 评估显示攻击在代表性智能体设置和任务中有效，能够实现长时间持久性并诱导未经授权行为，同时保持良性任务质量。结果表明，记忆演化可以将一次性间接注入转化为持久性控制。

Conclusion: 自进化智能体的记忆演化机制存在严重安全漏洞，仅关注每会话提示过滤的防御措施不足以保护这类系统，需要更全面的安全机制来应对跨会话攻击。

Abstract: Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the agent into a puppet of the attacker.
  We present a black-box attack framework that uses only indirect exposure through attacker-controlled web content. The attack has two phases. During infection, the agent reads a poisoned source while completing a benign task and writes the payload into long-term memory through its normal update process. During trigger, the payload is retrieved or carried forward and causes unauthorized tool behavior. We design mechanism-specific persistence strategies for common memory implementations, including sliding-window and retrieval-augmented memory, to resist truncation and relevance filtering. We evaluate the attack on representative agent setups and tasks, measuring both persistence over time and the ability to induce unauthorized actions while preserving benign task quality. Our results show that memory evolution can convert one-time indirect injection into persistent compromise, which suggests that defenses focused only on per-session prompt filtering are not sufficient for self-evolving agents.

</details>


### [95] [Revisiting Backdoor Threat in Federated Instruction Tuning from a Signal Aggregation Perspective](https://arxiv.org/abs/2602.15671)
*Haodong Zhao,Jinming Hu,Gongshen Liu*

Main category: cs.CR

TL;DR: 联邦学习安全研究新视角：挑战传统少数恶意客户端投毒范式，揭示良性客户端数据中低浓度分布式投毒数据的隐蔽后门威胁，在语言模型联邦指令调优中尤为严重。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习安全研究主要关注少数恶意客户端故意破坏模型更新的后门威胁。本文挑战这一范式，研究更普遍且隐蔽的威胁：良性客户端数据集中分布的低浓度投毒数据导致的后门漏洞。这在依赖未经验证的第三方和众包数据的语言模型联邦指令调优中日益常见。

Method: 1) 分析两种后门数据形式：自然触发（固有特征作为隐式触发器）和攻击者注入触发；2) 从信号聚合角度建模后门植入过程，提出后门信噪比量化分布式后门信号动态；3) 通过大量实验验证威胁严重性。

Result: 实验显示威胁严重：仅不到10%的训练数据被投毒并分布在客户端间，攻击成功率超过85%，而主要任务性能基本不受影响。关键发现：针对恶意客户端攻击设计的最先进后门防御机制对此威胁基本无效。

Conclusion: 研究结果突显了针对现代去中心化数据生态系统现实定制新防御机制的紧迫需求。分布式低浓度投毒数据构成联邦学习安全的新范式威胁，需要重新思考防御策略。

Abstract: Federated learning security research has predominantly focused on backdoor threats from a minority of malicious clients that intentionally corrupt model updates. This paper challenges this paradigm by investigating a more pervasive and insidious threat: \textit{backdoor vulnerabilities from low-concentration poisoned data distributed across the datasets of benign clients.} This scenario is increasingly common in federated instruction tuning for language models, which often rely on unverified third-party and crowd-sourced data. We analyze two forms of backdoor data through real cases: 1) \textit{natural trigger (inherent features as implicit triggers)}; 2) \textit{adversary-injected trigger}. To analyze this threat, we model the backdoor implantation process from signal aggregation, proposing the Backdoor Signal-to-Noise Ratio to quantify the dynamics of the distributed backdoor signal. Extensive experiments reveal the severity of this threat: With just less than 10\% of training data poisoned and distributed across clients, the attack success rate exceeds 85\%, while the primary task performance remains largely intact. Critically, we demonstrate that state-of-the-art backdoor defenses, designed for attacks from malicious clients, are fundamentally ineffective against this threat. Our findings highlight an urgent need for new defense mechanisms tailored to the realities of modern, decentralized data ecosystems.

</details>


### [96] [Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters](https://arxiv.org/abs/2602.15815)
*Matthew Regehr,Bingshan Hu,Ethan Leeman,Pasin Manurangsi,Pierre Tholoniat,Mathias Lécuyer*

Main category: cs.CR

TL;DR: 研究自然隐私过滤器，用于精确组合具有自适应选择隐私特性的差分隐私机制，发现自然隐私过滤器并非免费，只有良好排序的隐私机制族才允许免费的自然隐私过滤器。


<details>
  <summary>Details</summary>
Motivation: 现有隐私过滤器仅考虑简单的隐私参数（如Rényi-DP或高斯DP参数），而自然隐私过滤器考虑每个查询的完整隐私配置文件，承诺在给定隐私预算下提供更好的效用。

Method: 研究自然隐私过滤器，分析其与差分隐私机制组合的特性，探讨哪些隐私机制族在组合时具有良好排序性质。

Result: 发现与其他形式的差分隐私不同，自然隐私过滤器通常不是免费的，只有那些在组合时具有良好排序性质的隐私机制族才允许免费的自然隐私过滤器。

Conclusion: 自然隐私过滤器虽然能提供更好的效用，但并非普遍免费，其可行性取决于隐私机制族在组合时的排序特性。

Abstract: We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as Rényi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [97] [Enhancing Computational Efficiency in NetLogo: Best Practices for Running Large-Scale Agent-Based Models on AWS and Cloud Infrastructures](https://arxiv.org/abs/2602.15317)
*Michael A. Duprey,Georgiy V. Bobashev*

Main category: cs.MA

TL;DR: 本文提供了在AWS等云基础设施上优化NetLogo运行大规模基于主体模型(ABMs)的全面指南，通过内存管理、Java选项、BehaviorSpace执行和AWS实例选择等最佳实践，实现了32%的计算成本降低和性能一致性提升。


<details>
  <summary>Details</summary>
Motivation: 随着基于主体模型(ABMs)的复杂性和规模不断增长，需要高效的计算策略来应对处理能力和内存需求的增加，特别是在云基础设施上运行大规模模型时。

Method: 提供NetLogo在AWS云基础设施上的优化指南，包括内存管理最佳实践、Java选项配置、BehaviorSpace执行优化以及AWS实例选择策略，并使用狼-羊捕食模型在不同AWS实例上进行对比分析。

Result: 通过实施这些优化措施并选择合适的AWS实例，实现了32%的计算成本降低，同时提高了性能一致性。使用狼-羊捕食模型的对比分析展示了通过这些优化可实现的性能提升。

Conclusion: 本文为在云基础设施上运行大规模NetLogo模型提供了实用的优化指南，通过系统化的优化策略可以显著降低计算成本并提高性能，为ABM研究者在云环境中高效运行复杂模型提供了可行方案。

Abstract: The rising complexity and scale of agent-based models (ABMs) necessitate efficient computational strategies to manage the increasing demand for processing power and memory. This manuscript provides a comprehensive guide to optimizing NetLogo, a widely used platform for ABMs, for running large-scale models on Amazon Web Services (AWS) and other cloud infrastructures. It covers best practices in memory management, Java options, BehaviorSpace execution, and AWS instance selection. By implementing these optimizations and selecting appropriate AWS instances, we achieved a 32\% reduction in computational costs and improved performance consistency. Through a comparative analysis of NetLogo simulations on different AWS instances using the wolf-sheep predation model, we demonstrate the performance gains achievable through these optimizations.

</details>
