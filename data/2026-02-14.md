<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision](https://arxiv.org/abs/2602.12164)
*Xiaohan He,Shiyang Feng,Songtao Huang,Lei Bai,Bin Wang,Bo Zhang*

Main category: cs.AI

TL;DR: Sci-CoE是一个两阶段科学协同演化框架，通过从稀疏监督到无监督学习的转变，让模型作为求解器和验证器自我演化，提升科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学推理任务中仍然脆弱，主要原因是解决方案评估不可靠以及验证策略多样性有限。需要一种方法让模型能够自我演化，同时作为求解器和验证器，以提升科学推理的鲁棒性。

Method: 提出两阶段科学协同演化框架：第一阶段使用少量标注数据为验证器建立基本正确性判断锚点；第二阶段引入几何奖励机制，综合考虑共识、可靠性和多样性，驱动大规模无标签数据上的自我迭代。

Result: 在多个通用科学基准测试上的实验表明，Sci-CoE增强了复杂推理能力，展现出强大的可扩展性，有助于构建更鲁棒和多样化的评估系统。

Conclusion: Sci-CoE框架通过让模型作为求解器和验证器协同演化，有效解决了科学推理任务中的评估不可靠和策略单一问题，为构建更强大的科学推理系统提供了新途径。

Abstract: Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.

</details>
