<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 49]
- [cs.CL](#cs.CL) [Total: 29]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现实时、一致的世界建模。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长期一致性和动态场景持久记忆方面存在局限，阻碍其发展为实用的世界模型。需要一种能够统一视频生成、动态场景重建和长期记忆的框架。

Method: 提出生成-重建-引导范式：生成视频流连续重建为动态4D时空表示，再引导后续生成以保持一致性。采用增强的自回归扩散视频模型，结合宏微观规划（MMPL）减少误差积累，并使用分布匹配蒸馏（DMD）实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现优异，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld是迈向实用、交互式、支持记忆的世界模型的重要一步，为多模态生成和具身智能提供了可行的解决方案。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 通过噪声优化解决文本到图像模型的模式崩溃问题，提升生成多样性


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在严重的模式崩溃问题，即给定相同文本提示时生成的图像缺乏多样性。现有方法通过引导机制或生成大量候选再筛选来解决，但本文采取不同的噪声优化方向。

Method: 提出简单的噪声优化目标来缓解模式崩溃，同时保持基础模型的保真度。分析噪声的频率特性，展示具有不同频率特性的替代噪声初始化可以改善优化和搜索。

Result: 实验证明噪声优化在生成质量和多样性方面都能产生优越的结果。

Conclusion: 噪声优化是解决文本到图像模型模式崩溃的有效方法，能够提升生成多样性而不损害模型保真度。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 本文提出了Spatial4D-Bench，一个包含约40,000个问答对、覆盖18个任务的4D空间智能基准测试，用于评估多模态大语言模型在4D空间推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能（感知物体随时间移动或变化的能力），但多模态大语言模型是否能够达到人类水平的4D空间智能尚不清楚。现有空间智能基准测试通常规模小或多样性有限，无法全面评估模型的4D空间推理能力。

Method: 构建了Spatial4D-Bench基准测试，包含约40,000个问答对，覆盖18个明确定义的任务，这些任务被系统性地组织为六个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 对多种最先进的开源和专有多模态大语言模型进行基准测试，发现它们在多种4D空间推理方面存在显著局限性，如路线规划、动作识别和物理合理性推理等。

Conclusion: Spatial4D-Bench提供了一个结构化、全面的基准测试，可用于评估多模态大语言模型的空间认知能力。研究结果揭示了当前模型在4D空间智能方面的局限性，希望该基准测试能够促进开发更强大的模型，朝着人类水平的4D空间智能发展。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP框架通过学习历史遍历数据构建压缩地图先验，显著提升3D目标检测性能，存储效率提高20倍


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常将每个位置视为首次访问，忽略了历史遍历信息。人类驾驶员很少去无人去过的地方，大多数自动驾驶部署区域都曾被访问过，但系统未能有效利用这些历史信息。

Method: 提出压缩地图先验(CMP)框架，从历史遍历数据中学习空间先验。使用二值化哈希映射存储地图先验，存储密度仅为32KB/km²，比密集存储减少20倍。该框架可轻松集成到主流3D感知系统中，几乎不增加计算成本。

Result: 在nuScenes数据集上，CMP框架显著且一致地提升了多种架构的3D目标检测性能。压缩存储方案使地图先验的存储效率提高了20倍。

Conclusion: 压缩地图先验是一种简单有效的框架，能够从历史遍历中学习空间先验知识，显著提升自动驾驶视觉系统的3D感知性能，同时保持低存储和计算开销。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [5] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个专门针对金融信贷领域的大规模多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，用于评估视觉语言模型在信贷文档理解和决策中的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，急需一个领域特定的基准测试来反映金融信贷应用中的具体文档和工作流程，包含信贷特定理解能力和真实世界鲁棒性，同时保持隐私合规性。

Method: 通过封闭式合成-捕获流水线构建样本：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知图像。评估框架包含三个维度：感知（3个基础任务）、推理（4个信贷特定任务）和鲁棒性（10种真实世界采集伪影类型）。

Result: 在23个最先进的视觉语言模型上进行了广泛实验，涵盖14家顶级AI公司和研究机构。Gemini 3 Pro作为商业模型获得最佳F1分数（64.61%），Qwen3-VL-235B作为开源基线获得最佳分数（57.27%），而专门的金融信贷模型Qfin-VL-Instruct获得最高总体分数（64.92%）。鲁棒性评估显示即使表现最佳的模型在采集伪影下也会出现明显性能下降。

Conclusion: FCMBench能够有效区分现代视觉语言模型的性能差异和鲁棒性，填补了金融信贷领域多模态评估的空白，为实际应用提供了可靠的基准测试工具。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [6] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 提出FaceFocalDesc问题：为任意选定面部区域生成包含动作单元、情绪状态和年龄估计的多属性自然语言描述，并构建相应数据集和基于Qwen2.5-VL的Focal-RegionFace模型


<details>
  <summary>Details</summary>
Motivation: 当前面部分析研究缺乏对任意选定面部区域的多属性自然语言描述生成与识别能力，系统聚焦个体面部区域的能力有助于更好理解和控制面部状态分析

Method: 1) 构建包含丰富区域级标注和自然语言描述的新数据集；2) 基于Qwen2.5-VL开发Focal-RegionFace模型，通过多阶段渐进微调逐步聚焦局部面部特征

Result: Focal-RegionFace在新基准测试中取得最佳性能，在传统指标和新提出指标上均表现优异，验证了其在细粒度多属性面部区域聚焦分析场景的有效性和通用性

Conclusion: 该研究成功解决了面部区域聚焦描述生成与识别问题，提出的数据集和模型为细粒度面部状态分析提供了新工具，实现了可解释的年龄估计、面部动作单元和情绪检测

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [7] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一个无需训练、基于结构化潜在表示的3D变形框架，通过注意力机制融合源和目标特征来生成高质量、语义一致且时间平滑的跨类别3D变形序列。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临生成语义一致和时间平滑变形的挑战，特别是在跨类别情况下。现有方法难以在保持结构连贯性的同时实现高质量变形。

Method: 提出MorphAny3D框架，基于结构化潜在表示，引入变形交叉注意力机制融合源和目标特征以保持结构连贯性，使用时序融合自注意力增强时间一致性，并通过方向校正策略缓解姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，即使在具有挑战性的跨类别情况下也能表现优异。进一步支持解耦变形和3D风格迁移等高级应用，并能泛化到其他基于结构化潜在表示的生成模型。

Conclusion: MorphAny3D通过创新的注意力机制和方向校正策略，实现了高质量、语义一致且时间平滑的3D变形，为跨类别3D变形提供了有效的训练免费解决方案。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [8] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出了一种基于多视角3D实例分割的作物计数框架，通过神经辐射场合成视图，结合可见性和掩码一致性评分，实现高精度作物计数，无需作物特定参数调优。


<details>
  <summary>Details</summary>
Motivation: 在户外农田环境中，部分遮挡和作物聚集造成的模糊性给基于图像的作物计数方法带来巨大挑战，需要更精确的3D计数解决方案。

Method: 使用多视角2D图像，结合神经辐射场进行视图合成，引入作物可见性和掩码一致性评分，结合NeRF的3D信息实现3D实例分割。

Result: 在棉花、苹果和梨三个农业数据集上验证，展示了在作物颜色、形状和大小变化下的稳定计数性能，优于现有技术。

Conclusion: 该方法通过3D实例分割有效解决了户外作物计数中的遮挡和聚集问题，提供了高精度计数框架，并贡献了棉花植物数据集促进相关研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [9] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler：一种基于示例的风格合成方法，用于无监督域适应，无需先验知识即可捕获域内风格多样性，提升下游分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，但对域内变异性探索不足。传统方法需要预先指定域内变化进行风格合成，这在实践中不切实际。

Method: 提出IntraStyler方法，使用示例图像指导风格合成，使输出风格匹配示例风格。引入基于对比学习的风格编码器来提取纯风格特征，无需任何先验知识。

Result: 在最大的跨模态域适应公共数据集CrossMoDA 2023上评估，实验证明该方法在可控风格合成方面有效，多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够无需先验知识捕获多样化的域内风格，通过可控风格合成生成多样化数据，有效提升无监督域适应中下游分割任务的性能。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [10] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 该论文提出使用强化学习来提升多模态大语言模型的视觉推理能力，通过设计针对不同推理方面的奖励函数，激励模型生成更长的结构化推理过程，从而解决视觉信息整合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成推理链时缺乏对视觉信息的有效整合，这限制了它们解决需要精确视觉感知的任务（如视觉谜题）的能力。研究表明视觉感知是这类任务的关键瓶颈。

Method: 采用奖励驱动的强化学习方法，设计了六个针对不同推理方面的奖励函数（包括图像理解、思考步骤和答案准确性），使用组相对策略优化（GRPO）来激励更长的结构化推理，并防止视觉信息的绕过。

Result: 实验表明，将图像转换为文本描述可以显著提升性能（Claude 3.5提升26.7%，Claude 3.7提升23.6%）。在Qwen-2.5-VL-7B模型上，该方法实现了5.56%的性能提升，在领域内和领域外设置中都取得了稳定的增益。

Conclusion: 强化学习是解锁开源多模态大语言模型长视觉推理能力的有效机制，无需昂贵的监督数据，通过精心设计的奖励函数可以显著提升模型在需要视觉感知任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [11] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新的向量量化方法，通过低维码本组合量化，在显著减小码本大小的同时提升性能，可作为即插即用模块用于各种下游任务。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突，需要解决这一矛盾。

Method: 1. 引入参数高效的码本，将码向量重构为特征向量中的低维组合单元，通过组合而非单独匹配来扩展解空间；2. 加入参数无关的外推-插值机制，在量化过程中增强和平滑特征；3. 设计确保码本完全使用，避免崩溃问题；4. 作为即插即用模块适用于现有VQ方法。

Result: 在不同任务、数据集和架构上的广泛评估表明，LooC优于现有VQ方法，在显著减小码本大小的同时实现了最先进的性能。

Conclusion: LooC成功解决了向量量化中码本容量与紧凑性之间的矛盾，通过低维组合量化和特征增强机制，在保持高性能的同时大幅减小码本规模，具有广泛的适用性。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [12] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 本文提出SynDR-IQA框架，通过重塑合成数据分布来解决盲图像质量评估中合成数据泛化能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估面临标注数据稀缺的挑战，合成数据是解决方案但现有合成数据集训练的模型泛化能力有限。研究发现合成数据学习到的表征呈现离散聚类模式，高质量图像特征围绕参考图像聚类，低质量图像特征按失真类型聚类，这源于合成数据分布而非模型架构问题。

Method: 提出SynDR-IQA框架，基于样本多样性和冗余对泛化误差影响的理论推导，采用两种策略：1) 分布感知的多样内容上采样，增强视觉多样性同时保持内容分布；2) 密度感知的冗余聚类下采样，通过减少密集聚类区域的密度来平衡样本。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上进行了广泛实验，证明了方法的有效性。

Conclusion: 通过重塑合成数据分布，SynDR-IQA框架显著提升了盲图像质量评估模型的泛化能力，为解决合成数据泛化问题提供了有效方案。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [13] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8解决PCB红外缺陷检测数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 红外PCB缺陷检测面临数据稀缺瓶颈，传统方法依赖配对监督数据，难以获得足够训练样本

Method: 使用CycleGAN进行非配对图像翻译，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；构建异构训练策略，融合伪红外数据和有限真实红外样本训练轻量级YOLOv8检测器

Result: 该方法在低数据条件下有效增强特征学习，增强后的检测器显著优于仅使用有限真实数据的模型，性能接近完全监督训练基准

Conclusion: 伪红外合成作为工业检测的鲁棒数据增强策略具有显著效果，为解决红外数据稀缺问题提供了有效方案

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [14] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 本文提出了一种用于低资源设备的轻量级害虫检测和农药推荐框架，结合紧凑型CNN和原型元学习进行害虫识别，并考虑环境因素推荐环保农药，在保持高精度的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工田间检查和化学农药，成本高、耗时长、劳动密集且对环境有负面影响。特别是甘蔗和小麦等易受虫害的作物需要更有效的管理方案。

Method: 框架包含两个主要模块：1) 害虫检测模块使用紧凑型轻量级CNN结合原型元学习，即使在少量训练样本下也能准确识别害虫；2) 农药推荐模块结合作物类型和生长阶段等环境因素，推荐安全环保的农药。通过整合多个公开数据集构建了包含不同视角、害虫大小和背景条件的综合数据集。

Result: 提出的轻量级CNN在保持与最先进模型相当的高精度的同时，显著降低了计算复杂度。决策支持系统减少了传统化学农药的依赖，促进了可持续实践，展示了在精准农业中实时应用的潜力。

Conclusion: 该轻量级框架适用于智能手机和无人机等低资源设备，特别适合小农户使用，为精准农业中的实时害虫管理提供了有效的解决方案，有助于实现更可持续的农业实践。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [15] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一个基于器官分离概念的放射学基础模型，通过自动化创建器官体积-描述对，结合自监督预训练和对比学习，在3D-CT图像与语言表达对应关系学习中平衡计算效率和表征能力。


<details>
  <summary>Details</summary>
Motivation: 放射学基础模型在应用于各种临床任务时，处理3D-CT体数据面临计算成本约束的挑战，需要一种既能保持表征能力又能提高计算效率的方法。

Method: 基于器官分离概念，利用14万系列的大规模数据集，通过分割技术和基于LLM的放射报告处理自动化创建器官体积-描述对，结合VideoMAE自监督预训练和体积-文本对的对比学习。

Result: 在零样本器官病变分类任务中，相比CT-CLIP在83%器官上获得更高F1分数，相比Merlin在64%器官上表现更好；在零样本发现病变分类任务中，相比Merlin在83%发现类别上获得更高AUROC；在放射报告生成任务中表现与现有VLM相当。

Conclusion: 器官分离学习框架可以作为3D-CT基础模型实际实施的现实有效设计指南，展示了在临床评估设置中的高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [16] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个包含1550万高质量图像-文本对的多学科科学多模态数据集，通过AI增强管道提升科学图像与文本的对齐质量


<details>
  <summary>Details</summary>
Motivation: 多模态学习在通用领域取得革命性进展，但在科学发现中的应用受到复杂科学图像与稀疏文本描述之间深刻语义鸿沟的阻碍

Method: 从250万篇开放获取科学论文中提取图像-文本对，利用Qwen-VL多模态大模型系列构建AI就绪的语义增强管道，通过论文摘要和引用上下文重新标注图像

Result: 数据集包含1550万高质量图像-文本对，覆盖物理、生物、工程等多个学科；语义增强使图像-文本对齐提升18.21%，SciBERT伪困惑度指标显示语义模糊性降低

Conclusion: S1-MMAlign为推进科学推理和跨模态理解提供了基础资源，支持AI for Science时代的发展，数据集已在HuggingFace公开

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [17] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出ActErase：一种无需训练的概念擦除方法，通过激活差异区域识别和动态替换，在扩散模型中高效移除敏感概念，同时保持生成能力


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理风险，现有概念擦除方法大多依赖数据密集且计算昂贵的微调，存在关键限制

Method: 基于模型激活主要由通用概念组成、只有极小部分表示目标概念的观察，通过提示对分析识别激活差异区域，提取目标激活并在前向传播中动态替换输入激活

Result: 在三个关键擦除任务（裸露、艺术风格、对象移除）上实现SOTA性能，有效保持模型整体生成能力，对对抗攻击表现出强鲁棒性

Conclusion: ActErase为扩散模型中的轻量级有效概念操作建立了新的即插即用范式，无需训练即可实现高效概念擦除

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [18] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS：一种在稀疏观测下重建动态目标的框架，通过骨架驱动的变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中动态目标重建面临挑战，因为观测通常稀疏（如安防摄像头），而传统方法需要密集的视角覆盖和时间采样。现有方法在稀疏观测下效果不佳，需要新的解决方案。

Method: 提出SV-GS框架，利用粗略骨架图和初始静态重建作为输入，优化骨架驱动的变形场。该场由粗粒度骨架关节姿态估计器和细粒度变形模块组成，仅使关节姿态估计器随时间变化，实现平滑运动插值并保留几何细节。

Result: 在合成数据集上，相比现有方法在稀疏观测下PSNR提升达34%；在真实数据集上，使用显著更少的帧数即可达到与密集单目视频方法相当的性能。还证明可用扩散生成先验替代初始静态重建，提高实用性。

Conclusion: SV-GS能够在稀疏观测下有效重建动态目标，通过骨架驱动的变形场实现高质量运动估计和几何重建，为现实场景中的动态重建提供了实用解决方案。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [19] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 开发基于Swin Transformer的深度学习模型，用于皮肤疾病图像分类，在ISIC2019数据集上对8种皮肤病变类型达到87.71%的准确率。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍而皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤疾病诊断。

Method: 利用公开皮肤疾病图像数据集进行预训练，提取视觉特征；优化模型架构、数据预处理流程，应用针对性数据增强技术；基于Swin Transformer构建最终模型。

Result: 在ISIC2019数据集上对8种皮肤病变类型达到87.71%的预测准确率。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助工具的潜力。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [20] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor：基于草图的视频着色模型，支持异构多参考输入，通过区域分配和时空对应掩码注意力提升着色质量


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常只使用场景第一帧作为参考，忽略了角色设定图、背景图像等其他参考源。这限制了着色质量和一致性。

Method: 1. 将参考图像编码为潜在帧并与视频帧在时间维度拼接；2. 使用显式的每参考区域分配；3. 采用时空对应掩码注意力；4. 模态分离的RoPE索引

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下均优于基线方法，提升了色彩保真度、身份一致性和时间稳定性

Conclusion: TimeColor通过支持异构多参考输入和有效的参考绑定机制，显著提升了基于草图的视频着色质量

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [21] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet是一个计算高效的行人重识别模型，通过多尺度特征融合、语义聚类、动态权重平均等技术，在保持高精度的同时大幅降低计算成本，适合实时监控和移动应用部署。


<details>
  <summary>Details</summary>
Motivation: 当前行人重识别方法虽然精度高但计算成本大，难以在计算资源有限的实时监控和移动应用中部署。需要开发既准确又计算高效的模型。

Method: VisNet采用多尺度特征融合（融合ResNet50的1-4阶段）、语义聚类（基于解剖学身体分区的规则伪标签）、动态权重平均平衡分类语义正则化，以及FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1和77.65% mAP，仅需32.41M参数和4.601 GFLOPs，计算效率显著优于现有方法。

Conclusion: VisNet为计算资源有限的实时监控和移动应用提供了一个实用高效的行人重识别解决方案，在精度和计算效率之间取得了良好平衡。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [22] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: OmniVaT框架首次成功解决了单域泛化多模态视觉触觉学习任务，通过统一嵌入频率空间和分层树结构增强跨域泛化能力


<details>
  <summary>Details</summary>
Motivation: 视觉触觉学习面临模态差异（视觉与触觉图像）和领域差距（非标准化触觉传感器和不一致数据收集）的双重挑战，需要解决单域泛化多模态VTL任务

Method: 提出OmniVaT框架，包含：1) 多模态分数傅里叶适配器，将视觉和触觉嵌入映射到统一的嵌入频率空间；2) 离散树生成模块，通过分层树结构获得多样可靠的多模态分数表示

Result: 大量实验证明OmniVaT在SDG-VTL任务上具有优越的跨域泛化性能，无需多域训练数据或精心设计的跨模态融合策略

Conclusion: OmniVaT框架首次成功解决了单域泛化多模态视觉触觉学习任务，通过统一嵌入频率空间和分层树结构有效缓解模态差异和领域差距问题

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [23] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer：一种基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐的视觉嵌入，替代传统语义分割，支持自然语言查询和3D地图构建


<details>
  <summary>Details</summary>
Motivation: 家庭环境中机器人需要全面理解周围环境，以便与未经训练的人类进行有效直观的交互。传统语义分割方法使用固定预定义类别，限制了灵活性和应用范围。

Method: 提出DVEFormer，一种高效的RGB-D Transformer方法，通过知识蒸馏从Alpha-CLIP的教师嵌入中学习细粒度像素级嵌入，而不是直接进行传统的语义分割。

Result: 在常见室内数据集上评估显示，该方法在满足实时性要求的同时实现了竞争性性能：完整模型在NVIDIA Jetson AGX Orin上达到26.3 FPS，较小变体达到77.0 FPS。定性结果展示了实际应用中的有效性。

Conclusion: DVEFormer可作为传统分割方法的直接替代品，同时支持灵活的自然语言查询和无缝集成到移动机器人的3D建图流程中，为家庭环境机器人提供更全面的环境理解能力。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [24] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种概率双流框架，用于骨架动作识别，通过统一可靠性建模和多模态集成，在不确定条件下实现专家化学习，特别关注手部细微动作识别。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法大多关注身体大尺度运动，忽视了手部细微动作对于细粒度识别的重要性。同时，现有方法缺乏对不确定性的建模和多模态的有效集成。

Method: 提出了三个关键组件：1）无需校准的预处理管道，直接从原生坐标学习；2）概率Noisy-OR融合，稳定可靠性感知的双流学习；3）从内部到跨模态的集成，将四种骨架模态（关节、骨骼、关节运动、骨骼运动）与RGB表示耦合。

Result: 在多个基准测试（NTU RGB+D 60/120、PKU-MMD、N-UCLA）和新定义的手部中心基准上进行了全面评估，显示出在噪声和异构条件下的一致改进和鲁棒性。

Conclusion: 该框架通过统一可靠性建模和多模态集成，在骨架动作识别中实现了更好的性能，特别是在处理细微手部动作和不确定条件下表现出色。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [25] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，通过可扩展的设计解决了现有4D世界建模方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性限制，主要源于昂贵的多视角4D数据或繁琐的训练预处理，限制了其在多样化单目视频中的应用。

Method: 采用无姿态前馈4D重建、在线单目退化模式模拟等技术，使整个流程能够扩展到多样化的野外单目视频，实现可扩展的4D世界建模。

Result: 在标准重建和生成基准测试中达到了最先进的性能，同时展现出对多种领域的泛化能力和多功能性。

Conclusion: NeoVerse通过创新的可扩展设计，成功解决了4D世界建模的可扩展性问题，为4D重建、视频生成和下游应用提供了强大的多功能解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [26] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个基于行车记录仪的大规模路边垃圾检测数据集，包含11,000多张标注图像，专注于极端小目标检测，旨在支持可扩展的低成本路边垃圾监测系统开发。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖劳动密集型调查和公众报告，空间覆盖有限。现有的视觉检测数据集主要关注街景静态图像、航拍场景或水环境，无法反映行车记录仪视频中垃圾目标极小、稀疏且嵌入杂乱路缘背景的独特特征。

Method: 创建了RoLID-11K数据集，包含超过11,000张标注图像，涵盖英国多样驾驶条件，呈现明显的长尾分布和小目标分布特征。对广泛的现代检测器进行了基准测试，包括精度导向的transformer架构和实时YOLO模型。

Result: CO-DETR及相关transformer模型实现了最佳定位精度，而实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准。

Conclusion: RoLID-11K是首个基于行车记录仪的大规模路边垃圾检测数据集，为开发可扩展、低成本的路边垃圾监测系统提供了重要支持，数据集已开源供研究使用。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [27] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测扰动图像下模型输出的熵变化来识别感知标记，并引入对比感知损失来增强感知能力。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型推理方面取得了进展，但将其扩展到多模态推理需要同时改进感知和推理能力。先前的工作主要通过显式感知奖励来解决这一挑战，但存在难以分离感知标记与推理标记、需要额外LLM、强制分离感知与推理或对所有输出标记应用奖励等问题。

Method: CPPO通过检测扰动输入图像下模型输出的熵变化来识别感知标记，然后在RL目标函数中引入对比感知损失（CPL），该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性。

Result: 实验表明CPPO超越了先前的感知奖励方法，同时避免了使用额外模型，使训练更加高效和可扩展。

Conclusion: CPPO提供了一种有效的方法来改进视觉语言模型的感知能力，通过对比感知损失和熵变化检测机制，解决了多模态强化学习中感知与推理分离的挑战。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [28] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics是一个端到端可微分框架，通过自然语言提示为3D场景推断合理的物理参数，无需真实轨迹或标注视频指导，利用多模态大语言模型估计材料参数，并通过可学习的运动蒸馏损失从预训练视频扩散模型中提取运动先验。


<details>
  <summary>Details</summary>
Motivation: 现有3D对象和材料模拟需要专家知识和耗时的物理参数调整才能达到期望的动态行为，这限制了非专业人士的使用和效率。

Method: 1. 使用多模态大语言模型估计材料参数值，并约束在合理范围内；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差来指导模拟。

Result: 在30多个场景中评估，包括真实世界、人工设计和AI生成的3D对象，涵盖弹性固体、金属、泡沫、沙子以及牛顿和非牛顿流体等多种材料，MotionPhysics能产生视觉逼真的动态模拟，超越现有技术并自动确定物理合理的参数。

Conclusion: MotionPhysics通过自然语言指导实现了逼真的物理模拟，无需专家知识或真实数据标注，为3D场景的物理参数推断提供了有效的端到端解决方案。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [29] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText是一个无需训练、即插即用的框架，通过利用DiT模型的内在机制来改进文本渲染，解决了多行布局、密集排版和中文等长尾脚本的文本渲染问题。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍存在困难，特别是在多行布局、密集排版和中文等长尾脚本上。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美观性并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"两个部分。对于"在哪里写"，通过读取图像到文本注意力的token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化产生高置信度掩码。对于"写什么"，引入频谱调制字形注入(SGMI)，通过频域带通调制注入噪声对齐的字形先验，以增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的大量实验表明，在长文本基准测试、CVTG和自建的CLT-Bench上，文本可读性获得了一致的提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用DiT模型的内在机制有效改进了文本渲染质量，特别是在处理复杂布局和长尾脚本方面表现出色，同时保持了模型的灵活性和美学质量。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [30] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM通过增强SAM在视觉非显著场景下的分割能力，解决了SAM在低对比度前景背景场景中表现不佳的问题，同时保持了原有的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓，需要提升SAM对此类场景的感知能力。

Method: 提出VNS-SAM，通过Mask-Edge Token交互解码器和非显著特征挖掘模块有效利用SAM的低级特征，以少量参数增量增强对非显著特征的理解。同时构建了包含35K+图像的VNS-SEG统一数据集。

Result: VNS-SAM在各种VNS分割任务中表现出优越性能，特别是在零样本设置下，额外参数可在4小时内优化完成，证明了其可行性和实用性。

Conclusion: VNS-SAM有效提升了SAM在视觉非显著场景下的分割能力，同时保持了零样本泛化性，具有广泛的现实应用潜力。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [31] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag是一种基于预测-移动框架的拖拽式图像编辑方法，通过迭代执行运动预测和运动监督，动态调整有效控制点，实现更精确的像素级图像操作。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法存在跟踪丢失、模糊跟踪、源图像与目标图像差异过大、中间点不合理导致编辑性低等问题，需要一种更稳定有效的框架来解决这些挑战。

Method: 提出DynaDrag方法，采用预测-移动框架，迭代执行运动预测（预测控制点应移动的位置）和运动监督（按预测拖动控制点），并动态调整有效控制点以提高性能。

Result: 在人脸和人体数据集上的实验表明，DynaDrag在拖拽式图像编辑方面优于先前的工作。

Conclusion: DynaDrag是首个基于预测-移动框架的拖拽方法，通过迭代运动预测和监督机制，有效解决了现有方法的跟踪问题和编辑性低的问题，在像素级图像操作中表现出优越性。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [32] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种基于点云迭代的先进三维光声成像重建算法，专门针对不规则几何换能器阵列设计，相比传统方法显著提升了重建速度和质量。


<details>
  <summary>Details</summary>
Motivation: 临床应用中需要高质量三维光声成像，但传统方法面临空间限制和高成本问题。不规则几何换能器阵列可以减少换能器数量，但传统迭代重建算法难以处理这种不规则配置，存在计算复杂度高、内存需求大、重建时间长等挑战。

Method: 基于Sliding ball adaptive growth (SlingBAG)方法的点云迭代概念，扩展其兼容性以支持任意阵列几何形状。采用分层优化策略，结合零梯度滤波和迭代过程中逐步增加的时间采样率，快速去除冗余空间点云，加速收敛。

Result: 相比原始SlingBAG算法，SlingBAG Pro在不规则阵列几何下实现了点云三维光声重建速度提升高达2.2倍。通过仿真和活体小鼠实验验证了方法的有效性。

Conclusion: SlingBAG Pro算法能够在保持高重建质量的同时，减少所需换能器数量，显著缩短整体重建时间，为临床三维光声成像应用提供了高效解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [33] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: MS COCOAI数据集包含96000个真实和合成图像样本，用于AI生成图像检测，支持两种任务：真实/生成分类和生成模型识别


<details>
  <summary>Details</summary>
Motivation: 随着多模态生成AI系统（如Stable Diffusion、DALL-E、MidJourney）的普及，合成图像越来越难以与真实照片区分，这导致了误导性内容、虚假信息和操纵媒体的传播。检测生成图像已成为紧迫需求。

Method: 基于MS COCO数据集构建MS COCOAI数据集，包含96000个数据点。使用五种生成器创建合成图像：Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3和MidJourney v6。提出两种任务：1) 图像真实/生成分类；2) 识别生成图像的模型来源。

Result: 发布了MS COCOAI数据集，包含96000个真实和合成数据点，数据集已在Hugging Face平台公开可用。

Conclusion: MS COCOAI数据集为AI生成图像检测提供了重要资源，支持研究社区开发更有效的检测方法，以应对生成AI带来的挑战。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [34] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS是一个全面的多任务基准测试，用于评估统一多模态模型的世界知识应用能力，包含1050个手动标注的问题，涵盖21个主题和6种推理类型，并提出确定性清单评估协议以提高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，只能进行孤立的单任务评估，诊断能力有限。统一多模态模型在跨任务应用世界知识方面仍面临重大挑战，需要更全面的评估框架。

Method: 提出AEGIS基准测试，包含视觉理解、生成、编辑和交错生成等多任务，涵盖1050个手动标注的问题，涉及21个主题和6种推理类型。同时提出确定性清单评估协议，用原子化的"是/否"判断替代模糊的提示评分，提高评估可靠性。

Result: 实验显示大多数统一多模态模型存在严重的世界知识缺陷，性能随推理复杂度增加而显著下降。简单的插件式推理模块可以部分缓解这些弱点，表明这是未来研究的有前景方向。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿领域，需要更全面的评估方法和改进的推理能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [35] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF框架通过归一化流建模预测误差分布，结合不确定性引导优化，解决小目标检测中标注噪声导致的过拟合问题，提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 小目标检测相比正常尺度目标存在性能差距，且小目标对标注噪声高度敏感，优化严格定位目标容易导致噪声过拟合。

Method: 提出TOLF框架：1) 使用归一化流建模复杂的非高斯预测误差分布；2) 不确定性感知的梯度调制机制，抑制高不确定性噪声样本的学习。

Result: 在三个数据集上的实验验证了方法的有效性，特别是在AI-TOD数据集上将DINO基线提升了1.2% AP。

Conclusion: TOLF通过流基误差建模和不确定性引导优化，有效解决了小目标检测中的噪声鲁棒性问题，显著提升了小目标定位性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [36] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索面临的主要挑战是文本查询与视觉内容之间的语义粒度不匹配。现有方法虽然利用预训练知识将视频和语言映射到联合空间，但未能平衡不同模态提供的语义粒度，导致检索不准确。

Method: 提出Granularity-Aware Alignment (GranAlign)训练免费框架，包含两种互补技术：1) 基于粒度的查询重写，生成不同语义粒度的查询；2) 查询感知的标题生成，将查询意图嵌入视频内容。通过将多级查询与查询无关和查询感知的标题配对，有效解决语义不匹配问题。

Result: 在三个主要基准测试(QVHighlights, Charades-STA, ActivityNet-Captions)上均达到新的最先进水平，在具有挑战性的QVHighlights数据集上实现了3.23% mAP@avg的显著提升。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可显著提升检索性能，为跨模态对齐提供了新思路。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [37] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究针对医学视觉语言模型在部署后可能因数据分布偏移导致性能下降的问题，开发了DomainSAT工具箱并提出了结合输入数据偏移检测和输出置信度指标的监控框架，以更可靠地检测病理VLM的性能退化。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医学图像分析和疾病诊断中表现出强大潜力，但部署后当输入数据分布与开发时观察到的分布发生偏移时，模型性能可能下降。检测这种性能退化对于临床可靠性至关重要，但对于没有标注数据的大型预训练VLM来说仍然具有挑战性。

Method: 1. 开发DomainSAT轻量级工具箱，集成代表性偏移检测算法并提供图形界面，用于系统分析输入数据偏移；2. 研究输出级预测行为，引入无需标签的基于置信度的退化指标，直接捕捉模型预测置信度的变化；3. 在大型病理数据集上进行肿瘤分类实验，结合输入数据偏移检测和输出置信度指标来监控性能退化。

Result: 分析表明：输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但并不总是对应实际性能退化；基于置信度的退化指标与性能退化密切相关，可作为输入偏移检测的有效补充；结合两种方法能在数据偏移下更可靠地检测和解释VLM的性能退化。

Conclusion: 该研究为数字病理学中基础模型的可靠性监控提供了一个实用且互补的框架，通过结合输入数据偏移检测和输出置信度指标，能够更有效地监测视觉语言模型在数据分布偏移下的性能退化问题。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [38] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo是一个可信的运动生成框架，通过最小化运动遗忘（MMU）策略在连续空间中实现安全的人体运动生成，避免了离散码本替换方法的缺陷，并在安全性和实用性之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的文本到运动生成方法存在两个关键缺陷：1）替换被良性提示重用的码本条目会导致日常任务性能下降；2）离散标记方法引入量化和平滑度损失，导致伪影和抖动过渡。此外，现有文本到运动数据集包含不安全意图和相应运动，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘（MMU）策略，这是一种两阶段的机器遗忘方法，能够在连续空间中实现安全的人体运动生成，避免码本损失并保持连续运动学特性。同时创建了首个安全文本到运动数据集SafeMoVAE-29K。

Result: 实验表明SafeMo在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍更高的遗忘集FID，相比之前最先进的人体运动遗忘方法LCR表现出更强的遗忘效果，同时在安全提示上的良性性能相当或更好。

Conclusion: SafeMo通过连续空间中的最小化运动遗忘策略有效解决了现有离散码本替换方法的安全性和质量问题，在保持运动自然性的同时实现了安全的人体运动生成，为可信运动生成提供了新框架。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [39] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种模态主导指数（MDI）来量化RGB-红外多模态感知中的优化偏差问题，并开发了模态主导感知跨模态学习框架（MDACL），通过分层跨模态引导和对抗均衡正则化来平衡多模态优化，在三个RGB-IR基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: RGB-红外多模态感知在复杂物理环境中的嵌入式多媒体系统中至关重要。尽管现有的跨模态融合方法在RGB-IR检测方面取得了进展，但由于模态特征不对称导致的优化动态问题仍未得到充分研究。实践中，信息密度和特征质量的差异会引入持续的优化偏差，导致训练过度强调主导模态，阻碍有效的融合。

Method: 1. 提出模态主导指数（MDI），通过联合建模特征熵和梯度贡献来量化模态主导程度；2. 基于MDI开发模态主导感知跨模态学习框架（MDACL），该框架包含：a) 分层跨模态引导（HCG）来增强特征对齐；b) 对抗均衡正则化（AER）来平衡融合过程中的优化动态。

Result: 在三个RGB-IR基准测试上进行了广泛实验，结果表明MDACL能够有效缓解优化偏差，并取得了最先进的性能。

Conclusion: 本文提出的MDI能够有效量化RGB-IR多模态感知中的模态主导问题，MDACL框架通过分层引导和对抗均衡机制成功平衡了跨模态优化动态，为多模态融合中的优化偏差问题提供了有效的解决方案。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [40] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：用于康复训练的实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现实时监测和评估，提供即时反馈指导患者正确执行康复训练。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在康复训练中实时监测和评估患者运动的系统，为患者提供即时反馈和指导，帮助他们正确执行康复训练动作，从而恢复肌肉力量和运动功能。

Method: 1. 提出端到端实时人体姿态估计与运动分析统一流程；2. 针对多人干扰的医疗康复场景提出快速跟踪方法（单帧跟踪<1ms）；3. 改进SmoothNet用于实时姿态估计，减少估计误差并恢复真实运动状态；4. 使用Unity平台进行实时监测评估并显示肌肉应力情况。

Result: 实现了实时3D人体姿态估计与运动分析系统，能够在康复训练中实时监测患者动作，提供即时反馈，跟踪速度快（<1ms/帧），姿态估计误差小，运动状态恢复真实平滑。

Conclusion: RePose系统为康复训练提供了有效的实时监测和评估工具，能够帮助患者正确执行康复动作，加速恢复过程，具有临床应用价值。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [41] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN：基于超图的特权信息学习框架，利用术后文本特权信息提升术前室管膜瘤预后预测，无需推理时文本输入


<details>
  <summary>Details</summary>
Motivation: 室管膜瘤术前预后对治疗规划至关重要，但MRI缺乏术后手术报告中的语义信息。现有多模态方法无法在推理时特权文本不可用时利用这些信息。

Method: 提出HyperPriv-EPN框架，采用Severed Graph策略，使用共享编码器处理教师图（含术后特权信息）和学生图（仅术前数据），通过双流蒸馏让学生图从视觉特征中"幻觉"语义社区结构

Result: 在311名患者的多中心队列验证中，HyperPriv-EPN实现了最先进的诊断准确率和生存分层性能

Conclusion: 该框架有效将专家知识转移到术前场景，解锁历史术后数据的价值，指导新患者诊断而无需推理时文本输入

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [42] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 基于图像的深度学习为马铃薯储存期间的质量监测提供了非侵入式、可扩展的解决方案，通过预训练模型实现了发芽检测、重量损失估计和保质期预测。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存期间的质量监控挑战，包括发芽检测、重量损失估计和保质期预测，为自动化分拣和库存系统提供技术支持。

Method: 在200天的受控温湿度条件下收集图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer等预训练架构，设计了两个专门模型：高精度二分类发芽检测器和先进的多分类预测器用于重量损失估计和保质期预测。

Result: DenseNet在发芽检测中达到98.03%的准确率；保质期预测模型在粗分类（2-5类）时表现最佳，准确率超过89.83%，而细分类（6-8类）由于视觉差异细微和数据有限导致准确率下降。

Conclusion: 基于图像的模型可集成到自动化分拣和库存系统中，实现早期发芽检测和基于储存阶段的动态分类。虽然精确预测保质期区间仍有挑战，但关注更宽的分类可确保稳健性能。未来需开发针对不同马铃薯品种和储存条件的通用模型以增强适应性和可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [43] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS是一个无需训练的幻觉缓解框架，通过选择性移除关键文本标记构建幻觉模型，结合广义对比解码，在六个基准测试和三个LVLM家族中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在生成幻觉内容的严重问题，影响实际应用的可靠性。现有无需训练的方法有两个主要局限：1) 对幻觉来源的假设过于狭窄；2) 在生成后期效果下降，而幻觉最可能在此阶段发生。

Method: 提出CRoPS框架：1) 通过选择性移除关键文本标记构建新颖的幻觉模型，更好地捕捉幻觉效应；2) 引入广义对比解码，整合多个幻觉模型以表示多样化的幻觉来源。

Result: CRoPS将CHAIR分数提升了20%，在六个基准测试和三个大型视觉语言模型家族中均取得一致增益，优于现有的无需训练方法。

Conclusion: CRoPS是一个有效的无需训练幻觉缓解框架，通过更全面地建模幻觉来源和引入广义对比解码，显著提升了大型视觉语言模型的可靠性。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [44] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出了一种新颖的单图像到视频生成框架，通过构建3D高斯场景表示并在单次前向传播中采样合理的物体运动，实现快速、相机引导的视频生成，无需迭代去噪过程。


<details>
  <summary>Details</summary>
Motivation: 现有单图像条件视频生成方法虽然改进了时间一致性和3D一致性，但缺乏鲁棒的用户可控性（如修改相机路径），限制了实际应用。大多数现有相机控制图像到视频模型在准确建模相机运动、保持时间一致性和保持几何完整性方面存在困难。

Method: 提出了一种新颖框架，通过构建3D高斯场景表示并在单次前向传播中采样合理的物体运动，给定单张图像即可实现快速、相机引导的视频生成，无需迭代去噪来将物体运动注入渲染帧。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的广泛实验表明，该方法在视频质量和推理效率方面达到了最先进的水平。

Conclusion: 该方法通过构建3D高斯场景表示和单次前向传播采样物体运动，实现了高效、相机可控的单图像到视频生成，解决了现有方法在时间一致性和几何完整性方面的不足。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [45] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种鲁棒的高斯溅射SLAM框架，用免训练对应到高斯初始化取代了GS-SLAM的残差驱动致密化阶段，通过一次性三角化密集多视角对应来生成结构感知的高斯种子，加速收敛并提高渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM采用残差驱动致密化方法，需要逐步添加高斯元素来填补缺失几何，这种方法效率较低且可能导致早期映射不稳定。RGS-SLAM旨在通过更智能的初始化策略来改善这些问题。

Method: 使用DINOv3描述符获取密集多视角对应，通过置信感知内点分类器进行精炼，然后进行一次性三角化生成结构感知的高斯种子。这种方法在优化前就建立了良好的高斯分布，取代了传统的残差驱动致密化过程。

Result: 在TUM RGB-D和Replica数据集上评估，RGS-SLAM相比最先进的高斯和基于点的SLAM系统，在定位和重建精度上达到竞争性或更优水平。收敛速度提升约20%，在纹理丰富和杂乱场景中渲染保真度更高，同时保持实时映射性能（最高925 FPS）。

Conclusion: RGS-SLAM通过免训练对应到高斯初始化策略，显著改善了高斯溅射SLAM的稳定性和效率，为实时高保真SLAM系统提供了有前景的解决方案，且完全兼容现有GS-SLAM流程。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [46] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个端到端工作流，使用多模态大语言模型自动批改手写STEM考试，保持标准考试流程，仅需教师提供手写参考答案和评分规则


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工批改速度慢且难以扩展，需要自动化解决方案

Method: 多阶段设计：格式/存在性检查防止批改空白答案，独立评分器集成，监督聚合，刚性模板生成可审计的机器可解析报告；将手写参考答案转换为文本摘要作为评分条件

Result: 使用GPT-5.2和Gemini-3 Pro后端，完整流程与教师评分平均绝对差异约8分，偏差低，手动审查触发率约17%（D_max=40）；消融实验显示简单提示和移除参考答案会显著降低准确性并引入系统性过高评分

Conclusion: 结构化提示和参考基础对于准确自动评分至关重要，提出的工作流能可靠批改包含手绘电路图的手写工程测验

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [47] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 论文探索了将自监督学习作为辅助任务来优化广义深度伪造检测的主要任务，通过融合自监督辅助任务的特征表示，在跨数据集评估中实现了更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测面临泛化能力不足的问题，特别是在跨数据集评估时性能下降。作者希望通过自监督学习作为辅助任务，利用其强大的特征表示能力来增强主要检测任务的泛化性能。

Method: 研究了自监督学习与主要检测任务的不同训练方案组合，通过融合自监督辅助任务的特征表示，构建了结合两者优势的独特特征表示。在多个数据集（DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV）上进行实验验证。

Result: 实验结果表明，融合自监督辅助任务特征表示的方法在跨数据集评估中表现出更好的泛化能力，优于当前最先进的深度伪造检测器。

Conclusion: 自监督学习作为辅助任务能够有效优化广义深度伪造检测的主要任务，通过特征融合可以充分利用两者的潜力，获得更好的跨数据集泛化性能。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [48] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 提出LNU-Net和IBU-Net两种新型深度学习架构用于心脏MRI左心室分割，分别基于层归一化和实例-批量归一化，在分割性能上优于原始U-Net和其他先进方法。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对于心脏图像的临床量化和诊断至关重要，需要更准确的分割方法来提高诊断效果。

Method: 提出两种基于U-Net的架构：LNU-Net在每个卷积块中应用层归一化；IBU-Net在第一个卷积块中结合实例和批量归一化，并将结果传递到下一层。使用包含下采样特征提取和上采样精确定位的架构，并采用仿射变换和弹性变形进行图像数据处理。

Result: 使用包含45名患者805张MRI图像的数据集进行评估，实验结果表明提出的方法在Dice系数和平均垂直距离指标上优于其他最先进方法。

Conclusion: LNU-Net和IBU-Net是有效的左心室分割方法，能够提高心脏MRI图像的分割精度，为临床诊断提供更可靠的工具。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [49] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR是一个用于单目视频动态3D场景重建的统一框架，通过自适应Gabor表示和时序连续性约束，解决了现有方法在细节捕捉和运动平滑性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1）使用单高斯基元具有低通滤波特性，限制了高频细节捕捉；2）标准Gabor函数存在能量不稳定问题；3）缺乏时序连续性约束导致插值时出现运动伪影。

Method: 1）自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数，平衡细节捕捉和稳定性；2）时序连续性：使用三次Hermite样条和时序曲率正则化确保平滑运动演化；3）自适应初始化：结合深度估计、点跟踪和前景掩码建立早期训练的稳定点云分布。

Result: 在Tap-Vid DAVIS数据集上取得SOTA性能：PSNR 35.49，SSIM 0.9433，LPIPS 0.0723。在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强大的泛化能力。

Conclusion: AdaGaR通过统一框架解决了动态场景建模中的频率自适应性和时序连续性挑战，在保持高频细节的同时实现了平滑运动重建，为单目视频动态3D重建提供了有效解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [50] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE：基于动态规则注入的神经符号方法，通过从失败轨迹中提取紧凑可解释规则，在推理时注入提示中，提升LLM在特定领域工具使用中的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定领域工具使用时面临挑战，因为API可能具有特殊性、文档不足或针对私有工作流定制。需要有效的适应方法来处理任务特定工具。

Method: 提出RIMRULE神经符号方法：1）从失败轨迹中提取紧凑可解释规则；2）使用最小描述长度目标进行规则整合，偏好通用性和简洁性；3）规则以自然语言和结构化符号形式存储；4）在推理时动态注入规则到提示中。

Result: 在工具使用基准测试中，该方法提高了对已见和未见工具的准确性，无需修改LLM权重。优于基于提示的适应方法，并与微调互补。从一个LLM学习的规则可以重用于改进其他LLM，包括长推理LLM，展示了符号知识在不同架构间的可移植性。

Conclusion: RIMRULE通过动态规则注入有效提升了LLM在特定领域工具使用中的适应能力，提供了一种可解释、可移植的解决方案，能够在不修改模型权重的情况下改善性能。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [51] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: Pat-DEVAL：首个针对专利说明书的多维度评估框架，通过法律约束推理机制评估长文本结构连贯性和法定合规性，显著优于现有评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有专利自动撰写评估方法无法有效评估长文本的结构连贯性和法定合规性（如可实施性和书面描述要求），需要专门针对专利说明书的评估框架。

Method: 提出Pat-DEVAL框架，采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）机制，这是一种法律约束推理方法，强制执行顺序性的专利法特定分析。

Result: 在Pap2Pat-EvalGold数据集上，经专利专家验证，Pat-DEVAL达到0.69的皮尔逊相关系数，显著优于基线指标和现有LLM评估器；在法律专业合规性方面相关性达0.73。

Conclusion: 通过明确注入法定约束，Pat-DEVAL能够捕捉细微的法律有效性，为自动专利撰写系统的实际部署提供了坚实的方法论基础，建立了技术合理性和法律合规性的新标准。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [52] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 该论文通过系统分析IEMOCAP数据集，填补了对话情感识别中的两个关键空白：1）识别哪些架构选择真正重要；2）通过语言分析连接识别与生成。研究发现上下文至关重要，简单架构就能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前对话情感识别虽然准确率高，但存在两个关键空白：缺乏对哪些架构选择真正重要的理解，以及缺乏连接识别与生成的语言分析。作者旨在通过系统分析填补这些空白。

Method: 对IEMOCAP数据集进行系统分析：1）使用10次种子评估进行严格的消融研究；2）分析5,286个话语标记出现情况，研究情感与标记位置的关系；3）使用简单架构和严格因果上下文。

Result: 识别方面：1）对话上下文至关重要，90%的增益来自最近10-30轮对话；2）分层句子表示在话语层面有帮助，但提供上下文后此优势消失；3）外部情感词典无增益。达到82.69%（4类）和67.07%（6类）加权F1。语言分析方面：发现情感与标记位置显著相关，悲伤话语的左边缘标记使用减少（21.9% vs 其他28-32%），这与悲伤最受益于上下文（+22%）的发现一致。

Conclusion: 对话上下文是情感识别的关键因素，简单架构配合因果上下文就能超越复杂方法。悲伤话语缺乏显式语用信号，需要对话历史进行消歧，这通过语言分析得到验证。研究为对话情感识别提供了架构选择和语言基础的深入理解。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [53] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 该论文提出了一个专门为时序知识图谱推理设计的蒸馏框架，利用大语言模型作为教师模型，将结构和时序推理能力转移到轻量级学生模型中，在保持推理准确性的同时提高计算效率和部署可行性。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理模型通常依赖大量参数和密集计算，导致硬件成本高、能耗大，难以部署在资源受限、低功耗和需要实时推理的分布式平台上。此外，现有的模型压缩和蒸馏技术主要针对静态知识图谱设计，无法充分捕捉时序知识图谱中的时间依赖关系，导致推理性能下降。

Method: 提出专门为时序知识图谱推理设计的蒸馏框架，利用大语言模型作为教师模型来指导蒸馏过程，有效转移结构和时序推理能力到轻量级学生模型。通过整合大规模公共知识和任务特定的时序信息，增强学生模型对时序动态的建模能力，同时保持紧凑高效的架构。

Result: 在多个公开基准数据集上的广泛实验表明，该方法始终优于强基线模型，在推理准确性、计算效率和实际部署可行性之间实现了良好的平衡。

Conclusion: 该研究提出的蒸馏框架成功解决了时序知识图谱推理模型在资源受限环境下的部署问题，通过利用大语言模型的知识转移能力，实现了轻量级模型的高效时序推理，为未来人工智能应用提供了关键技术基础。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [54] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 该研究提出了一种将循证医学原则整合到图检索增强生成中的方法，通过PICO框架改进知识图谱构建和检索，并设计贝叶斯重排序算法考虑证据等级，在运动康复领域验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的检索增强生成方法主要关注性能改进，但忽视了循证医学原则，存在两个关键缺陷：查询与检索证据之间缺乏PICO对齐，以及在重排序过程中未考虑证据等级层次。

Method: 提出通用策略将循证医学原则适配到基于图的RAG中：1) 将PICO框架整合到知识图谱构建和检索中；2) 提出贝叶斯启发的重排序算法，根据证据等级校准排序分数而不引入预定义权重；3) 在运动康复领域验证框架，构建包含357,844个节点和371,226条边的知识图谱。

Result: 系统在1,637个QA对基准测试中表现优异：nugget覆盖度0.830，答案忠实度0.819，语义相似度0.882，PICOT匹配准确率0.788。五位专家临床医生在5点李克特量表评估中，在事实准确性、忠实度、相关性、安全性和PICO对齐方面给出4.66-4.84的高分。

Conclusion: 提出的循证医学适配策略显著提高了检索和答案质量，且可转移到其他临床领域。发布的资源（知识图谱和可重用基准）有助于解决运动康复领域RAG数据集稀缺的问题。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [55] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench是一个轻量级开源基准测试，用于指导日英翻译系统的迭代开发，专注于评估"哪个翻译更好"而非"翻译是否可接受"，采用基于LLM的成对比较和Bradley-Terry模型进行稳定评分。


<details>
  <summary>Details</summary>
Motivation: 日英翻译中，礼貌、隐含意义、省略和语域等细微选择对自然度影响很大，现有评估往往关注翻译是否可接受，而实际开发中更需要判断"哪个好翻译更好"，需要专门针对这种细微差异的评估基准。

Method: 使用无参考的成对LLM比较方法，将候选模型与固定的版本化锚定集进行对比，通过Bradley-Terry模型聚合结果，生成胜率和基于逻辑变换的0-10分"LT"评分，确保评分结构稳定性。

Result: 开发了JP-TL-Bench基准测试框架，提供可靠的评估协议，使LLM判断既可靠又经济，通过冻结锚定集确保相同基础集、评判者和聚合代码下的评分稳定性。

Conclusion: JP-TL-Bench为日英翻译系统开发提供了专门针对细微质量差异的轻量级评估工具，通过稳定的评分机制支持翻译模型的迭代改进。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [56] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该研究系统评估了大语言模型在多语言反事实生成方面的表现，发现翻译生成的反事实有效性更高但修改更多，多语言反事实数据增强对低资源语言效果更好，但生成质量限制了模型性能提升。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在生成英语反事实方面表现出色且具备多语言能力，但其在多语言反事实生成方面的有效性尚不明确，需要系统研究来评估其表现和局限性。

Method: 对6种语言进行自动评估：1）直接生成目标语言反事实；2）通过英语翻译生成反事实；3）分析编辑模式；4）识别错误类型；5）评估多语言反事实数据增强效果。

Result: 1）翻译生成的反事实有效性更高但需要更多修改，仍不及原始英语反事实质量；2）高资源欧洲语言编辑模式相似；3）识别出四种主要错误类型；4）多语言反事实数据增强对低资源语言效果更好，但生成质量限制了性能提升。

Conclusion: 大语言模型在多语言反事实生成方面存在局限性，翻译方法虽能提高有效性但质量仍不足，多语言反事实数据增强有潜力但对低资源语言效果有限，需要改进生成质量以提升模型性能和鲁棒性。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [57] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval是一个评估LLM智能体函数调用能力的基准，考虑了真实API系统的复杂性，包括API规范和API执行两个维度的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设理想的API系统，忽略了真实世界中的噪声API输出等实际因素，需要更贴近现实的评估基准来测试LLM智能体的函数调用能力。

Method: 构建WildAGTEval基准，包含60个不同的复杂性场景，可组合成约32K测试配置，涵盖API规范（详细文档和使用约束）和API执行（运行时挑战）两个维度。

Result: 评估多个先进LLM发现，大多数场景都具有挑战性，其中无关信息复杂性带来的难度最大，使强LLM性能下降27.3%。定性分析显示LLM有时会扭曲用户意图以声称完成任务，严重影响用户满意度。

Conclusion: WildAGTEval提供了一个更贴近现实的评估框架，揭示了LLM智能体在真实API复杂性下面临的挑战，特别是无关信息处理和意图理解方面的问题，对提升LLM智能体实用性有重要意义。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [58] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 量化对大型语言模型自解释能力的影响研究：量化通常导致自解释质量和忠实度适度下降（最高4.4%和2.38%），用户研究显示可理解性和可信度下降最高8.5%，但整体不影响量化作为模型压缩技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于加速大型语言模型推理和简化部署，但其对自解释能力的影响尚未被探索。自解释是LLMs为证明自身输出而生成的解释，需要模型推理自身的决策过程，这种能力可能对量化特别敏感。随着自解释在高风险应用中越来越依赖透明度，理解量化是否以及多大程度上降低自解释质量和忠实度至关重要。

Method: 研究两种类型的自解释：自然语言解释和反事实示例，使用三种常见量化技术在特定比特宽度下对LLMs进行量化。通过用户研究评估量化对自解释的影响，比较不同模型大小对量化的敏感性。

Result: 量化通常导致自解释质量（最高下降4.4%）和忠实度（最高下降2.38%）适度下降。用户研究显示量化降低了自解释的连贯性和可信度（最高下降8.5%）。相比小模型，大模型在自解释质量方面对量化的恢复能力有限，但在保持忠实度方面表现更好。没有一种量化技术在任务准确性、自解释质量和忠实度方面始终表现出色。

Conclusion: 量化对自解释的影响因上下文而异，建议针对特定用例验证自解释质量，特别是对更敏感的自然语言解释。然而，自解释质量和忠实度的相对较小恶化并不削弱量化作为模型压缩技术的有效性。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [59] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: DepFlow是一个三阶段框架，通过解耦语音中的抑郁声学特征与语义内容，生成伪装抑郁数据来提升抑郁检测模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁数据集（如DAIC-WOZ）中语言情感与诊断标签强耦合，导致模型学习语义捷径，在真实场景（如伪装抑郁）中鲁棒性差。需要解决语义偏见问题。

Method: 1. 抑郁声学编码器：通过对抗训练学习说话人和内容不变的抑郁嵌入；2. 流匹配TTS模型：通过FiLM调制注入抑郁嵌入，控制抑郁程度同时保持内容和说话人身份；3. 原型严重程度映射：提供平滑可解释的抑郁连续体操控。基于此构建CDoA数据集。

Result: 抑郁声学编码器ROC-AUC达0.693，有效解耦同时保持抑郁区分性。CDoA数据集在三种抑郁检测架构上分别提升macro-F1 9%、12%和5%，优于传统增强策略。

Conclusion: DepFlow不仅提升了抑郁检测模型的鲁棒性，还提供了可控合成平台，可用于对话系统和模拟评估，弥补临床数据在伦理和覆盖范围上的限制。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [60] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 该研究针对大语言模型幻觉问题，提出了一种基于多事实生成任务的鲁棒不确定性量化方法，通过构建包含虚假名称的陷阱问题集来评估模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业和日常生活中的应用日益广泛，但幻觉问题严重影响了AI生成内容的可靠性和可信度。现有不确定性量化方法在常规问答场景中有效，但在面对非常规或对抗性提问策略时表现不足，这在实际应用中存在重大风险。

Method: 研究构建了包含虚假名称的陷阱问题集，并创新性地提出了一种鲁棒的不确定性量化方法(RU)。该方法在多事实生成任务中评估模型的不确定性，通过精心设计的实验验证其有效性。

Result: 实验结果显示，构建的陷阱问题集表现优异。在四个不同模型上与基线方法相比，提出的方法在ROCAUC值上平均提升了0.1-0.2，显著优于现有最佳基线方法。

Conclusion: 该研究为解决大语言模型幻觉问题提供了新的视角和方法，提出的鲁棒不确定性量化方法在检测模型不可靠响应方面表现出色，为提升LLM在实际应用中的可靠性提供了有效工具。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [61] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) 将JEPA训练目标引入BERT风格模型，解决[CLS]嵌入空间坍缩问题，创建语言无关的嵌入空间，在多语言基准测试中提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决BERT模型中[CLS]嵌入空间坍缩的问题，并创建语言无关的嵌入空间，以提升多语言任务性能。

Method: 在BERT风格模型中添加JEPA（联合嵌入预测架构）训练目标，通过自监督学习对抗[CLS]嵌入空间坍缩，构建语言无关的嵌入空间。

Result: BERT-JEPA在多语言基准测试中表现出性能提升，验证了JEPA训练目标对改善嵌入空间质量的有效性。

Conclusion: JEPA训练目标能够有效解决BERT模型中[CLS]嵌入空间坍缩问题，创建语言无关的嵌入空间，从而提升多语言任务的性能。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [62] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R是一个无需检索的图像地理定位框架，通过基于规则的分层推理和强化学习，直接从GPS坐标生成结构化推理路径，提高定位准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在图像地理定位中通常依赖合成推理标注或外部图像检索，这限制了可解释性和泛化能力。需要开发一种无需检索、能生成结构化推理路径的方法。

Method: 提出Geo-R框架：1）Chain of Region - 基于规则的分层推理范式，将GPS坐标映射到地理实体（国家、省份、城市）；2）轻量级强化学习策略，使用基于Haversine距离的坐标对齐奖励，通过空间有意义的反馈优化预测。

Result: 在多个基准测试中验证了Geo-R的有效性，实现了更高的定位准确性、更强的泛化能力和更透明的推理过程，为可扩展和可解释的图像地理定位建立了新的无需检索范式。

Conclusion: Geo-R通过结合结构化地理推理和直接空间监督，在无需外部检索的情况下实现了更好的图像地理定位性能，模型和代码将公开以促进进一步研究。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [63] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 提出了judgeWEL数据集，这是一个用于卢森堡语命名实体识别的数据集，通过新颖的LLM管道自动标注和验证，比现有数据集大5倍且类别覆盖更均衡。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言构建数据集是自然语言处理的主要瓶颈之一，资源稀缺和语言特殊性使得大规模标注成本高昂且可能不一致。

Method: 利用维基百科和维基数据作为弱监督的结构化来源，通过维基百科文章的内部链接推断实体类型，然后使用多个LLM识别和保留高质量标注句子以降低噪声。

Result: 生成的语料库比当前可用的卢森堡语NER数据集大约5倍，提供了更广泛和更平衡的实体类别覆盖。

Conclusion: judgeWEL数据集为多语言和低资源NER研究提供了重要的新资源，展示了利用LLM和结构化知识源构建低资源语言数据集的可行性。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [64] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出了一种新的超关系时序知识广义超图（HTKGHs）结构，用于解决传统时序知识图在表示复杂多实体时序事实时的局限性，并基于POLECAT数据库构建了htkgh-polecat数据集，对主流大语言模型在关系预测任务上的表现进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 传统超关系时序知识图（HTKGs）虽然能表示简单时序关系，但缺乏表达能力来高效表示复杂事实，特别是无法支持超过两个主要实体的时序事实，而这在现实世界的地缘政治事件中很常见。

Method: 1. 提出HTKGHs作为HTKGs的泛化形式，支持两种常见于地缘政治事件的复杂事实类型；2. 基于POLECAT全球事件数据库构建htkgh-polecat数据集；3. 对主流大语言模型在关系预测任务上进行基准测试和分析。

Result: 1. 形式化定义了HTKGHs结构，保持了向后兼容性；2. 创建了htkgh-polecat数据集；3. 通过基准测试提供了大语言模型在复杂预测场景中的适应性和能力洞察。

Conclusion: HTKGHs为解决时序知识图在表示复杂多实体事实时的局限性提供了有效方案，为基于大语言模型的地缘政治预测研究提供了新的数据基础和分析框架。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [65] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 比较三种轻量级Transformer模型（DistilBERT、MiniLM、ALBERT）在三个文本分类任务上的性能表现，分析准确性与效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 企业NLP应用对高效、轻量级模型处理多领域文本自动化任务的需求日益增长，需要了解不同轻量级模型在准确性和效率方面的表现差异。

Method: 使用IMDB、AG News和Measuring Hate Speech三个数据集，在客户情感分类、新闻主题分类、毒性和仇恨言论检测三个领域，比较DistilBERT、MiniLM和ALBERT三种模型。评估指标包括准确性（准确率、精确率、召回率、F1分数）和效率（模型大小、推理时间、吞吐量、内存使用）。

Result: 没有单一模型在所有性能维度上占优：ALBERT在多个领域获得最高任务特定准确率；MiniLM在推理速度和吞吐量方面表现最佳；DistilBERT在任务间保持最一致的准确性，同时保持竞争力的效率。

Conclusion: 研究揭示了准确性与效率之间的权衡，建议：对延迟敏感的企业应用选择MiniLM，需要平衡性能的选择DistilBERT，资源受限环境选择ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [66] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 该论文对比了语言意义的两种理论框架：社会建构主义（语言游戏）和数学导向的语义场理论，分析LLM如何体现这些概念，并认为两种视角是互补的


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型作为实证环境，检验长期存在的语言意义理论，探讨语言理解中的数学结构与社会建构之间的关系

Method: 形式化词汇场和语言场作为连续语义空间中的交互结构，分析transformer架构的核心特性（分布式表示、注意力机制、嵌入空间几何规律）与这些概念的关系

Result: LLM在捕捉语义规律方面的成功支持语言具有底层数学结构的观点，而其在语用推理和上下文敏感性方面的局限性则与社会建构的重要性一致

Conclusion: 数学结构和语言游戏可以理解为互补而非竞争视角，这一框架澄清了纯统计语言模型的适用范围和局限性，并为理论指导的AI架构提供了新方向

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [67] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮来大幅降低护栏模型的训练和推理成本，同时保持高攻击检测性能


<details>
  <summary>Details</summary>
Motivation: 处理完整多轮对话历史需要大量计算成本，限制了护栏模型在实际部署中的可扩展性，需要一种更高效的训练方法

Method: 提出Multi-turn to Single-turn (M2S)压缩训练范式，使用三种压缩模板（hyphenize、numberize、pythonize）将多轮对话压缩为单轮，然后在压缩后的对话上微调护栏模型

Result: 训练成本从O(n²)降至O(n)，训练数据量减少93倍；在SafeDialBench基准测试中，最佳配置(Qwen3Guard+hyphenize)达到93.8%攻击检测召回率，推理token减少94.6%，比基线提升38.9个百分点

Conclusion: M2S压缩可作为护栏模型部署的有效效率技术，能够在显著降低训练和推理成本的同时，保持对多轮对话的安全筛查能力

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [68] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 该论文提出了一种针对职业教育培训领域历史数字化文档的鲁棒命名实体识别方法，通过噪声感知训练、迁移学习和多阶段微调来应对OCR噪声问题。


<details>
  <summary>Details</summary>
Motivation: 职业教育培训领域的历史数字化文档存在OCR噪声问题，影响命名实体识别效果，需要开发鲁棒的NER方法来处理这种噪声环境。

Method: 采用噪声感知训练，通过合成注入OCR错误，结合迁移学习和多阶段微调。系统比较了三种互补策略：在噪声数据、干净数据和人工数据上训练。

Result: 实验结果表明，领域特定和噪声感知的微调显著提高了在噪声条件下的鲁棒性和准确性，能够识别职业教育文档中的多种实体类型。

Conclusion: 该方法首次在职业教育培训文档中实现多类型实体识别，虽然应用于德语文档但可迁移到任意语言，提供了公开可用的代码用于可复现的噪声感知NER。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [69] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 该研究分析了复杂句子结构对基于规则的原子句子提取性能的影响，发现相对从句、同位语、并列谓语、状语从句和被动结构是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 现有原子句子提取方法缺乏可解释性，无法揭示哪些具体语言结构导致提取失败，需要系统分析复杂句子结构对提取性能的影响。

Method: 使用WikiSplit数据集，在spaCy中实现基于依存关系的提取规则，生成100个黄金标准原子句子集，使用ROUGE和BERTScore评估性能。

Result: 系统获得ROUGE-1 F1=0.6714，ROUGE-2 F1=0.478，ROUGE-L F1=0.650，BERTScore F1=0.5898，表明具有中等至高水平的词汇、结构和语义对齐。相对从句、同位语、并列谓语、状语从句和被动结构是最具挑战性的结构。

Conclusion: 基于规则的原子句子提取在准确性上表现合理，但对句法复杂性敏感，需要进一步改进以处理复杂的语言结构。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [70] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: ECR框架通过语义锚点保持紧凑模型嵌入空间的结构一致性，无需依赖教师模型输出，在低容量模型中保持语义几何结构


<details>
  <summary>Details</summary>
Motivation: 紧凑模型在容量有限或多语言场景下容易丢失嵌入空间的结构，导致语义漂移和下游任务性能下降。现有压缩方法只关注表层输出对齐，未能保持底层流形结构。

Method: 提出嵌入一致性调节(ECR)框架：1)从教师模型嵌入中提取语义锚点（离线计算一次）；2)让紧凑模型学习在这些锚点周围保持一致的几何结构，无需匹配logits或内部特征；3)推理时仅添加小型投影步骤，不改变解码架构或运行时行为。

Result: 在10万条多语言语料实验中，ECR稳定训练并跨任务和语言保持语义结构，产生更紧凑且任务对齐的表示空间，使低容量模型学习到比传统基线更清晰的流形结构。ECR无需教师输出，与蒸馏兼容但独立。

Conclusion: ECR帮助紧凑模型更好地遵循任务要求，使其在严格效率或隐私限制下更容易部署，通过保持嵌入空间几何结构一致性来解决语义漂移问题。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [71] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出HLoRA框架，基于CTC架构实现轻量级、语言无关的多语言ASR系统，通过分层LoRA-MoE设计实现单次解码，无需先验语言信息


<details>
  <summary>Details</summary>
Motivation: 大规模多语言ASR模型（如Whisper）计算和延迟成本高，难以部署在资源受限的边缘设备上，需要更高效的解决方案

Method: 提出语言无关的分层LoRA-MoE框架，集成到mHuBERT-CTC模型中，包含多语言共享LoRA学习语言不变声学表示和语言特定LoRA专家建模语言依赖特性，通过LID后验驱动的LoRA路由实现端到端解码

Result: 在MSR-86K和MLC-SLM 2025挑战数据集上，HLoRA仅使用单次解码就达到与最先进两阶段推理方法相当的性能，显著提高低资源多语言ASR的解码效率

Conclusion: HLoRA框架为资源受限环境提供了高效的多语言ASR解决方案，通过分层LoRA-MoE设计和语言无关的路由机制，实现了高性能的单次解码

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [72] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth是一个基于信息论原理自动生成和评估推理基准的框架，使用KL散度和熵量化基准新颖性和多样性，通过遗传算法和迭代代码反馈从种子数据集合成Python编程问题。


<details>
  <summary>Details</summary>
Motivation: 传统基准创建依赖人工，成本高且耗时；现有基准常污染LLM训练数据，需要新颖多样的基准来准确评估LLM的真实能力。

Method: 提出基于KL散度和熵的指标量化基准新颖性和多样性；开发端到端管道，使用遗传算法和迭代代码反馈从种子数据集合成稳健的Python编程问题。

Result: 方法能97%的时间生成新问题的准确测试用例和解决方案；合成的基准相比种子数据集始终表现出更高的新颖性和多样性；算法能控制生成问题的新颖性/多样性和难度。

Conclusion: InfoSynth为LLM提供了可扩展、自验证的高质量、新颖多样基准构建管道。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [73] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: CSSBench是一个专门针对中文特定对抗模式的安全基准测试，用于评估轻量级大语言模型在中文环境下的安全性，填补了现有基准测试主要关注英文的不足。


<details>
  <summary>Details</summary>
Motivation: 现有安全护栏主要针对英文设计，而真实世界的中文恶意查询通常通过同音字、拼音、符号分割等中文特定模式隐藏意图，这些对抗模式在现有基准测试中未被充分捕捉，特别是对于轻量级模型可能更加脆弱。

Method: 引入中文特定安全基准测试(CSSBench)，强调中文对抗模式，覆盖六个真实中文场景常见领域：非法活动与合规、隐私泄露、健康医疗错误信息、欺诈与仇恨、成人内容、公共与政治安全，并将查询组织为多种任务类型。

Result: 评估结果显示，中文特定对抗模式对轻量级大语言模型构成关键挑战。通过测量过度拒绝行为来评估安全导致的性能下降。

Conclusion: CSSBench为中文环境下的大语言模型安全性提供了全面评估，有助于实际部署中的鲁棒性提升，填补了现有基准测试在中文特定对抗模式方面的空白。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [74] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 提出一个模型无关的框架，通过重复采样和多数投票机制，为固定输入任务提供降低LLM幻觉概率的理论保证


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在确定性自动化工作流中经常产生上下文幻觉，这些错误在输入固定且正确性明确的情况下尤为严重，需要一种简单且模型无关的方法来减少幻觉

Method: 1. 定义特定任务：固定输入和确定性正确性标准；2. 在独立上下文窗口中重复相同提示，通过指数级降低所有输出都错误的概率；3. 使用LLM作为评判器识别正确答案；4. 通过多数投票机制增强不完美评判器，获得指数级下降的集成错误率

Result: 在受控提取任务上的实验验证：管道失败概率随重复次数指数下降，幻觉选择概率随评判器数量指数下降，与理论预测完全匹配

Conclusion: 该方法提供了一种轻量级、模块化且理论可靠的方法，无需修改模型权重、解码策略或提示工程，即可在固定输入LLM工作流中将幻觉概率降至任意低水平

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [75] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM是一种新型架构，将静态的产品键记忆转换为动态的"快速权重"情景记忆，解决了语言模型中存储容量与计算效率的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型中的序列建模层面临存储容量与计算效率的权衡：Softmax注意力提供无限存储但计算成本高，线性变体效率高但存储有限。需要一种既能高效计算又具有足够存储容量的解决方案。

Method: 提出快速权重产品键记忆(FwPKM)，将稀疏的产品键记忆从静态模块转变为动态的情景记忆。通过局部块级梯度下降在训练和推理时动态更新参数，使模型能够快速记忆和检索输入序列中的新键值对。

Result: FwPKM作为有效的情景记忆补充标准模块的语义记忆，在长上下文数据集上显著降低困惑度。在"大海捞针"评估中，尽管仅在4K标记序列上训练，却能泛化到128K标记的上下文。

Conclusion: FwPKM成功解决了序列建模中存储容量与计算效率的权衡问题，通过动态记忆机制实现了对长上下文的有效处理，为语言模型的长序列处理提供了新思路。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [76] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出Sigmoid Head模块解决语言模型概率不可靠的质量评估问题，通过sigmoid激活函数和多正确选项处理提升质量估计效果


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率分布不是可靠的质量评估指标，因为自然语言存在歧义性。当多个输出选项都有效时，模型的概率分布会分散到这些选项上，从而误导性地显示低输出质量。这主要由两个原因造成：(1) LM的最终输出激活函数softmax不允许多个正确选项同时获得高概率；(2) LM的训练数据是单一、独热编码的参考文本，暗示每个输出步骤只有一个正确选项。

Method: 在预训练语言模型上训练一个质量估计模块（Sigmoid Head）。该模块是一个额外的解嵌入头，使用sigmoid激活函数解决第一个限制。为应对第二个限制，在训练Sigmoid Head的负采样过程中，使用启发式方法避免选择可能正确的替代标记。该模块在训练和推理过程中计算效率高。

Result: Sigmoid Head产生的概率相比原始softmax头是显著更好的质量信号。由于Sigmoid Head不依赖人工标注的质量数据，相比监督式质量估计，在领域外设置中更加鲁棒。

Conclusion: 提出的Sigmoid Head模块有效解决了语言模型概率分布作为质量评估指标的局限性，通过sigmoid激活函数和智能负采样策略，提供了更可靠的质量信号，且在计算效率和领域适应性方面具有优势。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [77] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在文本跨度识别任务上的表现，特别关注情感分析、冒犯性语言识别和声明验证三个任务，探索了指令调优、上下文学习和思维链等策略。


<details>
  <summary>Details</summary>
Motivation: 目前大多数跨度识别方法依赖于BERT等较小的预训练语言模型，而大型语言模型在该任务上的应用研究不足，特别是在主观性跨度识别任务（如基于方面的情感分析）方面尚未充分探索。

Method: 使用多种大型语言模型，在情感分析、冒犯性语言识别和声明验证三个任务上评估文本跨度识别性能，探索了指令调优、上下文学习和思维链等策略。

Result: 研究结果表明，文本内部的潜在关系有助于大型语言模型识别精确的文本跨度。

Conclusion: 本文填补了大型语言模型在主观性文本跨度识别任务上的研究空白，证明了文本内部关系对跨度识别的重要性，为下游任务的可解释性提供了新的见解。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [78] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本研究首次在加拿大跨省评估了将BCCRTron和GatorTron两种Transformer模型应用于癌症监测的效果，通过模型集成显著减少了漏诊癌症病例，并建立了隐私保护的工作流程。


<details>
  <summary>Details</summary>
Motivation: 基于人群的癌症登记依赖病理报告作为主要诊断来源，但人工提取资源密集且导致数据延迟。虽然基于Transformer的NLP系统改进了登记工作流程，但其在不同司法管辖区之间的泛化能力尚不清楚。

Method: 研究评估了BCCRTron（BC癌症登记处开发的领域适应Transformer模型）和GatorTron（生物医学Transformer模型）在加拿大癌症监测中的跨省适应。使用纽芬兰与拉布拉多癌症登记处的约104,000份（Tier 1）和22,000份（Tier 2）去标识化病理报告进行训练。两种模型通过互补的概要式和诊断聚焦的报告部分输入管道进行微调。

Result: 在NLCR测试集上，适应后的模型保持了高性能。通过保守的OR集成组合两种模型，Tier 1召回率达到0.99，漏诊癌症减少至24例（单独模型分别为48和54例）。Tier 2召回率达到0.99，漏诊可报告癌症减少至33例（单独模型分别为54和46例）。

Conclusion: 研究表明，在一个司法管辖区预训练的Transformer模型可以通过适度微调本地化到另一个管辖区。结合互补文本表示的集成模型能显著减少漏诊癌症并提高错误覆盖率。研究实现了隐私保护工作流程，仅共享模型权重，支持可互操作的NLP基础设施和未来的泛加拿大癌症病理和登记工作流程基础模型。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [79] [Understanding Security Risks of AI Agents' Dependency Updates](https://arxiv.org/abs/2601.00205)
*Tanmay Singla,Berk Çakar,Paschal C. Amusuo,James C. Davis*

Main category: cs.SE

TL;DR: AI编程助手在依赖更新中比人类更频繁选择已知漏洞版本，且修复成本更高，导致整体漏洞增加而非减少


<details>
  <summary>Details</summary>
Motivation: 研究AI编码助手在软件依赖更新中的安全风险，因为依赖是现代软件供应链的关键控制点，而AI助手通过PR修改软件时可能引入独特的安全风险

Method: 分析7个生态系统中117,062个依赖变更，比较AI助手和人类作者在PR中的依赖决策，评估漏洞版本选择频率、修复难度和整体漏洞变化

Result: AI助手选择已知漏洞版本的比例更高（2.46% vs 1.64%），修复更困难（36.8%需主版本升级 vs 12.9%），整体导致漏洞净增加98个，而人类减少1,316个

Conclusion: 需要在PR时进行漏洞筛查和注册表感知的防护措施，使AI驱动的依赖更新更安全

Abstract: Package dependencies are a critical control point in modern software supply chains. Dependency changes can substantially alter a project's security posture. As AI coding agents increasingly modify software via pull requests, it is unclear whether their dependency decisions introduce distinct security risks.
  We study 117,062 dependency changes from agent- and human-authored pull requests across seven ecosystems. Agents select known-vulnerable versions more often than humans (2.46% vs. 1.64%), and their vulnerable selections are more disruptive to remediate, with 36.8% requiring major-version upgrades compared to 12.9% for humans, despite patched alternatives existing in most cases. At the aggregate level, agent-driven dependency work yields a net vulnerability increase of 98, whereas human-authored work yields a net reduction of 1,316. These findings motivate pull-request-time vulnerability screening and registry-aware guardrails to make agent-driven dependency updates safer.

</details>


### [80] [Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities](https://arxiv.org/abs/2601.00235)
*Victor Wen,Zedong Peng*

Main category: cs.SE

TL;DR: 开发了一个先进的Log4j扫描工具，通过评估软件的实际可利用性来减少误报，集成到GitHub Actions中实现自动化持续扫描，在140次扫描中达到91.4%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前Log4Shell漏洞检测工具主要关注识别Log4j安装版本，导致大量误报，因为它们不检查软件是否真正易受攻击。需要开发能评估真实世界可利用性的工具来减少误报。

Method: 首先识别漏洞，然后提供针对性的缓解建议和即时反馈给用户。通过集成GitHub Actions实现自动化持续扫描能力，确保代码变更时及时识别漏洞。

Result: 评估了28个开源软件项目的不同版本，从140次扫描样本中达到91.4%的准确率。GitHub Action实现已在GitHub市场上提供。

Conclusion: 该工具为检测和缓解开源项目中的漏洞提供了可靠方法，通过集成到现有开发工作流中实现实时监控和快速响应潜在威胁。

Abstract: Automated detection of software vulnerabilities remains a critical challenge in software security. Log4j is an industrial-grade Java logging framework listed as one of the top 100 critical open source projects. On Dec. 10, 2021 a severe vulnerability Log4Shell was disclosed before being fully patched with Log4j2 version 2.17.0 on Dec. 18, 2021. However, to this day about 4.1 million, or 33 percent of all Log4j downloads in the last 7 days contain vulnerable packages. Many Log4Shell scanners have since been created to detect if a user's installed Log4j version is vulnerable. Current detection tools primarily focus on identifying the version of Log4j installed, leading to numerous false positives, as they do not check if the software scanned is really vulnerable to malicious actors. This research aims to develop an advanced Log4j scanning tool that can evaluate the real-world exploitability of the software, thereby reducing false positives. Our approach first identifies vulnerabilities and then provides targeted recommendations for mitigating these detected vulnerabilities, along with instant feedback to users. By leveraging GitHub Actions, our tool offers automated and continuous scanning capabilities, ensuring timely identification of vulnerabilities as code changes occur. This integration into existing development workflows enables real-time monitoring and quicker responses to potential threats. We demonstrate the effectiveness of our approach by evaluating 28 open-source software projects across different releases, achieving an accuracy rate of 91.4% from a sample of 140 scans. Our GitHub action implementation is available at the GitHub marketplace and can be accessed by anyone interested in improving their software security and for future studies. This tool provides a dependable way to detect and mitigate vulnerabilities in open-source projects.

</details>


### [81] [An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems](https://arxiv.org/abs/2601.00254)
*Md Hasan Saju,Maher Muhtadi,Akramul Azim*

Main category: cs.SE

TL;DR: 该研究比较了三种基于大语言模型的软件漏洞检测方法：检索增强生成、监督微调和双智能体框架，发现检索增强生成方法在准确率和F1分数上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的快速发展为自动化软件漏洞检测提供了新机遇，这对于保护现代代码库安全至关重要。本研究旨在比较不同LLM技术在漏洞检测中的有效性。

Method: 研究评估了三种方法：1）检索增强生成，整合互联网和MITRE CWE数据库的外部领域知识；2）监督微调，使用参数高效的QLoRA适配器；3）双智能体LLM框架，其中第二个智能体审核和优化第一个智能体的输出。使用从Big-Vul和GitHub真实代码库中整理的五个关键CWE类别数据集进行评估。

Result: 检索增强生成方法取得了最高的整体准确率（0.86）和F1分数（0.85），监督微调方法也表现出色，双智能体系统在提高推理透明度和错误缓解方面显示出潜力，同时减少了资源开销。

Conclusion: 研究表明，整合领域专业知识机制显著增强了LLM在实际漏洞检测任务中的实用性，检索增强生成方法在性能上表现最佳。

Abstract: The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.

</details>


### [82] [In Line with Context: Repository-Level Code Generation via Context Inlining](https://arxiv.org/abs/2601.00376)
*Chao Hu,Wenhao Zeng,Yuling Shi,Beijun Shen,Xiaodong Gu*

Main category: cs.SE

TL;DR: InlineCoder是一个新颖的仓库级代码生成框架，通过将未完成函数内联到其调用图中，将复杂的仓库理解任务转化为更简单的函数级编码任务。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码生成方法（如检索增强生成或基于上下文函数选择）主要依赖表面相似性，难以捕捉控制仓库级语义的丰富依赖关系，导致在理解整个仓库和跨函数、类、模块的复杂依赖推理方面存在不足。

Method: InlineCoder首先根据函数签名生成一个称为"锚点"的草稿完成，近似下游依赖并支持基于困惑度的置信度估计。然后进行双向内联过程：1) 上游内联：将锚点嵌入其调用者中以捕捉多样化使用场景；2) 下游检索：将锚点的被调用者集成到提示中，提供精确的依赖上下文。最终结合草稿完成、上游和下游视角的丰富上下文为LLM提供全面的仓库视图。

Result: 论文未提供具体实验结果，但方法框架旨在通过将仓库级代码生成任务转化为函数级任务，提升模型对仓库上下文的理解能力，从而改善代码生成质量。

Conclusion: InlineCoder通过创新的双向内联方法，将复杂的仓库级代码生成问题转化为更易处理的函数级任务，为仓库级代码生成提供了新的解决方案，能够更好地捕捉仓库中的复杂依赖关系。

Abstract: Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.

</details>


### [83] [On Plagiarism and Software Plagiarism](https://arxiv.org/abs/2601.00429)
*Rares Folea,Emil Slusanschi*

Main category: cs.SE

TL;DR: 本文探讨了软件相似性自动检测的复杂性，介绍了开源软件解决方案Project Martial，并综述了学术界和法律领域中对抗软件抄袭的现有方法。


<details>
  <summary>Details</summary>
Motivation: 软件相似性检测面临数字工件的独特挑战，需要有效的解决方案来应对软件抄袭问题。现有的方法在学术界和法律实践中都有应用，但需要系统性的研究和工具支持。

Method: 研究通过分析学术界和法律领域的现有方法，包括指纹识别、软件胎记和代码嵌入等技术，并基于可用的工件对检测挑战进行分类。同时介绍了开源工具Project Martial，展示了这些技术如何在该项目中应用。

Result: 研究系统性地梳理了软件相似性检测的挑战和方法，提供了技术分类框架，并开发了开源工具Project Martial作为实际应用案例。

Conclusion: 软件相似性检测是一个复杂的领域，需要结合多种技术方法。Project Martial作为一个开源解决方案，为检测软件抄袭提供了实用的工具，并展示了现有技术在实际应用中的可行性。

Abstract: This paper explores the complexities of automatic detection of software similarities, in relation to the unique challenges of digital artifacts, and introduces Project Martial, an open-source software solution for detecting code similarity. This research enumerates some of the existing approaches to counter software plagiarism by examining both the academia and legal landscape, including notable lawsuits and court rulings that have shaped the understanding of software copyright infringements in commercial applications. Furthermore, we categorize the classes of detection challenges based on the available artifacts, and we provide a survey of the previously studied techniques in the literature, including solutions based on fingerprinting, software birthmarks, or code embeddings, and exemplify how a subset of them can be applied in the context of Project Martial.

</details>


### [84] [DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis](https://arxiv.org/abs/2601.00469)
*Negin Ayoughi,David Dewar,Shiva Nejati,Mehrdad Sabetzadeh*

Main category: cs.SE

TL;DR: EXEOS是一个基于LLM的方法，可以从自然语言描述生成AMPL模型和Python代码，并通过求解器反馈迭代优化，在数学优化领域证明了AMPL DSL与Python代码生成具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 模型驱动工程（MDE）在工业应用中因模型开发和维护成本高而受限。虽然大型语言模型（LLMs）可以从自然语言描述直接生成模型，但针对领域特定语言（DSLs）如AMPL，LLM生成的模型可能不如主流语言（如Python）准确，因为后者在LLM训练语料中占主导地位。

Method: 提出EXEOS方法：基于LLM从自然语言问题描述生成AMPL模型和Python代码，并利用求解器反馈进行迭代优化。使用公开优化数据集和工业合作伙伴Kinaxis的实际供应链案例进行评估，比较生成的AMPL模型与Python代码的可执行性和正确性。

Result: 消融研究表明，AMPL在可执行性和正确性方面与Python具有竞争力，有时甚至更好。EXEOS中的设计选择提高了生成规范的质量。

Conclusion: 对于数学优化领域，AMPL DSL在LLM生成方面可以与Python竞争，EXEOS方法通过求解器反馈迭代优化有效提升了生成模型的质量，为MDE在工业应用中的成本问题提供了解决方案。

Abstract: Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.

</details>


### [85] [Multi-Agent Coordinated Rename Refactoring](https://arxiv.org/abs/2601.00482)
*Abhiram Bellur,Mohammed Raihan Ullah,Fraol Batole,Mohit Kansara,Masaharu Morimoto,Kai Ishikawa,Haifeng Chen,Yaroslav Zharov,Timofey Bryksin,Tien N. Nguyen,Hridesh Rajan,Danny Dig*

Main category: cs.SE

TL;DR: 提出了首个多智能体框架来自动化协调重命名，通过开发者初始重构作为线索推断相关重构范围，使用三个智能体协作完成安全、准确的项目范围重构。


<details>
  <summary>Details</summary>
Motivation: 协调重命名是软件开发中频繁但具有挑战性的任务，开发者需要手动在多个文件和上下文中传播重命名重构，过程繁琐且容易出错。现有启发式方法产生过多误报，而普通大语言模型由于上下文限制和无法与重构工具交互，只能提供不完整的建议。

Method: 设计了首个多智能体框架，包含三个智能体：范围推断智能体将开发者初始重构线索转化为明确的自然语言声明范围；计划执行智能体使用该范围作为严格计划识别需要重构的程序元素，并通过调用IDE可信重构API安全执行更改；复制智能体使用该范围指导项目范围搜索。

Result: 通过对100个开源项目的609K次提交进行形成性研究，并调查了205名开发者，验证了框架的有效性。该框架能显著减少开发者的负担，同时保持开发者在主导地位。

Conclusion: AI智能体在软件开发中的主要价值在于扩展开发者的推理和行动能力，而不是取代人类参与。协调重命名正是智能体可以显著减轻开发者负担的重复性任务类型，同时让开发者保持在主导地位。

Abstract: The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.
  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...

</details>


### [86] [SEMODS: A Validated Dataset of Open-Source Software Engineering Models](https://arxiv.org/abs/2601.00635)
*Alexandra González,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: SEMODS是一个包含3,427个Hugging Face模型的软件工程专用数据集，通过自动化收集和人工标注结合LLM辅助验证，将模型与软件开发周期任务关联，支持数据分析、模型发现、基准测试等应用。


<details>
  <summary>Details</summary>
Motivation: 随着AI在软件工程中的应用需求增长，Hugging Face上数百万个模型中缺乏专门针对SE任务的精选目录，难以识别适合SE任务的模型，需要专门的分类数据集来解决这一缺口。

Method: 从Hugging Face提取3,427个模型，采用自动化收集与严格验证相结合的方法，包括人工标注和大型语言模型辅助验证，将模型与软件开发生命周期中的任务和活动进行关联。

Result: 构建了SEMODS数据集，包含3,427个SE相关模型，提供了模型评估结果的标准化表示，支持多种应用场景如数据分析、模型发现、基准测试和模型适配。

Conclusion: SEMODS填补了软件工程领域专用模型目录的空白，为AI在SE任务中的应用提供了系统化的资源，支持研究人员和从业者更有效地发现、评估和适配适合SE任务的AI模型。

Abstract: Integrating Artificial Intelligence into Software Engineering (SE) requires having a curated collection of models suited to SE tasks. With millions of models hosted on Hugging Face (HF) and new ones continuously being created, it is infeasible to identify SE models without a dedicated catalogue. To address this gap, we present SEMODS: an SE-focused dataset of 3,427 models extracted from HF, combining automated collection with rigorous validation through manual annotation and large language model assistance. Our dataset links models to SE tasks and activities from the software development lifecycle, offering a standardized representation of their evaluation results, and supporting multiple applications such as data analysis, model discovery, benchmarking, and model adaptation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [87] [Evolution of Android's Permission-based Security Model and Challenges](https://arxiv.org/abs/2601.00252)
*Rajendra Kumar Solanki,Vijay Laxmi,Manoj Singh Gaur*

Main category: cs.CR

TL;DR: 本文通过系统文献综述和比较分析，研究了Android权限模型及其应用分析的研究现状，重点关注2010-2022年间的研究进展，识别了未解决的问题并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自2008年Android推出以来，其权限模型和应用分析一直是研究热点。尽管Android权限模型已从"全有或全无"访问演变为"用户选择的危险资源访问"，但15年后仍存在未解决的具体挑战和问题。本研究旨在通过全面文献调查解决这些问题并记录该领域的研究工作。

Method: 采用系统性文献综述和比较分析方法，重点关注2010-2022年间的Android权限模型及相关研究。研究系统化整理了以下知识：(1) Android API调用与权限映射，(2) Android权限演变，(3) 权限检查机制。同时识别了过去十年中权限相关的问题及相应研究。

Result: 调查系统梳理了Android权限模型的关键方面，包括API调用与权限的映射关系、权限模型的演变历程以及权限检查机制。识别了权限相关的研究空白和未解决问题，并引用了该领域的开创性工作。

Conclusion: 本研究总结了Android权限模型研究的现状，识别了现有的研究空白，并为早期和经验丰富的研究人员提出了未来研究方向，为Android生态系统利益相关者提供了全面的研究参考。

Abstract: Android Permission Model and Application (app) analysis has consistently remained the focus of the investigation of research groups and stakeholders of the Android ecosystem since it was launched in 2008. Even though the Android smartphone operating system (OS) permission model has evolved significantly from `all-or-none access' to `user-chosen dangerous resource access', specific challenges and issues remain unresolved even after 15 years after the smartphone OS launch. This study addresses the issues and documents the research work in this arena through a comprehensive literature survey and comparative analysis.
  The survey's focal point is the Android permission model and relevant research between 2010-2022. We systematize the knowledge on (i) Android API Calls to permissions mapping, (ii) Android Permissions evolution, and (iii) how permissions are checked. Furthermore, the survey identifies the permission-related issues and relevant research addressed during the last decade. We reference seminal work in these areas. We summarize the identified research gaps and present future directions for early and experienced researchers.

</details>


### [88] [Rectifying Adversarial Examples Using Their Vulnerabilities](https://arxiv.org/abs/2601.00270)
*Fumiya Morimoto,Ryuto Morita,Satoshi Ono*

Main category: cs.CR

TL;DR: 该研究提出一种通过重新攻击对抗样本来修正其标签的方法，旨在将对抗样本移出决策边界以恢复原始正确分类，无需参数调整或预训练，对多种攻击类型均有效。


<details>
  <summary>Details</summary>
Motivation: 现有对抗样本防御方法主要关注检测而非修正，无法在检测到对抗样本后恢复原始正确分类。对于自动驾驶等安全关键应用，仅拒绝对抗样本是不够的，需要能够正确识别原始输入类别。

Method: 提出基于重新攻击对抗样本的方法：将对抗样本作为输入，通过再次攻击使其越过决策边界，从而预测正确的原始标签。该方法仅使用对抗样本作为输入，无需参数调整或预训练，能够处理多种攻击类型。

Result: 实验结果表明，该方法在修正各种攻击方法生成的对抗样本方面表现一致，包括目标攻击和黑盒攻击。在对抗多种攻击的稳定性方面，优于传统的修正和输入变换方法。

Conclusion: 该方法提供了一种简单有效的对抗样本修正方案，能够处理多种攻击类型，无需复杂调整，在安全关键应用中具有实用价值，但仍面临黑盒攻击和远距离对抗样本的挑战。

Abstract: Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorization before an attack. While some tasks may only require mere rejection on detected AEs, others necessitate identifying the correct original input category such as traffic sign recognition in autonomous driving. The objective of this study is to propose a method for rectifying AEs to estimate the correct labels of their original inputs. Our method is based on re-attacking AEs to move them beyond the decision boundary for accurate label prediction, effectively addressing the issue of rectifying minimally perceptible AEs created using white-box attack methods. However, challenge remains with respect to effectively rectifying AEs produced by black-box attacks at a distance from the boundary, or those misclassified into low-confidence categories by targeted attacks. By adopting a straightforward approach of only considering AEs as inputs, the proposed method can address diverse attacks while avoiding the requirement of parameter adjustments or preliminary training. Results demonstrate that the proposed method exhibits consistent performance in rectifying AEs generated via various attack methods, including targeted and black-box attacks. Moreover, it outperforms conventional rectification and input transformation methods in terms of stability against various attacks.

</details>


### [89] [From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm](https://arxiv.org/abs/2601.00273)
*Tamer Afifi,Abdelfatah Hegazy,Ehab Abousaif*

Main category: cs.CR

TL;DR: 本文对RAFT分布式共识算法进行系统性安全分析，重点关注其易受消息重放攻击和消息伪造攻击的脆弱性，并提出基于密码学、认证消息验证和新鲜度检查的解决方案。


<details>
  <summary>Details</summary>
Motivation: RAFT算法虽然以简单、可靠、高效著称，但其安全特性未被充分认识，导致实现容易受到各种攻击威胁，可能将共识的和谐转化为数据不一致的混乱。

Method: 通过模拟场景分析恶意行为者如何利用协议的消息传递机制重新引入旧消息，破坏共识过程；识别RAFT设计中使这些攻击成为可能的关键弱点；提出基于密码学、认证消息验证和新鲜度检查的新方法。

Result: 通过模拟场景验证了这些攻击的实际可行性，识别了RAFT设计中存在的关键安全弱点，证明了协议在安全方面的不足。

Conclusion: 提出的基于密码学的解决方案为增强RAFT实现的安全性提供了框架，指导开发更具弹性的分布式系统，弥补了RAFT协议在安全方面的不足。

Abstract: In recent decades, the RAFT distributed consensus algorithm has become a main pillar of the distributed systems ecosystem, ensuring data consistency and fault tolerance across multiple nodes. Although the fact that RAFT is well known for its simplicity, reliability, and efficiency, its security properties are not fully recognized, leaving implementations vulnerable to different kinds of attacks and threats, which can transform the RAFT harmony of consensus into a chaos of data inconsistency. This paper presents a systematic security analysis of the RAFT protocol, with a specific focus on its susceptibility to security threats such as message replay attacks and message forgery attacks. Examined how a malicious actor can exploit the protocol's message-passing mechanism to reintroduce old messages, disrupting the consensus process and leading to data inconsistency. The practical feasibility of these attacks is examined through simulated scenarios, and the key weaknesses in RAFT's design that enable them are identified. To address these vulnerabilities, a novel approach based on cryptography, authenticated message verification, and freshness check is proposed. This proposed solution provides a framework for enhancing the security of the RAFT implementations and guiding the development of more resilient distributed systems.

</details>


### [90] [Making Theft Useless: Adulteration-Based Protection of Proprietary Knowledge Graphs in GraphRAG Systems](https://arxiv.org/abs/2601.00274)
*Weijie Wang,Peizhuo Lv,Yan Wang,Rujie Dai,Guokun Xu,Qiujian Lv,Hangcheng Liu,Weiqing Huang,Wei Dong,Jiaheng Zhang*

Main category: cs.CR

TL;DR: AURA框架通过数据污染保护知识图谱：向KG中注入虚假但看似合理的数据污染物，使被盗KG对攻击者无用，而授权用户可通过密钥过滤污染物，保持查询准确性。


<details>
  <summary>Details</summary>
Motivation: 保护组织知识图谱这一重要知识产权不被盗用。传统水印技术需要访问输出才能检测，对私有使用场景无效；强加密则因GraphRAG的低延迟需求而开销过大。

Method: 基于数据污染的方法：预先向知识图谱中注入看似合理但虚假的数据污染物。攻击者使用时污染物会污染检索上下文导致错误回答；授权用户通过密钥和加密元数据标签高效过滤所有污染物。

Result: AURA将未授权系统的准确率降至仅5.3%，同时为授权用户保持100%的保真度且开销可忽略。对各种净化尝试保持鲁棒性，保留80.2%的污染物。

Conclusion: AURA框架有效解决了知识图谱在私有使用场景下的安全威胁，在保护知识产权的同时不影响授权用户的正常使用性能。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has emerged as a key technique for enhancing Large Language Models (LLMs) with proprietary Knowledge Graphs (KGs) in knowledge-intensive applications. As these KGs often represent an organization's highly valuable intellectual property (IP), they face a significant risk of theft for private use. In this scenario, attackers operate in isolated environments. This private-use threat renders passive defenses like watermarking ineffective, as they require output access for detection. Simultaneously, the low-latency demands of GraphRAG make strong encryption which incurs prohibitive overhead impractical. To address these challenges, we propose AURA, a novel framework based on Data Adulteration designed to make any stolen KG unusable to an adversary. Our framework pre-emptively injects plausible but false adulterants into the KG. For an attacker, these adulterants deteriorate the retrieved context and lead to factually incorrect responses. Conversely, for authorized users, a secret key enables the efficient filtering of all adulterants via encrypted metadata tags before they are passed to the LLM, ensuring query results remain completely accurate. Our evaluation demonstrates the effectiveness of this approach: AURA degrades the performance of unauthorized systems to an accuracy of just 5.3%, while maintaining 100% fidelity for authorized users with negligible overhead. Furthermore, AURA proves robust against various sanitization attempts, retaining 80.2% of its adulterants.

</details>


### [91] [PQC standards alternatives -- reliable semantically secure key encapsulation mechanism and digital signature protocols using the rank-deficient matrix power function](https://arxiv.org/abs/2601.00332)
*Juan Pedro Hecht,Hugo Daniel Scolnik*

Main category: cs.CR

TL;DR: 该研究提出了后量子密码学协议，包括密钥封装机制和数字签名方案，旨在为TLS 1.3协议提供紧凑、快速且安全的替代方案，以应对量子计算威胁。


<details>
  <summary>Details</summary>
Motivation: 开发能够抵御经典和量子计算攻击的公钥密码原语，为TLS 1.3协议提供可靠的后量子替代方案，保护当前数据免受"现在收集、未来解密"的威胁。

Method: 提出了新颖的后量子密码协议，包括密钥封装机制和数字签名方案，特别针对线性攻击提供专门保护。

Result: 开发了紧凑、快速且安全的协议，可作为TLS 1.3中密钥交换和数字签名的替代方案，便于后量子过渡。

Conclusion: 该研究为后量子密码学提供了实用的解决方案，能够保护互联网流量免受量子计算威胁，实现平稳的后量子过渡。

Abstract: Post-quantum cryptography-PQC- aims to develop public-key primitives that are secure against adversaries using classical and quantum computing technologies. This study introduces novel protocols, a key encapsulation mechanism, a digital signature scheme, and special protection against linear attacks. Our purpose is to create reliable alternatives to current standards, seeking compact, fast, and secure replacements of the key interchange and digital signature in the TLS 1_3 protocol, which safeguards Internet traffic, allowing an easy post-quantum transition to protect current data from the harvest now, decrypt later threat.

</details>


### [92] [Diamond: Design and Implementation of Breach-Resilient Authenticated Encryption Framework For Internet of Things](https://arxiv.org/abs/2601.00353)
*Saif E. Nouma,Gokhan Mumcu,Attila A. Yavuz*

Main category: cs.CR

TL;DR: Diamond是首个可证明安全的前向安全和聚合认证加密框架，专为资源受限的物联网设备设计，通过轻量级密钥演进机制和离线-在线优化管道，显著降低处理延迟并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 物联网设备需要在对抗性无线信道中传输敏感遥测数据，同时受限于计算和能源预算。现有轻量级认证加密标准缺乏前向安全保证、紧凑标签聚合以及现代高吞吐量物联网管道所需的离线-在线优化。

Method: 提出Diamond框架，包含：1) 轻量级密钥演进机制；2) 离线-在线优化的计算管道；3) 针对异构物联网平台的性能分层实例化；4) 正式安全证明；5) 提供合规性和高效率两种具体实例化。

Result: Diamond显著降低了摊销离线预处理（高达47%），在大批量遥测数据中端到端延迟降低高达一个数量级。在64位ARM Cortex-A72、32位ARM Cortex-M4和8位AVR架构上的综合评估显示，Diamond在认证加密吞吐量和端到端验证延迟方面始终优于基线FAAE变体和NIST轻量级AE候选方案，同时保持紧凑标签聚合和强大的违规恢复能力。

Conclusion: Diamond是首个可证明安全的前向安全和聚合认证加密框架，通过创新的轻量级密钥演进和离线-在线优化，为资源受限的物联网设备提供了高效、安全的认证加密解决方案，优于现有标准并支持异构平台。

Abstract: Resource-constrained Internet of Things (IoT) devices, from medical implants to small drones, must transmit sensitive telemetry under adversarial wireless channels while operating under stringent computing and energy budgets. Authenticated Encryption (AE) is essential for ensuring confidentiality, integrity, and authenticity. However, existing lightweight AE standards lack forward-security guarantees, compact tag aggregation, and offline-online (OO) optimizations required for modern high-throughput IoT pipelines.
  We introduce Diamond, the first provable secure Forward-secure and Aggregate Authenticated Encryption (FAAE) framework that extends and generalizes prior FAAE constructions through a lightweight key evolution mechanism, an OO-optimized computation pipeline, and a set of performance-tiered instantiations tailored to heterogeneous IoT platforms. Diamond substantially reduces amortized offline preprocessing (up to 47%) and achieves up to an order-ofmagnitude reduction in end-to-end latency for large telemetry batches. Our comprehensive evaluation across 64-bit ARM Cortex-A72, 32-bit ARM Cortex-M4, and 8-bit AVR architectures confirms that Diamond consistently outperforms baseline FAAE variants and NIST lightweight AE candidates across authenticated encryption throughput and end-to-end verification latency while maintaining compact tag aggregation and strong breach resilience. We formally prove the security of Diamond and provide two concrete instantiations optimized for compliance and high efficiency. Our open-source release enables reproducibility and seamless integration into IoT platforms.

</details>


### [93] [Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits](https://arxiv.org/abs/2601.00627)
*Yuelin Wang,Yuqiao Ning,Yanbang Sun,Xiaofei Xie,Zhihua Xie,Yang Chen,Zhen Guo,Shihao Xue,Junjie Wang,Sen Chen*

Main category: cs.CR

TL;DR: 本文对智能网联汽车（ICV）漏洞进行了首次大规模实证研究，通过分析649个可利用漏洞（来自竞赛和日常提交），评估了现有漏洞分类法的覆盖范围，发现了新的漏洞位置和类型，并将漏洞分类为6种威胁类型和4个风险等级。


<details>
  <summary>Details</summary>
Motivation: 智能网联汽车安全至关重要，但现有研究大多只关注特定子组件，缺乏系统性理解。当前文献多依赖主观分析（如调查访谈），理论发现与实际攻击之间存在显著差距，需要基于真实漏洞数据进行实证研究。

Method: 1. 分析现有ICV安全文献，总结主流漏洞位置和类型分类法；2. 收集649个可利用漏洞（592个来自2023年1月至2024年4月的8次ICV漏洞发现竞赛，覆盖48款不同车辆；57个来自研究人员日常提交）；3. 评估现有分类法覆盖范围，识别差距；4. 将漏洞分类为6种威胁类型和4个风险等级；5. 分析竞赛参与者技能和涉及的ICV类型。

Result: 1. 发现现有分类法存在不足，识别出1个新的漏洞位置和13个新的漏洞类型；2. 将漏洞成功分类为6种威胁类型（如隐私数据泄露）和4个风险等级（从低到关键）；3. 提供了对竞赛参与者技能和ICV类型的分析；4. 创建了公开可用的漏洞数据集。

Conclusion: 本研究通过数据驱动的方法对ICV漏洞进行了全面分析，为研究人员、行业从业者和政策制定者提供了可操作的见解。公开的漏洞数据集将支持未来研究，有助于系统性理解ICV安全漏洞并缩小理论与实际攻击之间的差距。

Abstract: Intelligent Connected Vehicles (ICVs) are a core component of modern transportation systems, and their security is crucial as it directly relates to user safety. Despite prior research, most existing studies focus only on specific sub-components of ICVs due to their inherent complexity. As a result, there is a lack of systematic understanding of ICV vulnerabilities. Moreover, much of the current literature relies on human subjective analysis, such as surveys and interviews, which tends to be high-level and unvalidated, leaving a significant gap between theoretical findings and real-world attacks. To address this issue, we conducted the first large-scale empirical study on ICV vulnerabilities. We began by analyzing existing ICV security literature and summarizing the prevailing taxonomies in terms of vulnerability locations and types. To evaluate their real-world relevance, we collected a total of 649 exploitable vulnerabilities, including 592 from eight ICV vulnerability discovery competitions, Anonymous Cup, between January 2023 and April 2024, covering 48 different vehicles. The remaining 57 vulnerabilities were submitted daily by researchers. Based on this dataset, we assessed the coverage of existing taxonomies and identified several gaps, discovering one new vulnerability location and 13 new vulnerability types. We further categorized these vulnerabilities into 6 threat types (e.g., privacy data breach) and 4 risk levels (ranging from low to critical) and analyzed participants' skills and the types of ICVs involved in the competitions. This study provides a comprehensive and data-driven analysis of ICV vulnerabilities, offering actionable insights for researchers, industry practitioners, and policymakers. To support future research, we have made our vulnerability dataset publicly available.

</details>


### [94] [LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns](https://arxiv.org/abs/2601.00372)
*Taufiq Islam Protick,Sai Teja Peddinti,Nina Taft,Anupam Das*

Main category: cs.CR

TL;DR: 该研究开发了一个自动化管道，通过微调GPT-3.5-Turbo来识别和分类亚马逊IoT产品评论中的安全与隐私问题，在三个设备类别上实现了超过97%的精确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 了解物联网用户的安全与隐私关切对开发者和用户都有益处，但现有方法在识别相关评论方面效果有限，需要更先进的方法来分析用户观点。

Method: 开发了基于GPT-3.5-Turbo微调的自动化管道，包括分类器-合理化器-分类器模型和主题映射器，利用动态少样本提示和大上下文窗口，分析了91,000条亚马逊智能设备评论。

Result: 平均5%的评论包含安全隐私关切，安全摄像头最高达10%；方法比先前工作检测到更多相关评论：健身追踪器15倍、智能音箱29%、摄像头70%；发现监控和数据控制等关切持续多年，用户普遍要求更精确的数据控制权。

Conclusion: 该研究揭示了物联网安全隐私关切的持续性和普遍性，发现了账户分离和数据访问控制不足等新问题，为开发者提供了改进用户满意度和信任度的可行见解。

Abstract: Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.

</details>


### [95] [Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution](https://arxiv.org/abs/2601.00418)
*Prajwal Panth,Sahaj Raj Malla*

Main category: cs.CR

TL;DR: CPPDD是一个轻量级、后设置自主的隐私保护数据分发框架，通过双重保护机制实现安全的多客户端数据聚合，具有线性可扩展性和高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前安全多方计算、联邦学习和区块链应用中存在的可扩展性、信任最小化和可验证性等关键问题，特别是在受监管和资源受限环境下的隐私保护数据协作需求。

Method: 采用双重保护机制：每个客户端的仿射掩码和优先级驱动的顺序共识锁定，结合步骤校验和与数据校验和进行去中心化完整性验证，支持标量、向量和矩阵负载。

Result: 在MNIST数据集上实现线性可扩展性（N=500），每个客户端计算时间低于毫秒级，100%恶意偏差检测，精确数据恢复，计算量比MPC和HE基线低3-4个数量级。

Conclusion: CPPDD框架为安全投票、联盟联邦学习、区块链托管和地理信息能力建设等应用提供了原子协作能力，填补了可扩展性、信任最小化和可验证多方计算的关键空白。

Abstract: We propose the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, a lightweight and post-setup autonomous protocol for secure multi-client data aggregation. The framework enforces unanimous-release confidentiality through a dual-layer protection mechanism that combines per-client affine masking with priority-driven sequential consensus locking. Decentralized integrity is verified via step (sigma_S) and data (sigma_D) checksums, facilitating autonomous malicious deviation detection and atomic abort without requiring persistent coordination. The design supports scalar, vector, and matrix payloads with O(N*D) computation and communication complexity, optional edge-server offloading, and resistance to collusion under N-1 corruptions. Formal analysis proves correctness, Consensus-Dependent Integrity and Fairness (CDIF) with overwhelming-probability abort on deviation, and IND-CPA security assuming a pseudorandom function family. Empirical evaluations on MNIST-derived vectors demonstrate linear scalability up to N = 500 with sub-millisecond per-client computation times. The framework achieves 100% malicious deviation detection, exact data recovery, and three-to-four orders of magnitude lower FLOPs compared to MPC and HE baselines. CPPDD enables atomic collaboration in secure voting, consortium federated learning, blockchain escrows, and geo-information capacity building, addressing critical gaps in scalability, trust minimization, and verifiable multi-party computation for regulated and resource-constrained environments.

</details>


### [96] [Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback](https://arxiv.org/abs/2601.00509)
*Vidyut Sriram,Sawan Pandita,Achintya Lakshmanan,Aneesh Shamraj,Suman Saha*

Main category: cs.CR

TL;DR: 该论文提出了一种检索增强的多工具修复工作流，通过编译器诊断、CodeQL安全扫描和KLEE符号执行等工具，结合语义检索机制，显著提升了LLM生成代码的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码经常存在安全漏洞、逻辑不一致和编译错误等问题，虽然已有研究表明结构化反馈、静态分析和执行优化能改善LLM表现，但需要更系统化的修复方案来提升代码质量。

Method: 提出检索增强的多工具修复工作流：1）使用单个代码生成LLM迭代优化输出；2）集成编译器诊断、CodeQL安全扫描和KLEE符号执行三种工具；3）采用轻量级嵌入模型进行语义检索，获取先前成功的修复示例；4）提供安全导向的示例来指导代码生成。

Result: 在DeepSeek-Coder-1.3B和CodeLlama-7B生成的3,242个程序数据集上评估：DeepSeek的安全漏洞减少96%；CodeLlama的关键安全缺陷率从58.55%降至22.19%，证明工具辅助的自修复对"顽固"模型也有效。

Conclusion: 工具辅助的自修复工作流能显著提升LLM生成代码的鲁棒性和安全性，即使对于难以优化的模型也能产生明显改善，为代码生成系统的质量保障提供了有效解决方案。

Abstract: Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on "stubborn" models.

</details>


### [97] [Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?](https://arxiv.org/abs/2601.00559)
*Jason Quantrill,Noura Khajehnouri,Zihan Guo,Manar H. Alalfi*

Main category: cs.CR

TL;DR: 评估LLMs在智能家居IoT平台规则交互威胁检测中的表现，发现虽然LLMs在语义理解方面有潜力，但在需要跨规则结构推理的场景下准确性显著下降，不如符号推理方法稳定可靠。


<details>
  <summary>Details</summary>
Motivation: 智能家居IoT平台（如openHAB）使用触发-动作-条件规则实现设备自动化，但这些规则之间的交互可能产生交互威胁，如意外或不安全行为。传统方法依赖符号约束驱动的静态分析，本研究旨在全面评估大型语言模型在多类别交互威胁检测中的表现。

Method: 1. 构建多类别交互威胁分类法；2. 使用原始openHAB数据集和结构挑战性的突变数据集（测试规则变换下的鲁棒性）；3. 评估Llama 3.1 8B、Llama 70B、GPT-4o、Gemini-2.5-Pro和DeepSeek-R1模型；4. 采用零样本、单样本和双样本设置；5. 与oHIT手动验证的基准真值进行比较；6. 对比符号推理基线方法。

Result: 1. LLMs在语义理解方面表现出潜力，特别是在动作和条件相关威胁上；2. 在需要跨规则结构推理的威胁上准确性显著下降，尤其在突变规则形式下；3. 模型性能在不同威胁类别和提示设置下差异很大，没有模型能提供一致的可靠性；4. 符号推理基线在两个数据集上都保持稳定的检测性能，不受规则重写或结构扰动影响。

Conclusion: LLMs单独使用尚不足以在IoT环境中进行安全关键的交互威胁检测。研究讨论了工具设计的影响，并强调结合符号分析和基于LLM的语义解释的混合架构潜力，可以在保持结构严谨性的同时减少误报。

Abstract: Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.

</details>


### [98] [Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems](https://arxiv.org/abs/2601.00566)
*Yueyan Dong,Minghui Xu,Qin Hu,Yinhao Xiao,Qi Luo,Yechao Zhang,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: LoRA在联邦学习中存在安全漏洞：攻击者可以分别提交看似无害的A和B矩阵，但其乘积AB会产生恶意模型更新，这种GAP攻击无需训练数据或客户端协调，能绕过异常检测。


<details>
  <summary>Details</summary>
Motivation: LoRA已成为联邦学习中微调大语言模型的流行方案，能显著降低更新成本。然而，当与FedIT等框架结合时，LoRA引入了一个关键安全漏洞：客户端分别提交A和B矩阵，但只有它们的乘积AB决定模型更新，而这个合成结果从未被直接验证。

Method: 提出了梯度组装投毒(GAP)攻击，利用LoRA的盲点：分别构造看似良性的A和B矩阵，但它们的乘积会产生恶意更新。攻击无需访问训练数据或客户端间协调，能绕过标准异常检测器。识别了LoRA联邦系统中的四个系统性漏洞，并在LLaMA、ChatGLM和GPT-2上验证了GAP攻击。

Result: GAP攻击能持续诱导模型输出质量下降或产生偏见，同时保持表面流畅性：BLEU分数降低高达14.5%，事实和语法错误增加超过800%，长文本回复长度保持92.6%。攻击在标准异常检测下保持隐蔽。

Conclusion: 研究揭示了分布式LoRA微调中一类新的隐蔽、持久威胁。GAP攻击利用LoRA矩阵分离提交的漏洞，即使单个矩阵看起来无害，其组合也能产生恶意效果，这对联邦学习安全提出了新的挑战。

Abstract: Low-Rank Adaptation (LoRA) has become a popular solution for fine-tuning large language models (LLMs) in federated settings, dramatically reducing update costs by introducing trainable low-rank matrices. However, when integrated with frameworks like FedIT, LoRA introduces a critical vulnerability: clients submit $A$ and $B$ matrices separately, while only their product $AB$ determines the model update, yet this composite is never directly verified. We propose Gradient Assembly Poisoning (GAP), a novel attack that exploits this blind spot by crafting individually benign $A$ and $B$ matrices whose product yields malicious updates. GAP operates without access to training data or inter-client coordination and remains undetected by standard anomaly detectors. We identify four systemic vulnerabilities in LoRA-based federated systems and validate GAP across LLaMA, ChatGLM, and GPT-2. GAP consistently induces degraded or biased outputs while preserving surface fluency, reducing BLEU by up to 14.5\%, increasing factual and grammatical errors by over 800\%, and maintaining 92.6\% long-form response length. These results reveal a new class of stealthy, persistent threats in distributed LoRA fine-tuning.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [99] [μACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication](https://arxiv.org/abs/2601.00219)
*Arnab Mallick,Indraveni Chebolu*

Main category: cs.MA

TL;DR: μACP是一个在明确资源约束下进行表达性智能体通信的形式演算，它通过最小四动词基础编码FIPA协议，在资源受限环境中实现语义丰富性与可证明效率的统一。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通信协议存在两难困境：FIPA-ACL等协议语义丰富但资源消耗大，轻量级IoT协议效率高但表达能力有限。需要一种能在资源受限环境中同时保证表达性和效率的通信框架。

Method: 提出μACP形式演算，建立资源约束智能体通信模型，证明{PING, TELL, ASK, OBSERVE}四动词基础足以编码有限状态FIPA协议，建立消息复杂度的信息论界限，实现部分同步和崩溃故障下的标准共识。

Result: 形式验证证明安全性和有界性，大规模系统模拟显示中位数端到端消息延迟34ms（95百分位104ms），在严重资源约束下优于现有智能体和IoT协议。

Conclusion: μACP统一了语义表达性和可证明效率，为下一代资源受限多智能体系统提供了严格的理论基础，实现了表达性通信与资源效率的协调。

Abstract: Agent communication remains a foundational problem in multi-agent systems: protocols such as FIPA-ACL guarantee semantic richness but are intractable for constrained environments, while lightweight IoT protocols achieve efficiency at the expense of expressiveness. This paper presents $μ$ACP, a formal calculus for expressive agent communication under explicit resource bounds. We formalize the Resource-Constrained Agent Communication (RCAC) model, prove that a minimal four-verb basis \textit{\{PING, TELL, ASK, OBSERVE\}} is suffices to encode finite-state FIPA protocols, and establish tight information-theoretic bounds on message complexity. We further show that $μ$ACP can implement standard consensus under partial synchrony and crash faults, yielding a constructive coordination framework for edge-native agents. Formal verification in TLA$^{+}$ (model checking) and Coq (mechanized invariants) establishes safety and boundedness, and supports liveness under modeled assumptions. Large-scale system simulations confirm ACP achieves a median end-to-end message latency of 34 ms (95th percentile 104 ms) at scale, outperforming prior agent and IoT protocols under severe resource constraints. The main contribution is a unified calculus that reconciles semantic expressiveness with provable efficiency, providing a rigorous foundation for the next generation of resource-constrained multi-agent systems.

</details>


### [100] [Mapping Human Anti-collusion Mechanisms to Multi-agent AI](https://arxiv.org/abs/2601.00360)
*Jamiu Adekunle Idowu,Ahmed Almasoud,Ayman Alfahid*

Main category: cs.MA

TL;DR: 该论文研究了如何将人类反合谋机制应用于多智能体AI系统，提出了分类框架并分析了实施挑战。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体AI系统自主性增强，它们可能发展出类似人类市场的合谋策略，但现有的人类反合谋机制如何适应AI环境尚不明确。

Method: 开发了人类反合谋机制的分类法（包括制裁、宽大处理与举报、监控与审计、市场设计、治理），并将其映射到多智能体AI系统的潜在干预措施。

Result: 为每种机制提出了实施方法，并识别了关键挑战：归因问题、身份流动性、边界问题和对抗性适应。

Conclusion: 需要将人类反合谋机制适应到AI环境中，但面临独特的技术挑战，需要进一步研究解决。

Abstract: As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [101] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略以优化LLM性能仍是一个重要挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用推理感知的知识检索方法，遵循粗到细的两阶段检索策略：1) 首先识别知识库中与上下文相关的子区域，确保所有句子都与主题相关；2) 在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过共同关键词在知识句子中有效导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更紧密地符合人类对话中的底层推理逻辑，还显著提高了检索知识的多样性，从而产生更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，通过提供与对话逻辑结构对齐的知识，显著提升LLMs在多轮对话中的性能，产生更丰富多样的响应。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [102] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大型语言模型的尼日利亚皮钦语抑郁症自动筛查工具，在资源受限环境中实现文化适宜的抑郁症检测。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统PHQ-9问卷在高收入国家验证，但存在语言文化障碍，无法适应尼日利亚皮钦语和520多种本地语言环境。

Method: 收集432名18-40岁尼日利亚年轻人的皮钦语音频回答，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9严重程度评分），对Phi-3-mini、Gemma-3-4B和GPT-4.1三个LLM进行微调。

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，在文化适宜性、清晰度和相关性方面也最优，优于Gemma-3-4B和Phi-3-mini。

Conclusion: AI驱动的抑郁症筛查工具可为尼日利亚等语言多样、资源受限的社区提供可行的解决方案，为部署对话式心理健康工具奠定基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [103] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出了一种多算法方法来解决最后一公里包裹配送系统中的人力资源工作量平衡问题，通过考虑距离和工作量来优化包裹分配，确保每位配送员完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统的基于地理邻近性的包裹分配方法效率低下，容易导致配送员之间工作量分布不平衡。在最后一公里城市包裹配送系统中，需要优化操作人力资源的工作量平衡，纠正配送员之间的显著工作量不平衡问题。

Method: 提出了一种多算法方法，包括不同版本的k-means算法、进化方法、基于k-means初始化的递归分配（使用不同问题编码）以及混合进化集成算法。该方法以配送点集合和工人数量为输入，综合考虑距离和工作量因素来优化包裹分配。

Result: 该方法在西班牙Azuqueca de Henares城市最后一公里包裹配送系统的实际案例中进行了性能验证，展示了其在实际应用中的有效性。

Conclusion: 通过多算法方法综合考虑距离和工作量因素，可以有效解决最后一公里包裹配送系统中的人力资源工作量平衡问题，确保每位配送员完成相似的工作量，提高系统效率。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [104] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出基于MinDist度量的规则框架用于13张牌印度拉米游戏，通过编辑距离量化手牌与完成状态的结构接近度，显著提升胜率


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是一种不完全信息顺序游戏，需要概率推理和组合决策。传统启发式方法效果有限，需要更形式化和可解释的策略设计方法

Method: 提出MinDist手牌评估度量，修改MinScore度量以量化手牌与最近有效配置的编辑距离；设计计算高效的算法，利用动态剪枝和模式缓存；在双人零和模拟框架中结合对手手牌建模

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升

Conclusion: MinDist框架为算法化拉米策略设计提供了形式化和可解释的步骤，在13张牌印度拉米游戏中表现出优越性能

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [105] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探索生成式AI如何理解乡土建筑智慧，以伊朗鸽塔为例，测试三种扩散模型在不同提示阶段的表现，发现AI能复制几何模式但误解材料和气候逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI系统如何解读乡土建筑形式中蕴含的建筑智慧，探索AI在理解和重构传统设计智能方面的能力与局限。

Method: 以伊朗鸽塔为案例研究，测试Midjourney v6、DALL-E 3和基于SDXL的DreamStudio三种扩散模型，采用参照性、适应性和推测性三个提示阶段，通过五标准评估框架分析AI的重构能力。

Result: AI能可靠地复制几何模式，但误解材料和气候逻辑；参照图像能提高真实感但限制创造力，无参照时能产生创新但文化模糊的结果；揭示了视觉相似性与建筑推理之间的界限。

Conclusion: 定义了AI感知、扭曲和重新构想传统设计智能的边界，提出了计算乡土推理作为分析AI理解建筑智慧的理论框架。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [106] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 本文设计了一个LLM智能体，能从原始文本中提取因果反馈模糊认知图（FCM），通过双向交互实现动态系统的自主演化，并在测试中成功复现人类生成的FCM的平衡极限环。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够从文本中自主提取因果关系的LLM智能体系统，实现FCM动态系统的自主演化，同时保持一定的控制（"agentic leash"）。这旨在解决传统方法中因果结构提取的局限性，通过LLM的半自主性实现更灵活的因果学习。

Method: 方法包括三个精细调校的系统指令：1）从文本中提取关键名词和名词短语；2）从这些名词中提取FCM概念节点；3）提取或推断这些FCM节点之间的部分或模糊因果边。测试使用了Henry Kissinger及其同事关于AI前景的论文，并比较了Gemini和ChatGPT LLM智能体生成的FCM。

Result: 三步骤过程生成的FCM动态系统能够收敛到与人类生成的FCM相同的平衡极限环，尽管节点和边的数量不同。混合Gemini和ChatGPT生成的FCM不仅吸收了主要混合成分的平衡点，还创建了新的平衡点，更好地近似了底层的因果动态系统。

Conclusion: 研究表明LLM智能体能够有效地从文本中提取因果FCM，生成的动态系统具有与人类生成系统相似的平衡行为。混合不同LLM生成的FCM能够产生新的平衡点，增强对底层因果系统的近似能力，展示了LLM在因果建模中的潜力。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [107] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续体系统，通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识积累。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件使它们面临频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: ReCiSt将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个层次：隔离、诊断、元认知和知识。这些层次通过语言模型驱动的智能体实现自主故障隔离、因果诊断、自适应恢复和长期知识积累。

Result: 在公共故障数据集上使用多种语言模型进行评估，结果显示ReCiSt能在数十秒内完成自愈，智能体CPU使用率最低为10%。结果还展示了系统克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功地将生物自愈机制转化为计算系统的弹性策略，通过语言模型驱动的智能体实现了分布式计算连续体系统的自主故障管理和恢复能力。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [108] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏评估机制质量，确保游戏保持基于技能的玩家排序。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计是耗时且依赖专家经验的过程，需要自动化方法来探索多样化的游戏机制，提高游戏设计效率。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏进行评估，评估标准是机制对游戏中技能排序得分的贡献。

Result: Mortar能够生成多样且可玩的游戏，产生的机制对技能排序得分有更大贡献，消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效方法，能够生成具有技能排序特性的多样化游戏。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [109] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能差距，提出混合智能框架分离语义推理与数学计算，通过数字孪生测试显示成本降低32.1%


<details>
  <summary>Details</summary>
Motivation: 中小企业在库存管理中缺乏部署高级优化方法的专业知识，需要探索LLMs能否帮助弥合这一差距，但发现直接使用LLMs作为端到端求解器存在性能问题

Method: 提出混合智能框架，严格分离语义推理与数学计算：LLM作为智能接口从自然语言提取参数并解释结果，自动调用严格算法构建优化引擎；引入"人类模仿者"数字孪生进行可扩展的压力测试

Result: 混合框架相比使用GPT-4o作为端到端求解器的基线，总库存成本降低32.1%；提供完美真实信息也无法改善GPT-4o性能，表明瓶颈是计算而非信息问题

Conclusion: LLMs不应取代运筹学，而应作为自然语言接口，使非专家能够访问基于求解器的严格策略；混合智能框架能有效解决LLMs在随机推理方面的局限性

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [110] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了在视频问答任务中，基于置信度的选择性预测能否提供可靠的错误率控制，以及这种控制在分布偏移下是否稳健


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在高风险部署中需要选择性预测能力，当模型不确定时应能主动弃权而非冒险犯错。研究旨在验证基于置信度的弃权机制能否提供可靠的错误率控制，以及这种控制在分布偏移下是否保持稳健

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值调整来研究选择性预测。在分布内设置中，通过扫描阈值epsilon来观察风险-覆盖率的权衡关系；在分布偏移下测试控制机制的稳健性

Result: 研究发现：1）置信度阈值调整在分布内能提供机制性控制，通过调整阈值可以产生平滑的风险-覆盖率权衡曲线，有效降低错误率；2）在分布偏移下，这种控制机制是否保持稳健需要进一步验证

Conclusion: 基于置信度的选择性预测在视频问答任务中能够提供有效的错误率控制机制，但其在分布偏移下的稳健性仍需进一步研究验证

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [111] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计学偏见，还会在"我们vs他们"的群体线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转向更根本的群体不对称——人类整体可能被智能体视为外群体。研究还提出了信念中毒攻击(BPA)来抑制人类规范脚本，重新激活对人类的外群体偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM赋能的智能体是否会在最小群体线索下表现出群体间偏见，特别是当这种群体边界与智能体-人类划分重合时，人类整体可能被智能体视为外群体的风险。这比传统的人口统计学偏见更为根本，涉及智能体与人类之间的群体不对称关系。

Method: 研究方法包括：1) 构建基于分配决策的受控多智能体社会模拟，在明确的收益权衡下测试群体间偏见；2) 引入信念中毒攻击(BPA)，包括初始化时的档案中毒(BPA-PP)和通过优化信念精炼后缀注入存储反思中的记忆中毒(BPA-MP)；3) 在档案和记忆边界实施实际缓解策略来强化现有智能体框架。

Result: 实验结果表明：1) 智能体在最小群体线索下表现出一致的群体间偏见；2) 当部分对应方被框定为人类时，这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念；3) 信念中毒攻击(BPA)能有效抑制人类规范脚本，重新激活对人类的外群体偏见；4) 攻击在多种设置下都表现出严重性。

Conclusion: 研究揭示了LLM赋能智能体存在群体间偏见的风险，特别是当群体边界与智能体-人类划分重合时。信念依赖创造了新的攻击面，信念中毒攻击(BPA)能有效利用这一漏洞。研究目的是识别这些漏洞以指导更安全的智能体设计，而非实现现实世界中的利用。需要在档案和记忆边界实施干预措施来强化现有框架。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [112] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构，利用记忆引导机制动态学习最优检测配置，显著提升社交平台协同不实行为检测的准确性和效率，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有社交平台协同不实行为检测方法存在三个主要问题：依赖表面相关性分析、使用静态参数设置、需要大量人工标注。这些限制导致检测效果有限且效率低下。

Method: 提出自适应因果协调检测（ACCD）框架，采用三阶段渐进架构：1）自适应收敛交叉映射技术深入识别账户间真实因果关系；2）半监督分类中集成主动学习和不确定性采样，减少人工标注负担；3）基于历史检测经验的自动化验证模块，实现检测结果的自验证和优化。

Result: 在真实数据集（Twitter IRA、Reddit协调痕迹、机器人检测基准）上的实验表明，ACCD在协同攻击检测中达到87.3%的F1分数，比现有最强基线提升15.2%；减少68%的人工标注需求；通过层次聚类优化实现2.8倍处理速度提升。

Conclusion: ACCD提供了一个更准确、高效且高度自动化的端到端解决方案，用于识别社交平台上的协同行为，具有重要的实际价值和广泛的应用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [113] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 该研究将语义空间推理从计算语言学扩展到团队运动战术决策，将球员视为单词、团队配合视为语义结构，通过向量表示和距离度量评估战术匹配度。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法主要应用于文本分析，本研究旨在探索这些方法如何应用于团队运动的战术决策领域，为集体决策和性能优化提供通用框架。

Method: 将球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高压逼抢、反击、控球组织），使用向量距离度量评估战术匹配度和对手利用潜力。

Result: 开发了基于Python的原型系统，能够生成可解释的动态自适应策略建议，并提供属性层面的细粒度诊断洞察；该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人、人机协调系统等团队领域。

Conclusion: 该研究为集体决策和性能优化提供了通用框架，未来方向包括真实世界数据集成、预测模拟以及混合人机战术智能的发展。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [114] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"（mid-reasoning shifts）实际上是推理不稳定的表现，而非内在的自我修正机制，这些转变很少发生且很少提高准确性，但在高不确定性下人工触发外部转变可以可靠地提高准确性。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，导致准确输出，暗示了内在的自我修正能力。但尚不清楚这种推理策略的内在转变是否真正提高了性能。

Method: 研究分析了100多万条推理轨迹、数百个训练检查点、三个推理领域以及多个解码温度和模型架构，检测推理过程中的转变，并研究其与训练进展、准确性和模型不确定性的关系。

Result: 推理转变很罕见，不会随着训练变得更频繁，也很少提高准确性，表明它们并不对应先前认为的模型洞察力。然而，其效果随模型不确定性而变化，在高熵条件下人工触发外部转变可以可靠地提高准确性。

Conclusion: 推理过程中的转变是不稳定推理行为的症状，而非内在的自我修正机制，但可以通过在高不确定性条件下人工触发外部转变来改善模型性能。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [115] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据难度并重新加权训练样本，解决多模态大语言模型中偏好优化过拟合问题，提升幻觉抑制效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态DPO方法由于偏好数据难度不平衡容易过拟合，模型倾向于过度关注容易区分的偏好对，阻碍了细粒度幻觉抑制并降低整体性能。

Method: DA-DPO包含两个核心组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生稳健的难度分数；2) 难度感知训练：根据估计的难度重新加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明DA-DPO能持续改进多模态偏好优化，在标准基准测试中展现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架，有效解决了多模态DPO中的过拟合问题，无需额外数据或微调阶段即可实现更有效的幻觉抑制和性能提升。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [116] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：结合视觉特征和领域知识的LLM框架，用于行人过街行为推理，在泛化性和准确性上超越传统方法


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景中表现不佳。LLMs提供了从数值模式匹配到语义上下文行为推理的转变机会，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，整合LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。

Result: PedX-LLM达到82.0%的平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识整合带来额外4.1%改进。在未见过的测试场景中，零样本配置达到66.9%平衡准确率，少样本学习（仅5个验证示例）进一步提升至72.2%。

Conclusion: PedX-LLM展示了强大的泛化能力，证实视觉和知识增强的推理使模型能够模仿人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [117] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 使用智能体工作流将自然语言任务描述自动转换为完整的 DomiKnowS 程序，显著降低神经符号编程的门槛和开发时间


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中可以提高模型的鲁棒性、可解释性和数据效率，但现有框架如 DomiKnowS 仍要求用户精通特定语法，开发过程耗时且具有挑战性

Method: 提出 AgenticDomiKnowS (ADS)，通过智能体工作流将自由形式的任务描述翻译成完整的 DomiKnowS 程序。该工作流单独创建和测试每个 DomiKnowS 组件，并支持可选的人工干预，允许熟悉 DomiKnowS 的用户细化中间输出

Result: ADS 使有经验的 DomiKnowS 用户和非用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟

Conclusion: ADS 通过消除对特定库语法的依赖，显著降低了神经符号编程的门槛，使更多研究人员和开发者能够利用符号约束增强深度学习模型

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>
