<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 35]
- [cs.CL](#cs.CL) [Total: 23]
- [cs.CR](#cs.CR) [Total: 9]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding](https://arxiv.org/abs/2602.17768)
*Boda Lin,Yongjie Zhu,Xiaocheng Gong,Wenyu Qin,Meng Wang*

Main category: cs.CV

TL;DR: 该论文针对视频描述模型中细粒度运动细节描述不准确和幻觉问题，提出了自动化标注流程构建KPM-Bench数据集，并开发了MoPE算法来提取运动属性、评估幻觉，最终通过GRPO框架显著提升运动中心视频描述模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前视频描述模型在准确描述细粒度运动细节方面存在显著限制，特别是在运动中心视频中，对复杂动作和肢体动态的精确描绘往往被忽视，同时存在严重的幻觉问题。

Method: 1. 提出自动化标注流程，整合基于运动学的运动计算和语言解析；2. 构建KPM-Bench数据集，包含细粒度视频-描述对、专注于运动理解的问答对、以及评估幻觉的精心策划评估集；3. 提出基于语言的运动解析与提取（MoPE）算法，从文本描述中准确提取运动特定属性；4. 将MoPE集成到GRPO后训练框架中。

Result: 1. 发布了开源的KPM-Bench数据集，促进细粒度运动理解；2. 开发了不依赖大规模视觉-语言或纯语言模型的精确幻觉评估指标；3. 有效缓解了幻觉问题，显著提高了运动中心视频描述模型的可靠性。

Conclusion: 通过整合运动学分析和语言解析的自动化标注流程，结合专门设计的KPM-Bench数据集和MoPE算法，能够系统性地解决视频描述中的细粒度运动理解不足和幻觉问题，为运动中心视频描述提供了更可靠的解决方案。

Abstract: Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.

</details>


### [2] [CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild](https://arxiv.org/abs/2602.17770)
*Balamurugan Thambiraja,Omid Taheri,Radek Danecek,Giorgio Becherini,Gerard Pons-Moll,Justus Thies*

Main category: cs.CV

TL;DR: 本文提出了3D-HIW数据集和CLUTCH系统，用于解决野外环境下3D手部动作建模的挑战，在文本到手部动作生成和动作描述任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 手部动作在日常生活中至关重要，但现有方法依赖工作室采集的有限数据集，难以扩展到野外环境，且现有模型在动画保真度和文本-动作对齐方面存在不足。

Method: 1) 构建3D-HIW数据集：结合视觉语言模型和先进3D手部追踪器，从大量第一人称动作视频中标注32K个3D手部动作序列和对应文本；2) 提出CLUTCH系统：包含SHIFT（部分模态分解的VQ-VAE架构）用于手部动作标记化，以及几何精炼阶段通过重建损失微调LLM。

Result: 在文本到手部动作生成和动作到文本描述任务上实现了最先进的性能，建立了可扩展的野外手部动作建模的首个基准。

Conclusion: 通过3D-HIW数据集和CLUTCH系统，成功解决了野外环境下手部动作建模的挑战，为可扩展的手部动画生成和描述建立了新标准。

Abstract: Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to "in-the-wild" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.

</details>


### [3] [LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge](https://arxiv.org/abs/2602.17793)
*Peide Zhu,Linbin Lu,Zhiqin Chen,Xiong Chen*

Main category: cs.CV

TL;DR: 提出LGD-Net框架，通过跨模态特征幻觉而非像素级图像生成，直接从H&E切片预测HER2表达水平，避免重建伪影，提高计算效率


<details>
  <summary>Details</summary>
Motivation: 传统IHC染色资源密集、昂贵耗时，许多地区无法获得；现有基于H&E切片的虚拟染色方法计算昂贵且易产生重建伪影，可能传播诊断错误

Method: 提出Latent-Guided Dual-Stream Network (LGD-Net)，学习将形态学H&E特征直接映射到分子潜在空间，通过教师IHC编码器指导训练；使用轻量级辅助正则化任务（核分布和膜染色强度）确保幻觉特征捕获临床相关表型

Result: 在公开BCI数据集上的实验表明，LGD-Net达到最先进性能，显著优于基线方法，同时支持使用单模态H&E输入进行高效推理

Conclusion: LGD-Net通过跨模态特征幻觉而非像素级图像生成，有效解决了传统虚拟染色方法的局限性，为乳腺癌HER2评估提供了更高效准确的替代方案

Abstract: It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.

</details>


### [4] [Enabling Training-Free Text-Based Remote Sensing Segmentation](https://arxiv.org/abs/2602.17799)
*Jose Sosa,Danila Rukhovich,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练的遥感图像文本引导分割方法，通过结合对比式和生成式视觉语言模型与SAM，实现了完全零样本或轻量级LoRA调优的分割流程。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型和视觉基础模型为遥感图像的零样本文本引导分割提供了新机会，但现有方法通常依赖额外的可训练组件，限制了其泛化能力和实际应用性。本研究旨在探索仅依赖现有基础模型、无需额外训练就能实现文本引导遥感分割的可能性。

Method: 提出两种方法：1）对比式方法使用CLIP作为SAM网格建议的掩码选择器，实现完全零样本的开放词汇语义分割；2）生成式方法使用GPT-5（零样本）和LoRA调优的Qwen-VL模型为SAM生成点击提示，实现推理和指代分割。

Result: 在19个遥感基准测试（包括开放词汇、指代和基于推理的任务）上进行了广泛实验，对比式方法在完全零样本设置下实现了最先进的开放词汇语义分割，生成式方法中LoRA调优的Qwen-VL模型表现最佳。

Conclusion: 该方法展示了仅依赖现有基础模型、无需额外训练即可实现高质量遥感图像文本引导分割的可行性，为遥感分割的实际应用提供了更通用和实用的解决方案。

Abstract: Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.

</details>


### [5] [VQPP: Video Query Performance Prediction Benchmark](https://arxiv.org/abs/2602.17814)
*Adrian Catalin Lutu,Eduard Poesina,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 本文提出了首个视频查询性能预测（VQPP）基准，包含两个文本到视频检索数据集和两个CBVR系统，共56K文本查询和51K视频，为视频领域的QPP研究提供了标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 查询性能预测（QPP）在信息检索中具有重要应用，但在基于内容的视频检索（CBVR）领域研究不足，缺乏标准化的评估基准。

Method: 构建了VQPP基准，包含两个文本到视频检索数据集和两个CBVR系统，探索了多种检索前和检索后性能预测器，并使用最佳检索前预测器作为奖励模型，通过直接偏好优化训练LLM进行查询重写。

Result: 检索前预测器取得了有竞争力的性能，能够在检索步骤之前实现应用；VQPP基准为视频领域的QPP研究提供了可复现的评估框架。

Conclusion: VQPP是视频查询性能预测的首个基准，填补了CBVR领域QPP研究的空白，为未来研究提供了标准化评估工具，并展示了在查询重写等实际应用中的潜力。

Abstract: Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

</details>


### [6] [On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective](https://arxiv.org/abs/2602.17854)
*Domonkos Varga*

Main category: cs.CV

TL;DR: 该论文对Liu和Szirányi提出的手势识别方法进行方法论分析，指出其评估协议存在严重的数据泄露问题，导致报告的近乎完美的准确率指标无效。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析Liu和Szirányi手势识别方法的评估协议有效性，揭示其评估中存在的严重数据泄露问题，强调在基于视觉的手势识别研究中，特别是对于需要识别未见个体手势的应用（如无人机-人交互），主体独立数据划分的重要性。

Method: 通过分析已发布的混淆矩阵、学习曲线和数据集构建过程，展示评估协议中帧级随机训练-测试分割如何不可避免地混合来自相同主体的样本，导致严重的数据泄露问题。

Result: 研究发现报告的近乎完美的准确率指标源于评估协议中的帧级随机训练-测试分割，该分割将同一主体的样本混合在训练集和测试集中，导致评估无法衡量对未见个体的泛化能力。

Conclusion: 该研究强调了在基于视觉的手势识别研究中主体独立数据划分的重要性，特别是在需要可靠识别未见个体手势的应用中，必须避免数据泄露以确保评估结果的有效性。

Abstract: This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.

</details>


### [7] [Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.17869)
*Yuxiao Chen,Jue Wang,Zhikang Zhang,Jingru Yi,Xu Zhang,Yang Zou,Zhaowei Cai,Jianbo Yuan,Xinyu Li,Hao Yang,Davide Modolo*

Main category: cs.CV

TL;DR: 提出一种用于长视频理解的新型端到端框架，包含基于信息密度的自适应视频采样器和基于自动编码器的时空视频压缩器，结合多模态大语言模型，有效处理长视频的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 随着视频骨干架构的进步和大语言模型的成功，分析长达数十分钟的长视频变得可行且普遍。然而，视频序列固有的冗余性给现有最先进模型带来了挑战：1) 在内存限制内高效处理更多帧；2) 从大量输入数据中提取判别性信息。

Method: 提出端到端的长视频理解框架，包含两个核心组件：1) 基于信息密度的自适应视频采样器(AVS)，根据视频内容重要性自适应采样；2) 基于自动编码器的时空视频压缩器(SVC)，与多模态大语言模型(MLLM)集成，实现高压缩率同时保留关键信息。

Result: 该框架在多个基准测试中表现出色，在长视频理解任务和标准视频理解基准上都取得了优异性能，证明了其在处理长时间视频序列复杂性方面的有效性和多功能性。

Conclusion: 提出的方法能够自适应地捕捉不同时长视频序列中的关键信息，实现高压缩率同时保留判别性信息，为解决长视频理解中的冗余问题提供了有效解决方案。

Abstract: With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.

</details>


### [8] [Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models](https://arxiv.org/abs/2602.17871)
*Dhruba Ghosh,Yuhui Zhang,Ludwig Schmidt*

Main category: cs.CV

TL;DR: 研究发现当前视觉语言模型在细粒度图像分类任务上表现不佳，通过实验发现更好的视觉编码器和预训练阶段对提升细粒度分类性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多种视觉问答基准测试中取得了显著进展，但在传统的细粒度图像分类任务上表现落后。本研究旨在探索视觉语言模型在细粒度视觉知识与通用视觉基准测试之间的性能差异及其原因。

Method: 对大量最新的视觉语言模型在细粒度分类基准上进行测试，通过一系列消融实验分析影响性能的因素，包括不同LLM、视觉编码器以及预训练阶段的影响。

Result: 研究发现：1）使用更好的LLM能同等提升所有基准测试分数；2）更好的视觉编码器能显著提升细粒度分类性能；3）预训练阶段对细粒度性能至关重要，特别是在语言模型权重未冻结的情况下。

Conclusion: 这些发现为增强视觉语言模型的细粒度视觉理解和视觉中心能力提供了重要见解，指出了改进视觉编码器和优化预训练策略的重要性。

Abstract: Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.

</details>


### [9] [A Single Image and Multimodality Is All You Need for Novel View Synthesis](https://arxiv.org/abs/2602.17909)
*Amirhosein Javadi,Chi-Shiang Gau,Konstantinos D. Polyzos,Tara Javidi*

Main category: cs.CV

TL;DR: 该论文提出了一种利用稀疏多模态测距数据（如雷达或激光雷达）改进基于扩散模型的新视角合成方法，通过高斯过程在角度域重建稠密深度图，显著提升了单图像新视角合成的几何一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的新视角合成方法依赖于单目深度估计的几何信息，但在低纹理、恶劣天气和遮挡严重的真实场景中，深度估计的可靠性有限，导致合成视图的质量和一致性受到限制。

Method: 提出多模态深度重建框架，利用极稀疏的测距传感数据（如汽车雷达或激光雷达），通过局部化高斯过程在角度域建模深度，实现计算高效推理并显式量化观测有限区域的不确定性。重建的深度和不确定性可直接替换现有扩散渲染流程中的单目深度估计器。

Result: 在真实世界多模态驾驶场景实验中，用稀疏测距重建深度替换纯视觉深度，显著提升了单图像新视角视频生成的几何一致性和视觉质量。

Conclusion: 可靠的几何先验对基于扩散的视角合成至关重要，即使极端稀疏的多模态传感也能带来实际效益，稀疏测距数据能有效克服纯视觉深度估计的局限性。

Abstract: Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.

</details>


### [10] [ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging](https://arxiv.org/abs/2602.17929)
*Athanasios Angelakis*

Main category: cs.CV

TL;DR: ZACH-ViT是一种紧凑的视觉Transformer，移除了位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性，在医学图像分类任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统视觉Transformer依赖位置嵌入和类别标记，这些固定的空间先验在医学图像中可能阻碍泛化能力，因为医学图像的空间布局信息较弱或不一致。

Method: 提出ZACH-ViT，移除位置嵌入和[CLS]标记，通过全局平均池化聚合补丁表示实现排列不变性，使用自适应残差投影保持训练稳定性。

Result: 在7个MedMNIST数据集上评估，ZACH-ViT（0.25M参数）在BloodMNIST上表现最佳，在PathMNIST上与TransMIL竞争，在具有强解剖先验的数据集上优势减弱。

Conclusion: 将架构归纳偏置与数据结构对齐比追求通用基准优势更重要，ZACH-ViT在资源受限的临床环境中具有部署潜力。

Abstract: Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term "Zero-token" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.
  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.

</details>


### [11] [ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models](https://arxiv.org/abs/2602.17951)
*Guoheng Sun,Tingting Du,Kaixi Feng,Chenxiang Luo,Xingguo Ding,Zheyu Shen,Ziyao Wang,Yexiao He,Ang Li*

Main category: cs.CV

TL;DR: ROCKET提出了一种残差导向的多层表示对齐框架，通过共享投影器和层不变映射，将VLA模型的多个层与3D视觉基础模型的多个层对齐，显著提升3D空间理解能力，同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action (VLA)模型通常在2D数据上预训练，缺乏3D空间理解能力。虽然表示对齐方法使用强大的视觉基础模型指导2D VLA模型，但现有方法通常只在单层应用监督，未能充分利用深度分布中的丰富信息，而简单的多层对齐可能导致梯度干扰。

Method: ROCKET采用残差导向的多层表示对齐框架，将多层对齐表述为将一个残差流与另一个残差流对齐。具体包括：1) 使用共享投影器通过层不变映射将VLA骨干的多个层与强大的3D视觉基础模型的多个层对齐；2) 提出Matryoshka风格的稀疏激活方案来平衡多个对齐损失；3) 结合无需训练的分层选择策略。

Result: 实验表明，ROCKET仅需约4%的计算预算，在LIBERO上达到98.5%的最先进成功率。在LIBERO-Plus和RoboTwin等多个数据集上，以及多个VLA模型上都表现出优越性能。

Conclusion: ROCKET通过残差导向的多层表示对齐框架，有效解决了现有VLA模型缺乏3D空间理解的问题，在显著降低计算成本的同时实现了优异的性能，为机器人操作任务提供了高效的解决方案。

Abstract: Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.

</details>


### [12] [Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching](https://arxiv.org/abs/2602.18000)
*Xuting Lan,Mingliang Zhou,Xuekai Wei,Jielu Yan,Yueting Huang,Huayan Pu,Jun Luo,Weijia Jia*

Main category: cs.CV

TL;DR: 提出了一种基于记忆驱动的质量感知框架（MQAF），通过建立存储失真模式的记忆库，动态切换双模式质量评估策略，减少对高质量参考图像的依赖，同时适应无参考和全参考图像质量评估任务。


<details>
  <summary>Details</summary>
Motivation: 现有全参考图像质量评估方法依赖参考图像质量，限制了在实际应用中理想参考源不可用的情况。受人类视觉系统能够积累视觉记忆的启发，希望开发一种减少对高质量参考图像依赖的评估框架。

Method: 提出记忆驱动的质量感知框架（MQAF），建立存储失真模式的记忆库，动态切换双模式质量评估策略：有参考图像时，通过自适应加权参考信息并与记忆库中的失真模式比较获得质量分数；无参考图像时，依赖记忆库中的失真模式推断图像质量。

Result: 实验结果表明，该方法在多个数据集上优于现有最先进方法，同时能够适应无参考和全参考两种任务。

Conclusion: 提出的记忆驱动框架通过模拟人类视觉记忆机制，有效减少了对高质量参考图像的依赖，在图像质量评估任务中表现出优越性能，为实际应用提供了更灵活的解决方案。

Abstract: Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.

</details>


### [13] [MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method](https://arxiv.org/abs/2602.18006)
*Ahsan Baidar Bakht,Mohamad Alansari,Muhayy Ud Din,Muzammal Naseer,Sajid Javed,Irfan Hussain,Jiri Matas,Arif Mahmood*

Main category: cs.CV

TL;DR: 论文提出了首个伪多模态水下目标跟踪基准MUOT_3M（包含300万帧数据）和基于SAM的多模态到单模态跟踪器MUTrack，通过知识蒸馏将多模态知识转移到单模态学生模型中，在五个UOT基准测试中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 水下目标跟踪对海洋机器人、生态监测和海洋探索至关重要，但现有基准数据集规模小且仅包含RGB模态，限制了在颜色失真、浑浊和低能见度条件下的鲁棒性。缺乏大规模、多模态、多样化的数据集阻碍了该领域的发展。

Method: 1. 构建MUOT_3M基准：包含3030个视频的300万帧数据，标注32个跟踪属性、677个细粒度类别，以及同步的RGB、估计增强RGB、估计深度和语言模态；2. 提出MUTrack跟踪器：基于SAM架构，采用视觉几何对齐、视觉语言融合和四级知识蒸馏，将多模态知识转移到单模态学生模型中。

Result: MUTrack在五个水下目标跟踪基准测试中，相比最强的SOTA基线方法，AUC提升高达8.40%，精度提升高达7.80%，同时以24 FPS的速度运行。MUOT_3M和MUTrack为可扩展、多模态训练但实际可部署的水下跟踪建立了新基础。

Conclusion: 该研究通过构建大规模多模态基准MUOT_3M和提出高效的MUTrack跟踪器，解决了水下目标跟踪领域的数据稀缺和模态限制问题，为实际部署提供了既具有多模态训练优势又保持单模态部署效率的解决方案。

Abstract: Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.

</details>


### [14] [Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating](https://arxiv.org/abs/2602.18016)
*Jiamin Luo,Xuqian Gu,Jingjing Wang,Jiahong Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型的LLM中心情感视觉定制任务，通过高效的情感语义转换和精确的情感无关内容保留，实现对图像主观情感的编辑。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定制研究主要关注客观对齐（如语言、布局等控制信号与编辑图像的匹配），但忽视了主观情感内容，且缺乏通用的情感视觉定制基础模型。

Method: 提出高效精确情感操纵方法，包含两个核心模块：1）高效情感间转换模块，使LLM在编辑前后高效对齐情感语义转换；2）精确情感外保留模块，精确保留情感无关内容。

Result: 在构建的L-AVC数据集上的综合实验评估表明，所提出的EPEM方法在L-AVC任务上优于多个最先进的基线方法。

Conclusion: 情感信息对L-AVC任务至关重要，EPEM方法能够高效精确地操纵这些信息，验证了情感视觉定制的可行性和有效性。

Abstract: Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

</details>


### [15] [DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE](https://arxiv.org/abs/2602.18019)
*Yujie Jin,Wenxin Zhang,Jingjing Wang,Guodong Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种新的深度安全导向视频理解任务DeepSVU，不仅要检测威胁还要分析威胁原因，并提出了UPRM方法来解决该任务中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有安全导向视频理解研究主要关注检测和定位威胁（如枪击、抢劫），但缺乏生成和评估威胁原因的有效能力。为填补这一空白，本文提出了新的深度安全导向视频理解任务DeepSVU。

Method: 提出了统一物理世界正则化混合专家（UPRM）方法，包含两个关键组件：统一物理世界增强MoE块（UPE）用于建模粗到细的物理世界信息，物理世界权衡正则器（PTR）用于自适应权衡这些因素。

Result: 在DeepSVU指令数据集（UCF-C指令和CUVA指令）上的大量实验表明，UPRM优于多个先进的视频LLM和非VLM方法，证明了粗到细物理世界信息的重要性以及UPRM在捕捉此类信息方面的有效性。

Conclusion: DeepSVU任务需要同时识别定位威胁并分析威胁原因，UPRM方法通过建模物理世界信息和自适应权衡机制有效解决了该任务的关键挑战，为安全导向视频理解提供了新的研究方向。

Abstract: In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.

</details>


### [16] [UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models](https://arxiv.org/abs/2602.18020)
*Jiabing Yang,Yixiang Chen,Yuan Xu,Peiyan Li,Xiangnan Wu,Zichen Wen,Bowen Fang,Tao Yu,Zhengbo Zhang,Yingda Li,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: 提出UAOR（不确定性感知观测重注入）模块，这是一种无需训练、即插即用的VLA模型增强方法，通过不确定性测量在推理时动态重注入观测信息，提升动作生成的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常需要额外的观测线索（如深度图、点云）或辅助模块（如物体检测器）来提升任务执行精度，但这些方法需要昂贵的数据收集和额外训练。作者希望开发一种无需额外训练、即插即用的方法来增强VLA模型的性能。

Method: 提出UAOR模块，当语言模型层表现出高不确定性（通过动作熵测量）时，通过注意力检索将关键观测信息重新注入到下一层的FFN中。该方法基于语言模型中FFN作为"键值记忆"的发现，在推理过程中动态增强模型对观测的关注。

Result: 综合实验表明，该方法能持续提升多种VLA模型在仿真和真实世界任务中的性能，且开销极小。UAOR无需额外观测线索或模块，可作为现有VLA管道的通用实用插件。

Conclusion: UAOR是一种有效、无需训练、即插即用的VLA模型增强模块，通过不确定性感知的观测重注入机制，帮助VLA模型在推理时更好地关注观测信息，实现更自信和忠实的行为生成。

Abstract: Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as "key-value memory", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.

</details>


### [17] [Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers](https://arxiv.org/abs/2602.18022)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: 本文提出DCAG框架，通过同时操控DiT中注意力机制的Key和Value通道，实现无需训练的图像编辑强度控制，相比仅操控Key的方法在编辑保真度上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于DiT架构的扩散图像编辑模型缺乏无需训练的编辑强度控制方法。当前注意力操控方法仅关注Key空间来调节注意力路由，而完全忽略了控制特征聚合的Value空间。

Method: 提出Dual-Channel Attention Guidance (DCAG)框架，基于观察到DiT多模态注意力层中Key和Value投影都表现出明显的偏置-增量结构。该框架同时操控Key通道（控制注意力位置）和Value通道（控制特征聚合），形成二维参数空间(δ_k, δ_v)实现更精确的编辑-保真度权衡。

Result: 在PIE-Bench基准测试（700张图像，10个编辑类别）上，DCAG在所有保真度指标上都优于仅操控Key的方法，特别是在对象删除（LPIPS降低4.9%）和对象添加（LPIPS降低3.2%）等局部化编辑任务中提升最显著。

Conclusion: DCAG通过同时操控注意力机制的Key和Value通道，实现了更精确的编辑控制，为基于DiT的图像编辑模型提供了无需训练的编辑强度调节方法，在编辑保真度方面取得了显著改进。

Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).

</details>


### [18] [Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition](https://arxiv.org/abs/2602.18043)
*Hongyu Qu,Xiangbo Shu,Rui Yan,Hailiang Gao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: DiST提出了一种基于分解-融合框架的少样本动作识别方法，利用大语言模型提供的解耦时空知识来学习多粒度原型，在五个标准数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的少样本动作识别方法通常使用语义粗糙的类别名称作为辅助上下文来指导视觉特征学习，但动作名称提供的上下文过于有限，无法为捕捉动作中的新颖时空概念提供足够的背景知识。

Method: 提出DiST框架：1) 分解阶段：将原始动作名称解耦为多样化的时空属性描述；2) 融合阶段：提出空间/时间知识补偿器(SKC/TKC)来发现判别性的对象级和帧级原型。SKC在空间知识指导下自适应聚合重要补丁标记，TKC利用时间属性辅助帧间时间关系建模。

Result: 实验结果表明DiST在五个标准少样本动作识别数据集上取得了最先进的结果。

Conclusion: 通过利用大语言模型提供的解耦时空知识，DiST能够学习表达性强的多粒度原型，有效捕捉细粒度空间细节和多样化时间模式，从而提升少样本动作识别性能。

Abstract: Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.

</details>


### [19] [CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras](https://arxiv.org/abs/2602.18047)
*Rong Fu,Wenxin Zhang,Yibo Meng,Jia Yee Tan,Jiaxuan Lu,Rui Lu,Jiekai Wu,Zhaolu Kang,Simon Fong*

Main category: cs.CV

TL;DR: CityGuard：一种用于分散式监控的隐私保护身份检索框架，通过拓扑感知Transformer处理城市规模行人重识别，在遵守数据保护规则的同时应对视角变化、遮挡和域偏移。


<details>
  <summary>Details</summary>
Motivation: 城市规模的行人重识别面临视角变化、遮挡和域偏移等严重外观变化，同时需要遵守数据保护规则，防止共享原始图像。现有方法难以在隐私保护和识别性能之间取得平衡。

Method: 1. 分散自适应度量学习器根据特征分布调整实例级边界；2. 空间条件注意力将粗略几何信息（如GPS或部署平面图）注入基于图的自注意力；3. 差分隐私嵌入映射与紧凑近似索引结合，支持安全高效部署。

Result: 在Market-1501和其他公共基准测试中，检索精度和查询吞吐量均优于强基线方法，数据库规模检索研究证实了框架在隐私关键城市身份匹配中的实用性。

Conclusion: CityGuard框架能够在严格的差分隐私约束下，实现视角变化、遮挡和域偏移的鲁棒描述符，并在隐私和效用之间提供可调节的平衡，适用于隐私关键的城市身份匹配应用。

Abstract: City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.

</details>


### [20] [Temporal Consistency-Aware Text-to-Motion Generation](https://arxiv.org/abs/2602.18057)
*Hongsong Wang,Wenjing Yan,Qiuxia Lai,Xin Geng*

Main category: cs.CV

TL;DR: TCA-T2M：一种时间一致性感知的文本到动作生成框架，通过跨序列时间对齐和运动约束块解决现有方法中的语义错位和物理不合理问题


<details>
  <summary>Details</summary>
Motivation: 现有两阶段文本到动作生成框架虽然利用离散运动表示取得了进展，但往往忽略了跨序列时间一致性（即同一动作不同实例间共享的时间结构），导致语义错位和物理上不合理的运动

Method: 提出TCA-T2M框架：1）时间一致性感知的空间VQ-VAE（TCaS-VQ-VAE）用于跨序列时间对齐；2）掩码运动变换器用于文本条件运动生成；3）运动学约束块减轻离散化伪影确保物理合理性

Result: 在HumanML3D和KIT-ML基准测试中，TCA-T2M实现了最先进的性能，证明了时间一致性在鲁棒和连贯的文本到动作生成中的重要性

Conclusion: TCA-T2M通过引入时间一致性感知机制和物理约束，显著提升了文本到动作生成的语义对齐和物理合理性，为相关研究提供了新方向

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.

</details>


### [21] [Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation](https://arxiv.org/abs/2602.18066)
*Daniel Busch,Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Richard Meyes,Tobias Meisen*

Main category: cs.CV

TL;DR: 本文提出了一种两阶段训练策略，通过自监督预训练和半监督微调，在减少BEV标注数据使用量的同时提升道路标记分割性能


<details>
  <summary>Details</summary>
Motivation: 当前多摄像头BEV语义地图方法依赖昂贵且标注不一致的BEV地面真值，需要减少对完全监督标注的依赖

Method: 两阶段训练：1) 自监督预训练阶段，将BEVFormer预测可微分地重投影到图像平面，使用Mask2Former生成的多视角语义伪标签进行训练，并加入时序一致性损失；2) 监督微调阶段仅需50%数据集

Result: 在nuScenes数据集上，相比完全监督基线模型提升高达2.5个百分点的mIoU，同时将标注数据使用量减半，总训练时间减少三分之二

Conclusion: 可微分重投影加相机视角伪标签能够产生可迁移的BEV特征，为减少标注的自动驾驶感知提供了一条可扩展的路径

Abstract: Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.

</details>


### [22] [DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text](https://arxiv.org/abs/2602.18089)
*Kunwar Arpit Singh,Ankush Prakash,Haroon R Lone*

Main category: cs.CV

TL;DR: DohaScript是一个大规模、多书写者的手写印地语数据集，包含531位书写者抄写的相同六首传统对句，用于系统分析书写者特定变异，支持手写识别、书写者识别等任务。


<details>
  <summary>Details</summary>
Motivation: 尽管有数亿使用者，但手写天城体文本在公开基准数据集中代表性严重不足。现有资源规模有限，主要关注孤立字符或短词，缺乏受控词汇内容和书写者多样性，无法捕捉天城体手写连续、融合和结构复杂的特性。

Method: 引入DohaScript数据集，收集531位独特贡献者的手写印地语文本。设计为平行风格语料库，所有书写者抄写相同的六首传统印地语对句。包含非识别性人口统计元数据，基于客观清晰度和分辨率标准的严格质量筛选，以及页面级布局难度标注。

Result: 基线实验显示清晰的质量分离和对未见书写者的强泛化能力，突出了数据集的可靠性和实用价值。数据集可作为标准化、可复现的基准，推动低资源脚本环境下连续手写天城体文本的研究。

Conclusion: DohaScript填补了天城体手写文本数据集的空白，通过受控设计支持系统分析书写者变异，为手写识别、书写者识别、风格分析和生成建模等任务提供标准化基准，促进低资源脚本环境下的研究进展。

Abstract: Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.

</details>


### [23] [Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.18093)
*Hanshuai Cui,Zhiqing Tang,Qianli Ma,Zhi Yao,Weijia Jia*

Main category: cs.CV

TL;DR: PrediT：一种无需训练的DiT加速框架，通过线性多步方法预测模型输出，结合校正器和动态步长调制，实现5.54倍延迟降低且质量损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiT）在高保真图像和视频生成中广泛应用，但其迭代去噪过程计算成本高。现有无训练加速方法基于特征缓存和重用，假设时间稳定性，但多步重用可能导致潜在漂移和视觉质量下降。

Method: 提出PrediT框架：1）将特征预测建模为线性多步问题，使用经典线性多步方法从历史信息预测未来模型输出；2）在高动态区域激活校正器防止误差累积；3）通过监测特征变化率动态调整预测步长的调制机制。

Result: 在各种基于DiT的图像和视频生成模型上实现了高达5.54倍的延迟降低，同时质量下降可忽略不计。

Conclusion: PrediT是一种有效的无训练DiT加速框架，通过预测而非简单重用特征，在保持生成保真度的同时显著提升推理效率。

Abstract: Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.

</details>


### [24] [OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2602.18094)
*Ling Lin,Yang Bai,Heng Su,Congcong Zhu,Yaoxing Wang,Yang Zhou,Huazhu Fu,Jingrun Chen*

Main category: cs.CV

TL;DR: OODBench：一个自动化构建的基准测试，用于评估视觉语言模型处理分布外数据的能力，包含4万实例级OOD对，发现现有模型在常见类别上仍表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型通常假设数据独立同分布，但现实场景中分布外数据不可避免，且处理不当可能带来安全风险。目前缺乏全面评估VLM处理OOD数据能力的有效基准。

Method: 提出OODBench方法，采用最小人工验证的自动化方式构建基准测试，包含4万实例级OOD实例-类别对，并提出基于基础到高级渐进提示问题的可靠自动化评估指标。

Result: 当前VLM在OODBench上表现显著下降，即使在基础图像类别常见的情况下；提出的自动化评估指标能更全面地评估OOD数据对不同难度问题的影响。

Conclusion: OODBench为评估VLM处理OOD数据能力提供了有效基准，总结了重要发现和见解，有助于未来OOD数据获取和评估研究。

Abstract: Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.

</details>


### [25] [BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards](https://arxiv.org/abs/2602.18193)
*Yiran Yang,Zhaowei Liu,Yuan Yuan,Yukun Song,Xiong Ma,Yinghao Song,Xiangji Zeng,Lu Sun,Yulu Wang,Hai Zhou,Shuai Cui,Zhaohan Gong,Jiefei Zhang*

Main category: cs.CV

TL;DR: BLM-Guard是一个用于短视频广告内容审核的框架，通过结合思维链推理、规则策略和强化学习奖励，检测多模态广告中的欺骗性内容。


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的多模态广告包含欺骗性的视觉、语音和字幕内容，需要比社区安全过滤器更细粒度、基于策略的审核方法。

Method: 1. 使用规则驱动的ICoT数据合成管道生成结构化场景描述、推理链和标签；2. 强化学习通过平衡因果一致性和策略遵从性的复合奖励来优化模型；3. 多任务架构建模模态内操作（如夸张图像）和跨模态不匹配（如字幕-语音漂移）。

Result: 在真实短视频广告上的实验表明，BLM-Guard在准确性、一致性和泛化能力方面超越了强基线模型。

Conclusion: BLM-Guard框架通过融合思维链推理、规则策略和强化学习奖励，为商业广告内容审核提供了有效的解决方案，能够检测多模态欺骗内容并降低标注成本。

Abstract: Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.

</details>


### [26] [A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion](https://arxiv.org/abs/2602.18199)
*Gahyeon Shim,Soogeun Park,Hyemin Ahn*

Main category: cs.CV

TL;DR: DMC是一个后处理模块，通过自监督数据驱动方法修正文本生成动作中的物理不合理性（如脚部漂浮），同时保持语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法在语义对齐方面进展迅速，但难以同时保证语义一致性和物理合理性（如脚部漂浮、穿透等问题）。

Method: 提出Distortion-aware Motion Calibrator（DMC），一个后处理模块，采用自监督数据驱动方法，学习从故意扭曲的动作和原始文本描述中恢复物理合理的动作。

Result: DMC在多个文本到动作生成模型上显著提升物理合理性：T2M上FID降低42.74%，T2M-GPT上降低13.20%，R-Precision最高；在MoMask上减少33.0%的穿透，并改善脚部漂浮问题。

Conclusion: DMC作为一个通用的后处理框架，能够有效提升任何文本到动作生成模型的物理合理性，同时保持语义一致性，具有广泛应用前景。

Abstract: Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.

</details>


### [27] [On the Adversarial Robustness of Discrete Image Tokenizers](https://arxiv.org/abs/2602.18252)
*Rishika Bhagwatkar,Irina Rish,Nicolas Flammarion,Francesco Croce*

Main category: cs.CV

TL;DR: 本文首次研究了离散图像分词器的对抗攻击脆弱性，提出了高效、应用无关的攻击方法，并设计了无监督对抗训练防御方案，显著提升了分词器在下游任务中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离散图像分词器在多模态系统中日益流行，但其对抗攻击脆弱性尚未被探索。与CLIP编码器不同，这些分词器的安全性问题需要系统研究，以确保多模态基础模型的安全发展。

Method: 1. 首次系统研究离散图像分词器的对抗攻击脆弱性；2. 提出旨在扰动分词器特征提取并改变提取令牌的攻击方法；3. 设计无监督对抗训练防御方案，仅微调分词器而保持其他组件冻结，利用未标记图像提升鲁棒性。

Result: 攻击方法在分类、多模态检索和字幕生成任务中均有效且计算高效；防御方法显著提升了对无监督和端到端监督攻击的鲁棒性，并能良好泛化到未见任务和数据；相比监督对抗训练，该方法更具通用性。

Conclusion: 分词器鲁棒性对下游任务至关重要，本文为开发安全的多模态基础模型迈出了重要一步，提出的无监督对抗训练方法为提升离散分词器安全性提供了有效解决方案。

Abstract: Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.

</details>


### [28] [DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282)
*Shiyan Du,Conghan Yue,Xinyu Cheng,Dongyu Zhang*

Main category: cs.CV

TL;DR: DEIG是一个用于细粒度可控多实例生成的新框架，通过实例细节提取器和细节融合模块解决现有方法在复杂文本描述下的语义理解挑战。


<details>
  <summary>Details</summary>
Motivation: 现有多实例生成方法在空间布局和属性绑定方面已有进步，但在处理复杂文本描述时仍面临细粒度语义理解的挑战，特别是在防止实例间属性泄漏方面存在局限。

Method: 提出DEIG框架，包含两个核心组件：1) 实例细节提取器(IDE)，将文本编码器嵌入转换为紧凑的实例感知表示；2) 细节融合模块(DFM)，应用基于实例的掩码注意力防止实例间属性泄漏。同时构建了包含详细组合实例描述的高质量数据集。

Result: DEIG在多个基准测试中在空间一致性、语义准确性和组合泛化方面持续优于现有方法。此外，DEIG可作为即插即用模块，轻松集成到标准基于扩散的流程中。

Conclusion: DEIG通过创新的实例细节提取和融合机制，实现了对复杂文本描述的细粒度语义理解，显著提升了多实例生成的质量和可控性，为可控图像生成提供了有效的解决方案。

Abstract: Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

</details>


### [29] [Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309)
*Ziyue Liu,Davide Talon,Federico Girella,Zanxi Ruan,Mattia Mondo,Loris Bazzani,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS框架通过多级条件引导将局部草图-文本对与全局草图结构相结合，增强时尚图像生成，在保持全局结构的同时利用局部语义指导。


<details>
  <summary>Details</summary>
Motivation: 设计师在早期时尚构思阶段使用草图表达结构和轮廓，文本描述补充材质、颜色和风格细节。需要一种方法在遵循草图视觉结构的同时，有效结合文本和视觉模态的局部属性指导。

Method: 提出LOTS框架：1) 多级条件阶段：在共享潜在空间中独立编码局部特征，同时保持全局结构协调；2) 扩散对引导阶段：通过注意力引导在扩散模型的多步去噪过程中整合局部和全局条件。创建了首个多文本-草图对时尚数据集Sketchy。

Result: 实验表明该方法增强了全局结构遵循性，同时利用了更丰富的局部语义指导，相比最先进方法有所改进。Sketchy数据集包含高质量专业草图和非专家草图的"野外"分割。

Conclusion: LOTS框架通过结合全局草图引导和多局部草图-文本对，有效提升了时尚图像生成的质量，在保持结构一致性的同时实现了更精细的局部控制。数据集、平台和代码已公开。

Abstract: Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

</details>


### [30] [Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314)
*Tianyi Song,Danail Stoyanov,Evangelos Mazomenos,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: Diff2DGS：用于手术场景实时重建的两阶段框架，结合扩散模型修复遮挡区域，使用2D高斯泼溅和可学习变形模型捕捉组织变形，在图像质量和深度精度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有手术场景重建方法在遮挡区域重建质量有限，且缺乏深度精度评估。EndoNeRF和StereoMIS等基准数据集缺少3D真实数据，导致重建质量评估不全面。

Method: 提出两阶段框架：第一阶段使用基于扩散的视频模块，利用时间先验修复被手术器械遮挡的组织区域；第二阶段采用2D高斯泼溅（2DGS）结合可学习变形模型（LDM）来捕捉动态组织变形和解剖几何结构。

Result: 在EndoNeRF上达到38.02 dB PSNR，在StereoMIS上达到34.40 dB PSNR，均优于现有方法。实验表明仅优化图像质量不一定能获得最佳3D重建精度，因此进一步优化深度质量以确保几何保真度。

Conclusion: Diff2DGS在手术场景重建中实现了高质量的遮挡区域修复和准确的几何重建，为机器人手术提供了更可靠的三维重建解决方案，并强调了深度精度评估的重要性。

Abstract: Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

</details>


### [31] [Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322)
*Ziteng Cui,Shuhong Liu,Xiaoyu Dong,Xuangeng Chu,Lin Gu,Ming-Hsuan Yang,Tatsuya Harada*

Main category: cs.CV

TL;DR: Luminance-GS++：基于3D高斯泼溅的框架，用于在多样化光照条件下实现鲁棒的新视角合成，通过全局自适应亮度调整和局部像素级残差细化解决多视角采集中的光度不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界环境中高质量图像采集面临挑战，复杂光照变化和相机成像管道的固有限制导致多视角采集中出现光度和色彩不一致，这违反了现代3D新视角合成方法（如NeRF和3DGS）所依赖的光度一致性假设，导致重建和渲染质量下降。

Method: 提出Luminance-GS++框架，结合全局视角自适应亮度调整和局部像素级残差细化进行精确色彩校正；设计无监督目标，联合强制亮度校正与多视角几何和光度一致性；保持显式3DGS表示，不修改底层表示。

Result: 在包括低光照、过曝光以及复杂亮度和色彩变化在内的挑战性场景中，实现了最先进的性能；在保持实时渲染效率的同时提高了重建保真度。

Conclusion: Luminance-GS++通过解决多视角采集中的光度不一致问题，在多样化光照条件下实现了鲁棒的新视角合成，同时保持了3D高斯泼溅的显式表示和实时渲染优势。

Abstract: High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

</details>


### [32] [G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329)
*Qingsong Wang,Jiaxing He,Bingzhe Hou,Tieru Wu,Yang Cao,Cailing Yao*

Main category: cs.CV

TL;DR: 提出基于高斯-拉普拉斯算子的双滤过结构G-LoG，用于医学图像拓扑特征提取，在多参数持久性模块中表现优于单参数滤过，性能媲美复杂深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 在拓扑数据分析中，构建实用的滤过结构以检测对象的拓扑和几何特征至关重要。本文旨在利用拉普拉斯高斯算子增强医学图像边界的能力，设计更适合多参数持久性模块的特征提取方法。

Method: 1. 定义G-LoG（高斯-拉普拉斯高斯）双滤过结构；2. 将体积图像建模为有界函数；3. 证明从有界函数双滤过获得的持久性模块的交错距离相对于有界函数的最大范数是稳定的；4. 在MedMNIST数据集上进行实验，与单参数滤过和深度学习基线模型（Google AutoML Vision、ResNet、AutoKeras、auto-sklearn）比较。

Result: 1. G-LoG双滤过显著优于单参数滤过；2. 使用双滤过生成的拓扑特征训练的简单多层感知器（MLP）性能与在原始数据集上训练的复杂深度学习模型相当；3. 证明了持久性模块交错距离的稳定性。

Conclusion: G-LoG双滤过为医学图像分析提供了一种有效的拓扑特征提取方法，在多参数持久性模块中表现优异，能够以简单的机器学习模型实现与复杂深度学习模型相当的性能，为拓扑数据分析在医学图像处理中的应用提供了新思路。

Abstract: Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

</details>


### [33] [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422)
*Linxi Xie,Lisong C. Sun,Ashley Neall,Tong Wu,Shengqu Cai,Gordon Wetzstein*

Main category: cs.CV

TL;DR: 提出了一种基于头部和手部姿态控制的人为中心视频世界模型，用于扩展现实(XR)中的交互式环境生成


<details>
  <summary>Details</summary>
Motivation: 当前视频世界模型只能接受文本或键盘等粗粒度控制信号，无法响应用户在现实世界中的跟踪运动，限制了其在具身交互中的应用

Method: 1) 评估现有扩散变换器条件策略；2) 提出有效的3D头部和手部控制机制；3) 训练双向视频扩散模型教师，并蒸馏为因果交互系统

Result: 通过人类受试者评估显示，该系统相比基线显著提高了任务性能，并显著增强了用户对执行动作的控制感知

Conclusion: 该人中心视频世界模型能够响应跟踪的头部和手部姿态，支持灵巧的手-物交互，为XR中的交互式环境生成提供了有效解决方案

Abstract: Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

</details>


### [34] [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424)
*Xia Su,Ruiqi Chen,Benlin Liu,Jingwei Ma,Zonglin Di,Ranjay Krishna,Jon Froehlich*

Main category: cs.CV

TL;DR: CapNav是一个评估视觉语言模型在考虑智能体物理能力约束下进行室内导航的新基准，定义了5种代表性智能体，包含45个真实室内场景和473个导航任务，发现当前VLM在严格移动约束下性能显著下降


<details>
  <summary>Details</summary>
Motivation: 现实世界导航决策需要考虑智能体的物理移动约束（如扫地机器人不能爬楼梯），但现有视觉语言导航研究缺乏对智能体具体能力条件的评估，需要建立能力条件导航基准来测试VLM在实际约束下的表现

Method: 定义了5种代表性人类和机器人智能体，描述其物理尺寸、移动能力和环境交互能力；构建了45个真实室内场景、473个导航任务和2365个问答对；评估了13个现代VLM模型在能力约束下的导航性能

Result: 当前VLM的导航性能随着移动约束收紧而急剧下降；即使最先进的模型在处理需要空间维度推理的障碍类型时也表现不佳；模型在理解智能体能力与导航决策的关系方面存在显著不足

Conclusion: 需要开发能力感知的导航系统，未来VLM应增强具身空间推理能力；CapNav基准为评估和改进VLM在现实约束下的导航性能提供了重要工具

Abstract: Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

</details>


### [35] [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434)
*Vatsal Agarwal,Saksham Suri,Matthew Gwilliam,Pulkit Kumar,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: MemStream通过扩展token预算、自适应选择策略和无训练检索专家混合，显著提升了流式视频理解性能


<details>
  <summary>Details</summary>
Motivation: 现有流式视频理解方法使用有限的每帧token数量，导致细粒度视觉细节丢失，且在处理密集视频流时存在查询-帧相似度随时间增加的偏差问题

Method: 1) 扩展token预算以支持更细粒度的时空理解；2) 引入自适应选择策略减少token冗余同时保留局部时空信息；3) 提出无训练检索专家混合，利用外部模型更好地识别相关帧

Result: 在CG-Bench上提升+8.0%，LVBench上提升+8.5%，VideoMME (Long)上提升+2.4%，均优于ReKV with Qwen2.5-VL-7B

Conclusion: MemStream通过解决现有方法的token限制和检索偏差问题，显著提升了流式视频问答的性能，为密集视频流理解提供了有效解决方案

Abstract: Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [36] [QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration](https://arxiv.org/abs/2602.17784)
*Meng Ye,Xiao Lin,Georgina Lukoczki,Graham W. Lederer,Yi Yao*

Main category: cs.CL

TL;DR: QueryPlot是一个语义检索和成矿预测框架，通过NLP技术整合地质文本语料库和地质图数据，支持自然语言查询进行矿产地预测。


<details>
  <summary>Details</summary>
Motivation: 传统的矿产地预测需要人工综合异质地质知识，包括文本矿床模型和地理空间数据，这个过程既耗时又依赖专家知识。需要一种自动化方法来整合大规模地质文本和地图数据，提高预测效率。

Method: 1. 整理了120多种矿床类型的描述性模型；2. 将州地质图汇编多边形转换为结构化文本表示；3. 使用预训练嵌入模型编码用户查询和区域描述；4. 计算语义相似度得分来排序和空间可视化区域；5. 支持组合查询，聚合多个相似度派生层进行多标准预测分析。

Result: 在钨矽卡岩矿床案例研究中，基于嵌入的检索实现了已知矿床的高召回率，产生的预测区域与专家定义的许可区域高度一致。相似度得分可作为监督学习管道的额外特征，显著提高分类性能。

Conclusion: QueryPlot成功整合了地质文本和地图数据，通过语义检索实现了高效的矿产地预测。该系统作为基于Web的交互式工具，支持查询、可视化和GIS兼容预测层的导出，为未来研究提供了开源代码和数据集。

Abstract: Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.

</details>


### [37] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 大型语言模型在预测眼动和阅读时间数据方面表现更好，但会低估人类反应概率；大模型对完形填空数据的预测质量更高，因为它们对词汇共现统计不敏感，而更符合人类语义选择


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在预测人类语言处理行为（如眼动和阅读时间）方面的表现差异，探索模型规模如何影响其对人类语言处理模式的预测能力

Method: 通过比较不同规模的语言模型在预测眼动数据、阅读时间数据和完形填空任务中的表现，分析模型规模对预测质量的影响

Result: 大型语言模型在预测眼动和阅读时间数据方面表现更好，但对人类反应概率估计不足；在完形填空任务中，大模型能提供更高质量的下一个词预测，因为它们对词汇共现统计不敏感，而更符合人类语义选择

Conclusion: 大型模型更强的记忆能力帮助它们猜测更语义合适的词语，但使它们对与词汇识别相关的低层次信息不敏感，这支持了模型规模影响语言处理预测能力的观点

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [38] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 研究发现转向向量的可靠性取决于训练激活差异的余弦相似度和正负激活在转向方向上的分离程度，当潜在目标行为表示无法被线性转向方向有效近似时，转向会不可靠。


<details>
  <summary>Details</summary>
Motivation: 转向向量是一种通过在推理时向激活添加学习偏置来控制语言模型行为的轻量级方法，虽然平均效果有效，但转向效果在不同样本间变化很大，对许多目标行为不可靠。本研究旨在探究为什么转向可靠性在不同行为间存在差异，以及转向向量训练数据如何影响可靠性。

Method: 通过分析转向向量的训练数据和效果来研究转向可靠性：1) 测量训练激活差异的余弦相似度与转向可靠性的关系；2) 观察正负激活在转向方向上的分离程度；3) 比较不同提示变体训练的转向向量的方向和性能。

Result: 1) 训练激活差异的余弦相似度越高，转向越可靠；2) 正负激活在转向方向上分离更好的行为数据集转向更可靠；3) 不同提示变体训练的转向向量方向不同但性能相似，在不同数据集上的效果相关。

Conclusion: 转向向量的不可靠性源于潜在目标行为表示无法被线性转向方向有效近似。这些发现为诊断转向不可靠性提供了实用工具，并激励开发更鲁棒的转向方法，需要显式考虑非线性潜在行为表示。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [39] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出一种使用语言模型生成语义软标签目标来改进神经主题模型的方法，通过将下一个词概率投影到预定义词汇表获得上下文丰富的监督信号，显著提升主题质量和文档检索效果。


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型通常通过重构文档的词袋表示进行优化，忽略了上下文信息且难以处理数据稀疏性问题，需要更有效的监督信号来捕捉语义信息。

Method: 使用语言模型通过专用提示词生成下一个词的概率分布，将其投影到预定义词汇表获得语义软标签目标，然后训练主题模型基于语言模型的隐藏状态重构这些软标签。

Result: 在三个数据集上的实验表明，该方法在主题连贯性和纯度方面相比现有基线有显著提升，同时引入的检索指标显示在识别语义相似文档方面明显优于现有方法。

Conclusion: 通过语言模型生成语义软标签目标的方法能够有效提升神经主题模型的质量，产生更符合语料库主题结构的主题，特别适用于检索导向的应用场景。

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [40] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: 提出了首个条件性生物医学问答基准CondMedQA和条件门控推理框架CGR，用于解决医学决策中条件依赖性的建模问题


<details>
  <summary>Details</summary>
Motivation: 现有生物医学问答系统假设医学知识普遍适用，但真实临床推理本质上是条件性的——几乎所有决策都依赖于患者特定因素（如并发症、禁忌症）。现有基准无法评估这种条件推理，检索增强或基于图的方法缺乏确保检索知识适用于给定上下文的明确机制。

Method: 提出了条件门控推理（CGR）框架：1）构建条件感知知识图谱；2）基于查询条件选择性地激活或剪枝推理路径。同时创建了CondMedQA基准，包含多跳问题，其答案随患者条件变化。

Result: CGR在可靠选择条件适当答案方面表现更优，同时在生物医学问答基准上达到或超过最先进性能，突显了显式建模条件性对稳健医学推理的重要性。

Conclusion: 条件性建模对于稳健的医学推理至关重要，CGR框架通过显式处理条件依赖关系，在生物医学问答中实现了更可靠的决策支持。

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [41] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 该论文首次系统比较了基于DSPy优化框架的指令优化方法在表格事实验证任务中的效果，评估了四种提示技术，发现指令优化能持续提升验证准确率，不同优化器对不同提示技术效果各异。


<details>
  <summary>Details</summary>
Motivation: 指令优化为提升大语言模型推理性能提供了一种轻量级、模型无关的方法，但缺乏在表格事实验证任务中的系统性比较研究。

Method: 基于DSPy优化框架，评估四种提示技术（直接预测、思维链、带SQL工具的ReAct、带Python执行的CodeAct），使用三种优化器（COPRO、MiPROv2、SIMBA），在四个基准测试和三个模型家族上进行实验。

Result: 指令优化持续提升验证准确率：MiPROv2对思维链提示效果最稳定，SIMBA对ReAct智能体提升最大（尤其在更大模型规模下）。行为分析显示SIMBA通过启发式方法鼓励更直接的推理路径，提升思维链中的数值比较能力，帮助ReAct智能体避免不必要的工具调用。

Conclusion: 在表格事实检查中，思维链提示仍然有效（尤其对小模型），虽然基于大模型的ReAct智能体能达到竞争性性能，但需要仔细的指令优化。不同优化器对不同提示技术有不同优势。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [42] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: CUICurate是一个基于图检索增强生成(GraphRAG)的框架，用于自动化UMLS概念集构建，结合知识图谱检索和LLM过滤，显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将自由文本映射到UMLS概念唯一标识符(CUIs)，但许多下游任务需要的是包含相关同义词、子类型和超类型的概念集。构建这样的概念集是劳动密集型的，执行不一致，现有工具支持不足。

Method: 构建UMLS知识图谱并进行嵌入以进行语义检索。对于每个目标概念，从知识图谱中检索候选CUIs，然后通过大语言模型(比较GPT-5和GPT-5-mini)进行过滤和分类。在五个词汇异质性临床概念上评估框架。

Result: CUICurate生成的概念集比人工基准更大更完整，同时保持与人类相当的精度。GPT-5-mini在过滤阶段召回率更高，GPT-5的分类结果更接近临床医生判断。输出稳定且计算成本低。

Conclusion: CUICurate提供了一个可扩展且可重复的方法来支持UMLS概念集构建，显著减少人工工作量。通过整合基于图的检索和LLM推理，该框架生成聚焦的候选概念集，可适应不同表型和分析需求的临床NLP流程。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [43] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 该研究针对金融监管文件问答中的检索失败问题，提出了一种针对页面级检索优化的方法，显著提升了页面召回率和块级检索性能。


<details>
  <summary>Details</summary>
Motivation: 在金融监管文件问答中，即使检索到了正确文档，但包含答案的具体页面或块可能被遗漏，导致生成器基于不完整上下文进行推断。这种文档内检索失败模式在实际应用中很重要，但在金融问答文献中缺乏系统研究。

Method: 评估了多粒度检索（文档、页面、块级），引入基于oracle的分析来提供检索和生成性能的实证上限。在FinanceBench的150个问题子集上，比较了密集、稀疏、混合和分层检索策略，并提出了领域微调的页面评分器，将页面作为文档和块之间的中间检索单元，专门针对金融文件微调双编码器进行页面级相关性判断。

Result: 文档发现率的提升通常转化为更强的页面召回率，但oracle性能仍表明页面和块级检索有改进空间。提出的领域微调页面评分器显著改善了页面召回率和块检索性能，利用了页面的语义连贯性。

Conclusion: 针对金融监管文件问答中的文档内检索失败问题，通过引入专门针对页面级检索优化的方法，能够显著提升检索性能，填补了现有金融问答文献中的研究空白。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [44] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: 研究发现，当用户被告知ChatGPT对其所属政党有偏见时，AI对话的说服效果会降低28%，表明AI说服力受政治中立性感知影响


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨精英阶层对LLM的政治偏见指控是否会影响AI对话系统的说服效果。随着大型语言模型进入党派冲突，精英们越来越多地将它们描绘成具有意识形态倾向，这可能影响公众对AI可信度的认知

Method: 采用预注册的美国调查实验（N=2144），参与者与ChatGPT进行三轮对话，讨论个人持有的经济政策误解。实验组收到简短信息表明LLM对参与者所属政党有偏见，对照组为中性信息。通过转录分析评估互动模式变化

Result: 与中性对照组相比，被告知LLM有党派偏见的参与者说服效果降低28%。转录分析显示警告改变了互动模式：受访者更频繁地反驳，接受度更低

Conclusion: 对话AI的说服效果具有政治依赖性，受党派一致性感知的限制。精英对AI的政治偏见指控会显著削弱其纠正公众误解的能力，这对AI在公共信息传播中的应用具有重要意义

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [45] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 本文提出了一种对抗性问答生成框架，通过比较待适配模型与基于参考文档的专家模型的输出，生成紧凑的语义挑战性问题，以更少的合成样本在专业领域实现更高准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域适应能力有限，现有微调方法面临高质量任务相关数据稀缺的问题。传统合成数据生成方法（如转述或知识提取）虽然擅长事实回忆和概念知识，但存在两个关键缺陷：1）对专业领域的解释性推理能力支持不足；2）生成的合成语料库通常过于庞大冗余，导致样本效率低下。

Method: 提出对抗性问答生成框架，通过迭代反馈驱动过程，比较待适配模型与基于参考文档的专家模型的输出，生成紧凑的语义挑战性问题。该方法旨在揭示和解决模型的理解差距，生成高质量、有针对性的训练数据。

Result: 在LegalBench语料库的专业子集上评估，该方法以显著更少的合成样本实现了更高的准确率，证明了其在专业领域适应中的有效性和样本效率。

Conclusion: 对抗性问答生成框架能够有效解决专业领域LLM适应的数据稀缺问题，通过生成紧凑、语义挑战性的问题，在减少数据冗余的同时提升模型在专业领域的解释性推理能力，为专业领域LLM微调提供了更高效的数据生成方法。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [46] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 本文提出了一种基于频率分析的注意力机制检测方法，用于识别大语言模型在上下文生成中的幻觉问题。通过将注意力分布建模为离散信号并提取高频成分，揭示了幻觉token与高频注意力能量之间的关联，并开发了轻量级幻觉检测器。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在基于上下文的生成中容易出现幻觉问题，这严重影响了模型的可靠性。现有方法主要依赖生成过程中的内在信号，其中注意力机制提供了直接观察模型基础行为的方式。然而，现有方法通常使用粗粒度的注意力总结，无法捕捉注意力中的细粒度不稳定性。

Method: 受信号处理启发，本文引入了频率感知的注意力分析视角。将注意力分布建模为离散信号，提取反映注意力快速局部变化的高频成分。分析发现幻觉token与高频注意力能量相关，反映了碎片化和不稳定的基础行为。基于这一洞察，开发了使用高频注意力特征的轻量级幻觉检测器。

Result: 在RAGTruth和HalluRAG基准测试上的实验表明，该方法在模型和任务上均优于基于验证的方法、基于内部表示的方法和基于注意力机制的方法，取得了性能提升。

Conclusion: 通过频率分析视角研究注意力机制，揭示了幻觉与高频注意力能量之间的关联，并开发了有效的幻觉检测方法。该方法为理解大语言模型的生成行为提供了新视角，并为提高模型可靠性提供了实用工具。

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [47] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 通过无损压缩分析发现，大语言模型生成的文本比人类写作具有更高的结构规律性和可压缩性，但在小尺度交互环境中这种差异会减弱


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何通过概率采样改变语言的结构统计组织，以及如何从表面文本区分生成文本与人类写作

Method: 使用无损压缩作为模型无关的统计规律性度量，分析三个渐进复杂的信息生态系统：受控的人机续写、知识基础设施生成（维基百科vsGrokipedia）、完全合成的社交互动环境（Moltbook vs Reddit）

Result: 在受控和中介环境中，LLM生成的语言比人类写作表现出更高的结构规律性和可压缩性；但在碎片化交互环境中，这种分离会减弱，表明在小尺度上表面可区分性存在根本限制

Conclusion: 压缩性为基础的分离为量化生成系统如何重塑文本生产提供了一个简单而稳健的框架，为通信复杂性演变提供了结构视角

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [48] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: FENCE是一个用于金融领域多模态越狱检测的双语数据集，包含韩语和英语的金融相关查询与图像威胁配对，用于训练和评估越狱检测器。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型存在越狱风险，特别是在金融领域，由于处理文本和图像的多模态特性，攻击面更广。目前缺乏专门针对金融领域的越狱检测资源。

Method: 创建FENCE双语多模态数据集，包含金融相关查询与图像威胁配对，强调领域真实性。使用商业和开源VLM进行实验，并训练基线检测器。

Result: 实验显示商业和开源VLM都存在越狱漏洞，GPT-4o有可测量的攻击成功率，开源模型暴露更大。基于FENCE训练的基线检测器在分布内准确率达99%，在外部基准测试中保持强劲性能。

Conclusion: FENCE为金融领域多模态越狱检测提供了专门资源，有助于训练可靠的检测模型，支持敏感领域更安全可靠的AI系统部署。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [49] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 提出一种结合Transformer文本嵌入和语言学特征的混合方法用于点击诱饵检测，最佳模型F1分数达91%，优于传统方法


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低了在线信息质量并损害用户信任，需要有效的检测方法

Method: 混合方法：结合Transformer文本嵌入和15个语言学特征（如第二人称代词、最高级、数字、标点等），使用XGBoost分类器

Result: 最佳模型F1分数91%，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和纯特征基线方法

Conclusion: 提出的特征集增强了可解释性，能突出显示关键语言学线索，实现透明且校准良好的点击诱饵预测，代码和模型已开源

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [50] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 本文提出Info-Gain Sampler，一种用于掩码扩散模型的新解码框架，通过平衡即时不确定性和对未来掩码标记的信息增益，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型解码器通常采用贪婪启发式方法，只关注局部确定性最高的位置，忽略了当前解码选择对后续步骤的下游影响，未能充分利用掩码扩散模型的非因果特性来最小化累积不确定性。

Method: 提出Info-Gain Sampler解码框架，通过评估当前解码决策如何重塑所有剩余掩码位置的标记概率/不确定性，平衡即时不确定性与对未来掩码标记的信息增益。

Result: 在推理、编码、创意写作和图像生成等多样化架构和任务上的评估显示，Info-Gain Sampler始终优于现有掩码扩散模型解码器。推理任务平均准确率提升3.6%，创意写作胜率达63.1%，推理任务累积不确定性从78.4降至48.6。

Conclusion: Info-Gain Sampler通过系统性地考虑当前解码决策对后续步骤的影响，充分利用掩码扩散模型的非因果特性，显著提升了生成质量，为掩码扩散模型解码提供了更优的解决方案。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [51] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 该研究提出了一种基于信息论的句子理解处理存储成本度量方法，通过预训练神经语言模型估计，能够预测阅读时间并解释已知的处理不对称性。


<details>
  <summary>Details</summary>
Motivation: 实时句子理解给工作记忆带来显著负荷，但现有基于符号语法的度量方法采用离散、统一的句法预测成本，需要更连续、理论中立的度量方式来更准确地反映语言处理中的存储成本。

Method: 提出基于信息论的存储成本度量，定义为先前词汇在不确定性条件下对未来上下文所携带的信息量。该方法连续、理论中立，可通过预训练神经语言模型进行估计。

Result: 通过三项英语分析验证了方法的有效性：(1)恢复了中心嵌入和关系从句中已知的处理不对称性；(2)与语法标注语料库中的语法基础存储成本相关；(3)在两个大规模自然数据集上预测阅读时间方差，优于包含传统信息预测因子的基线模型。

Conclusion: 基于信息论的存储成本度量提供了一种连续、理论中立的方法来量化句子理解中的工作记忆负荷，能够有效预测阅读时间并解释已知的心理语言学现象，为语言处理研究提供了新的工具。

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [52] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 提出Confidence-Driven Contrastive Decoding方法，通过检测解码过程中的低置信度token并针对性干预，提高大语言模型推理可靠性，同时减少输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法通常假设增加推理计算能均匀提高正确性，但研究发现推理不确定性高度局部化：少数低置信度token对推理错误和不必要输出扩展贡献不成比例。

Method: 提出Thinking by Subtraction方法，采用置信度驱动的对比解码。检测解码中的低置信度token，构建对比参考（将高置信度token替换为最小占位符），在低置信度位置通过减去参考分布来精炼预测。

Result: 实验表明CCD显著提高数学推理基准测试的准确性，同时大幅减少输出长度，KV缓存开销最小。作为无需训练的方法，通过针对性低置信度干预提高推理可靠性，避免计算冗余。

Conclusion: CCD通过置信度驱动的对比解码，针对性地干预低置信度token，有效提高大语言模型推理可靠性并减少不必要输出，是一种高效的无训练推理增强方法。

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [53] [Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262)
*Aaron Louis Eidt,Nils Feldhus*

Main category: cs.CL

TL;DR: ELIA是一个交互式Web应用，通过整合多种语言模型分析技术并引入AI生成的自然语言解释，降低了机制可解释性工具的使用门槛，使非专家也能理解复杂的LLM内部工作机制。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性领域虽然开发了强大的工具来分析大型语言模型的内部工作原理，但这些工具的复杂性造成了可访问性差距，限制了它们只能被专家使用。需要设计一个系统来简化这些分析结果，让更广泛的受众能够理解和使用。

Method: 设计、构建和评估ELIA交互式Web应用，整合三种关键技术：归因分析、函数向量分析和电路追踪。引入创新方法：使用视觉语言模型自动为这些方法产生的复杂可视化生成自然语言解释。通过混合方法的用户研究实证验证效果。

Result: 用户研究显示，用户明显偏好交互式、可探索的界面而非简单的静态可视化。AI生成的解释帮助非专家弥合了知识差距；统计分析表明用户的先验LLM经验与其理解分数之间没有显著相关性，说明系统降低了不同经验水平用户的认知障碍。

Conclusion: AI系统确实可以简化复杂的模型分析，但其真正潜力在于与深思熟虑、以用户为中心的设计相结合，这种设计优先考虑交互性、特异性和叙事指导，从而解锁系统的全部能力。

Abstract: While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

</details>


### [54] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 创建了首个罗马尼亚语抑郁和焦虑语料库PsihoRo，包含205名受访者的文本数据，填补了罗马尼亚语心理健康NLP资源的空白。


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语目前没有开源的心理健康语料库，而心理健康数据从社交媒体收集存在假设偏差问题，需要更实用的数据收集方法。

Method: 通过包含6个开放式问题的表格收集数据，配合标准化的PHQ-9和GAD-7筛查问卷，使用统计分析、罗马尼亚语LIWC文本分析、情感检测和主题建模等方法。

Result: 成功创建了包含205名受访者文本的PsihoRo语料库，虽然规模较小，但为分析罗马尼亚人口的心理健康文本迈出了第一步。

Conclusion: PsihoRo是首个罗马尼亚语抑郁和焦虑语料库，填补了该语言心理健康NLP资源的空白，为后续研究提供了重要基础。

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [55] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: Vichara是一个针对印度司法系统的框架，能够预测和解释上诉判决，通过将案件文档分解为决策点，并采用IRAC框架生成解释，在多个数据集上超越了现有基准。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，特别是上诉案件，人工智能在司法判决预测方面具有变革潜力，需要开发专门针对印度司法系统的预测和解释框架。

Method: Vichara框架处理英文上诉案件文档，将其分解为包含法律问题、裁决机构、结果、推理和时间背景的决策点，采用基于IRAC框架的结构化解释格式，并使用GPT-4o mini、Llama-3.1-8B等大型语言模型进行评估。

Result: 在PredEx和ILDC_expert数据集上，Vichara超越了现有判决预测基准，GPT-4o mini表现最佳（F1：PredEx 81.5，ILDC_expert 80.3），Llama-3.1-8B次之。人类评估显示GPT-4o mini在清晰度、关联性和实用性方面具有优越的可解释性。

Conclusion: Vichara框架为印度司法系统提供了有效的上诉判决预测和解释能力，通过结构化决策点表示和IRAC框架的适应，实现了准确预测和可解释性，有助于缓解案件积压问题。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [56] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 本文提出了一种双尺度验证框架，用于评估政治立场预测中的主观连续属性，结合点对点和成对人工标注，构建了大规模政治立场知识库。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示需要捕捉主观连续属性（如政治立场），这与广泛接受的成对验证黄金标准存在冲突。需要解决主观连续知识验证的挑战。

Method: 采用双尺度验证框架，结合点对点和成对人工标注。使用22个语言模型构建大规模政治立场预测知识库，包含23,228个论点，来自30场英国政治电视节目辩论。

Result: 点对点评估显示中等的人机一致性（Krippendorff's α=0.578），反映内在主观性；成对验证显示更强的人机排名对齐（最佳模型α=0.86）。

Conclusion: 贡献包括：实用的主观连续知识验证方法；经过验证的结构化论证知识库；证明可以从点对点语言模型预测中提取序数结构，推进传统符号或分类方法不足领域的知识表示能力。

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


### [57] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: RVR是一种多轮检索框架，通过检索-验证-检索的迭代过程最大化答案覆盖率，在QAMPARI数据集上比基线方法至少提升10%相对和3%绝对完整召回率。


<details>
  <summary>Details</summary>
Motivation: 针对需要广泛有效答案的查询，需要全面检索多样化文档以最大化答案覆盖率。

Method: 提出检索-验证-检索（RVR）多轮检索框架：首轮检索器处理原始查询返回候选文档集，验证器识别高质量子集；后续轮次将已验证文档加入查询以发现未覆盖答案。

Result: 在QAMPARI多答案检索数据集上，RVR比基线方法（包括智能搜索方法）至少获得10%相对和3%绝对完整召回率提升；在QUEST和WebQuestionsSP两个域外数据集上也获得一致增益。

Conclusion: RVR展示了利用验证器和适应新推理场景的迭代方法在全面答案召回方面的潜力。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [58] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: 论文提出VIRAASAT数据集和SCoM框架，用于解决LLMs在印度文化多跳推理任务上的不足。VIRAASAT包含3200多个多跳问题，覆盖印度所有地区；SCoM通过知识图谱操作模拟提升推理能力20%。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在需要丰富社会文化知识和多样本地背景的任务上表现不佳，特别是在涉及印度文化的任务中。现有文化基准测试存在三个主要问题：(1) 手工制作，(2) 仅包含测试事实记忆的单跳问题，(3) 扩展成本过高，导致这一缺陷未被充分衡量。

Method: 1. 提出VIRAASAT：半自动多跳方法，生成印度文化特定多跳问答数据集。基于包含700多个专家策划文化工件的知识图谱，涵盖印度文化的13个关键属性，覆盖所有28个邦和8个中央直辖区。2. 提出SCoM框架：适应Chain-of-Manipulation范式，训练模型在内部模拟原子知识图谱操作，可靠地遍历图谱的拓扑结构。

Result: 1. 生成超过3,200个多跳问题，需要链式文化推理。2. 评估当前SOTA LLMs发现关键局限性：在CoT轨迹上微调无法基于和合成低概率事实。3. 监督微调实验显示，SCoM比标准CoT基线提升高达20%。

Conclusion: VIRAASAT数据集和SCoM框架为构建文化感知推理模型奠定了坚实基础，解决了LLMs在文化推理任务上的不足，特别是在需要多跳推理和本地背景的印度文化任务中。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [59] [Exploiting Liquidity Exhaustion Attacks in Intent-Based Cross-Chain Bridges](https://arxiv.org/abs/2602.17805)
*André Augusto,Christof Ferreira Torres,André Vasconcelos,Miguel Correia*

Main category: cs.CR

TL;DR: 该论文分析了基于意图的跨链桥协议中的流动性枯竭攻击风险，通过参数化攻击模拟框架评估了三个主要协议的安全性，发现deBridge在当前参数下易受攻击，Across在所有测试配置中保持稳健，Mayan Swift在压力测试条件下变得脆弱。


<details>
  <summary>Details</summary>
Motivation: 基于意图的跨链桥通过让链下实体（解决者）提供即时流动性改善了用户体验，但引入了新的系统性风险，如解决者流动性集中和延迟结算。需要分析这些协议对流动性枯竭攻击的脆弱性。

Method: 提出了流动性枯竭攻击这一新攻击类别，并开发了基于重放的参数化攻击模拟框架。分析了2025年6月至11月期间三个主要协议（Mayan Swift、Across和deBridge）在9个区块链上的350万笔跨链意图交易，涉及价值92.4亿美元的代币转移。

Result: 1. 对于理性攻击者：deBridge因解决者利润较高而脆弱，210个历史攻击实例平均净收益286.14美元，80.5%的攻击盈利；Across因解决者利润低和流动性高在所有配置中保持稳健；Mayan Swift在正常条件下安全但在压力测试下变得脆弱。
2. 对于拜占庭攻击：可在所有协议上抑制可用性，导致数十个意图失败，解决者利润损失最高达978美元，约每16分钟发生一次。
3. 优化的攻击策略：利用数据模式将攻击成本降低90.5%，降低了流动性枯竭攻击的门槛。

Conclusion: 基于意图的跨链桥协议面临严重的流动性枯竭攻击风险，特别是解决者利润较高的协议。需要改进协议设计以缓解这些系统性风险，确保跨链互操作性的安全性。

Abstract: Intent-based cross-chain bridges have emerged as an alternative to traditional interoperability protocols by allowing off-chain entities (\emph{solvers}) to immediately fulfill users' orders by fronting their own liquidity. While improving user experience, this approach introduces new systemic risks, such as solver liquidity concentration and delayed settlement. In this paper, we propose a new class of attacks called \emph{liquidity exhaustion attacks} and a replay-based parameterized attack simulation framework. We analyze 3.5 million cross-chain intents that moved \$9.24B worth of tokens between June and November 2025 across three major protocols (Mayan Swift, Across, and deBridge), spanning nine blockchains.
  For rational attackers, our results show that protocols with higher solver profitability, such as deBridge, are vulnerable under current parameters: 210 historical attack instances yield a mean net profit of \$286.14, with 80.5\% of attacks profitable. In contrast, Across remains robust in all tested configurations due to low solver margins and very high liquidity, while Mayan Swift is generally secure but becomes vulnerable under stress-test conditions. Under byzantine attacks, we show that it is possible to suppress availability across all protocols, causing dozens of failed intents and solver profit losses of up to \$978 roughly every 16 minutes. Finally, we propose an optimized attack strategy that exploits patterns in the data to reduce attack costs by up to 90.5\% compared to the baseline, lowering the barrier to liquidity exhaustion attacks.

</details>


### [60] [Symfrog-512: High-Capacity Sponge-Based AEAD Cipher (1024-bit State)](https://arxiv.org/abs/2602.17900)
*Victor Duarte Melo*

Main category: cs.CR

TL;DR: 该论文提供了一个完整的AEAD加密方案参考实现，包括确定性测试向量、可复现的基准测试套件和公开的源代码，支持独立验证和重新实现。


<details>
  <summary>Details</summary>
Motivation: 提供完全透明、可验证的密码学实现，促进密码学方案的独立验证、重现性测试和外部密码分析，确保方案的安全性和性能可被社区审查。

Method: 采用海绵结构和双工结构，在理想置换模型下构建AEAD方案，包含完整的领域分离、速率和容量选择、标签生成规范，并提供参考CLI的确切文件格式。

Result: 实现了完整的参考实现，包含确定性测试向量、可复现的基准测试套件，性能数据在文档化的硬件和编译器设置下生成，代码以MIT许可证发布。

Conclusion: 该工作提供了一个透明、可验证的密码学实现框架，鼓励外部密码分析和重现性检查，为密码学方案的评估和采用建立了良好的实践标准。

Abstract: This submission includes a complete reference implementation together with deterministic test vectors and a reproducible benchmark suite. All source code, build instructions, and regression artifacts are publicly available in the project repository, enabling independent verification and reimplementation of the scheme. The AEAD construction is fully specified, including domain separation, rate and capacity choices, tag generation, and the exact file format used by the reference CLI. Reported performance numbers are produced by the built in benchmark tool under documented hardware and compiler settings. All security claims are made strictly within the ideal permutation model following standard sponge and duplex bounds, and no stronger guarantees are asserted for the concrete permutation beyond the documented analysis and empirical behavior. The implementation aims for constant time behavior with respect to secret dependent operations, although no formal side channel proof is provided. The project is released under the MIT license, and external cryptanalysis, feedback, and reproducibility checks are explicitly encouraged.

</details>


### [61] [Distributed Security: From Isolated Properties to Synergistic Trust](https://arxiv.org/abs/2602.18063)
*Minghui Xu*

Main category: cs.CR

TL;DR: 这篇愿景论文回顾了分布式安全40年来的演变，主张从孤立研究单个安全属性转向理解它们的协同组合，提出了五个基础属性，并指出未来研究应关注属性融合带来的新能力。


<details>
  <summary>Details</summary>
Motivation: 分布式安全在过去四十年经历了从容错协议到拜占庭容错架构的显著转变。当前研究前沿已从单个安全属性的研究转向多个属性的协同组合，需要理解这些属性如何相互作用以创建更强大的安全能力。

Method: 论文首先总结了五个基础安全属性：一致性、共识、隐私性、可验证性和可问责性。通过追溯这些属性的理论起源和实践发展，分析它们在不同应用场景中的成熟过程。然后探讨这些属性在交叉融合时产生的协同效应。

Result: 研究发现当前研究前沿在于这些安全属性的交叉融合，它们的组合能够创造出单个属性无法实现的能力。论文识别了四个关键研究挑战：新兴应用驱动的新安全属性发现、属性融合的系统性框架开发、高性能共识层中密码原语计算开销管理，以及后量子时代和人为因素挑战。

Conclusion: 分布式安全的未来不在于改进单个安全属性，而在于理解和利用它们的协同效应，构建一个统一的信任结构。需要系统性地研究属性融合，以应对新兴应用场景和计算环境的挑战。

Abstract: Over the past four decades, distributed security has undergone a remarkable transformation -- from crash-fault tolerant protocols designed for controlled environments to sophisticated Byzantine-resilient architectures operating in open, adversarial settings. This vision paper examines this evolution and argues for a fundamental shift in how we approach distributed security: from studying individual security properties in isolation to understanding their synergistic combinations. We begin by conclude four foundational properties, \textit{agreement, consistency, privacy, verifiability, accountability}. We trace their theoretical origins and practical maturation. We then demonstrate how the frontier of research now lies at the intersection of these properties, where their fusion creates capabilities that neither property could achieve alone. Looking forward, we identify critical research challenges: discovering new security properties driven by emerging applications, developing systematic frameworks for property convergence, managing the computational overhead of cryptographic primitives in high-performance consensus layers, and addressing post-quantum and human-factor challenges. The future of distributed security lies not in improving individual properties, but in understanding and harnessing their synergies to build a singular fabric of trust.

</details>


### [62] [AndroWasm: an Empirical Study on Android Malware Obfuscation through WebAssembly](https://arxiv.org/abs/2602.18082)
*Diego Soi,Silvia Lucia Sanna,Lorenzo Pisu,Leonardo Regano,Giorgio Giacinto*

Main category: cs.CR

TL;DR: 该论文研究WebAssembly作为Android恶意软件隐藏恶意负载的新技术，能够绕过传统静态分析和签名匹配机制，成功规避VirusTotal和MobSF等工业级工具的检测。


<details>
  <summary>Details</summary>
Motivation: 近年来，隐蔽的Android恶意软件采用越来越复杂的技术来绕过自动检测机制并加强手动分析。攻击者通常依赖混淆、反重新打包、隐写术、投毒、规避AI工具以及内存执行等技术来隐藏恶意功能。需要研究新的恶意软件隐藏技术及其检测方法。

Method: 研究WebAssembly作为隐藏恶意负载的新技术，深入分析Android可能采用Wasm模块的执行机制，并提供概念验证来演示攻击模型，展示攻击者如何嵌入和执行恶意例程。

Result: 研究表明Wasm技术能够有效绕过工业级最先进工具（如VirusTotal和MobSF）的IoC检测，证明这是一种有效的恶意软件隐藏和规避检测的新方法。

Conclusion: WebAssembly作为一种新颖的恶意软件隐藏技术，能够成功规避传统静态分析和签名匹配机制，对Android安全构成新的威胁，需要开发新的检测方法来应对这种攻击向量。

Abstract: In recent years, stealthy Android malware has increasingly adopted sophisticated techniques to bypass automatic detection mechanisms and harden manual analysis. Adversaries typically rely on obfuscation, anti-repacking, steganography, poisoning, and evasion techniques to AI-based tools, and in-memory execution to conceal malicious functionality.
  In this paper, we investigate WebAssembly (Wasm) as a novel technique for hiding malicious payloads and evading traditional static analysis and signature-matching mechanisms. While Wasm is typically employed to render specific gaming activities and interact with the native components in web browsers, we provide an in-depth analysis on the mechanisms Android may employ to include Wasm modules in its execution pipeline. Additionally, we provide Proofs-of-Concept to demonstrate a threat model in which an attacker embeds and executes malicious routines, effectively bypassing IoC detection by industrial state-of-the-art tools, like VirusTotal and MobSF.

</details>


### [63] [Many Tools, Few Exploitable Vulnerabilities: A Survey of 246 Static Code Analyzers for Security](https://arxiv.org/abs/2602.18270)
*Kevin Hermann,Sven Peldszus,Thorsten Berger*

Main category: cs.CR

TL;DR: 本文对246个静态安全分析器进行了系统文献综述，发现大多数分析器关注有限的弱点集合，检测的漏洞很少可被利用，且评估使用自定义的小型基准测试，无法进行稳健评估。


<details>
  <summary>Details</summary>
Motivation: 静态安全分析是广泛使用的软件漏洞检测技术，但之前的研究只针对特定弱点或应用领域进行调研，缺乏对整个安全领域的全面概述。

Method: 对246个静态安全分析器进行系统文献综述，从目标漏洞、应用领域、分析技术、评估方法和局限性五个维度进行分析。

Result: 研究发现：1）大多数分析器只关注有限的弱点集合；2）检测的漏洞很少是可被利用的；3）评估通常使用自定义的小型基准测试，无法进行稳健评估。

Conclusion: 静态安全分析领域需要更全面的漏洞覆盖、更关注实际可利用性，以及更大规模、标准化的评估基准来推动技术进步。

Abstract: Static security analysis is a widely used technique for detecting software vulnerabilities across a wide range of weaknesses, application domains, and programming languages. While prior work surveyed static analyzes for specific weaknesses or application domains, no overview of the entire security landscape exists. We present a systematic literature review of 246 static security analyzers concerning their targeted vulnerabilities, application domains, analysis techniques, evaluation methods, and limitations. We observe that most analyzers focus on a limited set of weaknesses, that the vulnerabilities they detect are rarely exploitable, and that evaluations use custom benchmarks that are too small to enable robust assessment.

</details>


### [64] [Detecting PowerShell-based Fileless Cryptojacking Attacks Using Machine Learning](https://arxiv.org/abs/2602.18285)
*Said Varlioglu,Nelly Elsayed,Murat Ozer,Zag ElSayed,John M. Emmert*

Main category: cs.CR

TL;DR: 该研究使用基于抽象语法树(AST)的微调CodeBERT模型检测PowerShell无文件加密劫持脚本，实现了高召回率。


<details>
  <summary>Details</summary>
Motivation: 随着远程代码执行漏洞和高级社会工程技术的出现，威胁行为者开始进行广泛的无文件加密劫持攻击。这些攻击基于PowerShell在Windows环境中具有隐蔽性，即使恶意脚本被移除，进程仍可能在受害者端点上运行，给检测机制带来重大挑战。

Method: 使用收集的数据集进行实验研究，采用基于抽象语法树(AST)的微调CodeBERT模型来检测PowerShell无文件加密劫持脚本。

Result: 结果显示，基于AST的微调CodeBERT实现了高召回率，证明了AST集成和针对编程语言的微调预训练模型的重要性。

Conclusion: 基于抽象语法树的微调预训练模型是检测PowerShell无文件加密劫持攻击的有效方法，AST集成和模型微调对提高检测性能至关重要。

Abstract: With the emergence of remote code execution (RCE) vulnerabilities in ubiquitous libraries and advanced social engineering techniques, threat actors have started conducting widespread fileless cryptojacking attacks. These attacks have become effective with stealthy techniques based on PowerShell-based exploitation in Windows OS environments. Even if attacks are detected and malicious scripts removed, processes may remain operational on victim endpoints, creating a significant challenge for detection mechanisms. In this paper, we conducted an experimental study with a collected dataset on detecting PowerShell-based fileless cryptojacking scripts. The results showed that Abstract Syntax Tree (AST)-based fine-tuned CodeBERT achieved a high recall rate, proving the importance of the use of AST integration and fine-tuned pre-trained models for programming language.

</details>


### [65] [Trojans in Artificial Intelligence (TrojAI) Final Report](https://arxiv.org/abs/2602.07152)
*Kristopher W. Reese,Taylor Kulp-McDowall,Michael Majurski,Tim Blattner,Derek Juba,Peter Bajcsy,Antonio Cardone,Philippe Dessauw,Alden Dima,Anthony J. Kearsley,Melinda Kleczynski,Joel Vasanth,Walid Keyrouz,Chace Ashcraft,Neil Fendley,Ted Staley,Trevor Stout,Josh Carney,Greg Canal,Will Redman,Aurora Schmidt,Cameron Hickert,William Paul,Jared Markowitz,Nathan Drenkow,David Shriver,Marissa Connor,Keltin Grimes,Marco Christiani,Hayden Moore,Jordan Widjaja,Kasimir Gabert,Uma Balakrishnan,Satyanadh Gundimada,John Jacobellis,Sandya Lakkur,Vitus Leung,Jon Roose,Casey Battaglino,Farinaz Koushanfar,Greg Fields,Xihe Gu,Yaman Jandali,Xinqiao Zhang,Akash Vartak,Tim Oates,Ben Erichson,Michael Mahoney,Rauf Izmailov,Xiangyu Zhang,Guangyu Shen,Siyuan Cheng,Shiqing Ma,XiaoFeng Wang,Haixu Tang,Di Tang,Xiaoyi Chen,Zihao Wang,Rui Zhu,Susmit Jha,Xiao Lin,Manoj Acharya,Wenchao Li,Chao Chen*

Main category: cs.CR

TL;DR: IARPA TrojAI项目旨在应对AI木马威胁，通过多年研究探索威胁本质、开发检测方法并识别未解决挑战，为AI安全领域提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 应对现代人工智能中新兴的AI木马威胁，这些恶意后门可导致系统意外失败或被恶意行为者劫持，需要系统性的研究和应对策略。

Method: 采用权重分析和触发器反演等检测方法，开发全面的测试评估框架，分析检测器性能、灵敏度以及"自然"木马的普遍性。

Result: 项目成功绘制了AI木马威胁的复杂图景，建立了基础检测方法，提供了检测器性能的全面评估，并识别了需要持续关注的未解决挑战。

Conclusion: 报告总结了关键发现和经验教训，提出了推进AI安全研究的建议，强调AI木马威胁需要持续关注和跨领域合作来解决。

Abstract: The Intelligence Advanced Research Projects Activity (IARPA) launched the TrojAI program to confront an emerging vulnerability in modern artificial intelligence: the threat of AI Trojans. These AI trojans are malicious, hidden backdoors intentionally embedded within an AI model that can cause a system to fail in unexpected ways, or allow a malicious actor to hijack the AI model at will. This multi-year initiative helped to map out the complex nature of the threat, pioneered foundational detection methods, and identified unsolved challenges that require ongoing attention by the burgeoning AI security field. This report synthesizes the program's key findings, including methodologies for detection through weight analysis and trigger inversion, as well as approaches for mitigating Trojan risks in deployed models. Comprehensive test and evaluation results highlight detector performance, sensitivity, and the prevalence of "natural" Trojans. The report concludes with lessons learned and recommendations for advancing AI security research.

</details>


### [66] [FeatureBleed: Inferring Private Enriched Attributes From Sparsity-Optimized AI Accelerators](https://arxiv.org/abs/2602.18304)
*Darsh Asher,Farshad Dizani,Joshua Kalyanapu,Rosario Cammarota,Aydin Aysu,Samira Mirbagher Ajorpaz*

Main category: cs.CR

TL;DR: FEATUREBLEED攻击利用AI加速器中的零跳过优化，通过端到端计时推断私有后端检索特征，绕过现有隐私防御，在多种硬件平台和数据集中实现高达98.87%的攻击优势。


<details>
  <summary>Details</summary>
Motivation: 后端增强技术广泛应用于敏感领域（如产品推荐、医疗、金融），这些模型在机密数据上训练并检索私有特征，但这些特征值对API调用者隐藏。现有硬件优化可能破坏数据机密性，需要研究硬件层面的数据窃取攻击。

Method: FEATUREBLEED攻击利用AI加速器中的零跳过优化，通过端到端计时分析推断私有后端检索特征，无需依赖功耗分析、DVFS操作或共享缓存侧信道。攻击在三种硬件后端（Intel AVX、Intel AMX、NVIDIA A100）和三种模型架构（DNN、CNN、混合CNN-MLP）上进行评估。

Result: 攻击在三个数据集（Texas-100X临床记录、OrganAMNIST医学影像、Census-19社会经济数据）上成功，泄漏可泛化到CPU和GPU加速器、数据模态和应用领域，攻击优势高达98.87个百分点。禁用零跳过会增加25%的能耗和100%的性能开销。

Conclusion: 泄漏的根本原因是现代硬件中的稀疏性驱动零跳过。提出了基于填充的防御方法，通过均衡响应到最坏情况执行时间来掩盖计时泄漏，仅带来7.24%的平均性能开销且无额外功耗成本。

Abstract: Backend enrichment is now widely deployed in sensitive domains such as product recommendation pipelines, healthcare, and finance, where models are trained on confidential data and retrieve private features whose values influence inference behavior while remaining hidden from the API caller. This paper presents the first hardware-level backend retrieval data-stealing attack, showing that accelerator optimizations designed for performance can directly undermine data confidentiality and bypass state-of-the-art privacy defenses.
  Our attack, FEATUREBLEED, exploits zero-skipping in AI accelerators to infer private backend-retrieved features solely through end-to-end timing, without relying on power analysis, DVFS manipulation, or shared-cache side channels. We evaluate FEATUREBLEED on three datasets spanning medical and non-medical domains: Texas-100X (clinical records), OrganAMNIST (medical imaging), and Census-19 (socioeconomic data). We further evaluate FEATUREBLEED across three hardware backends (Intel AVX, Intel AMX, and NVIDIA A100) and three model architectures (DNNs, CNNs, and hybrid CNN-MLP pipelines), demonstrating that the leakage generalizes across CPU and GPU accelerators, data modalities, and application domains, with an adversarial advantage of up to 98.87 percentage points.
  Finally, we identify the root cause of the leakage as sparsity-driven zero-skipping in modern hardware. We quantify the privacy-performance-power trade-off: disabling zero-skipping increases Intel AMX per-operation energy by up to 25 percent and incurs 100 percent performance overhead. We propose a padding-based defense that masks timing leakage by equalizing responses to the worst-case execution time, achieving protection with only 7.24 percent average performance overhead and no additional power cost.

</details>


### [67] [Drawing the LINE: Cryptographic Analysis and Security Improvements for the LINE E2EE Protocol](https://arxiv.org/abs/2602.18370)
*Benjamin Dowling,Prosanta Gope,Mehr U Nisa,Bhagya Wimalasiri*

Main category: cs.CR

TL;DR: 对LINEv2消息协议的首个可证明安全性分析，发现其缺乏前向安全性和后妥协安全性，并提出改进方案


<details>
  <summary>Details</summary>
Motivation: LINE作为东亚国家流行的通信平台，拥有数百万活跃用户，理解其安全保证至关重要。目前缺乏对LINEv2协议的可证明安全性分析。

Method: 通过修改多阶段密钥交换（MSKE）模型来捕获LINE消息协议的架构和安全性，在对抗条件下分析密码协议。然后提出增强版的LINE协议，引入前向安全性和后妥协安全性。

Result: LINEv2实现了基本的密钥不可区分性和消息认证等安全属性，但缺乏前向安全性和后妥协安全性。提出的增强版协议成功引入了这些安全特性。

Conclusion: LINEv2协议存在安全缺陷，特别是缺乏前向安全性和后妥协安全性。通过提出的增强方案可以弥补这些缺陷，提升LINE协议的整体安全性。

Abstract: LINE has emerged as one of the most popular communication platforms in many East Asian countries, including Thailand and Japan, with millions of active users. Therefore, it is essential to understand its security guarantees. In this work, we present the first provable security analysis of the LINE version two (LINEv2) messaging protocol, focusing on its cryptographic guarantees in a real-world setting. We capture the architecture and security of the LINE messaging protocol by modifying the Multi-Stage Key Exchange (MSKE) model, a framework for analysing cryptographic protocols under adversarial conditions. While LINEv2 achieves basic security properties such as key indistinguishability and message authentication, we highlight the lack of forward secrecy (FS) and post-compromise security (PCS). To address this, we introduce a stronger version of the LINE protocol, introducing FS and PCS to LINE, analysing and benchmarking our results.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [68] [Five Fatal Assumptions: Why T-Shirt Sizing Systematically Fails for AI Projects](https://arxiv.org/abs/2602.17734)
*Raja Soundaramourty,Ozkan Kilic,Ramu Chenchaiah*

Main category: cs.SE

TL;DR: 传统T-shirt sizing估算方法在AI项目（特别是LLM和多智能体系统）中会系统性失效，因为AI开发打破了传统软件的五个基本假设，作者提出了更人性化的Checkpoint Sizing方法


<details>
  <summary>Details</summary>
Motivation: 敏捷估算方法（特别是T-shirt sizing）在传统软件开发中简单有效，但在AI项目中会产生系统性误导，因为AI开发具有独特的非线性、不可预测性等特征，需要新的估算方法

Method: 分析传统T-shirt sizing的五个基本假设在AI项目中的失效情况，基于多智能体系统失败、扩展原则和多轮对话不可靠性等研究，提出Checkpoint Sizing方法——一种更人性化、迭代的方法，使用明确的决策门重新评估范围和可行性

Result: 发现AI开发打破了传统软件估算的五个核心假设：1) 线性努力扩展 2) 先前经验的可重复性 3) 努力-时间可替代性 4) 任务可分解性 5) 确定性完成标准。AI项目表现出非线性性能跳跃、复杂交互表面和"紧密耦合"等特征

Conclusion: 需要从传统的T-shirt sizing转向Checkpoint Sizing方法，这种方法更适应AI开发的特性，通过迭代决策门基于开发过程中的实际学习来重新评估项目，而不是依赖初始假设

Abstract: Agile estimation techniques, particularly T-shirt sizing, are widely used in software development for their simplicity and utility in scoping work. However, when we apply these methods to artificial intelligence initiatives -- especially those involving large language models (LLMs) and multi-agent systems -- the results can be systematically misleading. This paper shares an evidence-backed analysis of five foundational assumptions we often make during T-shirt sizing. While these assumptions usually hold true for traditional software, they tend to fail in AI contexts: (1) linear effort scaling, (2) repeatability from prior experience, (3) effort-duration fungibility, (4) task decomposability, and (5) deterministic completion criteria. Drawing on recent research into multi-agent system failures, scaling principles, and the inherent unreliability of multi-turn conversations, we show how AI development breaks these rules. We see this through non-linear performance jumps, complex interaction surfaces, and "tight coupling" where a small change in data cascades through the entire stack. To help teams navigate this, we propose Checkpoint Sizing: a more human-centric, iterative approach that uses explicit decision gates where scope and feasibility are reassessed based on what we learn during development, rather than what we assumed at the start. This paper is intended for engineering managers, technical leads, and product owners responsible for planning and delivering AI initiatives.

</details>


### [69] [Examining LLMs Ability to Summarize Code Through Mutation-Analysis](https://arxiv.org/abs/2602.17838)
*Lara Khatib,Micheal Pu,Bogdan Vasilescu,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 该研究提出了一种基于变异测试的方法来评估LLM生成的代码摘要是否准确反映程序的实际行为，发现随着代码复杂度增加，摘要准确性显著下降，且LLM倾向于描述算法意图而非实际行为。


<details>
  <summary>Details</summary>
Motivation: 随着开发者越来越依赖LLM生成的代码摘要进行文档编写、测试和代码审查，需要研究这些摘要是否准确反映程序的实际行为，因为LLM经常自信地描述代码看起来应该做什么（意图），而忽略定义实际行为的细微边界情况或逻辑变化。

Method: 提出基于变异的评估方法：生成代码摘要，向代码中注入针对性变异，检查LLM是否更新其摘要以反映新行为。通过三个实验验证：1）在12个受控合成程序上进行324个变异测试；2）在50个人工编写的Python程序上进行150个变异测试；3）比较GPT-4和GPT-5.2的性能差异。

Result: 摘要准确性随复杂度急剧下降：单函数76.5%，多线程系统17.3%。在人工编写程序上，摘要准确率为49.3%。GPT-5.2相比GPT-4有显著提升（从49.3%到85.3%），但两种模型都难以区分实现细节与标准算法模式。

Conclusion: 该工作确立了变异分析作为评估LLM生成摘要是否反映程序行为而非表面文本模式的系统方法，揭示了LLM在代码理解方面的局限性，特别是在复杂系统和细微逻辑变化方面。

Abstract: As developers increasingly rely on LLM-generated code summaries for documentation, testing, and review, it is important to study whether these summaries accurately reflect what the program actually does. LLMs often produce confident descriptions of what the code looks like it should do (intent), while missing subtle edge cases or logic changes that define what it actually does (behavior). We present a mutation-based evaluation methodology that directly tests whether a summary truly matches the code's logic. Our approach generates a summary, injects a targeted mutation into the code, and checks if the LLM updates its summary to reflect the new behavior. We validate it through three experiments totalling 624 mutation-summary evaluations across 62 programs. First, on 12 controlled synthetic programs with 324 mutations varying in type (statement, value, decision) and location (beginning, middle, end). We find that summary accuracy decreases sharply with complexity from 76.5% for single functions to 17.3% for multi-threaded systems, while mutation type and location exhibit weaker effects. Second, testing 150 mutated samples on 50 human-written programs from the Less Basic Python Problems (LBPP) dataset confirms the same failure patterns persist as models often describe algorithmic intent rather than actual mutated behavior with a summary accuracy rate of 49.3%. Furthermore, while a comparison between GPT-4 and GPT-5.2 shows a substantial performance leap (from 49.3% to 85.3%) and an improved ability to identify mutations as "bugs", both models continue to struggle with distinguishing implementation details from standard algorithmic patterns. This work establishes mutation analysis as a systematic approach for assessing whether LLM-generated summaries reflect program behavior rather than superficial textual patterns.

</details>


### [70] [Automated LLM-Based Accessibility Remediation: From Conventional Websites to Angular Single-Page Applications](https://arxiv.org/abs/2602.17887)
*Carla Fernández-Navarro,Francisco Chicano*

Main category: cs.SE

TL;DR: 使用大型语言模型自动化修复网页可访问性问题，针对静态网站和Angular单页应用，修复率分别达到80%和86%


<details>
  <summary>Details</summary>
Motivation: 网页可访问性问题普遍存在，现有工具只能检测问题但修复仍需人工完成，过程缓慢且成本高昂。特别是对于动态的单页应用，传统静态分析方法已不适用。

Method: 提出一个模块化工作流，利用大型语言模型自动修复可访问性问题。框架直接在静态网页的DOM或SPA的源代码中实施修正，并为图像生成有意义的视觉描述，同时保持应用的设计和稳定性。

Result: 在12个静态网站和6个开源Angular项目上测试，系统修复了公共网站上80%的可访问性问题和Angular应用中86%的问题。

Conclusion: 该工作有助于确保可访问性不再是被推迟的技术债务，而成为日常开发工作流程的自然组成部分，为静态网站和复杂SPA提供了有效的自动化解决方案。

Abstract: Web accessibility remains an unresolved issue for a large part of the web content. There are many tools to detect errors automatically, but fixing those issues is still mostly a manual, slow, and costly process in which it is easy for developers to overlook specific details. The situation becomes even more complex with modern Single-Page Applications (SPAs), whose dynamic nature makes traditional static analysis approaches inadequate. This work proposes a system that aims to address this challenge by using Large Language Models (LLMs) to automate accessibility fixes. The proposal presents a modular workflow applicable to both static websites and complex Angular projects. The framework actively implements corrections within the DOM of static web pages or the source code of SPAs. The system was tested on 12 static websites and 6 open-source Angular projects, fixing 80% of the accessibility issues on public websites and 86% of the issues on Angular applications. Our proposal also generates meaningful visual descriptions for images while preserving the application's design and stability. This work contributes to ensuring that accessibility stops being a technical debt deferred to the future and becomes a natural part of everyday development workflows.

</details>


### [71] [DeCEAT: Decoding Carbon Emissions for AI-driven Software Testing](https://arxiv.org/abs/2602.18012)
*Pragati Kumari,Novarun Deb*

Main category: cs.SE

TL;DR: 该研究提出了DeCEAT框架，专门评估小型语言模型在测试生成中的环境可持续性和性能权衡，发现不同SLM在能源消耗、执行速度、稳定性和准确性方面各有优势，且提示设计对可持续性有重要影响。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在自动化软件测试中的应用日益增多，但现有的可持续性分析几乎完全集中于大型语言模型，小型语言模型在测试生成过程中的能源消耗和碳排放特性尚未得到充分研究，存在研究空白。

Method: 研究提出了DeCEAT框架，使用HumanEval基准测试和基于Anthropic模板的自适应提示变体，在受控条件下系统评估SLM的环境和性能权衡。使用CodeCarbon测量能源消耗和碳排放，使用单元测试覆盖率评估生成测试的质量。

Result: 不同的小型语言模型展现出不同的可持续性优势：一些模型优先考虑较低的能源使用和更快的执行速度，而另一些模型在碳排放约束下保持更高的稳定性或准确性。结果表明SLM驱动的测试生成可持续性是多维度的，且受提示设计的强烈影响。

Conclusion: 该工作为基于SLM的自动化测试生成提供了一个专门的可持续性评估框架，阐明了提示结构和模型选择如何共同影响环境和性能结果，填补了小型语言模型在测试生成可持续性评估方面的研究空白。

Abstract: The increasing use of language models in automated software testing raises concerns about their environmental impact, yet existing sustainability analyses focus almost exclusively on large language models. As a result, the energy and carbon characteristics of small language models (SLMs) during test generation remain largely unexplored. To address this gap, this work introduces the DeCEAT framework, which systematically evaluates the environmental and performance trade-offs of SLMs using the HumanEval benchmark and adaptive prompt variants (based on the Anthropic template). The framework quantifies emission and time-aware behavior under controlled conditions, with CodeCarbon measuring energy consumption and carbon emissions, and unit test coverage assessing the quality of generated tests. Our results show that different SLMs exhibit distinct sustainability strengths: some prioritize lower energy use and faster execution, while others maintain higher stability or accuracy under carbon constraints. These findings demonstrate that sustainability in the generation of SLM-driven tests is multidimensional and strongly shaped by prompt design. This work provides a focused sustainability evaluation framework specifically tailored to automated SLM-based test generation, clarifying how prompt structure and model choice jointly influence environmental and performance outcomes.

</details>


### [72] [Role and Identity Work of Software Engineering Professionals in the Generative AI Era](https://arxiv.org/abs/2602.18190)
*Jorge Melegati*

Main category: cs.SE

TL;DR: 本文探讨生成式AI对软件工程师身份认同的影响，强调不同角色（开发者和测试者）在身份工作上的差异，并提出相关研究议程。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明生成式AI的采用触发了软件专业人员的身份工作（身份形成、适应和拒绝的过程），但这些研究没有考虑不同角色（如开发者和测试者）之间的差异。本文认为角色是定义软件专业人员身份工作的一个重要因素。

Method: 1. 回顾关于不同角色的现有研究；2. 回顾关于如何在软件工程中采用生成式AI的最新研究；3. 提出研究议程，以更好地理解角色如何影响生成式AI采用触发的软件专业人员身份工作；4. 基于此提出支持这种采用的新工具。

Result: 本文提出了一个研究议程，旨在：1. 更好地理解角色如何影响生成式AI采用触发的软件专业人员身份工作；2. 基于这些理解提出支持生成式AI采用的新工具；3. 讨论潜在的实际应用意义。

Conclusion: 角色是理解生成式AI对软件专业人员身份工作影响的关键因素。通过考虑角色差异，可以更有效地支持生成式AI在软件工程中的采用，并开发出更有针对性的工具来帮助不同角色的专业人员适应技术变革。

Abstract: The adoption of Generative AI (GenAI) suggests major changes for software engineering, including technical aspects but also human aspects of the professionals involved. One of these aspects is how individuals perceive themselves regarding their work, i.e., their work identity, and the processes they perform to form, adapt and reject these identities, i.e., identity work. Existent studies provide evidence of such identity work of software professionals triggered by the adoption of GenAI, however they do not consider differences among diverse roles, such as developers and testers. In this paper, we argue the need for considering the role as a factor defining the identity work of software professionals. To support our claim, we review some studies regarding different roles and also recent studies on how to adopt GenAI in software engineering. Then, we propose a research agenda to better understand how the role influences identity work of software professionals triggered by the adoption of GenAI, and, based on that, to propose new artifacts to support this adoption. We also discuss the potential implications for practice of the results to be obtained.

</details>


### [73] [ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation](https://arxiv.org/abs/2602.18306)
*Dongming Jin,Zhi Jin,Zheng Fang,Linyu Li,XiaoTian Yang,Yuanpeng He,Xiaohong Chen*

Main category: cs.SE

TL;DR: 本文提出了ReqElicitGym，一个用于评估对话式需求获取中访谈能力的自动评估环境，包含101个网站需求场景数据集、交互式用户模拟器和任务评估器，通过实验发现当前LLM在挖掘隐性需求方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 随着LLM编码能力的快速提升，基于LLM的自动化软件开发瓶颈已从生成正确代码转向获取用户需求。然而，LLM在对话式需求获取中的访谈能力尚未得到充分探索，现有评估方法依赖少量场景、真实用户交互和主观评分，缺乏系统性和定量比较。

Method: 提出ReqElicitGym评估环境，包含：1）101个网站需求获取场景的数据集，涵盖10种应用类型；2）交互式用户模拟器（oracle user）；3）任务评估器。该环境支持任何自动化对话需求获取方法（如基于LLM的智能体）进行可重复的定量评估。

Result: 对7个代表性LLM进行系统实证研究，结果显示：1）当前LLM在挖掘隐性需求方面能力有限，仅能获取不到一半的用户隐性需求；2）有效的需求获取问题往往出现在对话后期；3）LLM能够获取交互和内容相关的隐性需求，但在风格相关需求方面表现不佳。

Conclusion: ReqElicitGym为自动化对话式需求获取提供了可重复、定量的评估框架，有助于推动该领域的研究和发展。当前LLM在需求获取访谈能力上仍有提升空间，特别是在挖掘风格相关隐性需求方面。

Abstract: With the rapid improvement of LLMs' coding capabilities, the bottleneck of LLM-based automated software development is shifting from generating correct code to eliciting users' requirements. Despite growing interest, the interview competence of LLMs in conversational requirements elicitation remains fully underexplored. Existing evaluations often depend on a few scenarios, real user interaction, and subjective human scoring, which hinders systematic and quantitative comparison. To address these challenges, we propose ReqElicitGym, an interactive and automatic evaluation environment for assessing interview competence in conversational requirements elicitation. Specifically, ReqElicitGym introduces a new evaluation dataset and designs both an interactive oracle user and a task evaluator. The dataset contains 101 website requirements elicitation scenarios spanning 10 application types. Both the oracle user and the task evaluator achieve high agreement with real users and expert judgment. Using our ReqElicitGym, any automated conversational requirements elicitation approach (e.g., LLM-based agents) can be evaluated in a reproducible and quantitative manner through interaction with the environment. Based on our ReqElicitGym, we conduct a systematic empirical study on seven representative LLMs, and the results show that current LLMs still exhibit limited interview competence in uncovering implicit requirements. Particularly, they elicit less than half of the users' implicit requirements, and their effective elicitation questions often emerge in later turns of the dialogue. Besides, we found LLMs can elicit interaction and content implicit requirements, but consistently struggle with style-related requirements. We believe ReqElicitGym will facilitate the evaluation and development of automated conversational requirements elicitation.

</details>


### [74] [VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean](https://arxiv.org/abs/2602.18307)
*Yutong Xin,Qiaochu Chen,Greg Durrett,Işil Dillig*

Main category: cs.SE

TL;DR: VeriSoftBench：一个包含500个Lean 4证明义务的基准测试，专注于软件验证而非数学证明，评估LLM在真实代码库环境中的定理证明能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM定理证明基准主要基于Mathlib数学库，而软件验证证明通常在定义丰富的特定项目代码库中开发，需要评估LLM在真实软件验证环境中的表现

Method: 创建VeriSoftBench基准，包含500个来自开源形式化方法项目的Lean 4证明义务，保留真实的仓库上下文和跨文件依赖关系，评估前沿LLM和专业证明器

Result: 1. 针对Mathlib数学风格调优的证明器在此仓库中心化设置中表现不佳；2. 成功与传递性仓库依赖强相关，依赖闭包大的任务更难解决；3. 提供依赖闭包的精选上下文比暴露完整仓库效果更好，但仍有很大改进空间

Conclusion: 软件验证证明与数学证明在代码库环境上有本质差异，需要专门针对仓库中心化设置的LLM证明方法，VeriSoftBench为这一研究方向提供了评估基准

Abstract: Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.

</details>


### [75] [Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation](https://arxiv.org/abs/2602.18357)
*Wallace Albertini,Marina Condé Araújo,Júlia Condé Araújo,Antonio Pedro Santos Alves,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文提出并评估了统计功能正确性置信度方法，通过连接业务需求与统计置信度，为AI系统功能正确性评估提供实用统计方法。


<details>
  <summary>Details</summary>
Motivation: AI系统的质量评估面临固有挑战，现有标准如ISO/IEC 25059提供了质量模型，但缺乏实用且统计稳健的功能正确性评估方法。

Method: 提出SCFC方法，包含四个步骤：定义定量规格限、执行分层概率抽样、应用自助法估计性能指标置信区间、计算能力指数作为最终指标。

Result: 通过两个真实工业AI系统的案例研究，收集了AI专家关于方法实用性、易用性和采用意愿的宝贵见解，证实了方法的可行性。

Conclusion: 该方法是将功能正确性评估操作化的可行且有价值的方式，将评估从点估计转变为统计置信度陈述。

Abstract: The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [76] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 论文提出AI安全问题的根源不是训练缺陷，而是模型错误设定导致的理性行为，需要从操纵奖励转向塑造智能体的主观世界模型。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型和AI智能体在关键领域部署面临行为病理问题（如奉承、幻觉、战略欺骗），传统安全范式将这些视为训练缺陷，缺乏统一理论框架解释其出现和稳定性。

Method: 将经济学中的Berk-Nash理性化理论应用于人工智能，建立理论框架将智能体建模为在错误主观世界模型下优化；通过六个最先进模型家族的实验验证理论预测，生成相图精确映射安全行为的拓扑边界。

Result: 研究表明不安全行为是结构必然性：根据奖励方案，要么作为稳定的错位均衡出现，要么作为振荡循环；战略欺骗作为"锁定"均衡或认知不确定性持续存在；安全是离散相，由智能体的认知先验决定而非奖励大小的连续函数。

Conclusion: 安全问题的根源是模型错误设定而非训练缺陷，需要转向"主观模型工程"——设计智能体的内部信念结构，这是实现稳健对齐的必要条件，标志着从操纵环境奖励转向塑造智能体对现实的解释的范式转变。

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [77] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 该研究探索使用形式化领域本体（OpenMath）通过检索增强生成来提升语言模型在数学推理中的可靠性，发现高质量相关上下文能提升性能，但无关上下文会显著降低性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本限制，在需要可验证推理的高风险专业领域（如数学）中尤为成问题。研究者希望探索形式化领域本体是否能通过检索增强生成来提升语言模型的可靠性。

Method: 使用数学作为概念验证，实现了一个神经符号管道，利用OpenMath本体结合混合检索和交叉编码器重排序技术，将相关定义注入模型提示中。在MATH基准上评估了三个开源模型。

Result: 评估结果显示，当检索质量高时，本体引导的上下文能提升模型性能，但无关上下文会主动降低性能。这突显了神经符号方法的潜力和挑战。

Conclusion: 形式化领域本体在提升语言模型可靠性方面具有潜力，但检索质量至关重要。无关上下文会损害性能，表明神经符号方法需要精心设计的检索机制来确保有效性。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [78] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于编程谜题对决的评估框架，让大语言模型相互挑战创建谜题，通过Elo评分比较模型能力，无需人工创建题目。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工创建难题成本高，且难以确定模型是否真正推理还是见过类似训练数据。需要一种无法被设计饱和的评估范式。

Method: 受16世纪数学决斗启发，设计Token Games框架：模型通过创建编程谜题相互挑战（给定返回布尔值的Python函数，找到使其返回True的输入）。使用配对对决结果计算Elo评分来比较模型。

Result: 评估了10个前沿模型，TTG的排名与Humanity's Last Exam等现有基准高度匹配，且无需人工创建谜题。发现创建好谜题对当前模型仍是极具挑战的任务，这是先前基准未测量的能力。

Conclusion: TTG提出了一种新的推理评估范式，无法被设计饱和，能够同时测试模型的创造力、任务创建能力和问题解决能力，为模型评估开辟了新方向。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [79] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: WorkflowPerturb：一个用于评估工作流评估指标的基准测试，通过向黄金工作流施加受控扰动来研究指标的敏感性和校准度


<details>
  <summary>Details</summary>
Motivation: LLM生成的复杂任务结构化工作流难以自动评估，因为指标分数通常未校准，且分数变化不能直接反映工作流退化的严重程度

Method: 通过向黄金工作流施加三种类型的受控扰动（缺失步骤、压缩步骤、描述变化），每种类型在10%、30%、50%的严重程度下应用，创建包含4,973个黄金工作流和44,757个扰动变体的基准数据集

Result: 基准测试了多个指标家族，使用预期分数轨迹和残差分析其敏感性和校准度，揭示了不同指标家族的系统性差异，支持基于严重程度的工作流评估分数解释

Conclusion: WorkflowPerturb为工作流评估指标提供了受控基准，能够支持严重程度感知的工作流评估分数解释，数据集将在接受后发布

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [80] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 该研究结合离线强化学习和跨具身学习来解决机器人策略预训练中高质量演示数据成本高的问题，通过构建包含16个机器人平台的数据集进行系统分析，发现组合方法在包含大量次优轨迹的数据集上表现优于纯行为克隆，但次优数据比例和机器人类型增加会导致梯度冲突，为此提出了基于形态相似性的分组策略来缓解冲突。


<details>
  <summary>Details</summary>
Motivation: 机器人策略预训练面临高质量演示数据收集成本高昂的问题，需要寻找更高效的数据利用方法来降低对专家数据的依赖，同时适应不同形态的机器人平台。

Method: 结合离线强化学习和跨具身学习，利用专家数据和丰富的次优数据，聚合异构机器人轨迹来获取通用控制先验。构建包含16个不同机器人平台的运动数据集进行系统评估，并引入基于形态相似性的分组策略，通过组梯度更新模型来减少机器人间的梯度冲突。

Result: 实验证实组合方法在包含丰富次优轨迹的数据集上预训练表现优于纯行为克隆。但随着次优数据比例和机器人类型增加，不同形态间的梯度冲突会阻碍学习。提出的静态分组策略能显著减少机器人间冲突，并优于现有的冲突解决方法。

Conclusion: 离线强化学习与跨具身学习的结合为机器人策略预训练提供了有效途径，但需要解决多机器人类型带来的梯度冲突问题。基于形态相似性的分组策略是简单有效的解决方案，为大规模机器人策略学习提供了新思路。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [81] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: 研究发现无监督表示方法即使不包含敏感属性，仍能通过拓扑保持的自组织映射（SOMtime）恢复出年龄、收入等敏感属性的潜在轴，挑战了"通过无知实现公平"的假设。


<details>
  <summary>Details</summary>
Motivation: 挑战"通过无知实现公平"的假设，即认为在训练中排除敏感属性就能获得中立表示。研究表明即使明确排除敏感属性，无监督表示仍能恢复这些属性。

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表示方法），在两个大规模真实数据集（五个国家的世界价值观调查和人口普查收入数据集）上进行实验，与PCA、UMAP、t-SNE和自编码器等方法对比。

Result: SOMtime恢复了与排除的敏感属性对齐的单调排序，Spearman相关性高达0.85，而其他方法通常低于0.23（单个例外达到0.31）。无监督分割SOMtime嵌入会产生人口统计学偏斜的聚类。

Conclusion: "通过无知实现公平"在表示层面对序数敏感属性失效，公平性审计必须扩展到机器学习管道的无监督组件。无监督表示并非中立，即使敏感属性被排除。

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [82] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD：首个在线多智能体强化学习扩散策略框架，通过松弛策略目标最大化联合熵，实现高效探索与协调，在10个任务上达到SOTA性能，样本效率提升2.5-5倍。


<details>
  <summary>Details</summary>
Motivation: 在线多智能体强化学习需要增强策略表达能力以获得更好性能。扩散模型在图像生成和离线设置中表现出卓越的表达能力和多模态表示，但在在线MARL中潜力尚未充分探索。主要障碍是扩散模型的不可处理似然性阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）松弛策略目标最大化缩放联合熵，实现有效探索而不依赖可处理似然性；2）在CTDE范式下使用联合分布价值函数优化分散扩散策略；3）利用可处理的熵增强目标指导扩散策略同时更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上进行广泛评估，OMAD成为新的最先进方法，样本效率显著提高2.5到5倍。

Conclusion: OMAD成功将扩散策略应用于在线多智能体强化学习，通过创新的松弛策略目标和联合分布价值函数优化，解决了扩散模型不可处理似然性带来的探索和协调挑战，实现了卓越的性能和样本效率。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [83] [MultiVer: Zero-Shot Multi-Agent Vulnerability Detection](https://arxiv.org/abs/2602.17875)
*Shreshth Rajan*

Main category: cs.MA

TL;DR: MultiVer是一个零样本多智能体漏洞检测系统，无需微调即可达到最先进的召回率。四智能体集成（安全、正确性、性能、风格）通过联合投票在PyVul上达到82.7%召回率，超过微调GPT-3.5 1.4个百分点，是首个在该基准上超越微调性能的零样本系统。


<details>
  <summary>Details</summary>
Motivation: 在安全应用中，漏报（假阴性）的成本通常比误报（假阳性）更高。现有方法需要大量标注数据进行微调，而零样本方法在保持高召回率方面表现不佳。研究目标是开发一个无需微调就能达到高召回率的漏洞检测系统。

Method: 采用多智能体集成架构，包含四个专门化的智能体：安全智能体、正确性智能体、性能智能体和风格智能体。通过联合投票机制整合各智能体的检测结果，实现零样本漏洞检测，无需对模型进行特定任务的微调。

Result: 在PyVul基准测试中达到82.7%召回率，超过微调GPT-3.5（81.3%）1.4个百分点；在SecurityEval上达到91.7%检测率，与专用系统相当。多智能体集成相比单智能体安全分析提升了17个百分点的召回率，但精度为48.8%（微调基线为63.9%），F1分数为61.4%。

Conclusion: 对于安全应用中漏报成本高于误报的场景，零样本多智能体集成可以在最重要的指标（召回率）上匹配甚至超越微调模型，为无需大量标注数据的漏洞检测提供了有效解决方案。

Abstract: We present MultiVer, a zero-shot multi-agent system for vulnerability detection that achieves state-of-the-art recall without fine-tuning. A four-agent ensemble (security, correctness, performance, style) with union voting achieves 82.7% recall on PyVul, exceeding fine-tuned GPT-3.5 (81.3%) by 1.4 percentage points -- the first zeroshot system to surpass fine-tuned performance on this benchmark. On SecurityEval, the same architecture achieves 91.7% detection rate, matching specialized systems. The recall improvement comes at a precision cost: 48.8% precision versus 63.9% for fine-tuned baselines, yielding 61.4% F1. Ablation experiments isolate component contributions: the multi-agent ensemble adds 17 percentage points recall over single-agent security analysis. These results demonstrate that for security applications where false negatives are costlier than false positives, zero-shot multi-agent ensembles can match and exceed fine-tuned models on the metric that matters most.

</details>


### [84] [Mean-Field Reinforcement Learning without Synchrony](https://arxiv.org/abs/2602.18026)
*Shan Yang*

Main category: cs.MA

TL;DR: 该论文提出了Temporal Mean Field (TMF)框架，将传统基于平均动作的均值场强化学习扩展到异步决策场景，使用种群分布作为统计量，支持从完全同步到纯顺序决策的连续谱。


<details>
  <summary>Details</summary>
Motivation: 传统均值场强化学习(MF-RL)使用平均动作作为统计量，但要求所有智能体在每个时间步都行动。当部分智能体空闲时，平均动作未定义，无法处理异步决策场景。需要一种无论哪些智能体行动都保持定义的统计量。

Method: 构建Temporal Mean Field (TMF)框架，以种群分布μ∈Δ(O)为核心统计量，其维度与N无关且在可交换性下完全决定每个智能体的奖励和转移。框架覆盖从完全同步到纯顺序决策的连续谱，并设计了TMF-PG策略梯度算法。

Result: 证明了TMF均衡的存在性和唯一性，建立了O(1/√N)的有限种群近似界（无论每步有多少智能体行动），证明了TMF-PG算法收敛到唯一均衡。在资源选择游戏和动态排队游戏中的实验表明，TMF-PG在每步1个或所有N个智能体行动时性能几乎相同，近似误差以预测的O(1/√N)速率衰减。

Conclusion: TMF框架成功解决了传统MF-RL无法处理异步决策的问题，通过使用种群分布作为统计量，为从同步到顺序决策的连续谱提供了统一的理论基础，并提供了理论保证和有效的算法实现。

Abstract: Mean-field reinforcement learning (MF-RL) scales multi-agent RL to large populations by reducing each agent's dependence on others to a single summary statistic -- the mean action. However, this reduction requires every agent to act at every time step; when some agents are idle, the mean action is simply undefined. Addressing asynchrony therefore requires a different summary statistic -- one that remains defined regardless of which agents act. The population distribution $μ\in Δ(\mathcal{O})$ -- the fraction of agents at each observation -- satisfies this requirement: its dimension is independent of $N$, and under exchangeability it fully determines each agent's reward and transition. Existing MF-RL theory, however, is built on the mean action and does not extend to $μ$. We therefore construct the Temporal Mean Field (TMF) framework around the population distribution $μ$ from scratch, covering the full spectrum from fully synchronous to purely sequential decision-making within a single theory. We prove existence and uniqueness of TMF equilibria, establish an $O(1/\sqrt{N})$ finite-population approximation bound that holds regardless of how many agents act per step, and prove convergence of a policy gradient algorithm (TMF-PG) to the unique equilibrium. Experiments on a resource selection game and a dynamic queueing game confirm that TMF-PG achieves near-identical performance whether one agent or all $N$ act per step, with approximation error decaying at the predicted $O(1/\sqrt{N})$ rate.

</details>
